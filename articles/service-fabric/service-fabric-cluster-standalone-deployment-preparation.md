---
title: Подготовка автономного развертывания кластера
description: Документация по подготовке среды и созданию конфигурации кластера, с которой следует ознакомиться перед развертыванием кластера, предназначенным для обработки производственной рабочей нагрузки.
ms.topic: conceptual
ms.date: 9/11/2018
ms.openlocfilehash: 18b8b0ce8c0e877bf9dd274596b19f85b1febe12
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98790958"
---
# <a name="plan-and-prepare-your-service-fabric-standalone-cluster-deployment"></a>Планирование и подготовка развертывания изолированного кластера Service Fabric

<a id="preparemachines"></a>Перед созданием кластера выполните следующее.

## <a name="plan-your-cluster-infrastructure"></a>Планирование инфраструктуры кластера
Вы собираетесь создать кластер Service Fabric на принадлежащих вам компьютерах, поэтому вам нужно решить, к каким сбоям должен быть устойчив кластер. Например, нужны ли отдельные линии электропитания или подключения к Интернету для этих компьютеров? Кроме того, следует также учитывать физическую безопасность этих компьютеров. Где находятся компьютеры и кому необходим доступ к ним? После принятия этих решений вы можете логически сопоставить компьютеры с различными доменами сбоя (см. следующий шаг). Планирование инфраструктуры для рабочих кластеров требует больше усилий, чем для тестовых кластеров.

## <a name="determine-the-number-of-fault-domains-and-upgrade-domains"></a>Определение количества доменов сбоя и доменов обновления
[ *Домен сбоя* (демон восстановления)](service-fabric-cluster-resource-manager-cluster-description.md) — это физическая единица сбоя, которая напрямую связана с физической инфраструктурой в центрах обработки данных. Домен сбоя состоит из аппаратных компонентов (компьютеры, коммутаторы, сеть и многое другое), совместно использующих единую точку отказа. Хотя нет однозначного соответствия между доменами сбоя и стойками, грубо говоря, каждую стойку можно считать доменом сбоя.

При указании доменов сбоя в файле ClusterConfig.json можно выбрать имя для каждого из них. Service Fabric поддерживает иерархические домены сбоя, поэтому в них можно отразить имеющуюся топологию инфраструктуры.  Например, допускаются следующие домены сбоя.

* "faultDomain": "fd:/Room1/Rack1/Machine1"
* "faultDomain": "fd:/FD1"
* "faultDomain": "fd:/Room1/Rack1/PDU1/M1"

*Домен обновления* — это логическая единица узлов. Во время обновления под управлением Service Fabric (обновления приложения или кластера) все узлы в домене обновления отключаются, а узлы в других доменах обновления остаются доступными для обслуживания запросов. Обновления встроенного ПО, выполняемые на компьютерах, не связаны с работой доменов обновления, поэтому их необходимо выполнять на компьютерах по очереди.

Проще всего рассматривать эти понятия, считая домен сбоя единицей незапланированного сбоя, а домен обновления — единицей планового обслуживания.

При указании доменов обновления в файле ClusterConfig.json можно выбрать имя для каждого из них. Например, допускаются следующие имена:

* "upgradeDomain": "UD0"
* "upgradeDomain": "UD1A"
* "upgradeDomain": "DomainRed"
* "upgradeDomain": "Blue"

Дополнительные сведения о доменах обновления и доменах сбоя см. в статье [Описание кластера Service Fabric](service-fabric-cluster-resource-manager-cluster-description.md).

Если вы полностью контролируете обслуживание и использование узлов, то есть несете ответственность за обновление и замену компьютеров, кластер должен охватывать не менее трех доменов сбоя, чтобы он поддерживался в рабочей среде. Для кластеров, запущенных в средах (т. е. экземплярах виртуальных машин Amazon Web Services), в которых у вас нет полного контроля над компьютерами, требуется как минимум пять доменов сбоя в кластере. Каждый домен сбоя может содержать один или несколько узлов. Это позволяет предотвратить проблемы, вызванные обновлениями компьютеров, которые в зависимости от их расписания могут влиять на работу приложений и служб в кластерах.

## <a name="determine-the-initial-cluster-size"></a>Определение исходного размера кластера

Как правило, количество узлов в кластере определяется в зависимости от бизнес-требований, т. е. от того, сколько служб и контейнеров будет запущено в кластере и сколько ресурсов требуется для обработки рабочих нагрузок. Для рабочих кластеров рекомендуется наличие по крайней мере пять узлов в кластере, охватывающем пять доменов сбоя. Однако, как описано выше, если имеется полный контроль над узлами и возможность охвата троих доменов сбоя, три узла также должны выполнить задание.

Тестовые кластеры, выполняющие рабочие нагрузки с отслеживанием состояния, должны иметь три узла, тогда как для тестовых кластеров, выполняющих только рабочие нагрузки без отслеживания состояния, требуется только один узел. Важно отметить, что в целях разработки на одном компьютере можно настроить более одного узла. Однако в рабочей среде Service Fabric поддерживает только один узел на физический компьютер или виртуальную машину.

## <a name="prepare-the-machines-that-will-serve-as-nodes"></a>Подготовка компьютеров, которые будут работать в качестве узлов

Ниже приведены рекомендуемые спецификации для компьютеров в кластере Service Fabric.

* Не менее 16 ГБ ОЗУ.
* Наличие не менее 40 ГБ свободного дискового пространства.
* Центральный процессор с 4 ядрами или больше.
* Подключение к защищенной сети или сетям для всех компьютеров.
* Установлена ОС Windows Server (допустимые версии: 2012 R2, 2016, 1709 или 1803). Service Fabric версии 6.4.654.9590 и более поздних версий также поддерживает сервер 2019 и 1809.
* [Платформа .NET Framework 4.5.1 или более поздней версии](https://www.microsoft.com/download/details.aspx?id=40773), полная установка
* [Windows PowerShell 3.0](/powershell/scripting/windows-powershell/install/installing-windows-powershell)
* [Служба RemoteRegistry](/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/cc754820(v=ws.11)) должна быть запущена на всех компьютерах.
* **Диск установки Service Fabric должен быть файловой системой NTFS**
* ***Журналы производительности служб Windows & оповещения* и *журнал событий Windows* должны [быть включены](/previous-versions/windows/it-pro/windows-server-2008-r2-and-2008/cc755249(v=ws.11))**.

> [!IMPORTANT]
> У администратора кластера, который развертывает и настраивает кластер, должны быть [привилегии администратора](https://social.technet.microsoft.com/wiki/contents/articles/13436.windows-server-2012-how-to-add-an-account-to-a-local-administrator-group.aspx) на всех компьютерах. Пакет Service Fabric нельзя установить на контроллере домена.

## <a name="download-the-service-fabric-standalone-package-for-windows-server"></a>Скачивание изолированного пакета Service Fabric для Windows Server
[Скачайте изолированный пакет Service Fabric для Windows Server](https://go.microsoft.com/fwlink/?LinkId=730690) и извлеките его содержимое на компьютер развертывания, который не является частью кластера, или на один из компьютеров, которые будут частью кластера.

## <a name="modify-cluster-configuration"></a>Изменение конфигурации кластера
Чтобы создать изолированный кластер, для него необходимо создать файл конфигурации ClusterConfig.json, описывающий характеристики кластера. Можно создать этот файл на основе шаблонов, доступных по ссылке ниже. <br>
[Конфигурации изолированного кластера](https://github.com/Azure-Samples/service-fabric-dotnet-standalone-cluster-configuration/tree/master/Samples)

Сведения о разделах в этом файле см. в статье [Параметры конфигурации для автономного кластера Windows](service-fabric-cluster-manifest.md).

Откройте один из файлов ClusterConfig.json из скачанного пакета и настройте следующие параметры.

| **Параметр конфигурации** | **Описание** |
| --- | --- |
| **NodeTypes** |Типы узлов позволяют разделить узлы кластера на различные группы. У кластера должен быть по крайней мере один NodeType. Все узлы в группе имеют следующие общие характеристики. <br> **Name** — имя типа узла. <br>**Endpoint ports** — различные именованные конечные точки (порты), связанные с этим типом узла. Вы можете использовать любой номер порта, который не конфликтует с другими компонентами в этом манифесте и не используется другим приложением на компьютере или виртуальной машине. <br> **Placement Properties** — свойства для типа узла, с помощью которых задаются ограничения на размещение системных или своих служб. Эти свойства представляют собой определяемые пользователем пары "ключ-значение", которые содержат дополнительные метаданные для заданного узла. К свойствам узла относится, например, наличие у него жесткого диска или видеоадаптера, количество шпинделей в его жестком диске, число ядер и другие физические качества. <br> **Capacities** — емкость узла определяет имя и величину конкретного ресурса, доступного для использования на определенном узле. Например, для узла может быть определена емкость для метрики MemoryInMb и выделено 2048 МБ памяти, доступной по умолчанию. Емкости используются во время выполнения, чтобы гарантировать, что службы, которым требуется определенный объем ресурсов, будут размещены на узлах, обладающих такими ресурсами.<br>**IsPrimary** — при наличии нескольких определенных типов узлов убедитесь, что только один из них назначен первичным (это свойство имеет значение *true*) и на нем выполняются системные службы. Узлам всех остальных типов необходимо присвоить значение *false*. |
| **Узлы** |Сведения о каждом узле, который является частью кластера (тип узла, имя узла, IP-адрес, домен сбоя и домен обновления узла). В этом разделе необходимо перечислить компьютеры, на основе которых вы хотите создать кластер, и их IP-адреса. <br>  Если использовать одинаковые IP-адреса для всех узлов, будет создан универсальный кластер, который можно использовать для тестирования. Не используйте универсальные кластеры для развертывания рабочих нагрузок в рабочей среде. |

После настройки всех параметров конфигурации кластера в среде эту конфигурацию можно протестировать в среде кластера (шаг 7).

<a id="environmentsetup"></a>

## <a name="environment-setup"></a>Настройка среды

Когда администратор кластера настраивает изолированный кластер Service Fabric, ему необходимо настроить среду, чтобы выполнить приведенные ниже условия. <br>
1. У пользователя, создающего кластер, должны быть привилегии безопасности уровня администратора для всех компьютеров, которые указаны в качестве узлов в файле конфигурации кластера.
2. На компьютере, с которого создается кластер, а также на каждом компьютере узла кластера требуется выполнить следующее.
   * Удалите пакет SDK для Service Fabric.
   * Удалите среду выполнения Service Fabric.
   * Включите службу брандмауэра Windows (mpssvc).
   * Включите службу удаленного управления реестром (remote registry).
   * Включите общий доступ к файлам (SMB).
   * Откройте необходимые порты в соответствии с конфигурацией портов кластера.
   * Откройте необходимые порты для Windows SMB и службы удаленного управления реестром: 135, 137, 138, 139 и 445.
   * Установите сетевые подключения между ними.
3. Ни один из компьютеров узлов кластера не должен быть контроллером домена.
4. Если развертывается безопасный кластер, проверьте, установлены и настроены ли обязательные компоненты системы безопасности в соответствии с конфигурацией.
5. Если компьютеры в составе кластера не имеют доступ к Интернету, задайте в конфигурации кластера следующие параметры:
   * Отключить телеметрию: в разделе *Properties* задайте *"enableTelemetry": false*
   * Отключить автоматическое скачивание версии Fabric & уведомления о том, что приближается окончание поддержки текущей версии кластера: в разделе *Properties* Set *"fabricClusterAutoupgradeEnabled": false*
   * Кроме того, если сетевой доступ к Интернету ограничен доменами алловлистед, указанные ниже домены необходимы для автоматического обновления: go.microsoft.com download.microsoft.com

6. Установите соответствующие исключения при проверке антивирусной программой для Service Fabric:

| **Исключаемые при проверке антивирусной программой каталоги** |
| --- |
| Program Files\Microsoft Service Fabric |
| FabricDataRoot (из конфигурации кластера) |
| FabricLogRoot (из конфигурации кластера) |

| **Исключаемые при проверке антивирусной программой процессы** |
| --- |
| Fabric.exe |
| FabricHost.exe |
| FabricInstallerService.exe |
| FabricSetup.exe |
| FabricDeployer.exe |
| ImageBuilder.exe |
| FabricGateway.exe |
| FabricDCA.exe |
| FabricFAS.exe |
| FabricUOS.exe |
| FabricRM.exe |
| FileStoreService.exe |

## <a name="validate-environment-using-testconfiguration-script"></a>Проверка среды с помощью сценария TestConfiguration
Сценарий TestConfiguration.ps1 можно найти в изолированном пакете. Он используется как анализатор соответствия рекомендациям и позволяет проверить некоторые описанные выше условия. Его следует использовать для проверки работоспособности развертывания кластера в конкретной среде. В случае любого сбоя обратитесь к списку в подразделе [Настройка среды](service-fabric-cluster-standalone-deployment-preparation.md), чтобы устранить неполадки.

Этот сценарий может выполняться на любом компьютере, у которого есть доступ администратора ко всем компьютерам, перечисленным в качестве узлов в файле конфигурации кластера. Компьютер, на котором выполняется этот сценарий, может и не входить в кластер.

```powershell
PS C:\temp\Microsoft.Azure.ServiceFabric.WindowsServer> .\TestConfiguration.ps1 -ClusterConfigFilePath .\ClusterConfig.Unsecure.DevCluster.json
Trace folder already exists. Traces will be written to existing trace folder: C:\temp\Microsoft.Azure.ServiceFabric.WindowsServer\DeploymentTraces
Running Best Practices Analyzer...
Best Practices Analyzer completed successfully.


LocalAdminPrivilege        : True
IsJsonValid                : True
IsCabValid                 : True
RequiredPortsOpen          : True
RemoteRegistryAvailable    : True
FirewallAvailable          : True
RpcCheckPassed             : True
NoConflictingInstallations : True
FabricInstallable          : True
Passed                     : True
```

В настоящее время данный модуль тестирования конфигурации не проверяет конфигурацию безопасности, поэтому ее нужно проверить отдельно.

> [!NOTE]
> Мы постоянно вносим улучшения для повышения надежности модуля. Поэтому, если вы обнаружили сбои в работе модуля TestConfiguration или полагаете, что в нем чего-то не хватает, сообщите нам через [поддерживаемые каналы](./service-fabric-support.md).
>
>

## <a name="next-steps"></a>Дальнейшие действия
* [Создание изолированного кластера под управлением Windows Server](service-fabric-cluster-creation-for-windows-server.md)
