---
title: Аварийное восстановление Service Fabric Azure
description: Azure Service Fabric предлагает возможности для аварийного решения. В этой статье описаны типы сбоев, которые могут возникать, и приведены способы их устранения.
author: masnider
ms.topic: conceptual
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: 8d99b4d1fbf227d850de387b7ca24dcd3fd40646
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98791161"
---
# <a name="disaster-recovery-in-azure-service-fabric"></a>Аварийное восстановление в Azure Service Fabric
Критическая часть обеспечения высокого уровня доступности заключается в том, что службы могут выдерживать все различные типы сбоев. Это особенно важно для незапланированных сбоев и за пределами вашего элемента управления. 

В этой статье описываются некоторые распространенные режимы сбоев, которые могут быть аварийными, если они не моделируются и не управляются надлежащим образом. В нем также обсуждаются меры по устранению и действия, выполняемые в случае аварии. Целью является ограничение или устранение риска простоя или потери данных при сбоях, запланированных или других случаях.

## <a name="avoiding-disaster"></a>Предотвращение аварий
Основная цель Azure Service Fabric — помочь вам моделировать среду и службы таким образом, чтобы распространенные типы сбоев не были катастрофами. 

Как правило, существует два типа сценариев сбоя и сбоя:
- Сбои оборудования или программного обеспечения
- Проблемы с работоспособностью

### <a name="hardware-and-software-faults"></a>Сбои оборудования или программного обеспечения
Сбои оборудования и программного обеспечения — непредсказуемы. Самый простой способ продерживать ошибки — запустить больше копий службы на границах сбоя оборудования или программного обеспечения. 

Например, если служба запущена только на одном компьютере, то сбой этой службы может быть результатом сбоя одной машины. Простой способ избежать этой аварии — убедиться, что служба запущена на нескольких компьютерах. Тестирование также необходимо, чтобы гарантировать, что сбой одного компьютера не нарушит работу работающей службы. Планирование ресурсов гарантирует, что экземпляр для замены можно создать в любом расположении, а снижение емкости не приведет к перегрузке оставшихся служб. 

Этот шаблон работает независимо от того, какой сбой вы пытаетесь предотвратить. Например, если вы беспокоитесь о сбое сети SAN, то выполняется в несколько сетей SAN. Если вы хотите избежать выхода из строя серверов и серверных стоек, используйте несколько серверов и серверных стоек. Если вы беспокоитесь об утере центров обработки данных, ваша служба должна выполняться в нескольких регионах Azure, в нескольких Зоны доступности Azure или в собственных центрах обработки данных. 

Если служба распределена между несколькими физическими экземплярами (машинами, стойками, центрами обработки данных, регионами), вы все равно подпадаетесь на некоторые типы одновременных сбоев. Но один и даже несколько сбоев определенного типа (например, при сбое одной виртуальной машины или сетевого соединения) автоматически обрабатываются, поэтому они больше не являются "аварийными". 

Service Fabric предоставляет механизмы для расширения кластера и обработки невыполненных узлов и служб в обратном виде. Service Fabric также позволяет запускать несколько экземпляров служб, чтобы предотвратить незапланированные сбои в реальных авариях.

Возможны причины, по которым выполнение развертывания, достаточного для того, чтобы охватывать сбои, нецелесообразно. Например, может потребоваться больше аппаратных ресурсов, чем вы готовы платить за относительную вероятность сбоя. При работе с распределенными приложениями дополнительные прыжки или затраты на репликацию состояния на географических расстояниях могут привести к неприемлемой задержке. Этот уровень отличается для каждого приложения. 

В частности, ошибки программного обеспечения могут возникать в службе, которую вы пытаетесь масштабировать. В этом случае больше копий не препятствуют сбою, так как условие сбоя сопоставляется со всеми экземплярами.

### <a name="operational-faults"></a>Проблемы с работоспособностью
Даже если служба располагается во множестве географических регионов с большим количеством избыточных данных, она по-прежнему может столкнуться с катастрофическими событиями. Например, кто-либо может случайно изменить имя DNS для службы или удалить его. 

Например, предположим, что имеется служба Service Fabric с отслеживанием состояния и кто-то случайно ее удалил. Если не существует какого – то другого решения, это служба и все состояния, в которых она была создана. Для этих типов функциональных аварий (ошибок) требуются другие методы устранения рисков и шаги для восстановления, отличные от обычных незапланированных сбоев. 

Наилучшие способы избежать этих типов рабочих ошибок:
- Ограничьте оперативный доступ к среде.
- Строго аудит опасных операций.
- Автоматизация, предотвращение ручного или нестандартного изменения и проверка конкретных изменений в среде перед их выполнением.
- Убедитесь, что разрушающие операции являются "мягкими". Программные операции не вступают в силу немедленно или могут быть отменены в течение временного интервала.

Service Fabric предоставляет механизмы для предотвращения сбоев в работе, таких как предоставление управления доступом [на основе ролей](service-fabric-cluster-security-roles.md) для кластерных операций. Однако для предотвращения большинства таких функциональных сбоев требуются организационные усилия и другие методы. Service Fabric предоставляет механизмы для бесперебойной работы рабочих ошибок, что особенно важно [для резервного копирования и восстановления служб с отслеживанием состояния](service-fabric-backuprestoreservice-quickstart-azurecluster.md).

## <a name="managing-failures"></a>Обработка сбоев
Целью Service Fabric является автоматическое управление сбоями. Но для решения некоторых типов сбоев службы должны иметь дополнительный код. Другие типы сбоев _не_ следует автоматически устранять в целях обеспечения безопасности и непрерывности бизнес-процессов. 

### <a name="handling-single-failures"></a>Обработка единичных сбоев
Единичные компьютеры могут выйти из строя по множеству причин. Иногда это вызвано аппаратным обеспечением оборудования, например источниками питания и сбоями сетевого оборудования. а в других — сбои программного обеспечения. К ним относятся сбои операционной системы и самой службы. Service Fabric автоматически обнаруживает такие типы сбоев, включая случаи, когда компьютер изолирован от других компьютеров из-за сетевых проблем.

Независимо от типа службы выполнение одного экземпляра приводит к простою службы, если по какой-либо причине происходит сбой этой копии. 

Чтобы справиться с одним сбоем, проще всего сделать так, чтобы службы выполнялись на нескольких узлах по умолчанию. Для служб без отслеживания состояния убедитесь, что `InstanceCount` параметр больше 1. Для служб с отслеживанием состояния минимальная рекомендация заключается в том, что `TargetReplicaSetSize` и `MinReplicaSetSize` оба имеют значение 3. Запуск нескольких копий кода службы гарантирует, что служба может автоматически обработать любой единичный отказ. 

### <a name="handling-coordinated-failures"></a>Обработка координированных сбоев
Координированные сбои в кластере могут быть вызваны как запланированными, так и незапланированными сбоями инфраструктуры, а также изменениями или запланированными изменениями программного обеспечения. Service Fabric моделирует зоны инфраструктуры, в которых возникают координированные сбои в качестве *доменов сбоя*. Области, в которых будут возникать согласованные изменения в программном обеспечении, моделируются как *домены обновления*. Дополнительные сведения о доменах сбоя, доменах обновления и топологии кластеров см. [в разделе Описание кластера Service Fabric с помощью Диспетчер ресурсов кластера](service-fabric-cluster-resource-manager-cluster-description.md).

По умолчанию Service Fabric считает домены сбоя и обновления при планировании работы служб. По умолчанию Service Fabric пытается обеспечить работу служб в нескольких доменах сбоя и обновления, чтобы при запланированных или незапланированных изменениях службы оставались доступными. 

Например, предположим, что сбой источника питания приводит к сбою всех компьютеров в стойке. При наличии нескольких копий службы неисправность множества компьютеров в домене сбоя превращается в другой пример одиночного сбоя службы. Именно поэтому Управление доменами сбоя и обновления крайне важно для обеспечения высокой доступности служб. 

При запуске Service Fabric в Azure домены сбоя и домены обновления управляются автоматически. В других средах они могут не быть. При создании собственных кластеров в локальной среде обязательно сопоставьте и планируйте структуру домена сбоя правильно.

Домены обновления полезны для моделирования областей, в которых программное обеспечение будет обновляться одновременно. По этой причине в доменах обновления часто определяются границы, при которых программное обеспечение выводится на плановые обновления. Обновления Service Fabric и ваших служб следуют той же модели. Дополнительные сведения о последовательных обновлениях, доменах обновления и модели исправности Service Fabric, которые помогают предотвратить непредвиденные изменения, влияющие на кластер и службу, см. в следующих статьях:

 - [Обновление приложения](service-fabric-application-upgrade.md)
 - [Учебник по обновлению приложений](service-fabric-application-upgrade-tutorial.md)
 - [Модель исправности Service Fabric](service-fabric-health-introduction.md)

Вы можете визуализировать макет кластера с помощью схемы кластера, предоставленной в [Service Fabric Explorer](service-fabric-visualizing-your-cluster.md):

<center>

![Узлы, распределенные между доменами сбоя в Service Fabric Explorer][sfx-cluster-map]
</center>

> [!NOTE]
> Моделирование областей сбоя, последовательного обновления, выполнение множества экземпляров кода службы и состояния, правила размещения для обеспечения работы служб в доменах сбоя и обновления, а встроенный мониторинг работоспособности — лишь *некоторые* из функций, которые Service Fabric предоставляет для сохранения нормальных проблем в работе и сбоев, связанных с аварийным завершением работы. 
>

### <a name="handling-simultaneous-hardware-or-software-failures"></a>Обработка одновременных сбоев оборудования или программного обеспечения
Мы говорили об отдельных сбоях. Как видите, они просты в использовании для служб с отслеживанием состояния и без отслеживания состояния, сохраняя больше копий кода (и состояния), работающих в доменах сбоя и обновления. 

Также возможно возникновение нескольких одновременных случайных сбоев. Скорее всего, это приведет к простою или фактической аварии.


#### <a name="stateless-services"></a>Службы без отслеживания состояния
Число экземпляров службы без отслеживания состояния указывает требуемое количество экземпляров, которые должны выполняться. При сбое любого (или всех) экземпляров, Service Fabric отвечает, автоматически создавая замещающие экземпляры на других узлах. Service Fabric продолжит создавать замены до тех пор, пока служба не вернется к нужному количеству экземпляров.

Например, предположим, что служба без отслеживания состояния имеет `InstanceCount` значение-1. Это значение означает, что один экземпляр должен выполняться на каждом узле в кластере. В случае сбоя некоторых из этих экземпляров Service Fabric обнаружит, что служба не находится в требуемом состоянии, и попытается создать экземпляры на узлах, где они отсутствуют.

#### <a name="stateful-services"></a>Службы с отслеживанием состояния
Существует два типа служб с отслеживанием состояния:
- Отслеживание состояния с сохранением состояния.
- С отслеживанием состояния с нематериализованным состоянием. (Состояние хранится в памяти.)

Восстановление после сбоя службы с отслеживанием состояния зависит от типа службы с отслеживанием состояния, количества реплик, которые имела служба, и количества сбоев реплик.

В службе с отслеживанием состояния входящие данные реплицируются между репликами (основной и любой активный вторичный). Если большая часть реплик получает данные, данные считаются зафиксированными *кворумом* . (Для пяти реплик три они будут кворумом.) Это означает, что в любой момент будет существовать по крайней мере кворум реплик с последними данными. Если реплики завершаются сбоем (скажем, два из пяти), можно использовать значение кворума, чтобы вычислить, можно ли выполнить восстановление. (Поскольку оставшиеся три реплики по-прежнему остаются в работе, гарантируется, что по крайней мере одна реплика будет иметь полные данные.)

При сбое кворума реплик Секция объявляется в состоянии *потери кворума* . Предположим, что Секция имеет пять реплик, что означает, что по крайней мере три из них гарантированно содержат полные данные. Если кворум (три пяти) реплики завершился неудачей, Service Fabric не сможет определить, достаточно ли у оставшихся реплик (два из них пять) иметь достаточные данные для восстановления секции. В случаях, когда Service Fabric обнаруживает потери кворума, его поведение по умолчанию заключается в предотвращении дополнительных операций записи в секцию, при объявлении потерь кворума и ожидании восстановления кворума реплик.

Определение того, произошла ли авария в службе с отслеживанием состояния, а затем Управление ей выполняется в три этапа:

1. Определение наличия потерь кворума или нет.
   
   Потери кворума объявляются, когда большинство реплик службы с отслеживанием состояния переключается в одно и то же время.
2. Определение, является ли потери кворума постоянной или нет.
   
   В большинстве случаев сбои являются временными. Процессы перезапускаются, перезапускаются, виртуальные машины перезапускаются и выполняется восстановление сетевых разделов. Однако иногда сбои являются постоянными. Указывает, являются ли сбои постоянными или нет, зависит от того, сохраняется ли состояние службы с отслеживанием состояния или хранится ли она только в памяти: 
   
   - Для служб без сохраненного состояния потеря кворума или нескольких реплик _немедленно_ приводит к постоянной потере кворума. Когда платформа Service Fabric обнаруживает потерю кворума в непостоянной службе с отслеживанием состояния, она немедленно переходит к шагу 3, объявляя (возможную) потерю данных. Переход к утрате данных имеет смысл, поскольку Service Fabric известно, что в ожидании возврата реплик нет смысла. Даже при восстановлении данные будут потеряны из-за неустойчивой природы службы.
   - Для постоянных служб с отслеживанием состояния сбой кворума или нескольких реплик приводит к тому, что Service Fabric дожидаться возврата реплик и восстановления кворума. Это приводит к сбою любых операций _записи_ в затронутые секции (или наборы реплик) службы. Однако чтение по-прежнему возможно благодаря снижению гарантии согласованности. Количество времени по умолчанию, которое Service Fabric ожидает восстановления кворума, *бесконечно*, так как продолжение — это событие потери данных (потенциально), которое несет угрозу и другие риски. Это означает, что Service Fabric не будет переходить к следующему шагу, если только администратор не примет действия по объявлению потери данных.
3. Определение потери данных и восстановление из резервных копий.

   Если потеря кворума была объявлена (автоматически или через административное действие), Service Fabric и службы переходят на, чтобы определить факт потери данных. На этом этапе Service Fabric также известно, что другие реплики не приходят обратно. Это решение принимается в момент прекращения ожидания восстановления потери кворума. Лучше всего заморозить службу и дождаться помощи администратора.
   
   Когда Service Fabric вызывает `OnDataLossAsync` метод, это всегда обусловлено возможной потерей данных.  Service Fabric всегда направляет этот вызов к _лучшей_ оставшейся реплике. Это любая реплика с лучшим показателем состояния. 
   
   Причина, по которой мы _всегда говорим о_ возможной потере данных, заключается в том, что оставшаяся реплика имеет то же состояние, что и источник, при потере кворума. Однако возможность сравнить состояние для Service Fabric или операторов отсутствует.     
   
   Что же дает типичная реализация метода `OnDataLossAsync`?
   1. Запущенные журналы реализации `OnDataLossAsync` и запускают все необходимые административные оповещения.
   1. Как правило, реализация приостанавливает работу и ждет принятия дальнейших решений и действий, выполняемых вручную. Это связано с тем, что даже если резервные копии доступны, их может потребоваться подготовить. 
   
      Например, если в двух различных службах информация о координатах может потребоваться изменить, чтобы убедиться в том, что после восстановления все эти две службы будут согласованными. 
   1. Часто в службе есть некоторые другие данные телеметрии или исчерпания. Эти метаданные могут содержаться в других службах или в журналах. Эти сведения можно использовать при необходимости для определения того, были ли вызовы получены и обработаны на основном, которые отсутствовали в резервной копии или реплицированы в эту конкретную реплику. Перед восстановлением может потребоваться воспроизвести или добавить эти вызовы в резервную копию.  
   1. Реализация сравнивает состояние оставшейся реплики с, которое содержится во всех доступных резервных копиях. Если вы используете Service Fabric надежные коллекции, для этого доступны [инструменты и процессы](service-fabric-reliable-services-backup-restore.md) . Цель состоит в том, чтобы определить, достаточно ли состояния в реплике, и узнать, что может отсутствовать резервная копия.
   1. После выполнения сравнения и после завершения восстановления (при необходимости) код службы должен возвращать **значение true** , если были внесены какие-либо изменения состояния. Если реплика определила, что она была лучшей доступной копией состояния и не внесла изменений, код возвращает **значение false**. 
   
      Значение **true** указывает, что _остальные оставшиеся_ реплики теперь могут быть несовместимы с этим. Они будут удалены и пересозданы из этой реплики. Значение **false** указывает, что изменения состояния не были внесены, поэтому другие реплики могут обеспечить их работу. 

Очень важно, чтобы авторы служб могли реализовать потенциальные сценарии потери данных и сбоев перед развертыванием служб в рабочей среде. Чтобы защититься от возможной потери данных, важно периодически [выполнять резервное копирование состояния](service-fabric-reliable-services-backup-restore.md) любых служб с отслеживанием состояния в геоизбыточное хранилище. 

Также необходимо убедиться, что у вас есть возможность восстановить состояние. Поскольку резервное копирование многих разных служб выполняется в разное время, необходимо убедиться, что после восстановления службы будут иметь единообразное представление. 

Например, рассмотрим ситуацию, когда одна служба создает число и сохраняет ее, а затем отправляет ее в другую службу, которая также хранит ее. После восстановления может быть обнаружено, что вторая служба имеет номер, но первая — нет, так как ее резервная копия не включала эту операцию.

Если вы обнаружите, что оставшиеся реплики недостаточны для продолжения в сценарии потери данных и вы не можете восстановить состояние службы из телеметрии или исчерпания, периодичность резервного копирования определяет наилучшую целевую точку восстановления (RPO). Service Fabric предоставляет множество средств для тестирования различных сценариев сбоев, включая постоянный кворум и потери данных, требующие восстановления из резервной копии. Эти сценарии включены в состав средств тестирования в Service Fabric, управляемых службой анализа сбоев. Дополнительные сведения об этих средствах и шаблонах см. в статье [Введение в службу анализа сбоев](service-fabric-testability-overview.md). 

> [!NOTE]
> Системные службы могут также снизить вероятность потери кворума. Влияние зависит от рассматриваемой службы. Например, потери кворума в службе именования влияют на разрешение имен, в то время как потери кворума в службе диспетчер отработки отказов блокирует создание новых служб и отработку отказа. 
> 
> Service Fabric системные службы соответствуют тому же шаблону, что и службы для управления состоянием, но мы не рекомендуем попытаться переместить их из потери кворума и возможной потери данных. Вместо этого рекомендуется  [Искать](service-fabric-support.md) решение, предназначенное для вашей ситуации. Как правило, предпочтительнее просто подождать, пока будут возвращены немедленные реплики.
>

#### <a name="troubleshooting-quorum-loss"></a>Устранение потерь кворума

Реплики могут быть непериодическими из-за временного сбоя. Подождите некоторое время, пока Service Fabric попытается их перенести. Если реплики были отключены дольше ожидаемого времени, выполните следующие действия по устранению неполадок:
- Реплики могут быть аварийными. Проверьте отчеты о работоспособности на уровне реплик и журналы приложений. Собирайте аварийные дампы и выберем необходимые действия для восстановления.
- Процесс реплики мог перестать отвечать на запросы. Проверьте журналы приложений, чтобы проверить это. Собирайте дампы процесса, а затем останавливает процесс, не отвечающий на запросы. Service Fabric создаст процесс замены и попытается восстановить реплику.
- Узлы, на которых размещены реплики, могут быть отключены. Перезапустите базовую виртуальную машину, чтобы отобразить узлы.

В некоторых случаях восстановление реплик может оказаться невозможным. Например, неисправные диски или компьютеры физически не отвечают. В таких случаях Service Fabric необходимо не дожидаться восстановления реплики.

*Не* используйте эти методы, если потенциальная потеря данных неприемлема для перевода службы в режим в сети. В этом случае необходимо выполнить все усилия по восстановлению физических компьютеров.

Следующие действия могут привести к утере данных. Прежде чем следовать инструкциям, проверьте их.
   
> [!NOTE]
> Использовать эти методы, кроме, в качестве целевого способа для конкретных секций _нельзя_ . 
>

- Используйте `Repair-ServiceFabricPartition -PartitionId` API или `System.Fabric.FabricClient.ClusterManagementClient.RecoverPartitionAsync(Guid partitionId)` . Этот API позволяет указать идентификатор секции для перемещения из строя кворума и возможной потери данных.
- Если кластер сталкивается с частыми сбоями, которые приводят к тому, что службы переходят в состояние потери кворума, и возможная _потеря данных приемлема_, указание соответствующего значения [куорумлоссваитдуратион](/powershell/module/servicefabric/update-servicefabricservice) может помочь службе автоматически восстановиться. Service Fabric будет ожидать указанное `QuorumLossWaitDuration` значение (по умолчанию бесконечно) перед выполнением восстановления. Мы *не* рекомендуем использовать этот метод, так как он может привести к непредвиденным потерям данных.

## <a name="availability-of-the-service-fabric-cluster"></a>Доступность кластера Service Fabric
Как правило, кластер Service Fabric — это высокораспределенная среда без единой точки отказа. Сбой одного узла не приведет к проблемам с доступностью или надежностью для кластера, в основном потому, что Service Fabric системные службы следуют тем же рекомендациям, которые были предоставлены ранее. То есть они всегда выполняются с тремя или более репликами по умолчанию, а системные службы, которые работают на всех узлах без отслеживания состояния. 

Базовые сетевые подключения Service Fabric и уровни определения сбоев являются полностью распределенными. Большинство системных служб могут быть перестроены на основе метаданных в кластере или повторно синхронизировать свое состояние из других мест. Доступность кластера может стать скомпрометированной, если системные службы походят в ситуации потери кворума, подобные описанным выше. В таких случаях вы не сможете выполнять определенные операции в кластере (например, запуск обновления или развертывание новых служб), но сам кластер по-прежнему работает. 

Службы в работающем кластере будут продолжать работать в этих условиях, если для продолжения работы не требуется запись в системные службы. Например, если диспетчер отработки отказов находится в состоянии потери кворума, все службы будут продолжать работать. Но любые службы, которые не могут быть перезапущены, не смогут автоматически перезапускаться, так как это требует участия диспетчер отработки отказов. 

### <a name="failures-of-a-datacenter-or-an-azure-region"></a>Сбои центра обработки данных или региона Azure
В редких случаях физический центр обработки данных может стать временно недоступным после потери питания или подключения к сети. В этих случаях кластеры Service Fabric, а также службы в таких центрах обработки данных или в регионе Azure будут недоступны. Тем не менее _данные сохраняются_. 

Просмотреть обновления сбоев для кластеров, запущенных в Azure, можно на [странице состояния Azure][azure-status-dashboard]. В крайне маловероятном случае, если физический центр обработки данных частично или полностью уничтожен, все Service Fabric кластеры, размещенные там, или службы внутри них могут быть утрачены. Эта утрата включает в себя любое состояние, которое не является резервным, за пределами этого центра обработки данных или региона.

Существует две различные стратегии для бесперебойной или устойчивой неисправности одного центра обработки данных или региона: 

- Запускайте отдельные кластеры Service Fabric в нескольких таких регионах и используйте некоторый механизм для отработки отказа и восстановления размещения между этими средами. Такой тип модели "активный/активный" или "активный/пассивный" требует дополнительного управления и кода операций. Эта модель также требует координации резервных копий служб в одном центре обработки данных или регионе, чтобы они были доступны в других центрах обработки данных или регионах в случае сбоя одного из них. 
- Запустите кластер Service Fabric, охватывающий несколько центров обработки данных или регионов. Минимальная поддерживаемая конфигурация для этой стратегии — три центра обработки данных или регионы. Но рекомендуется пять. 
  
  Для этой модели требуется более сложная топология кластера. Однако преимущество заключается в том, что сбой одного центра обработки данных или региона преобразовался из аварии в нормальную ошибку. Эти ошибки можно обрабатывать с помощью механизмов, которые применимы для кластеров в одном регионе. Домены сбоя, домены обновления и правила размещения Service Fabric обеспечивают распределение рабочих нагрузок, чтобы они допускали нормальные сбои. 
  
  Дополнительные сведения о политиках, которые могут помочь в работе служб в кластере такого типа, см. в разделе [политики размещения для служб Service Fabric Services](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md).

### <a name="random-failures-that-lead-to-cluster-failures"></a>Случайные сбои, приводящие к сбоям кластера
Service Fabric имеет концепцию *начальных узлов*. Это узлы, которые поддерживают доступность базового кластера. 

Узлы начальных значений помогают убедиться, что кластер остается установленным, установив аренду на другие узлы и выполняя в качестве арендуя во время определенных видов сбоев. Если случайные сбои удаляют большую часть начальных узлов в кластере и не возвращаются обратно, кластер автоматически завершает работу. В этом случае происходит сбой кластера. 

В Azure Service Fabric поставщик ресурсов управляет конфигурациями кластера Service Fabric. По умолчанию поставщик ресурсов распределяет начальные узлы между доменами сбоя и обновления для *типа первичного узла*. Если тип первичного узла помечен как Серебряная или золотой, при удалении начального узла (путем масштабирования в типе первичного узла или при его удалении вручную) кластер попытается распространить другой неначальный узел из доступной емкости типа первичного узла. Эта попытки завершится неудачей, если у вас меньше ресурсов, чем требуется уровню надежности кластера для типа первичного узла.

В автономных кластерах Service Fabric и Azure тип первичного узла — это тот, который выполняет начальные значения. При определении типа первичного узла Service Fabric автоматически использует преимущества предоставляемого количества узлов, создавая до девяти начальных узлов и семи реплик каждой системной службы. Если набор случайных сбоев повлечет за собой большую часть этих реплик одновременно, системные службы перестанут потерять кворум. Если большинство начальных узлов выйдут из строя, работа кластера будет прекращена.

## <a name="next-steps"></a>Дальнейшие действия
- Узнайте, как имитировать различные сбои с помощью [платформы тестирования](service-fabric-testability-overview.md).
- Ознакомьтесь с другими материалами по аварийному восстановлению и обеспечению высокой доступности. Корпорация Майкрософт опубликовала множество руководств по этим темам. Хотя некоторые из этих ресурсов относятся к определенным методам использования в других продуктах, они содержат множество общих рекомендаций, которые можно применять в контексте Service Fabric:
  - [Контрольный список доступности](/azure/architecture/checklist/resiliency-per-service)
  - [Отработка аварийного восстановления](../azure-sql/database/disaster-recovery-drills.md)
  - [Аварийное восстановление и высокий уровень доступности для приложений Azure][dr-ha-guide]
- Узнайте о [вариантах поддержки Service Fabric](service-fabric-support.md).


<!-- External links -->

[repair-partition-ps]: /windows/win32/perfctrs/specifying-a-counter-path
[azure-status-dashboard]:https://azure.microsoft.com/status/
[azure-regions]: https://azure.microsoft.com/regions/
[dr-ha-guide]: /previous-versions/azure/dn251004(v=azure.100)


<!-- Images -->

[sfx-cluster-map]: ./media/service-fabric-disaster-recovery/sfx-clustermap.png
