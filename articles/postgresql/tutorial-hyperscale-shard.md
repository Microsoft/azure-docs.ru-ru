---
title: Руководство по Сегментирование данных в рабочих узлах — Гипермасштабирование (Citus) — База данных Azure для PostgreSQL
description: В этом руководстве объясняется, как создать распределенные таблицы и визуализировать распределение их данных с помощью Базы данных Azure для PostgreSQL с Гипермасштабированием (Citus).
author: jonels-msft
ms.author: jonels
ms.service: postgresql
ms.subservice: hyperscale-citus
ms.custom: mvc
ms.devlang: azurecli
ms.topic: tutorial
ms.date: 12/16/2020
ms.openlocfilehash: 7d93002af866aa653972182a13ea37d37e912ce8
ms.sourcegitcommit: 8c3a656f82aa6f9c2792a27b02bbaa634786f42d
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/17/2020
ms.locfileid: "97630315"
---
# <a name="tutorial-shard-data-on-worker-nodes-in-azure-database-for-postgresql--hyperscale-citus"></a>Руководство по сегментированию данных в рабочих узлах в Базе данных Azure для PostgreSQL с Гипермасштабированием (Citus)

В этом учебнике используется решение "Гипермасштабирование (Citus)" в Базе данных Azure для PostgreSQL, чтобы продемонстрировать следующее:

> [!div class="checklist"]
> * создание сегментов с хэш-распределением;
> * определение расположения сегментов таблицы;
> * определение смещения распределения;
> * создание ограничения для распределенных таблиц;
> * выполнение запросов к распределенным данным.

## <a name="prerequisites"></a>Предварительные требования

При работе с этим руководством вам потребуется использовать группу серверов Гипермасштабирования (Citus) с двумя рабочими узлами. Если у вас нет активной группы серверов, выполните инструкции из [руководства по созданию группы серверов](tutorial-hyperscale-server-group.md) и вернитесь к этому руководству.

## <a name="hash-distributed-data"></a>Данные с хэш-распределением

Распределение строк таблицы по нескольким серверам PostgreSQL — это основной метод для выполнения масштабируемых запросов в варианте "Гипермасштабирование (Citus)". Вместе несколько узлов могут содержать больше данных, чем традиционная база данных, а во многих случаях для выполнения запросов могут параллельно использоваться ЦП рабочих узлов.

Для выполнения предварительных требований мы создали группу серверов Гипермасштабирования (Citus) с двумя рабочими узлами.

![Координатор и два рабочих узла](tutorial-hyperscale-shard/nodes.png)

Таблицы метаданных в узле координатора отслеживают рабочие узлы и распределенные данные. Активные рабочие узлы можно просмотреть в таблице [pg_dist_node](reference-hyperscale-metadata.md#worker-node-table).

```sql
select nodeid from pg_dist_node where isactive;
```
```
 nodeid | nodename
--------+-----------
      1 | 10.0.0.21
      2 | 10.0.0.23
```

> [!NOTE]
> Имена узлов в варианте "Гипермасштабирование (Citus)" представлены внутренними IP-адресами в виртуальной сети. При этом фактические адреса могут отличаться.

### <a name="rows-shards-and-placements"></a>Строки, сегменты и размещение

Чтобы использовать ресурсы ЦП и хранилища рабочих узлов, необходимо распределить данные таблиц по всей группе серверов.  При распределении таблицы выполняется назначение каждой строки логической группе, называемой *сегментом*. Мы создадим таблицу и выполним ее распределение:

```sql
-- create a table on the coordinator
create table users ( email text primary key, bday date not null );

-- distribute it into shards on workers
select create_distributed_table('users', 'email');
```

Гипермасштабирование (Citus) назначает каждую строку сегменту с учетом значения в *столбце распределения*, которое в нашем случае представлено `email`. Каждая строка будет располагаться точно в одном сегменте, а каждый сегмент может содержать несколько строк.

![Таблица "Пользователи" со строками, указывающими на сегменты](tutorial-hyperscale-shard/table.png)

По умолчанию `create_distributed_table()` включает 32 сегмента, как можно увидеть, выполнив подсчет в таблице метаданных [pg_dist_shard](reference-hyperscale-metadata.md#shard-table):

```sql
select logicalrelid, count(shardid)
  from pg_dist_shard
 group by logicalrelid;
```
```
 logicalrelid | count
--------------+-------
 users        |    32
```

Гипермасштабирование (Citus) использует таблицу `pg_dist_shard` для назначения строк сегментам с учетом хэша значения в столбце распределения. Для работы с этим руководством не нужно вникать в детали хэширования. Важнее то, что мы можем отправить запрос и увидеть, какие значения сопоставлены с определенными идентификаторами сегментов:

```sql
-- Where would a row containing hi@test.com be stored?
-- (The value doesn't have to actually be present in users, the mapping
-- is a mathematical operation consulting pg_dist_shard.)
select get_shard_id_for_distribution_column('users', 'hi@test.com');
```
```
 get_shard_id_for_distribution_column
--------------------------------------
                               102008
```

Сопоставление строк сегментам выполняется абсолютно логично. Сегменты должны быть назначены определенным рабочим узлам для хранения — в Гипермасштабировании (Citus) это называется *размещением сегмента*.

![Сегменты, назначенные рабочим узлам](tutorial-hyperscale-shard/shard-placement.png)

Мы можем рассмотреть размещение сегментов в [pg_dist_placement](reference-hyperscale-metadata.md#shard-placement-table).
Если соединить эту таблицу с другими таблицами метаданных, можно понять, где расположен каждый сегмент.

```sql
-- limit the output to the first five placements

select
    shard.logicalrelid as table,
    placement.shardid as shard,
    node.nodename as host
from
    pg_dist_placement placement,
    pg_dist_node node,
    pg_dist_shard shard
where placement.groupid = node.groupid
  and shard.shardid = placement.shardid
order by shard
limit 5;
```
```
 table | shard  |    host
-------+--------+------------
 users | 102008 | 10.0.0.21
 users | 102009 | 10.0.0.23
 users | 102010 | 10.0.0.21
 users | 102011 | 10.0.0.23
 users | 102012 | 10.0.0.21
```

### <a name="data-skew"></a>Неравномерное распределение данных

Работа группы серверов будет максимально эффективной, если данные распределены по рабочим узлам равномерно и если связанные данные размещены в одном рабочем узле. В рамках этого раздела мы уделим внимание первому вопросу — однородности размещения.

Для демонстрации создадим пример данных для таблицы `users`:

```sql
-- load sample data
insert into users
select
    md5(random()::text) || '@test.com',
    date_trunc('day', now() - random()*'100 years'::interval)
from generate_series(1, 1000);
```

Чтобы определить размеры сегментов, можно выполнить для сегментов [функции для определения размера таблицы](https://www.postgresql.org/docs/current/functions-admin.html#FUNCTIONS-ADMIN-DBSIZE).

```sql
-- sizes of the first five shards
select *
from
    run_command_on_shards('users', $cmd$
      select pg_size_pretty(pg_table_size('%1$s'));
    $cmd$)
order by shardid
limit 5;
```
```
 shardid | success | result
---------+---------+--------
  102008 | t       | 16 kB
  102009 | t       | 16 kB
  102010 | t       | 16 kB
  102011 | t       | 16 kB
  102012 | t       | 16 kB
```

Как мы видим, сегменты имеют одинаковый размер. Размещения распределены равномерно между рабочими узлами, поэтому можно сделать вывод, что рабочие узлы содержат приблизительно одинаковое число строк.

Строки в нашем примере `users` распределены равномерно благодаря свойствам столбца распределения `email`.

1. Число адресов электронной почты было больше числа сегментов или равно ему.
2. Число строк на адрес электронной почты было похожим (в нашем случае использовалась точно одна строка на адрес, так как мы объявили его ключом).

Если выбрать таблицу и столбец распределения таким образом, что одно из свойств не будет работать, размещение данных в рабочих узлах будет неравномерным, то есть возникнет *неравномерное распределение данных*.

### <a name="add-constraints-to-distributed-data"></a>Добавление ограничений к распределенным данным

Использование Гипермасштабирования (Citus) позволяет получать все преимущества реляционной базы данных, включая [ограничения для базы данных](https://www.postgresql.org/docs/current/ddl-constraints.html).
Но здесь нужно помнить об одном моменте. Из-за особенностей распределенных систем Гипермасштабирование (Citus) не будет использовать перекрестные ссылки для проверки на уникальность ограничений или целостность данных в рабочих узлах.

Рассмотрим наш пример таблицы `users` со связанной таблицей.

```sql
-- books that users own
create table books (
    owner_email text references users (email),
    isbn text not null,
    title text not null
);

-- distribute it
select create_distributed_table('books', 'owner_email');
```

Для повышенной эффективности мы распределим `books` так же, как `users`: по адресу электронной почты владельца. Распределение по аналогичным значениям столбцов называется [совместным размещением](concepts-hyperscale-colocation.md).

У нас не возникло проблем с распределением пользователям таблицы books с внешним ключом, так как ключ был доступен в столбце распределения. Но если мы попытаемся сделать из `isbn` ключ, возникнут сложности:

```sql
-- will not work
alter table books add constraint books_isbn unique (isbn);
```
```
ERROR:  cannot create constraint on "books"
DETAIL: Distributed relations cannot have UNIQUE, EXCLUDE, or
        PRIMARY KEY constraints that do not include the partition column
        (with an equality operator if EXCLUDE).
```

В распределенной таблице оптимальным методом будет сделать столбцы уникальным остатком от деления столбца распределения:

```sql
-- a weaker constraint is allowed
alter table books add constraint books_isbn unique (owner_email, isbn);
```

Приведенное выше ограничение всего лишь делает isbn уникальным для пользователя. Другой вариант — сделать таблицу books [ссылочной таблицей](howto-hyperscale-modify-distributed-tables.md#reference-tables) (а не распределенной) и создать отдельную распределенную таблицу, связывающую данные о книгах с данными о пользователях.

## <a name="query-distributed-tables"></a>Запрашивание распределенных таблиц

Из предыдущих разделов мы узнали, как строки распределенной таблицы размещаются в сегментах в рабочих узлах. В большинстве случаев вам не нужно знать, как или где данные хранятся в группе серверов. Гипермасштабирование (Citus) включает исполнитель распределенных запросов, который автоматически разделяет обычные SQL-запросы. Он запускает их параллельно в рабочих узлах, расположенных близко к данным.

Например, можно выполнить запрос, чтобы найти средний возраст пользователей, обработав распределенную таблицу `users` как обычную таблицу в координаторе.

```sql
select avg(current_date - bday) as avg_days_old from users;
```
```
    avg_days_old
--------------------
 17926.348000000000
```

![Запрос к сегментам через координатор](tutorial-hyperscale-shard/query-fragments.png)

При этом исполнитель Гипермасштабирования (Citus) фактически создает отдельный запрос для каждого сегмента, запускает его в рабочих узлах и объединяет результат. Это можно увидеть, если воспользоваться командой EXPLAIN PostgreSQL:

```sql
explain select avg(current_date - bday) from users;
```
```
                                  QUERY PLAN
----------------------------------------------------------------------------------
 Aggregate  (cost=500.00..500.02 rows=1 width=32)
   ->  Custom Scan (Citus Adaptive)  (cost=0.00..0.00 rows=100000 width=16)
     Task Count: 32
     Tasks Shown: One of 32
     ->  Task
       Node: host=10.0.0.21 port=5432 dbname=citus
       ->  Aggregate  (cost=41.75..41.76 rows=1 width=16)
         ->  Seq Scan on users_102040 users  (cost=0.00..22.70 rows=1270 width=4)
```

В выходных данных приведен пример плана выполнения для *фрагмента запроса*, выполняющегося в сегменте 102040 (таблица `users_102040` в рабочем узле 10.0.0.21). Другие фрагменты не отображаются, так как они похожи. Как мы видим, рабочий узел проверяет таблицы сегмента и выполняет статистические вычисления. Узел координатора объединяет агрегированные данные для получения окончательного результата.

## <a name="next-steps"></a>Дальнейшие действия

С помощью инструкций из этого руководства мы создали распределенную таблицу. В нем также описаны сегменты и размещения. Мы рассмотрели проблему уникальности и ограничения для внешних ключей, а также то, как распределенные запросы работают на верхнем уровне.

* См. подробные сведения о [типах таблиц](concepts-hyperscale-nodes.md) в Гипермасштабировании (Citus).
* Изучите советы по [выбору столбца распределения](concepts-hyperscale-choose-distribution-column.md).
* Узнайте о преимуществах [совместного размещения таблиц](concepts-hyperscale-colocation.md).
