---
title: Использование концентратора событий из приложения Apache Kafka — Центры событий Azure | Документация Майкрософт
description: В этой статье содержатся сведения о поддержке Apache Kafka в службе "Центры событий Azure".
ms.topic: article
ms.date: 09/25/2020
ms.openlocfilehash: b0f0da76bba68f8a66695700d530e871cbd35e3c
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "97861338"
---
# <a name="use-azure-event-hubs-from-apache-kafka-applications"></a>Использование Центров событий Azure из приложений Apache Kafka
Концентраторы событий предоставляют конечную точку, совместимую с интерфейсами API Apache Kafka® производителя и потребителя, которые могут использоваться большинством существующих Apache Kafka клиентских приложений в качестве альтернативы запуску собственного кластера Apache Kafka. Концентраторы событий поддерживают клиентские API-интерфейсы производителя и потребителя Apache Kafka в версии 1,0 и более поздних.

> [!VIDEO https://www.youtube.com/embed/UE1WgB96_fc]

## <a name="what-does-event-hubs-for-kafka-provide"></a>Возможности, предоставленные Центрами событий для Kafka

Концентраторы событий для Apache Kafka функции предоставляют заголовок протокола поверх концентраторов событий Azure, совместимых с Apache Kafka клиентами, созданными для Apache Kafka Server версии 1,0 и более поздних версий и поддерживающими как чтение, так и запись в концентраторы событий, которые эквивалентны Apache Kafka темам. 

Вы часто можете использовать конечную точку Kafka концентраторов событий из приложений без изменений кода по сравнению с существующей установкой Kafka и изменять конфигурацию только: Обновите строку подключения в конфигурациях, чтобы она указывала на конечную точку Kafka, доступную для концентратора событий, а не на кластер Kafka. Затем вы можете начать потоковую передачу событий из приложений, использующих в Центрах событий протокол Kafka. 

По сути, Kafka и концентраторы событий очень похожи: они являются секционированными журналами, созданными для потоковой передачи данных, что позволяет клиенту управлять тем, какой частью журнала, который он хочет прочитать. В следующей таблице показано составление понятий Kafka и Центров событий.

### <a name="kafka-and-event-hub-conceptual-mapping"></a>Сопоставление понятий Kafka и концентратора событий

| Понятия Kafka | Понятия Центров событий|
| --- | --- |
| Кластер | Пространство имен |
| Раздел | Концентратор событий |
| Секция | Секция|
| Группа потребителей | Группа потребителей |
| Offset | Offset|

### <a name="key-differences-between-apache-kafka-and-event-hubs"></a>Основные различия между Apache Kafka и концентраторами событий

Хотя [Apache Kafka](https://kafka.apache.org/) — это программное обеспечение, которое обычно требуется установить и обработать, концентраторы событий — это полностью управляемая облачная служба. Нет серверов, дисков или сетей для управления и мониторинга, а также нет брокеров, которые можно было бы расдумать или настроить. Создайте пространство имен, которое является конечной точкой с полным доменным именем, а затем создайте концентраторы событий (разделы) в этом пространстве имен. 

Дополнительные сведения о Центрах событий и пространствах имен см. в статье [Особенности Центров событий](event-hubs-features.md#namespace). В качестве облачной службы концентраторы событий используют один стабильный виртуальный IP-адрес в качестве конечной точки, поэтому клиентам не нужно знать о брокерах или компьютерах в кластере. Хотя концентраторы событий реализуют один и тот же протокол, это означает, что весь трафик Kafka для всех секций прогнозируется через эту конечную точку, а не требует доступа к брандмауэру для всех брокеров кластера.   

Масштабирование в концентраторах событий регулируется количеством приобретенных единиц пропускной способности с каждой единицей пропускной способности, дающего в 1 МБ в секунду, а также 1000 событий в секунду и дважды в этом томе. Концентраторы событий могут автоматически масштабировать единицы пропускной способности при достижении предельной пропускной способности, если используется функция [автоматического](event-hubs-auto-inflate.md) расширения; Эта функция работает также с поддержкой протокола Apache Kafka.  

### <a name="is-apache-kafka-the-right-solution-for-your-workload"></a>Apache Kafka верное решение для вашей рабочей нагрузки?

Поступающие от создания приложений с помощью Apache Kafka, также будет полезно понимать, что концентраторы событий Azure являются частью парка служб, которые также включают в себя [служебную шину Azure и службу](../service-bus-messaging/service-bus-messaging-overview.md)" [Сетка событий Azure](../event-grid/overview.md)". 

Хотя некоторые поставщики коммерческих дистрибутивов Apache Kafka могут предлагать, что Apache Kafka является одним-остановкой для всех потребностей платформы обмена сообщениями, реальность заключается в том, что Apache Kafka не реализует, например, шаблон очереди [конкурирующих потребителей](/azure/architecture/patterns/competing-consumers) , не имеет поддержки  [публикации-Subscribe](/azure/architecture/patterns/publisher-subscriber) на уровне, который разрешает подписчикам доступ к входящим сообщениям на основе серверных правил, отличных от простых смещений, и не имеет средств для отслеживания жизненного цикла задания, инициированного сообщением или сиделининг ошибочных сообщений, в очередь недоставленной почты, все из которых основаны на многих сценариях корпоративного обмена сообщениями.

Сведения о различиях между шаблонами и о том, какой шаблон лучше подойдет для службы, см. в руководстве по использованию [параметров асинхронного обмена сообщениями в Azure](/azure/architecture/guide/technology-choices/messaging) . Как Apache Kafka пользователь, вы можете столкнуться с тем, чтобы пути взаимодействия, которые вы уже приступили к Kafka, могли быть реализованы с гораздо менее простой и еще более мощными возможностями с помощью службы "Сетка событий" или служебной шины. 

Если вам нужны специальные функции Apache Kafka, которые недоступны в концентраторах событий для Apache Kafka интерфейса, или если шаблон реализации превышает [квоты концентраторов событий](event-hubs-quotas.md), можно также запустить [собственный кластер Apache Kafka в Azure HDInsight](../hdinsight/kafka/apache-kafka-introduction.md).  

## <a name="security-and-authentication"></a>Безопасность и проверка подлинности
Каждый раз при публикации или использовании событий из концентраторов событий для Kafka клиент пытается получить доступ к ресурсам концентраторов событий. Необходимо обеспечить доступ к ресурсам с помощью полномочной сущности. При использовании протокола Apache Kafka с клиентами можно настроить конфигурацию для проверки подлинности и шифрования с помощью механизмов SASL. При использовании концентраторов событий для Kafka требуется TLS-шифрование (так как все данные, передаваемые с концентраторами событий, шифруются с помощью TLS). Это можно сделать, указав параметр SASL_SSL в файле конфигурации. 

Концентраторы событий Azure предоставляют несколько вариантов авторизации доступа к защищенным ресурсам. 

- OAuth 2.0
- Подписанный URL-адрес (SAS)

#### <a name="oauth-20"></a>OAuth 2.0
Концентраторы событий интегрируются с Azure Active Directory (Azure AD), который предоставляет сервер централизованной авторизации, совместимый с **OAuth 2,0** . С помощью Azure AD вы можете использовать управление доступом на основе ролей Azure (Azure RBAC), чтобы предоставить точные разрешения для удостоверений клиентов. Эту функцию можно использовать с клиентами Kafka, указав **SASL_SSL** для протокола и  **оаусбеарер** для механизма. Дополнительные сведения о ролях и уровнях Azure для доступа к области см. [в статье авторизация доступа с помощью Azure AD](authorize-access-azure-active-directory.md).

```properties
bootstrap.servers=NAMESPACENAME.servicebus.windows.net:9093
security.protocol=SASL_SSL
sasl.mechanism=OAUTHBEARER
sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;
sasl.login.callback.handler.class=CustomAuthenticateCallbackHandler;
```

#### <a name="shared-access-signature-sas"></a>Подписанный URL-адрес
Концентраторы событий также предоставляют **подписанные URL-адрес (SAS)** для делегированного доступа к концентраторам событий для ресурсов Kafka. Авторизация доступа с помощью механизма на основе токенов OAuth 2,0 обеспечивает более высокую безопасность и простоту использования SAS. Встроенные роли также могут устранить необходимость авторизации на основе ACL, которая должна поддерживаться и управляться пользователем. Эту функцию можно использовать с клиентами Kafka, указав для него **SASL_SSL** протокола и **простой** для механизма. 

```properties
bootstrap.servers=NAMESPACENAME.servicebus.windows.net:9093
security.protocol=SASL_SSL
sasl.mechanism=PLAIN
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="$ConnectionString" password="{YOUR.EVENTHUBS.CONNECTION.STRING}";
```

> [!IMPORTANT]
> Замените `{YOUR.EVENTHUBS.CONNECTION.STRING}` строками подключения для вашего пространства имен Центров событий. Инструкции по получению строки подключения см. в статье [Получение строки подключения Центров событий](event-hubs-get-connection-string.md). Пример конфигурации см. здесь: `sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="$ConnectionString" password="Endpoint=sb://mynamespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=XXXXXXXXXXXXXXXX";`

> [!NOTE]
> При использовании проверки подлинности SAS с клиентами Kafka установленные подключения не отключаются при повторном формировании ключа SAS. 


#### <a name="samples"></a>Примеры 
Пошаговые инструкции по созданию концентратора событий и доступу к нему с помощью SAS или OAuth см **. в статье** [Краткое руководство. потоковая передача данных с концентраторами событий с помощью протокола Kafka](event-hubs-quickstart-kafka-enabled-event-hubs.md).

Дополнительные **примеры** , демонстрирующие использование OAuth с концентраторами событий для Kafka, см. [в статье примеры на сайте GitHub](https://github.com/Azure/azure-event-hubs-for-kafka/tree/master/tutorials/oauth).

## <a name="other-event-hubs-features"></a>Другие функции концентраторов событий 

Концентраторы событий для Apache Kafka функции — это один из трех протоколов, параллельно доступных в концентраторах событий Azure, дополненных HTTP и AMQP. Вы можете писать с помощью любого из этих протоколов и читать друг с другом, чтобы текущие поставщики Apache Kafka могли продолжить публикацию с помощью Apache Kafka, но читатель может воспользоваться преимуществами встроенной интеграции с интерфейсом AMQP концентратора событий, например Azure Stream Analytics или функций Azure. Вы можете легко интегрировать концентраторы событий Azure в сети маршрутизации AMQP в качестве целевой конечной точки, а также считывать данные с помощью интеграции Apache Kafka.  

Кроме того, такие функции концентраторов событий, как [захват](event-hubs-capture-overview.md), позволяющие очень экономично выполнять долгосрочную архивацию с помощью хранилища BLOB-объектов Azure и Azure Data Lake Storage, а [геоаварийное восстановление](event-hubs-geo-dr.md) также работает с концентраторами событий для функции Kafka.

## <a name="apache-kafka-feature-differences"></a>Отличия функций Apache Kafka 

Целью концентраторов событий для Apache Kafka является предоставление доступа к возможностям концентратора событий Azure для приложений, которые заблокированы в Apache Kafka API и в противном случае должны быть резервными копиями кластера Apache Kafka. 

Как упоминалось [выше](#is-apache-kafka-the-right-solution-for-your-workload), парк обмена сообщениями Azure предоставляет широкие возможности для разнообразных ситуаций обмена сообщениями, и хотя в настоящее время в службе поддержки концентраторов событий для Apache Kafka API не поддерживаются следующие функции, мы указывали, где и как будет доступна нужная возможность.

### <a name="transactions"></a>Transactions

В [служебной шине Azure](../service-bus-messaging/service-bus-transactions.md) поддерживается устойчивая поддержка транзакций, которая позволяет получать и назначать сообщения и сеансы при отправке исходящих сообщений, полученных от обработки сообщений, к нескольким целевым сущностям при защите согласованности транзакций. Набор функций обеспечивает не только однократную обработку каждого сообщения в последовательности, но также позволяет избежать риска непреднамеренной повторной обработки тех же сообщений другим потребителем, так как это было бы в случае с Apache Kafka. Служебная шина является рекомендуемой службой для рабочих нагрузок транзакционных сообщений.

### <a name="compression"></a>Сжатие

Функция [сжатия](https://cwiki.apache.org/confluence/display/KAFKA/Compression) на стороне клиента Apache Kafka сжимает пакет нескольких сообщений в одно сообщение на стороне производителя и распаковывает пакет на стороне потребителя. Брокер Apache Kafka обрабатывает пакет как специальное сообщение.

Эта функция является фундаментальной в основе многопротокольной модели концентраторов событий Azure, которая позволяет получать сообщения, даже отправляемые пакетами, отдельно от брокера и по любому протоколу. 

Полезной нагрузкой любого события концентратора событий является байтовый поток, и содержимое можно сжать с помощью алгоритма выбора. Формат кодирования Apache Avro поддерживает сжатие в собственном виде.

### <a name="log-compaction"></a>Сжатие журнала

Apache Kafka сжатие журнала — это функция, которая позволяет выключать все, кроме последней записи всех ключей из секции, что фактически приводит Apache Kafka раздел в хранилище "ключ — значение", где Последнее добавленное значение переопределяет предыдущее. Эта функция сейчас не реализована концентраторами событий Azure. Шаблон хранилища "ключ-значение" даже с частыми обновлениями гораздо лучше поддерживается службами баз данных, такими как [Azure Cosmos DB](../cosmos-db/introduction.md). Дополнительные сведения см. в разделе о [проекции журнала](event-hubs-federation-overview.md#log-projections) в руководстве по Федерации концентраторов событий. 

### <a name="kafka-streams"></a>потоки Kafka.

Потоки Kafka — это клиентская библиотека для Stream Analytics, которая является частью проекта Apache Kafka с открытым исходным кодом, но отдельно от Apache Kafka брокера потока событий. 

Наиболее распространенная причина, по которой клиенты концентраторов событий Azure запрашивают поддержку потоков Kafka, заключается в том, что они заинтересованы в продукте "Ксклдб". "Ксклдб" — это частный проект с общим исходным кодом, который [лицензируется таким](https://github.com/confluentinc/ksql/blob/master/LICENSE) образом, что ни один из поставщиков не предлагает поставщику "программное обеспечение как услуга", "платформа как услуга", "инфраструктура как служба" или других аналогичных веб-службы, которые конкурируют с неограниченными продуктами или службами, могут использовать или предлагать поддержку "ксклдб". Практически, если вы используете Ксклдб, необходимо либо работать с Kafka самостоятельно, либо использовать облачные предложения. Условия лицензионного соглашения также могут повлиять на клиентов Azure, предлагающих службы для цели, исключенной из лицензии.

Автономные и без Ксклдб, Kafka потоки имеют меньше возможностей, чем многие альтернативные платформы и службы, большинство из которых имеют встроенные потоковые интерфейсы SQL и все они интегрируются с концентраторами событий Azure сегодня:

- [Azure Stream Analytics](../stream-analytics/stream-analytics-introduction.md)
- [Azure синапсе Analytics (через захват концентраторов событий)](../event-grid/event-grid-event-hubs-integration.md)
- [Azure Databricks](/azure/databricks/scenarios/databricks-stream-from-eventhubs)
- [Apache Samza](https://samza.apache.org/learn/documentation/latest/connectors/eventhubs)
- [Apache Storm](event-hubs-storm-getstarted-receive.md)
- [Apache Spark](event-hubs-kafka-spark-tutorial.md)
- [Apache Флинк](event-hubs-kafka-flink-tutorial.md)
- [Потоки Akka Streams](event-hubs-kafka-akka-streams-tutorial.md)

Перечисленные службы и платформы обычно могут получать потоки событий и ссылочные данные непосредственно из различных наборов источников через адаптеры. Потоки Kafka могут получать данные только из Apache Kafka и проекты аналитики заблокированы в Apache Kafka. Чтобы использовать данные из других источников, необходимо сначала импортировать данные в Apache Kafka с помощью Kafka Connect Framework.

Если вам необходимо использовать платформу Kafka Streams в Azure, [Apache Kafka в HDInsight](../hdinsight/kafka/apache-kafka-introduction.md) предоставит этот вариант. Apache Kafka в HDInsight предоставляет полный контроль над всеми аспектами настройки Apache Kafka, в то время как полная интеграция с различными аспектами платформы Azure — от сбоя или обновления домена до сетевой изоляции до наблюдения за интеграцией. 

## <a name="next-steps"></a>Дальнейшие действия
В этой статье приведены ознакомительные сведения о Центрах событий для компонента Kafka. См. сведения в [руководстве для разработчиков Apache Kafka по Центрам событий Azure](apache-kafka-developer-guide.md).