---
title: Федерация с несколькими сайтами и несколькими регионами — концентраторы событий Azure | Документация Майкрософт
description: В этой статье представлен обзор Федерации с несколькими сайтами и несколькими регионами с помощью концентраторов событий Azure.
ms.topic: article
ms.date: 12/12/2020
ms.author: spelluru
ms.openlocfilehash: 7deb6fe04241225f1f97a204cc62b4aefad9f440
ms.sourcegitcommit: 7e97ae405c1c6c8ac63850e1b88cf9c9c82372da
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/29/2020
ms.locfileid: "97804043"
---
# <a name="multi-site-and-multi-region-federation"></a>Федерация для нескольких сайтов и нескольких регионов

Для многих сложных решений требуется, чтобы одни и те же потоки событий были доступны для потребления в нескольких местах, или для них требуется собирать потоки событий в нескольких расположениях, а затем консолидировать их в определенное место для использования. Также часто возникает необходимость в обогащении или сокращении потоков событий или преобразований форматов событий, а также в одном регионе и решении.

Практически это означает, что решение будет поддерживать несколько концентраторов событий, часто в разных регионах и пространствах имен концентраторов событий, а затем реплицировать события между ними. Вы также можете обмениваться событиями с источниками и целевыми объектами, такими как [служебная шина Azure](../service-bus-messaging/service-bus-messaging-overview.md), [центр Интернета вещей Azure](../iot-fundamentals/iot-introduction.md)или [Apache Kafka](https://kafka.apache.org). 

Обслуживание нескольких активных концентраторов событий в разных регионах позволяет клиентам выбирать и переключаться между ними при объединении их содержимого, что делает общую систему более устойчивой по отношению к региональным проблемам доступности.

В этой главе "Федерация" объясняются шаблоны Федерации и способы их реализации с помощью бессерверных [Azure Stream Analytics](../stream-analytics/stream-analytics-introduction.md) или сред выполнения [функций Azure][1] с возможностью ввода собственного кода преобразования или дополнения непосредственно в пути потока событий. 

## <a name="federation-patterns"></a>Шаблоны Федерации

Есть много потенциальных причин, по которым может потребоваться переместить события между разными концентраторами событий или другими источниками и целями, и мы перечислением наиболее важных шаблонов в этом разделе, а также ссылками на более подробные рекомендации по соответствующему шаблону. 

- [Устойчивость к событиям региональной доступности](#resiliency-against-regional-availability-events)
- [Оптимизация задержки](#latency-optimization)
- [Проверка, сокращение и обогащение](#validation-reduction-and-enrichment)
- [Интеграция со службами аналитики](#integration-with-analytics-services)
- [Консолидация и нормализация потоков событий](#consolidation-and-normalization-of-event-streams)
- [Разделение и маршрутизация потоков событий](#splitting-and-routing-of-event-streams)
- [Ведение журнала проекций](#log-projections)
  
### <a name="resiliency-against-regional-availability-events"></a>Устойчивость к событиям региональной доступности 

![Доступность по регионам](media/event-hubs-federation-overview/regional-availability.jpg)

Хотя максимальная доступность и надежность являются основными рабочими приоритетами для концентраторов событий, существует множество способов, с помощью которых производитель или потребитель может предотвратить переход к назначенному "основному" концентратору событий из-за проблем с сетью или разрешением имен, а также когда концентратор событий может быть временно не отвечает или возвращать ошибки. 

Такие условия не «катастрофируют», так что вы захотите полностью отказаться от региона в случае [аварийного восстановления](event-hubs-geo-dr.md) , но бизнес-сценарий некоторых приложений может уже повлиять на события доступности, которые находятся в течение нескольких минут или даже секунд. 

Существуют два базовых шаблона для решения таких сценариев:

- Шаблон [репликации][4] предназначен для репликации содержимого основного концентратора событий в дополнительный концентратор событий, при котором основной концентратор событий обычно используется приложением для создания и использования событий, а вторичный — как резервный вариант в случае, если основной концентратор событий становится недоступным. Так как репликация выполняется однонаправленным, от основного до дополнительного, переключение поставщиков и потребителей из недоступного первичного сервера в дополнительный приведет к тому, что старый первичный сервер больше не будет получать новые события, и, следовательно, не станет актуальным.
  Поэтому чистая репликация подходит только для односторонних сценариев отработки отказа. После выполнения отработки отказа старая база данных-источник отменяется, а новый дополнительный концентратор событий необходимо создать в другом целевом регионе.
- Шаблон [слияния][5] расширяет шаблон репликации, выполняя непрерывное слияние содержимого двух или более концентраторов событий. Каждое событие, изначально созданное в одном из концентраторов событий, включенных в схему, реплицируется в другие концентраторы событий. При репликации событий они записываются в заметки таким образом, что они затем игнорируются процессом репликации целевого объекта репликации. Результаты использования шаблона слияния — это два или более концентраторов событий, которые будут содержать одинаковый набор событий в конечном итоге. 
  
В любом случае содержимое концентраторов событий не будет совпадать. События от одного производителя, сгруппированные по одному и тому же ключу секции, будут отображаться в том же относительно порядке, в котором они были изначально отправлены, но абсолютный порядок событий может отличаться. Это особенно справедливо для сценариев, в которых количество секций исходного и целевого концентраторов событий отличается, что желательно для некоторых из описанных здесь расширенных шаблонов. [Разделитель или маршрутизатор](#splitting-and-routing-of-event-streams) может получить срез гораздо большего концентратора событий с сотнями секций и воронкой в меньший концентратор событий с несколькими разделами, более подходящим для обработки подмножества с ограниченными ресурсами обработки. И наоборот, [Консолидация](#consolidation-and-normalization-of-event-streams) может привести к перенаправлению данных из нескольких небольших концентраторов событий в один большой концентратор событий с большим количеством секций, чтобы справиться с консолидированной пропускной способностью и обработкой.

Для хранения событий вместе используется ключ секции, а не идентификатор исходной секции. Дополнительные сведения о относительном порядке и способах выполнения отработки отказа из одного концентратора событий в следующий, не полагаясь на ту же область смещения потока, обсуждаются в описании шаблона [репликации][4] .


Руководство по 
- [Шаблон репликации][4]
- [Шаблон слияния][5]

### <a name="latency-optimization"></a>Оптимизация задержки 

![Оптимизация задержки](media/event-hubs-federation-overview/latency-optimization.jpg)  

Потоки событий записываются производителями, но могут быть прочитаны в любое количество раз потребителями событий. Для сценариев, где поток событий в регионе совместно используется несколькими потребителями и должен быть постоянно доступен во время обработки аналитики, находящейся в другом регионе, или при наличии всех требований, которые могут привести к нехватке одновременных потребителей, может оказаться полезным разместить копию потока событий рядом с обработчиком аналитики, чтобы уменьшить задержку обмена данными. 

Хорошим примером того, когда репликация должна быть предпочтительнее, чем использование событий удаленно из разных регионов, особенно в тех случаях, когда регионы находятся далеко друг от друга, например Европа и Австралия почти антиподес, географически и сетевые задержки могут легко превысить 250 мс для любого кругового пути.
Скорость освещения не позволяет ускорить работу, но можно уменьшить число циклов круговых поездок с высокой задержкой для взаимодействия с данными.

Руководство по 
- [Шаблон репликации][4]

### <a name="validation-reduction-and-enrichment"></a>Проверка, сокращение и обогащение

![Проверка, сокращение, обогащение](media/event-hubs-federation-overview/validation-enrichment.jpg)  

Потоки событий могут отправляться в концентратор событий внешними клиентами для вашего решения. Такие потоки событий могут потребовать, чтобы события, отправленные извне, проверялись на соответствие заданной схеме, а также для удаления несоответствующих событий. 

В сценариях, где клиенты имеют ограниченную пропускную способность, так как это происходит во многих сценариях ""Интернет вещей"" с лимитным пропускной способностью или когда события изначально отправляются в сетях, не относящихся к IP-адресу с ограниченными размерами пакетов, события могут быть дополнены с помощью ссылочных данных, чтобы добавить дополнительный контекст для использования нисходящими обработчиками событий

В других случаях, особенно при консолидации потоков, данные событий могут уменьшиться по сложности или объему, пропуская некоторые подробности.

Любая из этих операций может выполняться в рамках репликации, консолидации или слияния потоков. 

Руководство по 
- [Шаблон редактора][6]

### <a name="integration-with-analytics-services"></a>Интеграция со службами аналитики

![Интеграция со службами аналитики](media/event-hubs-federation-overview/integration.jpg)

Некоторые облачные службы аналитики Azure, такие как Azure Stream Analytics или Azure синапсе, лучше работают с потоковой или предварительно пакетированными данными из концентраторов событий Azure, а концентраторы событий Azure также обеспечивают интеграцию с несколькими пакетами аналитики с открытым кодом, такими как Apache Самза, Apache Флинк, Apache Spark и Apache Storm. 

Если решение в основном использует служебную шину или службу "Сетка событий", эти события можно легко сделать доступными для таких систем аналитики, а также для архивации с помощью записи концентраторов событий, если они передаются в концентратор событий. Служба "Сетка событий" может сделать это с помощью своей [интеграции с концентратором событий](../event-grid/handler-event-hubs.md). для служебной шины необходимо следовать инструкциям по репликации служебной [шины](https://github.com/Azure-Samples/azure-messaging-replication-dotnet/tree/main/functions/config/ServiceBusCopyToEventHub).

Azure Stream Analytics [интегрируется с концентраторами событий напрямую](../stream-analytics/stream-analytics-define-inputs.md#stream-data-from-event-hubs).

Руководство по 
- [Шаблон репликации][4]

### <a name="consolidation-and-normalization-of-event-streams"></a>Консолидация и нормализация потоков событий

![Консолидация и нормализация потоков событий](media/event-hubs-federation-overview/consolidation.jpg)

Глобальные решения часто состоят из национальных объемов, которые во многом независимы, в том числе с помощью собственных возможностей аналитики, но для супра-региона и глобальной аналитики потребуется интегрированная перспектива, и именно поэтому централизованная консолидация тех же потоков событий, которые оцениваются в соответствующих регионах для локальной перспективы. 

Нормализация — это разновидность сценария консолидации, в результате которой два или более входящих потока событий имеют одинаковые типы событий, но с разными структурами или разными кодировками, а события, которые чаще всего преобразуются в код или преобразованы, прежде, чем они могут быть использованы. 

Нормализация может также включать в себя криптографические операции, такие как расшифровка сквозных полезных данных и их повторное шифрование с помощью различных ключей и алгоритмов для аудитории-получателя. 

Руководство по 
- [Шаблон слияния][5]
- [Шаблон редактора][6]

### <a name="splitting-and-routing-of-event-streams"></a>Разделение и маршрутизация потоков событий

![Разделение и маршрутизация потоков событий](media/event-hubs-federation-overview/splitting.jpg)

Концентраторы событий Azure иногда используются в сценариях "публикация-подписка", где входящие торрент событий значительно превышают емкость служебной шины Azure или службы "Сетка событий Azure", обе из которых имеют встроенную фильтрацию и возможности распространения подписки и являются предпочтительными для этого шаблона. 

Хотя истинная функция публикации-подписки оставляет его подписчикам для выбора нужных событий, шаблон разбиения имеет возможность сопоставлять события в секции с предварительно заданной моделью распространения и назначенными потребителями, а затем монопольно извлекать из "их секции". Когда концентратор событий замещает общий трафик в буфер, содержимое определенной секции, представляющее долю исходного объема пропускной способности, затем может быть реплицировано в очередь для обеспечения надежного, транзакционного и конкурентного потребления потребителей.

Многие сценарии, в которых концентраторы событий в основном используются для перемещения событий в пределах приложения внутри региона, имеют несколько случаев, когда события SELECT, возможно, только из одной секции, также должны быть доступны в других местах. Этот сценарий аналогичен сценарию разбиения, но может использовать масштабируемый маршрутизатор, который считает все сообщения, поступающие в концентратор событий, и выборочно выбирать всего лишь несколько для маршрутизации и может отличать целевые объекты маршрутизации по метаданным или содержимому событий. 

Руководство по
- [Шаблон маршрутизации][7]

### <a name="log-projections"></a>Ведение журнала проекций 

![Проекция журнала](media/event-hubs-federation-overview/log-projection.jpg)

В некоторых сценариях требуется доступ к последнему значению, отправленному для любого подпотока события, и, как правило, отличается ключом секции. В Apache Kafka это часто достигается путем включения "сжатия журнала" в разделе, который удаляет все события, кроме последнего, с меткой любого уникального ключа. Подход к сжатию журнала имеет три недостатка: 

- Для сжатия требуется непрерывная реорганизация журнала, которая является чрезмерно дорогостоящей операцией для брокера, оптимизированного для рабочих нагрузок только для добавления. 
- Сжатие является необратимым и не поддерживает сжатые и несжатые перспективы того же потока.
- В сжатом потоке по-прежнему имеется модель последовательного доступа. Это означает, что для поиска требуемого значения в журнале требуется чтение всего журнала в худшем случае, что обычно приводит к оптимизации, которые реализуют точный шаблон, представленный здесь: проецирование содержимого журнала в базу данных или кэш. 

В конечном итоге, сжатый журнал является хранилищем «ключ-значение» и, таким образом, является наихудшим возможным вариантом реализации такого магазина. Это гораздо более эффективно для уточняющих запросов и для создания и использования постоянной проекции журнала на подходящее хранилище "ключ — значение" или другую базу данных. 

Так как события являются неизменяемыми и порядок всегда сохраняется в журнале, любая проекция журнала в хранилище «ключ-значение» всегда будет идентична для одного и того же диапазона событий, то есть проекция, которую вы обновляете, всегда предоставляет полномочное представление, и нет никаких веских причин перестраивать его из содержимого журнала после его создания. 

Руководство по
- [Проекция журнала][8]

## <a name="replication-application-technologies"></a>Технологии приложений репликации

Для реализации приведенных выше шаблонов требуется масштабируемая и надежная среда выполнения для задач репликации, которые необходимо настроить и запустить. В Azure среды выполнения, которые лучше всего подходят для таких задач, — это [Azure Stream Analytics](../stream-analytics/stream-analytics-introduction.md) задачах репликации потоков с отслеживанием состояния и [функций Azure](../azure-functions/functions-overview.md) для задач репликации без отслеживания состояния.

### <a name="stateful-replication-applications-in-azure-stream-analytics"></a>Приложения репликации с отслеживанием состояния в Azure Stream Analytics

Для приложений репликации с отслеживанием состояния, которые должны рассматривать отношения между событиями, создавать составные события, расширять события или сокращать события, создавать агрегаты данных и преобразовывать полезные данные событий, [Azure Stream Analytics](../stream-analytics/stream-analytics-introduction.md) является наилучшим вариантом реализации.

В Azure Stream Analytics вы [создаете задания](../stream-analytics/stream-analytics-quick-create-portal.md) , которые объединяют [входные](../stream-analytics/stream-analytics-add-inputs.md) и [выходные](../stream-analytics/stream-analytics-define-outputs.md) данные и интегрируют их из входных данных с помощью [запросов](/stream-analytics-query/stream-analytics-query-language-reference) , которые возвращают результат, который затем становится доступным для выходных данных.

Запросы основаны на [языке SQL-запросов](/stream-analytics-query/stream-analytics-query-language-reference) и могут использоваться для простого фильтрования, сортировки, агрегирования и объединения данных потоковой передачи за определенный период времени. Этот язык SQL также можно расширить с помощью [JavaScript](../stream-analytics/stream-analytics-javascript-user-defined-functions.md) и [определяемых пользователем функций (UDF) C#](../stream-analytics/stream-analytics-edge-csharp-udf-methods.md). Вы можете легко настроить параметры упорядочивания и продолжительность временных окон при осуществлении операций агрегирования с помощью простых языковых конструкций и (или) конфигураций.

Каждое задание поддерживает один или несколько потоков вывода преобразованных данных. Вы можете также настроить действия по результатам анализа информации. Например, администратор может сделать следующее:

- отправлять данные в службы, такие как Функции Azure, разделы служебной шины или Очередь, чтобы активировать связи или нисходящие пользовательские рабочие процессы;
- отправлять данные на информационную панель Power BI для мониторинга в режиме реального времени;
- Храните данные в других службах хранилища Azure (например, Azure Data Lake, Azure синапсе Analytics и т. д.) для выполнения пакетной аналитики или обучения моделей машинного обучения на основе очень больших индексируемых пулов данных с предысторией.
- Проекции магазинов (также называемые материализованными представлениями) в базах данных ([база данных SQL](../stream-analytics/sql-database-output.md), [Cosmos DB](../stream-analytics/azure-cosmos-db-output.md) ).

### <a name="stateless-replication-applications-in-azure-functions"></a>Приложения репликации без отслеживания состояния в функциях Azure

Для задач репликации без отслеживания состояния, когда вы хотите пересылать события, не учитывая их полезные данные, или обрабатываете их по отдельности без необходимости учитывать отношения событий (за исключением их относительного порядка), можно использовать функции Azure, которые обеспечивают огромную гибкость.

Функции Azure имеют предварительно созданные, масштабируемые триггеры и выходные привязки для [концентраторов событий Azure](../azure-functions/functions-bindings-event-hubs.md), [центра Интернета вещей](../azure-functions/functions-bindings-event-iot.md)Azure, [служебной шины Azure, службы](../azure-functions/functions-bindings-service-bus.md)" [Сетка событий Azure](../azure-functions/functions-bindings-event-grid.md)" и [хранилища очередей azure](../azure-functions/functions-bindings-storage-queue.md), а также пользовательские расширения для [RabbitMQ](https://github.com/azure/azure-functions-rabbitmq-extension)и [Apache Kafka](https://github.com/azure/azure-functions-kafka-extension). Большинство триггеров динамически адаптируются к потребностям пропускной способности путем масштабирования количества параллельно выполняемых экземпляров на основе документированных метрик. 

Для создания проекций журналов функции Azure поддерживают выходные привязки для [Cosmos DB](../azure-functions/functions-bindings-cosmosdb-v2-output.md) и [хранилища таблиц Azure](../azure-functions/functions-bindings-storage-table-output.md).

Функции Azure могут выполняться с [управляемым удостоверением Azure](../active-directory/managed-identities-azure-resources/overview.md) и с ним. они могут содержать значения конфигурации для учетных данных в строго контролируемом хранилище в [Azure Key Vault](../key-vault/general/overview.md).

Функции Azure Кроме того позволяют задачам репликации напрямую интегрироваться с виртуальными сетями и [конечными точками службы](../virtual-network/virtual-network-service-endpoints-overview.md) Azure для всех служб обмена сообщениями Azure, и они легко интегрируются с [Azure Monitor](../azure-monitor/overview.md).

При использовании плана потребления функций Azure готовые триггеры могут даже масштабироваться до нуля, а для репликации нет доступных сообщений. Это означает отсутствие затрат на поддержание готовности к масштабированию. ключевым недостатком использования плана потребления является то, что задержка задач репликации, "Пробуждение" из этого состояния, значительно выше, чем планы размещения, в которых работает инфраструктура.  

В отличие от всех этих, наиболее распространенных механизмов репликации для обмена сообщениями и событий, таких как [MirrorMaker](http://kafka.apache.org/documentation/#basic_ops_mirror_maker) Apache Kafka, требуется предоставить среду размещения и самостоятельно масштабировать модуль репликации. Это включает в себя настройку и интеграцию функций безопасности и сети, а также упрощает поток данных мониторинга, а затем не имеет возможности внедрять в последовательность пользовательские задачи репликации. 

### <a name="choosing-between-azure-functions-and-azure-stream-analytics"></a>Выбор между функциями Azure и Azure Stream Analytics

Azure Stream Analytics (ASA) — лучший вариант, если необходимо обработать полезные данные событий при их репликации. ASA может копировать события по одному или создавать статистические выражения, которые сжимают данные потоков событий перед их пересылкой. Он может легко нанести дополнительные [Ссылочные данные](../stream-analytics/stream-analytics-use-reference-data.md) , хранящиеся в хранилище BLOB-объектов Azure или базе данных SQL Azure, без необходимости импортировать эти данные в поток.

С помощью ASA можно легко создавать постоянные материализованные представления потоков в базах данных Hyper-Scale. Это очень старший подход к неуклюжим модели сжатия журнала для Apache Kafka и временных проекций табличных таблиц на стороне клиента для потоков Kafka. 

ASA может легко обрабатывать события, имеющие полезные данные, закодированные в [форматах CSV, JSON и Apache Avro](../stream-analytics/stream-analytics-parsing-json.md) . Кроме того, можно подключать [пользовательские десериализаторы](../stream-analytics/custom-deserializer.md) для любого другого формата.

Для всех задач репликации, в которых требуется копировать потоки событий "как есть" и не затрагивая полезные данные, или если необходимо реализовать маршрутизатор, выполнить криптографию, изменить кодировку полезных данных или, если в противном случае требуется полный контроль над содержимым потока данных, лучшим вариантом является функция Azure.

## <a name="next-steps"></a>Next Steps

В этой статье мы изучили ряд шаблонов Федерации и объяснили роль функций Azure в качестве среды выполнения репликации событий и обмена сообщениями в Azure.

Далее вы можете ознакомиться с тем, как настроить приложение репликатора с помощью Azure Stream Analytics или функций Azure, а затем реплицировать потоки событий между концентраторами событий и другими системами обработки и обмена событиями.

- [Шаблоны задач репликации событий][10]
- [Обработка данных с помощью Azure Stream Analytics][9]
- [Приложения репликатора событий в функциях Azure][1]
- [Репликация событий между концентраторами событий][2]
- [Репликация событий в служебную шину Azure][3]

[1]: event-hubs-federation-replicator-functions.md
[2]: https://github.com/Azure-Samples/azure-messaging-replication-dotnet/tree/main/functions/config/EventHubCopy
[3]: https://github.com/Azure-Samples/azure-messaging-replication-dotnet/tree/main/functions/config/EventHubCopyToServiceBus
[4]: event-hubs-federation-patterns.md#replication
[5]: event-hubs-federation-patterns.md#merge
[6]: event-hubs-federation-patterns.md#editor
[7]: event-hubs-federation-patterns.md#routing
[8]: event-hubs-federation-patterns.md#log-projection
[9]: process-data-azure-stream-analytics.md
[10]: event-hubs-federation-patterns.md#replication