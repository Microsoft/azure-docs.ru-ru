---
title: Управление библиотеками для Apache Spark
description: Узнайте, как добавлять библиотеки, используемые Apache Spark, в Azure синапсе Analytics и управлять ими.
services: synapse-analytics
author: midesa
ms.service: synapse-analytics
ms.topic: conceptual
ms.date: 10/16/2020
ms.author: midesa
ms.reviewer: jrasnick
ms.subservice: spark
ms.openlocfilehash: 0458fb8b140166b7bdf0fc0df41dbb207fdce3c9
ms.sourcegitcommit: e972837797dbad9dbaa01df93abd745cb357cde1
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/14/2021
ms.locfileid: "100518527"
---
# <a name="manage-libraries-for-apache-spark-in-azure-synapse-analytics"></a>Управление библиотеками для Apache Spark в Azure синапсе Analytics

Библиотеки предоставляют многократно используемый код, который может потребоваться включить в программы или проекты. Чтобы сделать код, разработанный сторонним приложением, доступным для приложений, можно установить библиотеку на одном из несерверных пулов Apache Spark. После установки библиотеки для пула Spark она будет доступна для всех сеансов, использующих тот же пул. 

## <a name="before-you-begin"></a>Подготовка к работе
- Чтобы установить и обновить библиотеки, необходимо иметь разрешения на доступ к **данным большого двоичного объекта хранилища** или **владельца BLOB-объектов** хранилища в основной учетной записи хранения Gen2, связанной с рабочей областью Azure синапсе Analytics.
  
## <a name="default-installation"></a>Установка по умолчанию
Apache Spark в Azure синапсе Analytics содержит полную установку Анакондас, а также дополнительные библиотеки. Список полных библиотек можно найти по адресу [Apache Spark поддержки версий](apache-spark-version-support.md). 

При запуске экземпляра Spark эти библиотеки будут автоматически добавлены. Дополнительные Python и пользовательские пакеты можно добавить на уровне пула Spark.


## <a name="manage-python-packages"></a>Управление пакетами Python
Определив библиотеки, которые вы хотите использовать для приложения Spark, можно установить их в пул Spark. 

  `pip freeze` Для обновления виртуальной среды можно использовать файлrequirements.txt(выходные данные команды). Пакеты, перечисленные в этом файле для установки или обновления, загружаются из PyPI во время запуска пула. Этот файл требований используется при каждом создании экземпляра Spark из пула Spark.

> [!IMPORTANT]
> - Если устанавливаемый пакет является большим или занимает много времени, это повлияет на время запуска экземпляра Spark.
> - Пакеты, требующие поддержки компилятора во время установки, например GCC, не поддерживаются.
> - Пакеты не могут быть понижены, только добавляются или обновляются.
> - Изменение версии PySpark, Python, Scala/Java, .NET или Spark не поддерживается.
> - Установка пакетов из PyPI не поддерживается в рабочих областях с поддержкой DEP.


### <a name="requirements-format"></a>Формат требований

В следующем фрагменте кода показан формат файла требований. Имя пакета PyPi отображается вместе с точной версией. Этот файл соответствует формату, описанному в справочной документации по [замораживанию PIP](https://pip.pypa.io/en/stable/reference/pip_freeze/) . В этом примере закрепляется конкретная версия. 

```
absl-py==0.7.0
adal==1.2.1
alabaster==0.7.10
```

### <a name="install-python-packages"></a>Установка пакетов Python
При разработке приложения Spark может оказаться, что необходимо обновить существующие или установить новые библиотеки. Библиотеки можно обновлять во время или после создания пула.

> [!IMPORTANT]
> Чтобы установить библиотеки, необходимо иметь разрешения на доступ к данным BLOB-объекта хранилища или владельца BLOB-объектов хранилища в основной учетной записи хранения Gen2, связанной с рабочей областью синапсе.

#### <a name="install-packages-during-pool-creation"></a>Установка пакетов во время создания пула
Установка библиотек в пул Spark во время создания пула:
   
1. Перейдите к рабочей области Azure синапсе Analytics из портал Azure.
   
2. Выберите **создать пул Apache Spark** и перейдите на вкладку **Дополнительные параметры** . 
   
3. Отправьте файл конфигурации среды с помощью средства выбора файлов в разделе " **пакеты** " страницы. 
   
    ![Добавление библиотек Python во время создания пула](./media/apache-spark-azure-portal-add-libraries/apache-spark-azure-portal-add-library-python.png "Добавление библиотек Python")
 

#### <a name="install-packages-from-the-synapse-workspace"></a>Установка пакетов из рабочей области синапсе
Чтобы обновить или добавить дополнительные библиотеки в пул Spark на портале Azure синапсе Analytics, выполните следующие действия.

1.  Перейдите к рабочей области Azure синапсе Analytics из портал Azure.
   
2.  Запустите рабочую область Azure синапсе Analytics из портал Azure.

3.  Выберите **Управление** на главной панели навигации, а затем выберите **Пулы Apache Spark**.
   
4. Выберите один пул Spark и отправьте файл конфигурации среды с помощью средства выбора файлов в разделе "  **пакеты** " страницы.

    ![Добавление библиотек Python в синапсе](./media/apache-spark-azure-portal-add-libraries/apache-spark-azure-portal-update.png)
   
#### <a name="install-packages-from-the-azure-portal"></a>Установка пакетов из портал Azure
Чтобы установить библиотеку в пул Spark непосредственно из портал Azure:
   
 1. Перейдите к рабочей области Azure синапсе Analytics из портал Azure.
   
 2. В разделе **ресурсов синапсе** выберите вкладку **Пулы Apache Spark** и выберите пул Spark из списка.
   
 3. Выберите **пакеты** из раздела **Параметры** пула Spark. 

 4. Отправьте файл конфигурации среды с помощью средства выбора файлов.

    ![Снимок экрана, посвященный кнопке "отправить файл конфигурации среды".](./media/apache-spark-azure-portal-add-libraries/apache-spark-add-library-azure.png "Добавление библиотек Python")

### <a name="verify-installed-libraries"></a>Проверка установленных библиотек

Чтобы проверить, установлены ли правильные версии правильных библиотек, выполните приведенный ниже код.

```python
import pkg_resources
for d in pkg_resources.working_set:
     print(d)
```
### <a name="update-python-packages"></a>Обновление пакетов Python
Пакеты можно добавлять или изменять в любое время между сеансами. Новый файл конфигурации пакета будет перезаписывать существующие пакеты и версии.  

Чтобы обновить или удалить библиотеку, выполните следующие действия.
1. Перейдите к рабочей области Azure синапсе Analytics. 

2. С помощью портал Azure или рабочей области Azure синапсе выберите **пул Apache Spark** , который требуется обновить.

3. Перейдите к разделу " **пакеты** " и передайте новый файл конфигурации среды.
   
4. После сохранения изменений необходимо будет завершить активные сеансы и разрешить перезапуск пула. При необходимости можно принудительно завершить активные сеансы, установив флажок для **принудительного применения новых параметров**.

    ![Добавление библиотек Python](./media/apache-spark-azure-portal-add-libraries/update-libraries.png "Добавление библиотек Python")
   

> [!IMPORTANT]
> Выбрав параметр для **принудительного создания новых параметров**, вы завершите все текущие сеансы для выбранного пула Spark. После завершения сеансов необходимо будет дождаться перезапуска пула. 
>
> Если этот параметр не установлен, необходимо дождаться завершения текущего сеанса Spark или завершить его вручную. После завершения сеанса необходимо разрешить перезапуск пула. 


## <a name="manage-a-python-wheel"></a>Управление колесом Python

### <a name="install-a-custom-wheel-file"></a>Установка пользовательского файла колеса
Пользовательские пакеты Wheel можно установить в пул Apache Spark, отгружая все файлы колеса в учетную запись Azure Data Lake Storage (Gen2), связанную с рабочей областью синапсе. 

Файлы должны быть отправлены по следующему пути в контейнере учетной записи хранения по умолчанию: 

```
abfss://<file_system>@<account_name>.dfs.core.windows.net/synapse/workspaces/<workspace_name>/sparkpools/<pool_name>/libraries/python/
```

Может потребоваться добавить ```python``` папку в ```libraries``` папку, если она еще не существует.

>[!IMPORTANT]
>Пользовательские пакеты можно добавлять или изменять между сеансами. Тем не менее для просмотра обновленного пакета необходимо подождать, пока пул и сеанс перезапускаются.

## <a name="next-steps"></a>Дальнейшие шаги
- Просмотр библиотек по умолчанию: [Поддержка версий Apache Spark](apache-spark-version-support.md)
