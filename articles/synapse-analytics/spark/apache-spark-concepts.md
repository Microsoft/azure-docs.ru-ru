---
title: Основные принципы работы Apache Spark
description: Введение в основные понятия об использовании Apache Spark в Azure Synapse Analytics.
services: synapse-analytics
author: euangMS
ms.service: synapse-analytics
ms.topic: overview
ms.subservice: spark
ms.date: 04/15/2020
ms.author: euang
ms.reviewer: euang
ms.openlocfilehash: 51b2e8cd968c4c14777d196d90686b13158aef42
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98120314"
---
# <a name="apache-spark-in-azure-synapse-analytics-core-concepts"></a>Ключевые концепции Apache Spark в Azure Synapse Analytics

Apache Spark — это платформа параллельной обработки, которая поддерживает обработку в памяти, чтобы повысить производительность приложений для анализа больших данных. Apache Spark в Azure Synapse Analytics — это одна из реализаций Apache Spark в облаке, предоставляемая корпорацией Майкрософт. 

Azure Synapse упрощает создание и настройку компонентов Spark в Azure. Azure Synapse предоставляет различные реализации компонентов Spark, которые здесь описаны.

## <a name="spark-pools"></a>Пулы Spark

Бессерверный пул Apache Spark создается на портале Azure. Это определение пула Spark, при реализации которого создается экземпляр Spark, обрабатывающий данные. Созданный пул Spark существует только в виде метаданных. Соответственно, ресурсы не потребляются и не выполняются, а значит за них не взимается плата. В пуле Spark есть ряд свойств, управляющих характеристиками экземпляра Spark. Эти характеристики среди прочего включают имя, размер, поведение масштабирования и время жизни.

Для создания пулов Spark не нужны средства или ресурсы, поэтому их можно создавать в любом количестве с любыми конфигурациями. К пулам Spark также можно применять разрешения, чтобы предоставлять пользователям доступ только к определенным из них.

Рекомендуется создавать пулы Spark малого размера для разработки и отладки, а более крупные пулы — для производственных рабочих нагрузок.

Сведения о том, как создать пул Spark в Azure Synapse Analytics и просмотреть все его свойства, см. в кратком руководстве [Создание нового бессерверного пула Apache Spark с помощью портала Azure](../quickstart-create-apache-spark-pool-portal.md).

## <a name="spark-instances"></a>Экземпляры Spark

При подключении к пулу Spark, создании сеанса и выполнении задания создаются экземпляры Spark. У нескольких пользователей может быть доступ к одному и тому же пулу Spark, поэтому для каждого пользователя, который подключается, создается экземпляр Spark. 

Если при отправке второго задания в пуле есть емкость, существующий экземпляр Spark также будет иметь емкость. Затем существующий экземпляр обработает задание. В противном случае, если емкость доступна на уровне пула, будет создан новый экземпляр Spark.

## <a name="examples"></a>Примеры

### <a name="example-1"></a>Пример 1

- Создайте пул Spark с именем SP1 и фиксированным размером кластера — 20 узлов.
- Если вы отправите задание записной книжки J1, использующее 10 узлов, будет создан экземпляр Spark с именем SI1 для обработки задания.
- Если вы отправите еще одно задание J2, использующее 10 узлов, в пуле и экземпляре все еще будет емкость и SI1 обработает J2.
- Если бы J2 были необходимы 11 узлов, в SP1 и SI1 не хватило бы емкости. В таком случае если J2 поступит из записной книжки, задание будет отклонено. Если J2 поступит из пакетного задания, то будет поставлено в очередь.

### <a name="example-2"></a>Пример 2

- Создайте пул Spark с именем SP2 и со включенным автомасштабированием 10–20 узлов.
- Если вы отправите задание записной книжки с именем J1, в котором используются 10 узлов, будет создан экземпляр Spark с именем SI1 для обработки задания.
- Если вы отправите еще одно задание с именем J2, в котором используются 10 узлов, в пуле все еще будет емкость, поэтому экземпляр автоматически увеличится до 20 узлов и обработает J2.

### <a name="example-3"></a>Пример 3

- Создайте пул Spark с именем SP1 и фиксированным размером кластера — 20 узлов.
- Если вы отправите задание записной книжки J1, использующее 10 узлов, будет создан экземпляр Spark с именем SI1 для обработки задания.
- Если другой пользователь с именем U2 отправит задание J3, в котором используются 10 узлов, будет создан экземпляр Spark с именем SI2 для обработки задания.
- Если сейчас вы отправите еще одно задание, J2, использующее 10 узлов, в пуле все еще будет емкость и экземпляр, поэтому J2 будет обработано SI1.

## <a name="quotas-and-resource-constraints-in-apache-spark-for-azure-synapse"></a>Квоты и ограничения ресурсов в Apache Spark для Azure Synapse

### <a name="workspace-level"></a>Уровень рабочей области

В каждой рабочей области Azure Synapse есть квота виртуальных ядер по умолчанию, которую можно использовать для Spark. Квота разделяется на квоту пользователя и квоту потока данных, чтобы предотвратить использование всех виртуальных ядер в рабочей области одним шаблоном использования. Квота различается в зависимости от типа подписки, но является симметричной между пользователем и потоком данных. Тем не менее, если запросить больше виртуальных ядер, чем осталось в рабочей области, отобразится следующая ошибка:

```console
Failed to start session: [User] MAXIMUM_WORKSPACE_CAPACITY_EXCEEDED
Your Spark job requested 480 vcores.
However, the workspace only has xxx vcores available out of quota of yyy vcores.
Try reducing the numbers of vcores requested or increasing your vcore quota. Click here for more information - https://go.microsoft.com/fwlink/?linkid=213499
```

Ссылка в сообщении указывает на эту статью.

В следующей статье описывается, как запросить увеличение квоты виртуальных ядер в рабочей области.

- Выберите "Azure Synapse Analytics" в качестве типа службы.
- В окне сведений о квоте выберите Apache Spark (виртуальное ядро) на рабочую область.

[Запросить увеличение емкости на портале Azure](../../azure-portal/supportability/per-vm-quota-requests.md#request-a-standard-quota-increase-from-help--support)

### <a name="spark-pool-level"></a>Уровень пула Spark

При определении пула Spark вы эффективно определяете квоту для каждого пользователя в этом пуле. Если запустить несколько записных книжек или заданий или их сочетание, можно исчерпать квоты пула. В этом случае будет создано сообщение об ошибке, как показано ниже:

```console
Failed to start session: Your Spark job requested xx vcores.
However, the pool is consuming yy vcores out of available zz vcores.Try ending the running job(s) in the pool, reducing the numbers of vcores requested, increasing the pool maximum size or using another pool
```

Чтобы решить эту проблему, необходимо уменьшить использование ресурсов пула перед отправкой нового запроса ресурсов путем запуска записной книжки или задания.

## <a name="next-steps"></a>Дальнейшие действия

- [Azure Synapse Analytics](../index.yml)
- [Документация по Apache Spark](https://spark.apache.org/docs/2.4.5/)