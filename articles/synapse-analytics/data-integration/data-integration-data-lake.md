---
title: Прием данных в Azure Data Lake Storage 2-го поколения
description: Узнайте, как принимать данные в Azure Data Lake Storage 2-го поколения с помощью Azure Synapse Analytics
services: synapse-analytics
author: djpmsft
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 04/15/2020
ms.author: daperlov
ms.reviewer: jrasnick
ms.openlocfilehash: fbc4f11b450a645002daedc800d4fed74ed37a3d
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98219578"
---
# <a name="ingest-data-into-azure-data-lake-storage-gen2"></a>Прием данных в Azure Data Lake Storage 2-го поколения 

В этой статье объясняется, как реализовать прием данных из одного расположения в другое в учетной записи хранения Azure Data Lake 2-го поколения с помощью Azure Synapse Analytics.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**: Если у вас еще нет подписки Azure, создайте [бесплатную учетную запись](https://azure.microsoft.com/free/) Azure, прежде чем начинать работу.
* **учетную запись хранения,** Azure Data Lake 2-го поколения используется в качестве хранилища *исходных* данных. Если у вас нет учетной записи хранения Azure, создайте ее по инструкциям из статьи [Создание учетной записи хранения Azure](../../storage/common/storage-account-create.md?bc=%2fazure%2fsynapse-analytics%2fbreadcrumb%2ftoc.json&toc=%2fazure%2fsynapse-analytics%2ftoc.json).

## <a name="create-linked-services"></a>Создание связанных служб

В Azure Synapse Analytics связанная служба используется для определения сведений о подключении к другим службам. В этом разделе показано, как добавить Azure Synapse Analytics и Azure Data Lake 2-го поколения в качестве связанных служб.

1. Откройте пользовательский интерфейс Azure Synapse Analytics и перейдите на вкладку **Управление**.
1. В разделе **Внешние подключения** выберите **Связанные службы**.
1. Чтобы добавить связанную службу, выберите **Создать**.
1. Выберите плитку Azure Data Lake Storage 2-го поколения из списка и нажмите кнопку **продолжить**.
1. Введите учетные данные для проверки подлинности. В настоящее время поддерживаются следующие типы проверки подлинности: ключ учетной записи, субъект-служба и управляемое удостоверение. Выберите Проверить подключение, чтобы проверить правильность учетных данных. 
1. По завершении нажмите кнопку **Создать**.

## <a name="create-pipeline"></a>Создание конвейера

Конвейер содержит логический поток для выполнения набора действий. В этом разделе вы создадите конвейер, содержащий действие копирования, которое принимает данные из Azure Data Lake Gen 2 в выделенный пул SQL.

1. Перейдите на вкладку **orchestration** (управление). Выберите значок "плюс" рядом с заголовком конвейеров и выберите **конвейер**.
1. В разделе **Move and Transform** (Перемещение и преобразование) на панели действий перетащите **Копирование данных** на холст конвейера.
1. Выберите действие копирования и перейдите на вкладку **источник** . Выберите **создать** , чтобы создать новый исходный набор данных.
1. Выберите Azure Data Lake Storage 2-го поколения в качестве хранилища данных и нажмите кнопку продолжить.
1. Выберите DelimitedText в качестве формата и нажмите кнопку продолжить.
1. На панели задания свойств выберите созданную связанную службу ADLS. Укажите путь к исходным данным и укажите, содержит ли первая строка заголовок. Можно импортировать схему из хранилища файлов или из примера файла. Выберите ОК после завершения.
1. Перейдите на вкладку **приемник** . Выберите **создать, чтобы** создать новый набор данных приемника.
1. Выберите Azure Data Lake Storage Gen2 в качестве хранилища данных и нажмите кнопку продолжить.
1. Выберите DelimitedText в качестве формата и нажмите кнопку продолжить.
1. На панели задания свойств выберите созданную связанную службу ADLS. Укажите путь к папке, в которую нужно записать данные. Выберите ОК после завершения.

## <a name="debug-and-publish-pipeline"></a>Отладка и публикация конвейера

Завершив настройку конвейера, можно выполнить отладку перед публикацией артефактов, чтобы убедиться, что все правильно.

1. Чтобы выполнить отладку конвейера, на панели инструментов щелкните **Отладка**. Состояние выполнения конвейера вы можете найти на вкладке **Выходные данные** в нижней части окна. 
1. После успешного запуска конвейера в верхней панели инструментов выберите **Опубликовать все**. Это действие опубликует сущности (наборы данных и конвейеры), которые вы создали в службе Synapse Analytics.
1. Дождитесь сообщения **Successfully published** (Публикация выполнена). Чтобы отобразить уведомления, нажмите кнопку в виде колокольчика в правом верхнем углу. 


## <a name="trigger-and-monitor-the-pipeline"></a>Активация и мониторинг конвейера

На этом шаге вы вручную активируете конвейер, опубликованный ранее. 

1. Выберите **Добавить триггер** на панели инструментов, а затем **Trigger Now** (Запустить сейчас). На странице **Pipeline Run** (Запуск конвейера) нажмите кнопку **Готово**.  
1. Перейдите на вкладку **Монитор** на левой боковой панели. Вы увидите выполнение конвейера, которое вы только что активировали вручную. Ссылки в столбце **действий** позволят вам просмотреть подробные сведения о действиях и (или) повторно выполнить конвейер.
1. Чтобы просмотреть запуски действий, связанные с этим запуском конвейера, щелкните ссылку **View Activity Runs** (Просмотр запусков действий) в столбце **Действия**. В нашем примере определено только одно действие, поэтому в списке вы увидите только одну запись. Чтобы увидеть сведения об операции копирования, щелкните ссылку **Сведения** (значок очков) в столбце **Действия**. Выберите **Конвейеры Runs** (Запуски конвейера) в верхней части окна, чтобы вернуться к представлению Pipeline Runs (Запуски конвейера). Чтобы обновить список, нажмите кнопку **Обновить**.
1. Убедитесь, что данные правильно записаны в выделенный пул SQL.


## <a name="next-steps"></a>Дальнейшие действия

Дополнительные сведения об интеграции данных для Azure синапсе Analytics см. в статье прием [данных в выделенном пуле SQL](data-integration-sql-pool.md) .