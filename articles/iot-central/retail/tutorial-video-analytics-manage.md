---
title: Руководство по мониторингу видео с помощью шаблона приложения "Видеоаналитика — распознавание объектов и движения" для Azure IoT Central
description: В этом руководстве показано, как использовать панели мониторинга в шаблоне приложения "Видеоаналитика — распознавание объектов и движения", чтобы управлять камерами и отслеживать видеопоток.
services: iot-central
ms.service: iot-central
ms.subservice: iot-central-retail
ms.topic: tutorial
ms.author: nandab
author: KishorIoT
ms.date: 07/31/2020
ms.openlocfilehash: fbfef094cd062e437f2a28369162de96631ef41b
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "99832612"
---
# <a name="tutorial-monitor-and-manage-a-video-analytics---object-and-motion-detection-application"></a>Руководство по мониторингу и управлению видео с помощью приложения "Видеоаналитика — распознавание объектов и движения"

В этом руководстве описано следующее:
> [!div class="checklist"]
> * добавление камер обнаружения объектов и движения в приложение IoT Central;
> * управление потоками видео и их воспроизведение при обнаружении интересных событий.

## <a name="prerequisites"></a>Предварительные требования

Перед началом работы необходимо изучить следующие ресурсы:

* Статья [Руководство. Создание приложения видеоаналитики для распознавания объектов и движения в Azure IoT Central (YOLO v3)](./tutorial-video-analytics-create-app-yolo-v3.md) или [Руководство. Создание приложения видеоаналитики для распознавания объектов и движения в Azure IoT Central (OpenVINO)&trade;](tutorial-video-analytics-create-app-openvino.md).
* [Руководство по созданию экземпляра IoT Edge для видеоаналитики (виртуальная машина Linux)](tutorial-video-analytics-iot-edge-vm.md) или [Руководство по созданию экземпляра IoT Edge для видеоаналитики (Intel NUC)](tutorial-video-analytics-iot-edge-nuc.md).

Чтобы запустить приложение для просмотра видео, на локальном компьютере необходимо установить [Docker](https://www.docker.com/products/docker-desktop).

## <a name="add-an-object-detection-camera"></a>Добавление камеры обнаружения объектов

В приложении IoT Central перейдите к ранее созданному устройству **LVA Gateway 001**. Затем выберите вкладку **Commands** (Команды).

Укажите приведенные в следующей таблице значения в качестве значений для параметров команды **Add Camera Request** (Запрос на добавление камеры). Значения в этой таблице представлены на основе предположения о том, что вы используете на виртуальной машине Azure имитацию камеры. Если у вас настоящая камера, измените эти значения соответствующим образом.

| Поле| Описание| Образец значения|
|---------|---------|---------|
| Camera ID (Идентификатор камеры)      | Идентификатор устройства для подготовки | camera-003 |
| Camera Name (Название камеры)    | Понятное имя           | Камера обнаружения объектов |
| RTSP Url (URL-адрес RTSP)       | Адрес потока   | RTSP://10.0.0.4:554/media/camera-300s.mkv|
| RTSP Username (Имя пользователя RTSP)  |                         | пользователь    |
| RTSP Password (Пароль RTSP)  |                         | password    |
| Тип обнаружения | "Раскрывающийся список";                | Обнаружение объектов       |

Щелкните **Run** (Запустить), чтобы добавить устройство камеры:

:::image type="content" source="media/tutorial-video-analytics-manage/add-camera.png" alt-text="Добавление камеры":::

> [!NOTE]
> В приложении уже существует шаблон устройства **LVA Edge Object Detector** (Детектор объектов LVA Edge).

## <a name="add-a-motion-detection-camera-optional"></a>Добавление камеры обнаружения движения (необязательно)

Если к вашему устройству шлюза IoT Edge подключены две камеры, повторите предыдущие шаги и добавьте в приложение вторую камеру для обнаружения движения. Укажите для нее другие значения параметров **Camera ID**, **Camera Name** и **RTSP Url**.

## <a name="view-the-downstream-devices"></a>Просмотр подчиненных устройств

Выберите вкладку **Downstream Devices** (Подчиненные устройства) для устройства **LVA Gateway 001**, чтобы увидеть только что добавленные камеры:

:::image type="content" source="media/tutorial-video-analytics-manage/inspect-downstream.png" alt-text="Проверить":::

Камеры также появятся в списке на странице **Devices** (Устройства) в приложении.

## <a name="configure-and-manage-the-camera"></a>Настройка камеры и управление ею

Перейдите к устройству **camera-003** и выберите вкладку **Manage** (Управление).

Подтвердите значения по умолчанию или измените их, если нужны другие свойства устройства.

**Параметры камеры**

| Свойство | Описание | Рекомендуемое значение |
|-|-|-|
| Video Playback Host (Узел воспроизведения видео) | Узел для размещения средства просмотра "Проигрыватель мультимедиа Azure" | http://localhost:8094 |

**Операции и диагностика LVA**

| Свойство | Описание | Рекомендуемое значение |
|-|-|-|
| Автозапуск | Запуск обнаружения объектов при перезапуске шлюза LVA | Флажок установлен |
| Debug Telemetry (Телеметрия отладки) | Трассировка событий | Необязательно |
|Inference Timeout (sec) (Время ожидания вывода, с)| Количество времени, по истечении которого считается, что вывод остановлен | 20 |

**Обнаружение объектов с помощью ИИ**

| Свойство | Описание | Рекомендуемое значение |
|-|-|-|
| Max Inference Capture Time (sec) (Максимальное время захвата вывода, с) | Максимальное время захвата | 15 |
| Классы обнаружения | Строки, разделенные запятыми, с тегами обнаружения. Дополнительные сведения см. в [списке поддерживаемых тегов.](https://github.com/Azure/live-video-analytics/blob/master/utilities/video-analysis/yolov3-onnx/tags.txt) | truck, bus |
| Confidence Threshold (Порог достоверности) | Требуемый процент, определяющий достоверность обнаружения объекта | 70 |
| Inference Frame Sample Rate (fps) (Частота выборки для кадра вывода, кадр/с) | [Добавьте описание] | 2 |

Щелкните **Сохранить**.

Через несколько секунд появится подтверждающее сообщение **Accepted** (Принято) для каждого параметра:

:::image type="content" source="media/tutorial-video-analytics-manage/object-detection.png" alt-text="Обнаружение объектов":::

## <a name="start-lva-processing"></a>Начало обработки LVA

Перейдите к устройству **camera-003** и выберите вкладку **Commands** (Команды).

Выполните команду **Start LVA Processing** (Начать обработку LVA).

Когда выполнение этой команды завершится, проверьте журнал команд на наличие ошибок.

:::image type="content" source="media/tutorial-video-analytics-manage/start-processing.png" alt-text="Команда начала обработки LVA":::

## <a name="monitor-the-cameras"></a>Мониторинг камер

Перейдите к устройству **camera-003** и выберите вкладку **Dashboard** (Панель мониторинга).

:::image type="content" source="media/tutorial-video-analytics-manage/camera-dashboard.png" alt-text="Панель мониторинга камеры":::

На плитке **Detection Count** (Счетчик обнаружений) отображается среднее число обнаружений для каждого из выбранных объектов классов обнаружения за интервал длительностью в одну секунду.

Круговая диаграмма **Detection Classes** (Классы обнаружения) отображает процент обнаружений для каждого типа класса.

**Inference Event Video** (Видео событий вывода) — это список ссылок на ресурсы в Службах мультимедиа Azure, которые содержат данные обнаружения. Для этих ссылок используется проигрыватель узла, который описывается в следующем разделе.

## <a name="start-the-streaming-endpoint"></a>Запуск конечной точки потоковой передачи

Запустите конечную точку Служб мультимедиа, чтобы позволить клиентскому приложению проигрывателя мультимедиа выполнять потоковую передачу записанного видео:

* На портале Azure перейдите к группе ресурсов **lva-rg**.
* Откройте ресурс **Streaming Endpoint** (Конечная точка потоковой передачи).
* На странице **Streaming endpoint details** (Сведения о конечной точке потоковой передачи) выберите **Start** (Запустить). Вы увидите предупреждение о том, что при запуске конечной точки начнется начисление платы.

## <a name="view-stored-video"></a>Просмотр сохраненных видео

Прошли те времена, когда нужно было самостоятельно следить за камерами и реагировать на подозрительные кадры. Автоматическое размещение тегов событий и прямых ссылок на сохраненные видео с обнаружением вывода позволяет операторам служб безопасности находить интересующие их события в списке, а затем переходить по ссылкам для просмотра соответствующих видео.

Вы можете использовать [видеопроигрыватель AMP](https://github.com/Azure/live-video-analytics/tree/master/utilities/amp-viewer) для просмотра видео, сохраненных в учетной записи Служб мультимедиа Azure.

Приложение IoT Central сохраняет видео в Службах мультимедиа Azure, откуда вы можете выполнять потоковую передачу. Для воспроизведения видео, хранящегося в Службах мультимедиа Azure, потребуется видеопроигрыватель.

Убедитесь, что средство **Docker** запущено на локальном компьютере.

Откройте командную строку и выполните следующую команду, чтобы запустить видеопроигрыватель в контейнере Docker на локальном компьютере. Замените заполнители в этой команде значениями, которые вы ранее сохранили в файле *scratchpad.txt*. При создании субъекта-службы для учетной записи Служб мультимедиа вы зафиксировали значения `amsAadClientId`, `amsAadSecret`, `amsAadTenantId`, `amsSubscriptionId` и `amsAccountName`.

```bash
docker run -it --rm -e amsAadClientId="<FROM_AZURE_PORTAL>" -e amsAadSecret="<FROM_AZURE_PORTAL>" -e amsAadTenantId="<FROM_AZURE_PORTAL>" -e amsArmAadAudience="https://management.core.windows.net" -e amsArmEndpoint="https://management.azure.com" -e amsAadEndpoint="https://login.microsoftonline.com" -e amsSubscriptionId="<FROM_AZURE_PORTAL>" -e amsResourceGroup="<FROM_AZURE_PORTAL>" -e amsAccountName="<FROM_AZURE_PORTAL>" -p 8094:8094 mcr.microsoft.com/lva-utilities/amp-viewer:1.0-amd64
```

|Параметр Docker | Доступ к API AMS (JSON)|
|-|-|
|amsAadClientId| AadClientId|
|amsAadSecret| AadSecret |
|amsAadTenantId| AADTenantId |
|amsSubscriptionId| SubscriptionId|
|amsResourceGroup| ResourceGroup |
|amsAccountName| AccountName|

Перейдите к устройству **camera-003** и выберите вкладку **Dashboard** (Панель мониторинга). Затем щелкните одну из захваченных гиперссылок обнаружения объектов на плитке **Inference Event Video** (Видео событий вывода). Видеоконтент появится на странице, которую отображает локальный видеопроигрыватель:

:::image type="content" source="media/tutorial-video-analytics-manage/video-snippet.png" alt-text="Фрагмент видео":::

## <a name="change-the-simulated-devices-in-application-dashboards"></a>Изменение имитированных устройств на панелях мониторинга приложения

Панели мониторинга приложений первоначально заполняются данными телеметрии и свойствами, созданными на основе имитированных устройств IoT Central. Чтобы настроить плитки для получения телеметрии от реальных камер или симулятора Live555, выполните следующие действия.

1. Перейдите к панели мониторинга приложений **(Sample) Real Camera Monitor** (Мониторинг реальной камеры (пример)).
1. Выберите команду **Изменить**.
1. Выберите плитку **Note** (Примечание) и удалите ее.
1. Измените заголовок панели мониторинга на *Real Camera Monitor* (Мониторинг реальной камеры).
1. На плитке **Inference Count** (Счетчик вывода) щелкните значок настройки.
1. В разделе **Configure Chart** (Настройка диаграммы) выберите одну или несколько реальных камер из группы устройств **LVA Edge Object Detector** (Детектор объектов LVA Edge).
1. Выберите поле телеметрии `AI Inference Interface/Inference Count`.
1. Выберите **Обновить**.

1. Повторите эти шаги для следующих плиток.
    1. Для круговой диаграммы **Detection** (Обнаружение) используется тип телеметрии `AI Inference Interface/Inference/entity/tag/value`.
    1. Для **Inference** (Вывод) используется последнее известное значение `AI Inference Interface/Inference/entity/tag/value`.
    1. Для **Confidence %** (Процент достоверности) используется последнее известное значение `AI Inference Interface/Inference/entity/tag/confidence`.
    1. Для **Snapshot** (Моментальный снимок) используется `AI Inference Interface/Inference Image` в формате изображения.
    1. Для **Inference Event Video** (Видео события вывода) используется `AI Inference Interface/Inference Event Video` в формате ссылки.
1. Щелкните **Сохранить**.

Панель мониторинга **Real Camera Monitor** (Мониторинг реальной камеры) теперь отображает значения, полученные от реальной камеры:

:::image type="content" source="media/tutorial-video-analytics-manage/update-real-cameras.png" alt-text="Панель мониторинга приложения для реальных камер":::

## <a name="pause-processing"></a>Приостановка обработки

Вы можете приостановить обработку видео в реальном времени в приложении, сделав следующее.

1. В приложении перейдите на страницу **Commands** (Команды) для камеры обнаружения объектов. Затем выполните команду **Stop LVA Processing** (Прекратить обработку LVA).

1. Остановите конечную точку потоковой передачи для учетной записи служб мультимедиа:
    * На портале Azure перейдите к группе ресурсов **lva-rg**.
    * Щелкните ресурс **Streaming Endpoint** (Конечная точка потоковой передачи).
    * На странице **Streaming endpoint details** (Сведения о конечной точке потоковой передачи) выберите **Stop** (Остановить).

## <a name="clean-up-resources"></a>Очистка ресурсов

Если вы завершили работу с приложением, можете удалить все созданные ресурсы следующим образом:

1. В приложении IoT Central перейдите на страницу **Ваше приложение** в разделе **Администрирование**. Теперь щелкните **Удалить**.
1. На портале Azure удалите группу ресурсов **lva-rg**.
1. На локальном компьютере закройте контейнер Docker **amp-viewer**.

## <a name="next-steps"></a>Дальнейшие действия

Вы научились добавлять камеры в приложение IoT Central и настраивать для них обнаружение объектов и движения.

Чтобы узнать, как настроить исходный код для модулей IoT Edge, изучите следующее руководство:

> [!div class="nextstepaction"]
> [Изменение и создание модулей шлюза для динамической видеоаналитики](./tutorial-video-analytics-build-module.md)
