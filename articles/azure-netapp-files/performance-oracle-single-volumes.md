---
title: Производительность базы данных Oracle на Azure NetApp Files одном томе | Документация Майкрософт
description: Описание результатов теста производительности Azure NetApp Files одного тома в базе данных Oracle.
services: azure-netapp-files
documentationcenter: ''
author: b-juche
manager: ''
editor: ''
ms.assetid: ''
ms.service: azure-netapp-files
ms.workload: storage
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 09/30/2020
ms.author: b-juche
ms.openlocfilehash: c6cdf2f6dada0aa4dea2f70f18237b7ee39e3ea1
ms.sourcegitcommit: 772eb9c6684dd4864e0ba507945a83e48b8c16f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "91571413"
---
# <a name="oracle-database-performance-on-azure-netapp-files-single-volumes"></a>Производительность базы данных Oracle в отдельных томах Azure NetApp Files

В этой статье рассматриваются следующие темы о Oracle в облаке. Эти темы могут быть особенно интересны администратору базы данных, архитектору облака или архитектору хранилища:   

* Как работает Рабочая нагрузка оперативной обработки транзакций (OLTP) (в основном операции ввода-вывода) или рабочая нагрузка OLAP (в основном это последовательная операция ввода-вывода), как выглядит производительность?   
* Какова разница в производительности между обычным клиентом Linux ядра NFS (КНФС) и собственным клиентом Direct NFS для Oracle?
* Насколько важна пропускная способность, производительность одного Azure NetApp Filesного тома достаточно?

## <a name="testing-environment-and-components"></a>Тестирование среды и компонентов

На следующей схеме показана среда, используемая для тестирования. Для обеспечения согласованности и простоты Ansible модули PlayBook использовались для развертывания всех элементов тестовой испытательной версии.

![Среда тестирования Oracle](../media/azure-netapp-files/performance-oracle-test-environment.png)  

### <a name="virtual-machine-configuration"></a>Конфигурация виртуальной машины

В тестах использовалась следующая настройка для виртуальной машины:
* Операционная система:   
    RedHat Enterprise Linux 7,8 (вле-ora01)
* Типы экземпляров:   
    В тестировании использовались две модели — D32s_v3 и D64s_v3
* Число сетевых интерфейсов:   
    Один (1), помещенный в подсеть 3  
* Диски   
    Двоичные файлы и ОС Oracle помещаются на один диск класса Premium

### <a name="azure-netapp-files-configuration"></a><a name="anf_config"></a>Конфигурация Azure NetApp Files
В тестах использовалась следующая конфигурация Azure NetApp Files:   

* Размер пула емкости:  
    Были настроены различные размеры пула: 4 Тиб, 8 Тиб, 16 ТиБ, 32 тиб 
* Уровень обслуживания:  
    Ultra (128 MiB/с пропускной способностью в 1 Тиб объем выделенного тома)
* Тома:  
    Вычислен один и два теста тома

### <a name="workload-generator"></a>Генератор рабочей нагрузки 

В тестах использовалась рабочая нагрузка, созданная СЛОБ 2.5.4.2. СЛОБ (глупо незначительная производительность Oracle) — это хорошо известный генератор рабочих нагрузок в пространстве Oracle, предназначенный для нагрузки и тестирования подсистемы ввода-вывода с физической рабочей нагрузкой операций ввода-вывода с СГА буферизацией.  

СЛОБ 2.5.4.2 не поддерживает подключаемую базу данных (PDB). Таким образом, в `setup.sh` `runit.sh` скрипты и ДОБАВЛЕНА поддержка PDB для добавления в них изменений.  

Переменные СЛОБ, используемые в тестах, описаны в следующих разделах.

#### <a name="workload-80-select-20-update--random-io--slobconf-variables"></a>Рабочая нагрузка 80% SELECT, 20% обновления | Случайные операции ввода-вывода — `slob.conf` переменные   

`UPDATE_PCT=20`   
`SCAN_PCT=0`   
`RUN_TIME=600`   
`WORK_LOOP=0`   
`SCALE=75G`   
`SCAN_TABLE_SZ=50G`   
`WORK_UNIT=64`   
`REDO_STRESS=LITE`   
`LOAD_PARALLEL_DEGREE=12`   

#### <a name="workload-100-select--sequential-io--slobconf-variables"></a>Рабочая нагрузка 100% SELECT | Последовательные операции ввода-вывода — `slob.conf` переменные

`UPDATE_PCT=0`   
`SCAN_PCT=100`   
`RUN_TIME=600`   
`WORK_LOOP=0`   
`SCALE=75G`   
`SCAN_TABLE_SZ=50G`   
`WORK_UNIT=64`   
`REDO_STRESS=LITE`   
`LOAD_PARALLEL_DEGREE=12`   

### <a name="database"></a>База данных

Версия Oracle, используемая для тестов, — Oracle Database Enterprise Edition 19.3.0.0.

Ниже приведены параметры Oracle.  
* `sga_max_size`: 4096M
* `sga_target`: 4096
* `db_writer_processes`: 12
* `awr_pdb_autoflush_enabled`: true
* `filesystemio_options`: СЕТАЛЛ
* `log_buffer`: 134217728

Для базы данных СЛОБ был создан PDB-файл.

На следующей диаграмме показано табличное пространство с именем ПЕРФИО с размером 600 ГБ (20 файлов данных, 30 ГБ каждый), созданных для размещения четырех СЛОБных схем пользователей. Размер каждой схемы пользователя составляет 125 ГБ.

![База данных Oracle](../media/azure-netapp-files/performance-oracle-tablespace.png)  

## <a name="performance-metrics"></a>Метрики производительности

Целью было сообщить о производительности ввода-вывода в соответствии с опытом работы приложения. Таким образом, все схемы в этой статье используют метрики, сообщаемые базой данных Oracle, с помощью отчетов по автоматическому репозиторию рабочих нагрузок (AWR). Ниже приведены метрики, используемые на схемах.   

* **Среднее число запросов ввода-вывода в секунду**   
    Соответствует сумме среднего числа запросов ввода-вывода на чтение/с и среднего количества запросов ввода-вывода в секунду из раздела профиль загрузки.
* **Среднее число операций ввода-вывода, МБ/с**   
    Соответствует сумме средней операции ввода-вывода при чтении МБ/с и средней операции ввода-вывода (МБ/с) из раздела профиль загрузки.
* **Средняя задержка чтения**   
    Соответствует средней задержке события ожидания Oracle "последовательное чтение файла базы данных" в микросекундах.
* **Число потоков/схем**   
    Соответствует количеству СЛОБ потоков на схему пользователя

## <a name="performance-measurement-results"></a>Результаты оценки производительности  

В этом разделе описываются результаты измерения производительности.

### <a name="linux-knfs-client-vs-oracle-direct-nfs"></a>Linux КНФС Client и Oracle Direct NFS

Этот сценарий выполнялся на Standard_D32s_v3 виртуальной машины Azure (Intel 2673 v4 @ 2,30 ГГц). Рабочая нагрузка составляет 75% SELECT и 25% обновления, в основном случайные операции ввода-вывода, и при попадании буфера базы данных в ~ 7,5%. 

Как показано на следующей схеме, клиент Oracle ДНФС доставил до 2,8 x больше пропускной способности, чем обычный клиент Linux КНФС:  

![Клиент Linux КНФС по сравнению с Oracle Direct NFS](../media/azure-netapp-files/performance-oracle-kfns-compared-dnfs.png)  

На следующей диаграмме показана кривая задержки для операций чтения. В этом контексте узким местом для клиента КНФС является подключение сокета TCP одного NFS между клиентом и сервером NFS (Azure NetApp Filesным томом).  

![Клиент Linux КНФС по сравнению с кривой задержки прямого подключения NFS Oracle](../media/azure-netapp-files/performance-oracle-latency-curve.png)  

Клиент ДНФС смог отправить больше запросов ввода-вывода в секунду из-за его возможности создавать сотни подключений через сокеты TCP, тем самым используя преимущества параллелизма. Как описано в разделе [конфигурация Azure NetApp Files](#anf_config), каждый дополнительный Тиб распределения ресурсов позволяет дополнительно пропускную способность 128MiB/с. ДНФС накладывается с пропускной способностью 1 гиб/с, что является ограничением, наложенным на выделение емкости 8-тиб. Учитывая большую емкость, была бы управляемая пропускная способность.

Пропускная способность — это лишь одно из соображений. Еще один вопрос — это задержка, которая оказывает основное влияние на взаимодействие с пользователем. Как показано на следующей схеме, увеличение задержки может ожидать гораздо быстрее с КНФС, чем с помощью ДНФС. 

![Клиент КНФС для Linux по сравнению с задержкой чтения Direct NFS Oracle](../media/azure-netapp-files/performance-oracle-read-latency.png)  

Гистограммы дают превосходную информацию о задержек в базе данных. На следующей диаграмме представлено полное представление с точки зрения записанного объекта "последовательное чтение файлов в базе данных", при использовании ДНФС в самой высокой точке данных параллелизма (32 потоков/схем). Как показано на следующей схеме, 47% всех операций чтения соблюдается в течение 512 микросекунд и 1000 микросекунд, а 90% всех операций чтения выполнялись в задержке ниже 2 мс.

![Клиент Linux КНФС по сравнению с гистограммами Oracle Direct NFS](../media/azure-netapp-files/performance-oracle-histogram-read-latency.png)  

В заключение ясно, что ДНФС является обязательной, когда дело доходит до повышения производительности экземпляра базы данных Oracle на NFS.

### <a name="single-volume-performance-limits"></a>Ограничения производительности одного тома

В этом разделе описываются ограничения производительности одного тома с произвольным вводом-выводом и последовательным вводом-выводом. 

#### <a name="random-io"></a>Случайные операции ввода-вывода

ДНФС может потреблять гораздо больше пропускной способности, чем предоставляет квота производительности в 8 ТБ Azure NetApp Files. Увеличив емкость тома Azure NetApp Files до 16 ТиБ, что является мгновенным изменением, объем пропускной способности тома увеличился с 1024 MiB/с на 2 – 2048 MiB/с. 

На следующей схеме показана конфигурация для рабочей нагрузки "Select" на 80% и 20% обновлений, а также с коэффициентом попадания в буфер базы данных в 8%. СЛОБ удалось выполнить один том для 200 000 NFS запросов ввода-вывода в секунду. Учитывая, что каждая операция имеет размер 8 КИБ, тестируемая система смогла доставить ~ 200 000 запросов ввода-вывода в секунду или 1600 MiB/с.
 
![Пропускная способность Oracle ДНФС](../media/azure-netapp-files/performance-oracle-dnfs-throughput.png)  

Следующая схема кривой задержки чтения показывает, что при увеличении пропускной способности чтения задержка повышается после строки 1-MS, и она насчитывает завяз кривой в ~ 165 000 среднее количество запросов ввода-вывода в секунду при средней задержке чтения ~ 1,3 мс.  Это значение представляет собой невероятную задержку при недостижимости операции ввода-вывода почти с любой другой технологией в облаке Azure. 

![Кривая задержки Oracle ДНФС](../media/azure-netapp-files/performance-oracle-dnfs-latency-curve.png)  

#### <a name="sequential-io"></a>Последовательный ввод-вывод  

Как показано на следующей схеме, не все операции ввода-вывода являются случайными, учитывая RMAN резервную копию или полное сканирование таблицы, например, в качестве рабочей нагрузки, которая требует настолько большой объем пропускной способности, как они могут быть получены.  Используя ту же конфигурацию, которая описана ранее, но при изменении размера тома до 32 Тиб, на следующей схеме показано, что один экземпляр Oracle DB может управлять пропускной способностью 3 900 МБ/с, что очень близко к квоте производительности Azure NetApp Filesного тома, равной 32 ТБ (128 МБ/с * 32 = 4096 МБ/с).

![Ввод-вывод Oracle ДНФС](../media/azure-netapp-files/performance-oracle-dnfs-io.png)  

В сводке Azure NetApp Files помогает перевести базы данных Oracle в облако. Она обеспечивает производительность, когда она требует база данных. Вы можете в любое время динамически и без сбоев изменять размер квоты тома.

## <a name="next-steps"></a>Дальнейшие действия

- [Рекомендации по тестам производительности для Azure NetApp Files](azure-netapp-files-performance-metrics-volumes.md)
- [Тесты производительности для Linux](performance-benchmarks-linux.md)