---
title: Непрерывные интеграция и поставка в Фабрике данных Azure
description: Сведения об использовании непрерывных интеграции и поставки для перемещения конвейеров Фабрики данных из одной среды (разработки, тестирования, рабочей) в другую.
ms.service: data-factory
author: dcstwh
ms.author: weetok
ms.reviewer: maghan
ms.topic: conceptual
ms.date: 03/11/2021
ms.openlocfilehash: 4f03236176acea14bed2dfaac53b1a1e6cf7a1e2
ms.sourcegitcommit: 5f32f03eeb892bf0d023b23bd709e642d1812696
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/12/2021
ms.locfileid: "103197873"
---
# <a name="continuous-integration-and-delivery-in-azure-data-factory"></a>Непрерывные интеграция и поставка в Фабрике данных Azure

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

## <a name="overview"></a>Обзор

Непрерывная интеграция — это способ автоматического тестирования каждого изменения, внесенного в базу кода.  Непрерывная поставка следует за проверкой, которая выполняется во время непрерывной интеграции. Она передает изменения в промежуточную или рабочую систему.

В Фабрике данных Azure под непрерывными интеграцией и поставкой (CI/CD) подразумевается перемещение конвейеров Фабрики данных из одной среды (разработки, тестирования, рабочей) в другую. Фабрика данных Azure использует [шаблоны Azure Resource Manager](../azure-resource-manager/templates/overview.md) для хранения конфигурации различных сущностей Фабрики данных Azure (конвейеры, наборы данных, потоки данных и т. д.). Существуют два рекомендуемых метода перемещения фабрики данных в другую среду.

-    Автоматизированное развертывание с помощью интеграции Фабрики данных с [Azure Pipelines](/azure/devops/pipelines/get-started/what-is-azure-pipelines).
-    Отправка шаблона Resource Manager вручную с помощью интеграции пользовательского интерфейса Фабрики данных с Azure Resource Manager.

[!INCLUDE [updated-for-az](../../includes/updated-for-az.md)]

## <a name="cicd-lifecycle"></a>Жизненный цикл CI/CD

Ниже приведен обзор примера жизненного цикла CI/CD в фабрике данных Azure, настроенной с помощью Azure Repos Git. Дополнительные сведения о настройке репозитория Git см. в статье [Система управления версиями в Фабрике данных Azure](source-control.md).

1.  Фабрика данных для разработки создается и настраивается с помощью Azure Repos Git. Все разработчики должны иметь разрешение на создание ресурсов Фабрики данных, таких как конвейеры и наборы данных.

1.  Разработчик [создает ветвь компонента](source-control.md#creating-feature-branches) для внесения изменений. Он отлаживает запуски конвейера с самыми последними изменениями. Дополнительные сведения об отладке запуска конвейера см. в статье [Итеративные разработка и отладка в Фабрике данных Azure](iterative-development-debugging.md).

1.  После того, как разработчик удовлетворен своими изменениями, он создает запрос на вытягивание от своей ветви компонентов к главной ветви или ветвь совместной работы, чтобы получить изменения, которые будут проверяться одноранговыми узлами.

1.  После утверждения запроса на вытягивание и слияния изменений в главной ветви изменения публикуются в фабрике разработки.

1.  Когда команда готова к развертыванию изменений в тестовой или UAT (пользовательское приемочное тестирование), Группа переходит к выпуску Azure Pipelines и развертывает нужную версию фабрики разработки в UAT. Это развертывание выполняется как часть задачи Azure Pipelines и использует параметры шаблона Resource Manager, чтобы применить соответствующую конфигурацию.

1.  После проверки изменений в фабрике тестовой среды выполните развертывание в фабрике для разработки с помощью следующей задачи выпуска конвейеров.

> [!NOTE]
> Только фабрика для разработки будет связана с репозиторием Git. В тестовой и рабочей фабрике не должно быть связанного с ними репозитория Git. Их следует обновлять только через конвейер Azure DevOps или шаблон управления ресурсами.

На приведенном ниже рисунке показаны различные этапы этого жизненного цикла.

![Схема непрерывной интеграции с помощью Azure Pipelines](media/continuous-integration-deployment/continuous-integration-image12.png)

## <a name="automate-continuous-integration-by-using-azure-pipelines-releases"></a>Автоматизация непрерывной интеграции с помощью выпусков Azure Pipelines

Ниже приведены шаги настройки выпуска Azure Pipelines для автоматизации развертывания фабрики данных в различные среды.

### <a name="requirements"></a>Требования

-   Подписка Azure, связанная с Team Foundation Server или Azure Repos Visual Studio, использующая [конечную точку службы Azure Resource Manager](/azure/devops/pipelines/library/service-endpoints#sep-azure-resource-manager).

-   Фабрика данных, настроенная с интеграцией Git Azure Repos.

-   [Хранилище ключей Azure](https://azure.microsoft.com/services/key-vault/) , содержащее секреты для каждой среды.

### <a name="set-up-an-azure-pipelines-release"></a>Настройка выпуска Azure Pipelines

1.  В [Azure DevOps](https://dev.azure.com/) откройте проект, настроенный с фабрикой данных.

1.  В левой части страницы выберите **Конвейеры**, а затем **Выпуски**.

    ![Выбор параметров "Конвейеры", "Выпуски"](media/continuous-integration-deployment/continuous-integration-image6.png)

1.  Выберите **Новый конвейер** или, если у вас есть конвейеры, выберите **Новый**, а затем **Создать конвейер выпуска**.

1.  Выберите шаблон **Пустое задание**.

    ![Выбор шаблона "Пустое задание"](media/continuous-integration-deployment/continuous-integration-image13.png)

1.  В поле **Имя этапа** введите имя своей среды.

1.  Щелкните **Добавить артефакт**, а затем выберите репозиторий Git, настроенный с фабрикой данных для разработки. Выберите [опубликовать ветвь](source-control.md#configure-publishing-settings) репозитория для поля **Ветвь по умолчанию**. По умолчанию эта ветвь публикации имеет значение `adf_publish`. Для поля **Версия по умолчанию** выберите **Последний из ветви по умолчанию**.

    ![Добавление артефакта](media/continuous-integration-deployment/continuous-integration-image7.png)

1.  Добавьте задачу развертывания Azure Resource Manager.

    а.  В представлении этапа выберите **Просмотр задач этапа**.

    ![Представлении этапа](media/continuous-integration-deployment/continuous-integration-image14.png)

    b.  Создайте задачу. Найдите **Развертывание шаблона ARM** и нажмите кнопку **Добавить**.

    c.  В задаче "Развертывание" выберите подписку, группу ресурсов и расположение для целевой фабрики данных. При необходимости предоставьте учетные данные.

    d.  В списке **Действие** выберите **Create or update resource group** (Создание или изменение группы ресурсов).

    д)  Нажмите кнопку с многоточием ( **…** ) рядом с полем **Шаблон**. Найдите шаблон Azure Resource Manager, созданный в ветви публикации настроенного репозитория Git. Найдите файл `ARMTemplateForFactory.json` в папке <FactoryName> ветви adf_publish.

    е)  Выберите **…** рядом с полем **Параметры шаблона** для выбора файла параметров. Найдите файл `ARMTemplateParametersForFactory.json` в папке <FactoryName> ветви adf_publish.

    ж.  Выберите **…** рядом с полем **Переопределить параметры шаблона** и введите значения необходимых параметров для целевой фабрики данных. Для учетных данных, полученных из Azure Key Vault, заключите имя секрета в двойные кавычки. Например, если имя секрета — cred1, введите **"$(cred1)"** для этого значения.

    h. В поле **Режим развертывания** выберите **Добавочные**.

    > [!WARNING]
    > В режиме полного развертывания ресурсы, которые существуют в группе ресурсов, но не указаны в новом шаблоне диспетчер ресурсов, будут **удалены**. Дополнительные сведения см. в разделе [режимы развертывания Azure Resource Manager](../azure-resource-manager/templates/deployment-modes.md) .

    ![Рабочее развертывание Фабрики данных](media/continuous-integration-deployment/continuous-integration-image9.png)

1.  Сохраните конвейер выпуска.

1. Для активации выпуска нажмите кнопку **Создать выпуск**. Сведения об автоматизации создания выпусков см. в статье [Триггеры выпуска](/azure/devops/pipelines/release/triggers).

   ![Выбор параметра "Создать выпуск"](media/continuous-integration-deployment/continuous-integration-image10.png)

> [!IMPORTANT]
> В сценариях CI/CD тип среды выполнения интеграции (IR) в разных средах должен совпадать. Например, если у вас есть локальная среда IR в среде разработки, ей необходим также тип "Локальная" в других средах, таких как рабочая и тестовая. Аналогично, если вы совместно используете среды выполнения интеграции в нескольких средах, необходимо настроить их в качестве связанных локальных сред во всех средах (разработки, тестирования и рабочей).

### <a name="get-secrets-from-azure-key-vault"></a>Получение секретов из Azure Key Vault

Если вам нужно передать секреты в шаблоне Azure Resource Manager, рекомендуем использовать Azure Key Vault с выпуском Azure Pipelines.

Обработать секреты можно двумя способами.

1.  Добавьте секреты в файл параметров. Дополнительные сведения см. в статье [Использование Azure Key Vault для передачи защищенного значения параметра во время развертывания](../azure-resource-manager/templates/key-vault-parameter.md).

    Создайте копию файла параметров, который отправляется в ветвь публикации. Задайте значения параметров, которые требуется получить из Key Vault, в следующем формате:

    ```json
    {
        "parameters": {
            "azureSqlReportingDbPassword": {
                "reference": {
                    "keyVault": {
                        "id": "/subscriptions/<subId>/resourceGroups/<resourcegroupId> /providers/Microsoft.KeyVault/vaults/<vault-name> "
                    },
                    "secretName": " < secret - name > "
                }
            }
        }
    }
    ```

    При использовании этого метода секрет автоматически извлекается из хранилища ключей.

    Файл параметров также должен находиться в ветви публикации.

1. Перед задачей развертывания Azure Resource Manager, описанной в предыдущем разделе, добавьте [задачу Azure Key Vault](/azure/devops/pipelines/tasks/deploy/azure-key-vault):

    1.  На вкладке **Задачи** создайте задачу. Найдите **Azure Key Vault** и добавьте его.

    1.  В задаче Key Vault выберите подписку, в которой вы создали хранилище ключей. При необходимости предоставьте учетные данные, а затем выберите хранилище ключей.

    ![Добавление задачи Key Vault](media/continuous-integration-deployment/continuous-integration-image8.png)

#### <a name="grant-permissions-to-the-azure-pipelines-agent"></a>Предоставление разрешений для агента Azure Pipelines

Задача Azure Key Vault может завершиться ошибкой отказа в доступе, если не заданы правильные разрешения. Загрузите журналы для выпуска и найдите PS1-файл с командой для предоставления разрешений агенту Azure Pipelines. Вы можете выполнить команду напрямую. Или скопировать идентификатор участника из файла и вручную добавить политику доступа на портале Azure. `Get` и `List` — минимальные требуемые разрешения.

### <a name="updating-active-triggers"></a>Обновление активных триггеров

При попытке обновления активных триггеров развертывание может завершиться сбоем. Чтобы обновить активные триггеры, необходимо вручную остановить, а затем перезапустить их после развертывания. Это можно сделать с помощью задачи Azure PowerShell:

1.  На вкладке **Задачи** выпуска добавьте задачу **Azure PowerShell**. Выберите версию задачи 4.*. 

1.  Выберите подписку, в которой находится фабрика.

1.  В качестве типа сценария выберите **Путь к файлу сценария**. Для этого необходимо сохранить сценарий PowerShell в репозитории. Следующий сценарий PowerShell можно использовать для остановки триггеров:

    ```powershell
    $triggersADF = Get-AzDataFactoryV2Trigger -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName

    $triggersADF | ForEach-Object { Stop-AzDataFactoryV2Trigger -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.name -Force }
    ```

Вы можете выполнить те же шаги (с функцией `Start-AzDataFactoryV2Trigger`), чтобы перезапустить триггеры после развертывания.

В конце статьи команда фабрики данных предоставила [пример сценария, выполняемого до и после развертывания](#script). 

## <a name="manually-promote-a-resource-manager-template-for-each-environment"></a>Перемещение шаблона Resource Manager для каждой среды вручную

1. В списке **Шаблон ARM** выберите **Export ARM Template** (Экспорт шаблона ARM), чтобы экспортировать шаблон Resource Manager в фабрику данных в среде разработки.

   ![Экспорт шаблона Resource Manager](media/continuous-integration-deployment/continuous-integration-image1.png)

1. В тестовой и рабочей средах выберите **Import ARM Template** (Импорт шаблона ARM). После этого вы перейдете на портал Azure, где сможете импортировать экспортированный шаблон. Выберите **Создать собственный шаблон в редакторе**, чтобы открыть редактор шаблона Resource Manager.

   ![Создание собственного шаблона](media/continuous-integration-deployment/custom-deployment-build-your-own-template.png) 

1. Выберите **Загрузить файл**, а затем — созданный шаблон Resource Manager. Это файл **arm_template.json**, расположенный в ZIP-файле (экспортирован на шаге 1).

   ![Изменить шаблон](media/continuous-integration-deployment/custom-deployment-edit-template.png)

1. В разделе параметров введите значения конфигурации, например учетные данные связанной службы. После этого нажмите кнопку **Оплатить**, чтобы развернуть шаблон Resource Manager.

   ![Раздел параметров](media/continuous-integration-deployment/continuous-integration-image5.png)

## <a name="use-custom-parameters-with-the-resource-manager-template"></a>Использование пользовательских параметров с шаблоном Resource Manager

Если у вашей фабрики для разработки есть связанный репозиторий Git, можно переопределить параметры шаблона Resource Manager по умолчанию, созданного путем публикации или экспорта шаблона. Может потребоваться переопределить конфигурацию параметров диспетчер ресурсов по умолчанию в следующих сценариях:

* Вы используете автоматизацию CI/CD и хотите изменить некоторые свойства во время развертывания Resource Manager, но свойства не будут параметризованы по умолчанию.
* Ваша фабрика настолько велика, что шаблон Resource Manager по умолчанию является недопустимым, так как он превышает максимально допустимое количество параметров (256).

    Для обработки ограничения пользовательского параметра 256 доступны три варианта:    
  
    * Используйте файл пользовательских параметров и удалите свойства, которые не требуют параметризации, например свойства, которые могут иметь значение по умолчанию и, следовательно, уменьшить число параметров.
    * Рефакторинг логики в потоке данных для сокращения параметров, например, все параметры конвейера имеют одинаковое значение, можно просто использовать глобальные параметры.
    * Разделите одну фабрику данных на несколько потоков данных.

Чтобы переопределить конфигурацию параметров диспетчер ресурсов по умолчанию, перейдите в раздел **Управление** центром и выберите пункт **шаблон ARM** в разделе "система управления версиями". В разделе **Конфигурация параметра ARM** щелкните значок **изменить** в окне "изменение конфигурации параметров", чтобы открыть редактор кода конфигурации диспетчер ресурсов параметров.

![Управление настраиваемыми параметрами](media/author-management-hub/management-hub-custom-parameters.png)

> [!NOTE]
> **Настройка параметров ARM** включена только в "режиме Git". Сейчас она отключена в режиме "динамический режим" или "Фабрика данных".

При создании пользовательской конфигурации диспетчер ресурсов параметров в корневой папке ветви Git создается файл с именем **arm-template-parameters-definition.js** . Необходимо использовать точное имя файла.

![Файл пользовательских параметров](media/continuous-integration-deployment/custom-parameters.png)

При публикации из ветви совместной работы Фабрика данных считывает этот файл и использует его конфигурацию, чтобы определить свойства, которые будут параметризованы. Если файл не найден, используется шаблон по умолчанию.

При экспорте шаблона диспетчер ресурсов фабрика данных считывает этот файл из любой ветви, над которой вы работаете в данный момент, а не ветви совместной работы. Вы можете создать или изменить файл из частной ветви, где можно протестировать изменения, выбрав **Export ARM Template** (Экспорт шаблона ARM) в пользовательском интерфейсе. Затем можно выполнить слияние файла в ветвь совместной работы.

> [!NOTE]
> Настраиваемая конфигурация диспетчер ресурсов параметров не изменяет ограничение на параметр шаблона ARM, равное 256. Он позволяет выбирать и уменьшать количество параметризованных свойств.

### <a name="custom-parameter-syntax"></a>Синтаксис пользовательских параметров

Ниже приведены некоторые рекомендации, которые следует выполнить при создании файла пользовательских параметров **arm-template-parameters-definition.json**. Файл состоит из раздела для каждого типа сущности: триггера, конвейера, связанной службы, набора данных, среды выполнения интеграции и потока данных.

* Введите путь к свойству в соответствующем типе сущности.
* Задание имени свойства `*` означает, что необходимо параметризовать все свойства под ним (только на первый уровень, но не рекурсивно). Вы также можете указать исключения в этой конфигурации.
* Установка значения свойства в виде строки указывает, что вы хотите параметризовать свойство. Используйте следующий формат: `<action>:<name>:<stype>`.
   *  `<action>` может быть одним из следующих символов:
      * `=` означает, что текущее значение сохраняется как значение по умолчанию для параметра.
      * `-` означает, что значение по умолчанию для параметра не сохраняется.
      * `|` является особым случаем для секретов из Azure Key Vault для строк подключения или ключей.
   * `<name>` является именем параметра. Если оно пустое, то принимает имя свойства. Если значение начинается со знака `-`, то оно сокращено. Например, `AzureStorage1_properties_typeProperties_connectionString` будет сокращено до `AzureStorage1_connectionString`.
   * `<stype>` тип параметра. Если `<stype>` параметр пуст, используется тип по умолчанию `string` . Поддерживаемые значения: `string` , `securestring` , `int` , `bool` , `object` `secureobject` и `array` .
* При указании массива в файле определения вы можете указать, что соответствующее свойство в шаблоне является массивом. Фабрика данных выполняет итерацию всех объектов в массиве с помощью определения, указанного в объекте среды выполнения интеграции массива. Второй объект, строка, становится именем свойства, которое используется в качестве имени параметра для каждой итерации.
* Определение не может быть указано для экземпляра ресурса. Любое определение применяется ко всем ресурсам этого типа.
* По умолчанию все защищенные строки, такие как секреты Key Vault и защищенные строки, такие как строки подключения, ключи и токены, являются параметризованными.
 
### <a name="sample-parameterization-template"></a>Пример шаблона параметризации

Ниже приведен пример того, как может выглядеть конфигурация параметров диспетчер ресурсов.

```json
{
    "Microsoft.DataFactory/factories/pipelines": {
        "properties": {
            "activities": [{
                "typeProperties": {
                    "waitTimeInSeconds": "-::int",
                    "headers": "=::object"
                }
            }]
        }
    },
    "Microsoft.DataFactory/factories/integrationRuntimes": {
        "properties": {
            "typeProperties": {
                "*": "="
            }
        }
    },
    "Microsoft.DataFactory/factories/triggers": {
        "properties": {
            "typeProperties": {
                "recurrence": {
                    "*": "=",
                    "interval": "=:triggerSuffix:int",
                    "frequency": "=:-freq"
                },
                "maxConcurrency": "="
            }
        }
    },
    "Microsoft.DataFactory/factories/linkedServices": {
        "*": {
            "properties": {
                "typeProperties": {
                    "accountName": "=",
                    "username": "=",
                    "connectionString": "|:-connectionString:secureString",
                    "secretAccessKey": "|"
                }
            }
        },
        "AzureDataLakeStore": {
            "properties": {
                "typeProperties": {
                    "dataLakeStoreUri": "="
                }
            }
        }
    },
    "Microsoft.DataFactory/factories/datasets": {
        "properties": {
            "typeProperties": {
                "*": "="
            }
        }
    }
}
```
Ниже приведено объяснение того, как создавался предыдущий шаблон, упорядоченный по типу ресурсов.

#### <a name="pipelines"></a>Конвейеры
    
* Любое свойство в пути `activities/typeProperties/waitTimeInSeconds` параметризовано. Любое действие в конвейере, которое имеет свойство уровня кода с именем `waitTimeInSeconds` (например, действие `Wait`) параметризовано как число с именем по умолчанию. Но в шаблоне Resource Manager не будет значения по умолчанию. Оно будет обязательным во время развертывания Resource Manager.
* Аналогично свойство `headers` (например, в действии `Web`) параметризовано с типом `object` (JObject). Оно имеет значение по умолчанию, то есть то же значение, что и у исходной фабрики.

#### <a name="integrationruntimes"></a>IntegrationRuntimes

* Все свойства в пути `typeProperties` параметризованы с соответствующими значениями по умолчанию. Например, в свойствах типа `IntegrationRuntimes` есть два свойства: `computeProperties` и `ssisProperties`. Оба типа свойств создаются с соответствующими значениями по умолчанию и типами (объект).

#### <a name="triggers"></a>Триггеры

* В разделе `typeProperties` два свойства являются параметризованными. Первое из них `maxConcurrency`, для которого задано значение по умолчанию и имеет тип `string`. Имя параметра по умолчанию — `<entityName>_properties_typeProperties_maxConcurrency`.
* Свойство `recurrence` также параметризовано. В его разделе все свойства на этом уровне указываются для параметризации в виде строк со значениями по умолчанию и имен параметров. Исключением является свойство `interval`, параметризованное как тип `int`. Имя параметра имеет суффикс `<entityName>_properties_typeProperties_recurrence_triggerSuffix`. Аналогичным образом свойство `freq` — это строка, и параметризовано как строка. Однако свойство `freq` параметризовано без значения по умолчанию. Имя сокращено и имеет суффикс. Например, `<entityName>_freq`.

#### <a name="linkedservices"></a>LinkedServices

* Связанные службы уникальны. Так как связанные службы и наборы данных имеют широкий спектр типов, можно указать настройку для конкретного типа. В этом примере для всех связанных служб типа `AzureDataLakeStore` будет применен конкретный шаблон. Для всех остальных (через `*`) будет применен другой шаблон.
* Свойство `connectionString` будет параметризовано как значение `securestring`. Оно не имеет значения по умолчанию У него будет имя сокращенного параметра с суффиксом `connectionString`.
* Свойство `secretAccessKey` является `AzureKeyVaultSecret` (например, в связанной службе Amazon S3). Оно автоматически параметризовано как секрет Azure Key Vault и получено из настроенного хранилища ключей. Вы также можете параметризовать само хранилище ключей.

#### <a name="datasets"></a>Наборы данных

* Хотя настройка для наборов данных доступна для конкретного типа, можно предоставить конфигурацию без явной настройки уровня \*. В предыдущем примере все свойства набора данных в разделе `typeProperties` были параметризованными.

> [!NOTE]
> **Оповещения и матрицы Azure**  , если они настроены для конвейера, в настоящее время не поддерживаются в качестве параметров для развертываний ARM. Чтобы повторно применить оповещения и матрицы в новой среде, используйте [мониторинг фабрики данных, оповещения и матрицы.](https://docs.microsoft.com/azure/data-factory/monitor-using-azure-monitor#data-factory-metrics)
> 

### <a name="default-parameterization-template"></a>Шаблон параметризации по умолчанию

Ниже приведен текущий шаблон параметризации по умолчанию. Если необходимо добавить только несколько параметров, то рекомендуется изменить этот шаблон напрямую, так как вы не потеряете существующую структуру параметризации.

```json
{
    "Microsoft.DataFactory/factories": {
        "properties": {
            "globalParameters": {
                "*": {
                    "value": "="
                }
            }
        },
        "location": "="
    },
    "Microsoft.DataFactory/factories/pipelines": {
    },
    "Microsoft.DataFactory/factories/dataflows": {
    },
    "Microsoft.DataFactory/factories/integrationRuntimes":{
        "properties": {
            "typeProperties": {
                "ssisProperties": {
                    "catalogInfo": {
                        "catalogServerEndpoint": "=",
                        "catalogAdminUserName": "=",
                        "catalogAdminPassword": {
                            "value": "-::secureString"
                        }
                    },
                    "customSetupScriptProperties": {
                        "sasToken": {
                            "value": "-::secureString"
                        }
                    }
                },
                "linkedInfo": {
                    "key": {
                        "value": "-::secureString"
                    },
                    "resourceId": "="
                },
                "computeProperties": {
                    "dataFlowProperties": {
                        "externalComputeInfo": [{
                                "accessToken": "-::secureString"
                            }
                        ]
                    }
                }
            }
        }
    },
    "Microsoft.DataFactory/factories/triggers": {
        "properties": {
            "pipelines": [{
                    "parameters": {
                        "*": "="
                    }
                },  
                "pipelineReference.referenceName"
            ],
            "pipeline": {
                "parameters": {
                    "*": "="
                }
            },
            "typeProperties": {
                "scope": "="
            }
        }
    },
    "Microsoft.DataFactory/factories/linkedServices": {
        "*": {
            "properties": {
                "typeProperties": {
                    "accountName": "=",
                    "username": "=",
                    "userName": "=",
                    "accessKeyId": "=",
                    "servicePrincipalId": "=",
                    "userId": "=",
                    "host": "=",
                    "clientId": "=",
                    "clusterUserName": "=",
                    "clusterSshUserName": "=",
                    "hostSubscriptionId": "=",
                    "clusterResourceGroup": "=",
                    "subscriptionId": "=",
                    "resourceGroupName": "=",
                    "tenant": "=",
                    "dataLakeStoreUri": "=",
                    "baseUrl": "=",
                    "database": "=",
                    "serviceEndpoint": "=",
                    "batchUri": "=",
                    "poolName": "=",
                    "databaseName": "=",
                    "systemNumber": "=",
                    "server": "=",
                    "url":"=",
                    "functionAppUrl":"=",
                    "environmentUrl": "=",
                    "aadResourceId": "=",
                    "sasUri": "|:-sasUri:secureString",
                    "sasToken": "|",
                    "connectionString": "|:-connectionString:secureString",
                    "hostKeyFingerprint": "="
                }
            }
        },
        "Odbc": {
            "properties": {
                "typeProperties": {
                    "userName": "=",
                    "connectionString": {
                        "secretName": "="
                    }
                }
            }
        }
    },
    "Microsoft.DataFactory/factories/datasets": {
        "*": {
            "properties": {
                "typeProperties": {
                    "folderPath": "=",
                    "fileName": "="
                }
            }
        }
    },
    "Microsoft.DataFactory/factories/managedVirtualNetworks/managedPrivateEndpoints": {
        "properties": {
            "*": "="
        }
    }
}
```

### <a name="example-parameterizing-an-existing-azure-databricks-interactive-cluster-id"></a>Пример. Параметризация существующего идентификатора интерактивного кластера Azure Databricks

В следующем примере показано, как добавить одно значение в шаблон параметризации по умолчанию. Нужно только добавить существующий идентификатор интерактивного кластера Azure Databricks для связанной службы Databricks в файле параметров. Обратите внимание, что этот файл совпадает с предыдущим файлом, за исключением добавления `existingClusterId` в поле свойства `Microsoft.DataFactory/factories/linkedServices`.

```json
{
    "Microsoft.DataFactory/factories": {
        "properties": {
            "globalParameters": {
                "*": {
                    "value": "="
                }
            }
        },
        "location": "="
    },
    "Microsoft.DataFactory/factories/pipelines": {
    },
    "Microsoft.DataFactory/factories/dataflows": {
    },
    "Microsoft.DataFactory/factories/integrationRuntimes":{
        "properties": {
            "typeProperties": {
                "ssisProperties": {
                    "catalogInfo": {
                        "catalogServerEndpoint": "=",
                        "catalogAdminUserName": "=",
                        "catalogAdminPassword": {
                            "value": "-::secureString"
                        }
                    },
                    "customSetupScriptProperties": {
                        "sasToken": {
                            "value": "-::secureString"
                        }
                    }
                },
                "linkedInfo": {
                    "key": {
                        "value": "-::secureString"
                    },
                    "resourceId": "="
                }
            }
        }
    },
    "Microsoft.DataFactory/factories/triggers": {
        "properties": {
            "pipelines": [{
                    "parameters": {
                        "*": "="
                    }
                },  
                "pipelineReference.referenceName"
            ],
            "pipeline": {
                "parameters": {
                    "*": "="
                }
            },
            "typeProperties": {
                "scope": "="
            }
 
        }
    },
    "Microsoft.DataFactory/factories/linkedServices": {
        "*": {
            "properties": {
                "typeProperties": {
                    "accountName": "=",
                    "username": "=",
                    "userName": "=",
                    "accessKeyId": "=",
                    "servicePrincipalId": "=",
                    "userId": "=",
                    "clientId": "=",
                    "clusterUserName": "=",
                    "clusterSshUserName": "=",
                    "hostSubscriptionId": "=",
                    "clusterResourceGroup": "=",
                    "subscriptionId": "=",
                    "resourceGroupName": "=",
                    "tenant": "=",
                    "dataLakeStoreUri": "=",
                    "baseUrl": "=",
                    "database": "=",
                    "serviceEndpoint": "=",
                    "batchUri": "=",
                    "poolName": "=",
                    "databaseName": "=",
                    "systemNumber": "=",
                    "server": "=",
                    "url":"=",
                    "aadResourceId": "=",
                    "connectionString": "|:-connectionString:secureString",
                    "existingClusterId": "-"
                }
            }
        },
        "Odbc": {
            "properties": {
                "typeProperties": {
                    "userName": "=",
                    "connectionString": {
                        "secretName": "="
                    }
                }
            }
        }
    },
    "Microsoft.DataFactory/factories/datasets": {
        "*": {
            "properties": {
                "typeProperties": {
                    "folderPath": "=",
                    "fileName": "="
                }
            }
        }}
}
```

## <a name="linked-resource-manager-templates"></a>Связанные шаблоны Resource Manager

Если вы настроили CI/CD для фабрик данных, вы можете превысить ограничения шаблонов Azure Resource Manager по мере роста фабрики. Например, одним из ограничений является максимальное количество ресурсов в шаблоне Resource Manager. Для размещения больших фабрик при создании полного шаблона Resource Manager для фабрики Фабрика данных теперь создает связанные шаблоны Resource Manager. С помощью этой функции полезные данные всей фабрики можно разбить на несколько файлов, чтобы не превысить ограничения.

Если у вас настроен Git, связанные шаблоны создаются и сохраняются вместе с полными шаблонами Resource Manager в ветви adf_publish в новой папке с именем linkedTemplates:

![Папка связанных шаблонов Resource Manager](media/continuous-integration-deployment/linked-resource-manager-templates.png)

Связанные шаблоны Resource Manager обычно имеют главный шаблон и набор дочерних шаблонов, связанных с главным. Родительский шаблон называется ArmTemplate_master.json, а дочерние шаблоны именуются по образцу: ArmTemplate_0.json, ArmTemplate_1.json и т. д. 

Для использования связанных шаблонов вместо полного шаблона Resource Manager обновите вашу задачу CI/CD, чтобы она указывала ArmTemplate_master.json вместо ArmTemplateForFactory.json (полный шаблон Resource Manager). Для Resource Manager также необходимо отправлять связанные шаблоны в учетную запись хранения, чтобы они были доступны в Azure во время развертывания. Дополнительные сведения см. в статье [Развертывание связанных шаблонов Resource Manager с помощью VSTS](/archive/blogs/najib/deploying-linked-arm-templates-with-vsts).

Не забудьте добавить сценарии фабрики данных в конвейер CI/CD до и после завершения развертывания.

Если у вас не настроен Git, доступ к связанным шаблонам можно получить, выбрав **Export ARM Template** (Экспорт шаблона ARM) в списке **шаблонов ARM**.

## <a name="hotfix-production-environment"></a>Рабочая среда исправления

Если вы развертываете фабрику в рабочей среде и понимаете, что существует ошибка, которую необходимо исправить немедленно, но вы не можете развернуть текущую ветвь совместной работы, может потребоваться развернуть пакет исправлений. Этот подход известен как наложение исправлений или исправление QFE.

1.    В Azure DevOps перейдите к выпуску, развернутому в рабочей среде. Найдите последнюю развернутую фиксацию.

2.    В сообщении о фиксации получите идентификатор фиксации ветви совместной работы.

3.    Создайте ветвь исправления из этой фиксации.

4.    Перейдите в пользовательский интерфейс Фабрики данных Azure и переключитесь на ветвь исправлений.

5.    Исправьте ошибку с помощью пользовательского интерфейса Фабрики данных Azure. Проверьте изменения.

6.    После проверки исправления выберите **Export ARM Template** (Экспорт шаблона ARM), чтобы получить исправления шаблона Resource Manager.

7.    Проверьте эту сборку в ветви adf_publish вручную.

8.    Если конвейер выпуска настроен на автоматическую активацию на основе синхронизаций adf_publish, новый выпуск будет запущен автоматически. В противном случае поставьте выпуск в очередь вручную.

9.    Разверните выпуск исправления на тестовой и рабочей фабриках. Этот выпуск содержит предыдущие полезные данные, а также исправление, выполненное на шаге 5.

10.   Добавьте изменения из исправления в ветвь разработки, чтобы в последующих выпусках не включалась та же ошибка.

Просмотрите видеоролик с подробным руководством по устранению неполадок в средах. 

> [!VIDEO https://www.microsoft.com/videoplayer/embed/RE4I7fi]

## <a name="exposure-control-and-feature-flags"></a>Флаги управления экспозицией и функций

При работе с командой существуют экземпляры, в которых вы можете объединить изменения, но не нужно, чтобы они выполнялись в таких средах, как "производство" и "вопросы и ответы". Для решения этой ситуации группа ADF рекомендует [DevOps концепцию использования флагов компонентов](/azure/devops/migrate/phase-features-with-feature-flags). В ADF можно объединять [глобальные параметры](author-global-parameters.md) и [действие условия If](control-flow-if-condition-activity.md) , чтобы скрыть наборы логики на основе этих флагов среды.

Сведения о настройке флага функции см. в следующем видеоучебнике:

> [!VIDEO https://www.microsoft.com/videoplayer/embed/RE4IxdW]

## <a name="best-practices-for-cicd"></a>Рекомендации для CI/CD

Если вы используете интеграцию Git с фабрикой данных и у вас есть конвейер CI/CD, перемещающий изменения из среды разработки в тестовую, а затем в рабочую, рекомендуем следующее:

-   **Интеграция Git.** Настройте интеграцию Git только для своей фабрики данных для разработки. Изменения в тестовую и рабочую среду развертываются в рамках процесса CI/CD, и им не требуется интеграция Git.

-   **Сценарий, выполняемый до и после развертывания.** Перед шагом развертывания с помощью Resource Manager в CI/CD необходимо выполнить определенные задачи, такие как остановка и перезапуск триггеров и выполнение очистки. Рекомендуется использовать сценарии PowerShell до и после задачи развертывания. Дополнительные сведения см. в разделе [Обновление активных триггеров](#updating-active-triggers). В нижней части этой страницы команда фабрики данных [предоставила сценарий](#script), который необходимо использовать.

-   **Среды выполнения интеграции и общий доступ.** Среды выполнения интеграции не меняются часто и похожи на всех этапах в CI/CD. Поэтому Фабрика данных ожидает, что имена и типы сред выполнения интеграции одинаковы на всех этапах CI/CD. Если вы хотите совместно использовать среды выполнения интеграции на всех этапах, рассмотрите возможность использования тернарной фабрики только для хранения общих сред выполнения интеграции. Эту общую фабрику можно использовать во всех средах в качестве связанного типа среды выполнения интеграции.

-   **Управляемое развертывание закрытой конечной точки**. Если частная конечная точка уже существует в фабрике и вы пытаетесь развернуть шаблон ARM, содержащий закрытую конечную точку с тем же именем, но с измененными свойствами, развертывание завершится ошибкой. Иными словами, можно успешно развернуть частную конечную точку, если она имеет те же свойства, что и та, которая уже существует в фабрике. Если какое-либо свойство различается в разных средах, его можно переопределить путем параметризации этого свойства и предоставления соответствующего значения во время развертывания.

-   **Key Vault**. При использовании связанных служб, сведения о соединении которых хранятся в Azure Key Vault, рекомендуется сохранять отдельные хранилищах ключей для разных сред. Вы также можете настроить отдельные уровни разрешений для каждого из хранилища ключей. Например, вы не хотите, чтобы у участников вашей команды были разрешения на доступ к секретам рабочей среды. При таком подходе рекомендуем использовать одинаковые имена секретов на всех этапах. Если вы сохраняете одни и те же имена секретов, вам не нужно параметризовать каждую строку подключения в средах CI/CD, так как единственное, что изменяется — это имя хранилища ключей, которое является отдельным параметром.

-  **Именование ресурсов** Из-за ограничений шаблона ARM проблемы при развертывании могут возникать, если ресурсы содержат пробелы в имени. Группа фабрики данных Azure рекомендует использовать символы "_" или "-" вместо пробелов для ресурсов. Например, "Pipeline_1" будет предпочтительным именем для "конвейер 1".

## <a name="unsupported-features"></a>Неподдерживаемые функции

- Ожидаемо, что Фабрика данных не допускает выборочного отбора фиксаций или публикации ресурсов. Публикации будут включать все изменения, внесенные в фабрику данных.

    - Сущности фабрики данных зависят друг от друга. Например, триггеры зависят от конвейеров, а конвейеры зависят от наборов данных и других конвейеров. Выборочная публикация подмножества ресурсов может привести к непредвиденному поведению и ошибкам.
    - В редких случаях, когда требуется выборочная публикация, рассмотрите возможность использования исправления. Дополнительные сведения см. в [статье исправление рабочей среды](#hotfix-production-environment).

- Группа фабрики данных Azure не рекомендует назначать элементы управления Azure RBAC отдельным сущностям (конвейеры, наборы данных и т. д.) в фабрике данных. Например, если разработчик имеет доступ к конвейеру или набору данных, он также должен иметь доступ ко всем конвейерам или наборам данных в фабрике данных. Если вы считаете, что вам нужно реализовать множество ролей Azure в фабрике данных, ознакомьтесь с разворачиванием второй фабрики данных.

-   Вы не можете опубликовать из частных ветвей.

-   В настоящее время вы не можете размещать проекты на Bitbucket.

-   В настоящее время нельзя экспортировать и импортировать предупреждения и матрицы в качестве параметров. 

## <a name="sample-pre--and-post-deployment-script"></a><a name="script"></a> Пример сценария, выполняемого до и после развертывания

Ниже приведен пример сценария для остановки триггеров перед развертыванием и их последующего перезапуска. Скрипт также содержит код для удаления ресурсов. Сохраните сценарий в репозитории Azure DevOps Git и ссылайтесь на него с помощью задачи Azure PowerShell, используя версию 4.*.

При запуске сценария, выполняемого перед развертыванием, необходимо указать вариант следующих параметров в поле **Аргументы скрипта**.

`-armTemplate "$(System.DefaultWorkingDirectory)/<your-arm-template-location>" -ResourceGroupName <your-resource-group-name> -DataFactoryName <your-data-factory-name>  -predeployment $true -deleteDeployment $false`


При запуске сценария, выполняемого после развертывания, необходимо указать вариант следующих параметров в поле **Аргументы скрипта**.

`-armTemplate "$(System.DefaultWorkingDirectory)/<your-arm-template-location>" -ResourceGroupName <your-resource-group-name> -DataFactoryName <your-data-factory-name>  -predeployment $false -deleteDeployment $true`

![Задача Azure PowerShell](media/continuous-integration-deployment/continuous-integration-image11.png)

Ниже приведен сценарий, который можно использовать до и после развертывания. Он учитывает удаленные ресурсы и ссылки на ресурсы.

  
```powershell
param
(
    [parameter(Mandatory = $false)] [String] $armTemplate,
    [parameter(Mandatory = $false)] [String] $ResourceGroupName,
    [parameter(Mandatory = $false)] [String] $DataFactoryName,
    [parameter(Mandatory = $false)] [Bool] $predeployment=$true,
    [parameter(Mandatory = $false)] [Bool] $deleteDeployment=$false
)

function getPipelineDependencies {
    param([System.Object] $activity)
    if ($activity.Pipeline) {
        return @($activity.Pipeline.ReferenceName)
    } elseif ($activity.Activities) {
        $result = @()
        $activity.Activities | ForEach-Object{ $result += getPipelineDependencies -activity $_ }
        return $result
    } elseif ($activity.ifFalseActivities -or $activity.ifTrueActivities) {
        $result = @()
        $activity.ifFalseActivities | Where-Object {$_ -ne $null} | ForEach-Object{ $result += getPipelineDependencies -activity $_ }
        $activity.ifTrueActivities | Where-Object {$_ -ne $null} | ForEach-Object{ $result += getPipelineDependencies -activity $_ }
        return $result
    } elseif ($activity.defaultActivities) {
        $result = @()
        $activity.defaultActivities | ForEach-Object{ $result += getPipelineDependencies -activity $_ }
        if ($activity.cases) {
            $activity.cases | ForEach-Object{ $_.activities } | ForEach-Object{$result += getPipelineDependencies -activity $_ }
        }
        return $result
    } else {
        return @()
    }
}

function pipelineSortUtil {
    param([Microsoft.Azure.Commands.DataFactoryV2.Models.PSPipeline]$pipeline,
    [Hashtable] $pipelineNameResourceDict,
    [Hashtable] $visited,
    [System.Collections.Stack] $sortedList)
    if ($visited[$pipeline.Name] -eq $true) {
        return;
    }
    $visited[$pipeline.Name] = $true;
    $pipeline.Activities | ForEach-Object{ getPipelineDependencies -activity $_ -pipelineNameResourceDict $pipelineNameResourceDict}  | ForEach-Object{
        pipelineSortUtil -pipeline $pipelineNameResourceDict[$_] -pipelineNameResourceDict $pipelineNameResourceDict -visited $visited -sortedList $sortedList
    }
    $sortedList.Push($pipeline)

}

function Get-SortedPipelines {
    param(
        [string] $DataFactoryName,
        [string] $ResourceGroupName
    )
    $pipelines = Get-AzDataFactoryV2Pipeline -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName
    $ppDict = @{}
    $visited = @{}
    $stack = new-object System.Collections.Stack
    $pipelines | ForEach-Object{ $ppDict[$_.Name] = $_ }
    $pipelines | ForEach-Object{ pipelineSortUtil -pipeline $_ -pipelineNameResourceDict $ppDict -visited $visited -sortedList $stack }
    $sortedList = new-object Collections.Generic.List[Microsoft.Azure.Commands.DataFactoryV2.Models.PSPipeline]
    
    while ($stack.Count -gt 0) {
        $sortedList.Add($stack.Pop())
    }
    $sortedList
}

function triggerSortUtil {
    param([Microsoft.Azure.Commands.DataFactoryV2.Models.PSTrigger]$trigger,
    [Hashtable] $triggerNameResourceDict,
    [Hashtable] $visited,
    [System.Collections.Stack] $sortedList)
    if ($visited[$trigger.Name] -eq $true) {
        return;
    }
    $visited[$trigger.Name] = $true;
    if ($trigger.Properties.DependsOn) {
        $trigger.Properties.DependsOn | Where-Object {$_ -and $_.ReferenceTrigger} | ForEach-Object{
            triggerSortUtil -trigger $triggerNameResourceDict[$_.ReferenceTrigger.ReferenceName] -triggerNameResourceDict $triggerNameResourceDict -visited $visited -sortedList $sortedList
        }
    }
    $sortedList.Push($trigger)
}

function Get-SortedTriggers {
    param(
        [string] $DataFactoryName,
        [string] $ResourceGroupName
    )
    $triggers = Get-AzDataFactoryV2Trigger -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName
    $triggerDict = @{}
    $visited = @{}
    $stack = new-object System.Collections.Stack
    $triggers | ForEach-Object{ $triggerDict[$_.Name] = $_ }
    $triggers | ForEach-Object{ triggerSortUtil -trigger $_ -triggerNameResourceDict $triggerDict -visited $visited -sortedList $stack }
    $sortedList = new-object Collections.Generic.List[Microsoft.Azure.Commands.DataFactoryV2.Models.PSTrigger]
    
    while ($stack.Count -gt 0) {
        $sortedList.Add($stack.Pop())
    }
    $sortedList
}

function Get-SortedLinkedServices {
    param(
        [string] $DataFactoryName,
        [string] $ResourceGroupName
    )
    $linkedServices = Get-AzDataFactoryV2LinkedService -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName
    $LinkedServiceHasDependencies = @('HDInsightLinkedService', 'HDInsightOnDemandLinkedService', 'AzureBatchLinkedService')
    $Akv = 'AzureKeyVaultLinkedService'
    $HighOrderList = New-Object Collections.Generic.List[Microsoft.Azure.Commands.DataFactoryV2.Models.PSLinkedService]
    $RegularList = New-Object Collections.Generic.List[Microsoft.Azure.Commands.DataFactoryV2.Models.PSLinkedService]
    $AkvList = New-Object Collections.Generic.List[Microsoft.Azure.Commands.DataFactoryV2.Models.PSLinkedService]

    $linkedServices | ForEach-Object {
        if ($_.Properties.GetType().Name -in $LinkedServiceHasDependencies) {
            $HighOrderList.Add($_)
        }
        elseif ($_.Properties.GetType().Name -eq $Akv) {
            $AkvList.Add($_)
        }
        else {
            $RegularList.Add($_)
        }
    }

    $SortedList = New-Object Collections.Generic.List[Microsoft.Azure.Commands.DataFactoryV2.Models.PSLinkedService]($HighOrderList.Count + $RegularList.Count + $AkvList.Count)
    $SortedList.AddRange($HighOrderList)
    $SortedList.AddRange($RegularList)
    $SortedList.AddRange($AkvList)
    $SortedList
}

$templateJson = Get-Content $armTemplate | ConvertFrom-Json
$resources = $templateJson.resources

#Triggers 
Write-Host "Getting triggers"
$triggersInTemplate = $resources | Where-Object { $_.type -eq "Microsoft.DataFactory/factories/triggers" }
$triggerNamesInTemplate = $triggersInTemplate | ForEach-Object {$_.name.Substring(37, $_.name.Length-40)}

$triggersDeployed = Get-SortedTriggers -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName

$triggersToStop = $triggersDeployed | Where-Object { $triggerNamesInTemplate -contains $_.Name } | ForEach-Object { 
    New-Object PSObject -Property @{
        Name = $_.Name
        TriggerType = $_.Properties.GetType().Name 
    }
}
$triggersToDelete = $triggersDeployed | Where-Object { $triggerNamesInTemplate -notcontains $_.Name } | ForEach-Object { 
    New-Object PSObject -Property @{
        Name = $_.Name
        TriggerType = $_.Properties.GetType().Name 
    }
}
$triggersToStart = $triggersInTemplate | Where-Object { $_.properties.runtimeState -eq "Started" -and ($_.properties.pipelines.Count -gt 0 -or $_.properties.pipeline.pipelineReference -ne $null)} | ForEach-Object { 
    New-Object PSObject -Property @{
        Name = $_.name.Substring(37, $_.name.Length-40)
        TriggerType = $_.Properties.type
    }
}

if ($predeployment -eq $true) {
    #Stop all triggers
    Write-Host "Stopping deployed triggers`n"
    $triggersToStop | ForEach-Object {
        if ($_.TriggerType -eq "BlobEventsTrigger") {
            Write-Host "Unsubscribing" $_.Name "from events"
            $status = Remove-AzDataFactoryV2TriggerSubscription -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name
            while ($status.Status -ne "Disabled"){
                Start-Sleep -s 15
                $status = Get-AzDataFactoryV2TriggerSubscriptionStatus -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name
            }
        }
        Write-Host "Stopping trigger" $_.Name
        Stop-AzDataFactoryV2Trigger -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name -Force
    }
}
else {
    #Deleted resources
    #pipelines
    Write-Host "Getting pipelines"
    $pipelinesADF = Get-SortedPipelines -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName
    $pipelinesTemplate = $resources | Where-Object { $_.type -eq "Microsoft.DataFactory/factories/pipelines" }
    $pipelinesNames = $pipelinesTemplate | ForEach-Object {$_.name.Substring(37, $_.name.Length-40)}
    $deletedpipelines = $pipelinesADF | Where-Object { $pipelinesNames -notcontains $_.Name }
    #dataflows
    $dataflowsADF = Get-AzDataFactoryV2DataFlow -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName
    $dataflowsTemplate = $resources | Where-Object { $_.type -eq "Microsoft.DataFactory/factories/dataflows" }
    $dataflowsNames = $dataflowsTemplate | ForEach-Object {$_.name.Substring(37, $_.name.Length-40) }
    $deleteddataflow = $dataflowsADF | Where-Object { $dataflowsNames -notcontains $_.Name }
    #datasets
    Write-Host "Getting datasets"
    $datasetsADF = Get-AzDataFactoryV2Dataset -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName
    $datasetsTemplate = $resources | Where-Object { $_.type -eq "Microsoft.DataFactory/factories/datasets" }
    $datasetsNames = $datasetsTemplate | ForEach-Object {$_.name.Substring(37, $_.name.Length-40) }
    $deleteddataset = $datasetsADF | Where-Object { $datasetsNames -notcontains $_.Name }
    #linkedservices
    Write-Host "Getting linked services"
    $linkedservicesADF = Get-SortedLinkedServices -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName
    $linkedservicesTemplate = $resources | Where-Object { $_.type -eq "Microsoft.DataFactory/factories/linkedservices" }
    $linkedservicesNames = $linkedservicesTemplate | ForEach-Object {$_.name.Substring(37, $_.name.Length-40)}
    $deletedlinkedservices = $linkedservicesADF | Where-Object { $linkedservicesNames -notcontains $_.Name }
    #Integrationruntimes
    Write-Host "Getting integration runtimes"
    $integrationruntimesADF = Get-AzDataFactoryV2IntegrationRuntime -DataFactoryName $DataFactoryName -ResourceGroupName $ResourceGroupName
    $integrationruntimesTemplate = $resources | Where-Object { $_.type -eq "Microsoft.DataFactory/factories/integrationruntimes" }
    $integrationruntimesNames = $integrationruntimesTemplate | ForEach-Object {$_.name.Substring(37, $_.name.Length-40)}
    $deletedintegrationruntimes = $integrationruntimesADF | Where-Object { $integrationruntimesNames -notcontains $_.Name }

    #Delete resources
    Write-Host "Deleting triggers"
    $triggersToDelete | ForEach-Object { 
        Write-Host "Deleting trigger "  $_.Name
        $trig = Get-AzDataFactoryV2Trigger -name $_.Name -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName
        if ($trig.RuntimeState -eq "Started") {
            if ($_.TriggerType -eq "BlobEventsTrigger") {
                Write-Host "Unsubscribing trigger" $_.Name "from events"
                $status = Remove-AzDataFactoryV2TriggerSubscription -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name
                while ($status.Status -ne "Disabled"){
                    Start-Sleep -s 15
                    $status = Get-AzDataFactoryV2TriggerSubscriptionStatus -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name
                }
            }
            Stop-AzDataFactoryV2Trigger -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name -Force 
        }
        Remove-AzDataFactoryV2Trigger -Name $_.Name -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Force 
    }
    Write-Host "Deleting pipelines"
    $deletedpipelines | ForEach-Object { 
        Write-Host "Deleting pipeline " $_.Name
        Remove-AzDataFactoryV2Pipeline -Name $_.Name -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Force 
    }
    Write-Host "Deleting dataflows"
    $deleteddataflow | ForEach-Object { 
        Write-Host "Deleting dataflow " $_.Name
        Remove-AzDataFactoryV2DataFlow -Name $_.Name -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Force 
    }
    Write-Host "Deleting datasets"
    $deleteddataset | ForEach-Object { 
        Write-Host "Deleting dataset " $_.Name
        Remove-AzDataFactoryV2Dataset -Name $_.Name -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Force 
    }
    Write-Host "Deleting linked services"
    $deletedlinkedservices | ForEach-Object { 
        Write-Host "Deleting Linked Service " $_.Name
        Remove-AzDataFactoryV2LinkedService -Name $_.Name -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Force 
    }
    Write-Host "Deleting integration runtimes"
    $deletedintegrationruntimes | ForEach-Object { 
        Write-Host "Deleting integration runtime " $_.Name
        Remove-AzDataFactoryV2IntegrationRuntime -Name $_.Name -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Force 
    }

    if ($deleteDeployment -eq $true) {
        Write-Host "Deleting ARM deployment ... under resource group: " $ResourceGroupName
        $deployments = Get-AzResourceGroupDeployment -ResourceGroupName $ResourceGroupName
        $deploymentsToConsider = $deployments | Where { $_.DeploymentName -like "ArmTemplate_master*" -or $_.DeploymentName -like "ArmTemplateForFactory*" } | Sort-Object -Property Timestamp -Descending
        $deploymentName = $deploymentsToConsider[0].DeploymentName

       Write-Host "Deployment to be deleted: " $deploymentName
        $deploymentOperations = Get-AzResourceGroupDeploymentOperation -DeploymentName $deploymentName -ResourceGroupName $ResourceGroupName
        $deploymentsToDelete = $deploymentOperations | Where { $_.properties.targetResource.id -like "*Microsoft.Resources/deployments*" }

        $deploymentsToDelete | ForEach-Object { 
            Write-host "Deleting inner deployment: " $_.properties.targetResource.id
            Remove-AzResourceGroupDeployment -Id $_.properties.targetResource.id
        }
        Write-Host "Deleting deployment: " $deploymentName
        Remove-AzResourceGroupDeployment -ResourceGroupName $ResourceGroupName -Name $deploymentName
    }

    #Start active triggers - after cleanup efforts
    Write-Host "Starting active triggers"
    $triggersToStart | ForEach-Object { 
        if ($_.TriggerType -eq "BlobEventsTrigger") {
            Write-Host "Subscribing" $_.Name "to events"
            $status = Add-AzDataFactoryV2TriggerSubscription -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name
            while ($status.Status -ne "Enabled"){
                Start-Sleep -s 15
                $status = Get-AzDataFactoryV2TriggerSubscriptionStatus -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name
            }
        }
        Write-Host "Starting trigger" $_.Name
        Start-AzDataFactoryV2Trigger -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name $_.Name -Force
    }
}
```
