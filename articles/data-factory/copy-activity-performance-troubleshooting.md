---
title: Устранение неполадок с производительностью действия копирования
description: Узнайте, как устранять производительность действий копирования в фабрике данных Azure.
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 01/07/2021
ms.openlocfilehash: ee6105376f5e8dc884f13e04db51126c039328e9
ms.sourcegitcommit: 9514d24118135b6f753d8fc312f4b702a2957780
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/07/2021
ms.locfileid: "97968897"
---
# <a name="troubleshoot-copy-activity-performance"></a>Устранение неполадок с производительностью действия копирования

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

В этой статье описано, как устранить проблему с производительностью действия копирования в фабрике данных Azure. 

После запуска действия копирования можно получить результаты выполнения и статистику производительности в представлении [мониторинг действия копирования](copy-activity-monitoring.md) . Пример.

![Отслеживание сведений о выполнении действия копирования](./media/copy-activity-overview/monitor-copy-activity-run-details.png)

## <a name="performance-tuning-tips"></a>Советы по настройке производительности

В некоторых сценариях при выполнении действия копирования в фабрике данных вы увидите **"советы по настройке производительности"** в верхней части, как показано в приведенном выше примере. Советы указывают на узкие места, выявленные модулем ADF для этого конкретного выполнения копирования, а также рекомендации по повышению пропускной способности копирования. Попробуйте выполнить перекомандное изменение, а затем снова запустите копию.

В качестве справочной ссылки в настоящее время советы по настройке производительности предоставляют рекомендации в следующих случаях:

| Категория              | Советы по настройке производительности                                      |
| --------------------- | ------------------------------------------------------------ |
| Конкретное хранилище данных   | Загрузка данных в **Azure синапсе Analytics**: предложить использование polybase или инструкции Copy, если они не используются. |
| &nbsp;                | Копирование данных из **базы данных SQL Azure** и в нее: при высокой загрузке DTU рекомендуется обновить до более высокого уровня. |
| &nbsp;                | Копирование данных из **Azure Cosmos DB** и обратно: когда единица используется в условиях высокой загрузки, рекомендуется выполнить обновление до более крупного уровня. |
|                       | Копирование данных из **таблицы SAP**. при копировании большого объема данных рекомендуется использовать параметр секции SAP Connector, чтобы включить параллельную загрузку и увеличить максимальный номер секции. |
| &nbsp;                | Прием данных из **Amazon RedShift**: предложение использовать unload, если оно не используется. |
| Регулирование хранилища данных | Если количество операций чтения и записи регулируется хранилищем данных во время копирования, рекомендуется проверить и увеличить разрешенную частоту запросов для хранилища данных или уменьшить число параллельных рабочих нагрузок. |
| Среда выполнения интеграции  | Если вы используете локально **размещенное Integration Runtime (IR)** , а действие копирования ожидает длительное время в очереди до тех пор, пока у него не будет доступного ресурса для выполнения, рекомендуется масштабировать IR-объект. |
| &nbsp;                | Если вы используете **Azure Integration Runtime** , который находится в неоптимальном регионе, что приводит к медленным операциям чтения и записи, рекомендуется настроить для использования IR в другом регионе. |
| Отказоустойчивость       | Если настройка отказоустойчивости и пропуск несовместимых строк приводит к снижению производительности, рекомендуется обеспечить совместимость исходных и приемниковых данных. |
| промежуточное копирование           | Если промежуточная копия настроена, но не полезна для пары источников и приемников, рекомендуется удалить ее. |
| Возобновить                | Когда действие копирования возобновляется с последней точки сбоя, но вы изменили параметр Диу после исходного запуска, обратите внимание, что новый параметр Диу не вступит в силу. |

## <a name="understand-copy-activity-execution-details"></a>Общие сведения о выполнении действия копирования

Сведения о выполнении и длительности в нижней части представления мониторинга действия копирования описывают ключевые этапы, с которыми проходит действие копирования (см. пример в начале этой статьи), что особенно полезно для устранения неполадок с производительностью копирования. Узким местом при выполнении копирования является одна из самых длинных периодов. Ознакомьтесь со следующей таблицей в определении каждого этапа и Узнайте, как [устранять неполадки, связанные с копированием Azure IR](#troubleshoot-copy-activity-on-azure-ir) и [устранять неполадки при копировании на автономной IR](#troubleshoot-copy-activity-on-self-hosted-ir) с такой информацией.

| Этап           | Описание                                                  |
| --------------- | ------------------------------------------------------------ |
| Очередь           | Время, прошедшее до фактического запуска действия копирования в среде выполнения интеграции. |
| Скрипт перед копированием | Время, прошедшее между действием копирования, начинающимся с IR и действием копирования, которое завершило выполнение скрипта, выполняемого перед копированием, в приемнике хранилища данных. Применяется при настройке скрипта перед копированием для приемников базы данных, например, при записи данных в базу данных SQL Azure очистите перед копированием новых данных. |
| Перенос        | Время, прошедшее между окончанием предыдущего шага и передачей данных от источника к приемнику. <br/>Обратите внимание, что вложенные шаги в процессе перемещения выполняются параллельно, а некоторые операции не отображаются, например для анализа и создания формата файлов.<br><br/>- **Время до первого байта:** Время, прошедшее между окончанием предыдущего шага и моментом, когда IR получает первый байт из исходного хранилища данных. Применяется к источникам, не являющимся файлами.<br>- **Источник списка:** Количество времени, затраченного на перечисление исходных файлов или секций данных. Последний применяется при настройке параметров секционирования для источников базы данных, например при копировании данных из баз данных, таких как Oracle/SAP HANA/Teradata/Netezza/т. д.<br/>-**Чтение из источника:** Время, затраченное на получение данных из исходного хранилища данных.<br/>- **Запись в приемник:** Время, затраченное на запись данных в хранилище данных приемника. Обратите внимание, что на данный момент у некоторых соединителей нет этой метрики, включая Azure Когнитивный поиск, Azure обозреватель данных, хранилище таблиц Azure, Oracle, SQL Server, Common Data Service, Dynamics 365, Dynamics CRM, Salesforce или Salesforce Service Cloud. |

## <a name="troubleshoot-copy-activity-on-azure-ir"></a>Устранение неполадок с действием копирования Azure IR

Выполните [шаги по настройке производительности](copy-activity-performance.md#performance-tuning-steps) , чтобы спланировать и провести тест производительности для вашего сценария. 

Если производительность действия копирования не соответствует ожиданиям, то для устранения неполадок с одним действием копирования в Azure Integration Runtime, если в представлении "мониторинг копирования" отображаются [Советы по настройке производительности](#performance-tuning-tips) , примените предложение и повторите попытку. В противном случае [Ознакомьтесь с подробностями о выполнении действия копирования](#understand-copy-activity-execution-details), проверьте, на каком этапе имеет **наибольшее** время, и примените приведенные ниже инструкции для повышения производительности копирования.

- **"Скрипт перед копированием"** , длительная длительность: это означает, что сценарий, выполняемый перед копированием в базе данных-приемнике, занимает много времени. Настройте указанную логику скрипта перед копированием, чтобы повысить производительность. Если вам нужна дополнительная помощь по улучшению сценария, обратитесь к группе баз данных.

- **"Время передачи на первый байт"**. Это означает, что исходный запрос занимает много времени и не возвращает никаких данных. Проверьте и оптимизируйте запрос или сервер. Если вам нужна дополнительная помощь, обратитесь в службу хранилища данных.

- **"Источник списка передаваемых данных"** имеет длительное рабочее время: это означает, что перечисление исходных файлов или секций с данными базы данных-источника выполняется медленно.
  - Если при копировании данных из файлового источника использовать фильтр по **шаблону** для пути к папке или имени файла ( `wildcardFolderPath` или `wildcardFileName` ) или использовать **Фильтр времени последнего изменения файла** ( `modifiedDatetimeStart` или `modifiedDatetimeEnd` ), обратите внимание, что такой фильтр может привести к тому, что действие копирования перечислит все файлы в указанной папке на стороне клиента и применит фильтр. Такое перечисление файлов может стать узким местом, особенно при условии, что только небольшой набор файлов удовлетворяет правилу фильтра.

    - Проверьте, можно ли [Копировать файлы на основе пути или имени файла с секционированными датами](tutorial-incremental-copy-partitioned-file-name-copy-data-tool.md). Такой подход не приносит накладных расходов на сторону исходного кода.

    - Проверьте, можно ли использовать собственный фильтр хранилища данных, а именно "**префикс**" для Amazon S3/BLOB-объекта Azure, хранилища файлов Azure и "**листафтер/листбефоре**" для ADLS 1-го поколения. Эти фильтры являются фильтром на стороне сервера для хранилища данных и имеют гораздо более высокую производительность.

    - Рассмотрите возможность разбиения одного большого набора данных на несколько небольших наборов данных и позволяющие одновременно выполнять эти задания копирования, каждый из которых обрабатывает часть данных. Это можно сделать с помощью поиска/-метаданных + ForEach + Copy. См. статью [копирование файлов из нескольких контейнеров](solution-template-copy-files-multiple-containers.md) или [Перенос данных из Amazon S3 в ADLS 2-го поколения](solution-template-migration-s3-azure.md) шаблоны решений как общий пример.

  - Проверьте, сообщает ли ADF об ошибке регулирования в источнике или в том, что хранилище данных находится в состоянии высокой загрузки. Если это так, либо Сократите рабочие нагрузки в хранилище данных, либо попробуйте обратиться к администратору хранилища данных, чтобы увеличить предел регулирования или доступный ресурс.

  - Используйте Azure IR в том же или близком к региону исходного хранилища данных.

- Длительная **Рабочая длительность "перемещение-чтение из источника"**: 

  - При применении рекомендаций по загрузке данных, связанных с соединителем, рекомендуется использовать. Например, при копировании данных из [Amazon RedShift](connector-amazon-redshift.md)настройте для использования REDSHIFT Unload.

  - Проверьте, сообщает ли ADF об ошибке регулирования в источнике или в том, что хранилище данных находится в режиме высокой загрузки. Если это так, либо Сократите рабочие нагрузки в хранилище данных, либо попробуйте обратиться к администратору хранилища данных, чтобы увеличить предел регулирования или доступный ресурс.

  - Проверьте источник копирования и шаблон приемника: 

    - Если шаблон копирования поддерживает больше 4 единиц интеграции данных (диус), см. сведения в [этом разделе](copy-activity-performance-features.md#data-integration-units) , как правило, можно попробовать увеличить диус, чтобы повысить производительность. 

    - В противном случае рассмотрите возможность разбиения одного большого набора данных на несколько небольших наборов данных и позволяющие одновременно выполнять эти задания копирования, каждый из которых обрабатывает часть данных. Это можно сделать с помощью поиска/-метаданных + ForEach + Copy. См. статью [копирование файлов из нескольких контейнеров](solution-template-copy-files-multiple-containers.md), [Перенос данных из Amazon S3 в ADLS 2-го поколения](solution-template-migration-s3-azure.md)или [полное копирование с помощью шаблонов решений для управления таблицами](solution-template-bulk-copy-with-control-table.md) в качестве общего примера.

  - Используйте Azure IR в том же или близком к региону исходного хранилища данных.

- **"Перенос-запись в приемник", длительная Рабочая длительность**:

  - При применении рекомендаций по загрузке данных, связанных с соединителем, рекомендуется использовать. Например, при копировании данных в [Azure синапсе Analytics](connector-azure-sql-data-warehouse.md)используйте polybase или инструкцию Copy. 

  - Проверьте, сообщает ли ADF об ошибке регулирования в приемнике или в случае высокой загрузки хранилища данных. Если это так, либо Сократите рабочие нагрузки в хранилище данных, либо попробуйте обратиться к администратору хранилища данных, чтобы увеличить предел регулирования или доступный ресурс.

  - Проверьте источник копирования и шаблон приемника: 

    - Если шаблон копирования поддерживает больше 4 единиц интеграции данных (диус), см. сведения в [этом разделе](copy-activity-performance-features.md#data-integration-units) , как правило, можно попробовать увеличить диус, чтобы повысить производительность. 

    - В противном случае постепенно настраивайте [Параллельные копии](copy-activity-performance-features.md), обратите внимание, что слишком большое количество параллельных копий может даже повредить производительность.

  - Используйте Azure IR в том же или близком к региону хранилища данных приемника.

## <a name="troubleshoot-copy-activity-on-self-hosted-ir"></a>Устранение неполадок с действием копирования на локальной среде IR

Выполните [шаги по настройке производительности](copy-activity-performance.md#performance-tuning-steps) , чтобы спланировать и провести тест производительности для вашего сценария. 

Если производительность копирования не соответствует ожиданиям, то для устранения неполадок с одним действием копирования в Azure Integration Runtime, если в представлении мониторинга копирования отображаются [Советы по настройке производительности](#performance-tuning-tips) , примените предложение и повторите попытку. В противном случае [Ознакомьтесь с подробностями о выполнении действия копирования](#understand-copy-activity-execution-details), проверьте, на каком этапе имеет **наибольшее** время, и примените приведенные ниже инструкции для повышения производительности копирования.

- **"Очередь — длительная длительность":** это означает, что действие копирования ожидает длительное время в очереди до тех пор, пока на локальном компьютере не будет исполняться ресурс. Проверьте емкость и использование IR и увеличьте [масштаб](create-self-hosted-integration-runtime.md#high-availability-and-scalability) в соответствии с рабочей нагрузкой.

- **"Время передачи на первый байт"**. Это означает, что исходный запрос занимает много времени и не возвращает никаких данных. Проверьте и оптимизируйте запрос или сервер. Если вам нужна дополнительная помощь, обратитесь в службу хранилища данных.

- **"Источник списка передаваемых данных"** имеет длительное рабочее время: это означает, что перечисление исходных файлов или секций с данными базы данных-источника выполняется медленно.

  - Проверьте, имеет ли локально размещенный IR-компьютер низкую задержку при подключении к исходному хранилищу данных. Если ваш источник находится в Azure, вы можете использовать [это средство](http://www.azurespeed.com/Azure/Latency) для проверки задержки с самостоятельно РАЗМЕЩЕНного IR-компьютера в регионе Azure, чем больше.

  - Если при копировании данных из файлового источника использовать фильтр по **шаблону** для пути к папке или имени файла ( `wildcardFolderPath` или `wildcardFileName` ) или использовать **Фильтр времени последнего изменения файла** ( `modifiedDatetimeStart` или `modifiedDatetimeEnd` ), обратите внимание, что такой фильтр может привести к тому, что действие копирования перечислит все файлы в указанной папке на стороне клиента и применит фильтр. Такое перечисление файлов может стать узким местом, особенно при условии, что только небольшой набор файлов удовлетворяет правилу фильтра.

    - Проверьте, можно ли [Копировать файлы на основе пути или имени файла с секционированными датами](tutorial-incremental-copy-partitioned-file-name-copy-data-tool.md). Такой подход не приносит накладных расходов на сторону исходного кода.

    - Проверьте, можно ли использовать собственный фильтр хранилища данных, а именно "**префикс**" для Amazon S3/BLOB-объекта Azure, хранилища файлов Azure и "**листафтер/листбефоре**" для ADLS 1-го поколения. Эти фильтры являются фильтром на стороне сервера для хранилища данных и имеют гораздо более высокую производительность.

    - Рассмотрите возможность разбиения одного большого набора данных на несколько небольших наборов данных и позволяющие одновременно выполнять эти задания копирования, каждый из которых обрабатывает часть данных. Это можно сделать с помощью поиска/-метаданных + ForEach + Copy. См. статью [копирование файлов из нескольких контейнеров](solution-template-copy-files-multiple-containers.md) или [Перенос данных из Amazon S3 в ADLS 2-го поколения](solution-template-migration-s3-azure.md) шаблоны решений как общий пример.

  - Проверьте, сообщает ли ADF об ошибке регулирования в источнике или в том, что хранилище данных находится в состоянии высокой загрузки. Если это так, либо Сократите рабочие нагрузки в хранилище данных, либо попробуйте обратиться к администратору хранилища данных, чтобы увеличить предел регулирования или доступный ресурс.

- Длительная **Рабочая длительность "перемещение-чтение из источника"**: 

  - Проверьте, имеет ли локально размещенный IR-компьютер низкую задержку при подключении к исходному хранилищу данных. Если ваш источник находится в Azure, [это средство](http://www.azurespeed.com/Azure/Latency) можно использовать для проверки задержки с самостоятельно РАЗМЕЩЕНного ИК-компьютера в регионах Azure, чем меньше.

  - Убедитесь, что на собственном компьютере IR достаточно пропускной способности для эффективного чтения и передачи данных. Если исходное хранилище данных находится в Azure, [это средство](https://www.azurespeed.com/Azure/Download) можно использовать для проверки скорости загрузки.

  - Проверьте тенденцию использования ЦП и памяти в портал Azure-> странице > обзор фабрики данных. Рассмотрите возможность [увеличения или уменьшения IR](create-self-hosted-integration-runtime.md#high-availability-and-scalability) , если загрузка ЦП высока или если объем доступной памяти мал.

  - При применении рекомендаций по загрузке данных, связанных с соединителем, рекомендуется использовать. Пример:

    - При копировании данных из [Oracle](connector-oracle.md#oracle-as-source), [Netezza](connector-netezza.md#netezza-as-source), [Teradata](connector-teradata.md#teradata-as-source), [SAP HANA](connector-sap-hana.md#sap-hana-as-source), [таблицы SAP](connector-sap-table.md#sap-table-as-source)и [открытого концентратора SAP](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source)можно включить параметры секций данных для параллельного копирования данных.

    - При копировании данных из [HDFS](connector-hdfs.md)настройте для использования DistCp.

    - При копировании данных из [Amazon RedShift](connector-amazon-redshift.md)настройте для использования REDSHIFT Unload.

  - Проверьте, сообщает ли ADF об ошибке регулирования в источнике или в том, что хранилище данных находится в режиме высокой загрузки. Если это так, либо Сократите рабочие нагрузки в хранилище данных, либо попробуйте обратиться к администратору хранилища данных, чтобы увеличить предел регулирования или доступный ресурс.

  - Проверьте источник копирования и шаблон приемника: 

    - При копировании данных из хранилищ данных с поддержкой параметров секционирования рекомендуется постепенно настраивать [Параллельные копии](copy-activity-performance-features.md). Обратите внимание, что слишком большое количество параллельных копий может даже повредить производительность.

    - В противном случае рассмотрите возможность разбиения одного большого набора данных на несколько небольших наборов данных и позволяющие одновременно выполнять эти задания копирования, каждый из которых обрабатывает часть данных. Это можно сделать с помощью поиска/-метаданных + ForEach + Copy. См. статью [копирование файлов из нескольких контейнеров](solution-template-copy-files-multiple-containers.md), [Перенос данных из Amazon S3 в ADLS 2-го поколения](solution-template-migration-s3-azure.md)или [полное копирование с помощью шаблонов решений для управления таблицами](solution-template-bulk-copy-with-control-table.md) в качестве общего примера.

- **"Перенос-запись в приемник", длительная Рабочая длительность**:

  - При применении рекомендаций по загрузке данных, связанных с соединителем, рекомендуется использовать. Например, при копировании данных в [Azure синапсе Analytics](connector-azure-sql-data-warehouse.md)используйте polybase или инструкцию Copy. 

  - Проверьте, имеет ли локально размещенный IR-компьютер низкую задержку подключения к хранилищу данных приемника. Если ваш приемник находится в Azure, вы можете использовать [это средство](http://www.azurespeed.com/Azure/Latency) для проверки задержки с самостоятельно РАЗМЕЩЕНного IR-компьютера в регионе Azure, чем больше.

  - Проверьте, достаточна ли пропускная способность на автономном компьютере для передачи и записи данных. Если хранилище данных-приемник находится в Azure, [это средство](https://www.azurespeed.com/Azure/UploadLargeFile) можно использовать для проверки скорости передачи.

  - Проверьте, не используется ли на странице обзора данных > общие сведения о производительности ЦП и памяти для саморазмещенной ИК-нагрузки в портал Azure->. Рассмотрите возможность [увеличения или уменьшения IR](create-self-hosted-integration-runtime.md#high-availability-and-scalability) , если загрузка ЦП высока или если объем доступной памяти мал.

  - Проверьте, сообщает ли ADF об ошибке регулирования в приемнике или в случае высокой загрузки хранилища данных. Если это так, либо Сократите рабочие нагрузки в хранилище данных, либо попробуйте обратиться к администратору хранилища данных, чтобы увеличить предел регулирования или доступный ресурс.

  - Рекомендуется постепенно настраивать [Параллельные копии](copy-activity-performance-features.md). Обратите внимание, что слишком большое количество параллельных копий может даже повредить производительность.


## <a name="connector-and-ir-performance"></a>Производительность соединителя и ИК-связи

В этом разделе рассматриваются некоторые руководства по устранению неполадок производительности для определенного типа соединителя или среды выполнения интеграции.

### <a name="activity-execution-time-varies-using-azure-ir-vs-azure-vnet-ir"></a>Время выполнения действия зависит от использования среды IR Azure IR и Azure VNet

Время выполнения действия меняется, если набор данных основан на разных Integration Runtime.

- **Симптомы**. Простое переключение связанной службы в наборе данных выполняет те же действия конвейера, но значительно отличается от времени выполнения. Если набор данных основан на Integration Runtime управляемой виртуальной сети, то среднее для завершения выполнения занимает более 2 минут, но при использовании Integration Runtime по умолчанию выполнение занимает примерно 20 секунд.

- **Причина**. при проверке сведений о выполнении конвейера можно увидеть, что медленный конвейер работает в управляемой виртуальной сети (виртуальная сеть) IR, а обычная — на Azure IR. По своей структуре управляемая виртуальная сеть использует больше времени в очереди, чем Azure IR, так как мы не будем обслуживать один расчетный узел на фабрику данных, поэтому для каждого действия копирования достаточно 2 минуты, и это происходит в основном при присоединении к виртуальной сети, а не Azure IR.

    
### <a name="low-performance-when-loading-data-into-azure-sql-database"></a>Низкая производительность при загрузке данных в базу данных SQL Azure

- **Симптомы**. при копировании данных в в базу данных SQL Azure происходит снижение скорости.

- **Причина**. Основная причина проблемы в основном инициируется узким местом на стороне базы данных SQL Azure. Ниже приведены некоторые возможные причины.

    - Уровень базы данных SQL Azure недостаточно высок.

    - Использование DTU базы данных SQL Azure близко к 100%. Вы можете [отслеживать производительность](https://docs.microsoft.com/azure/azure-sql/database/monitor-tune-overview) и обновлять уровень базы данных SQL Azure.

    - Индексы заданы неправильно. Удалите все индексы перед загрузкой данных и создайте их повторно после завершения загрузки.

    - WriteBatchSize недостаточно велик, чтобы вместить размер строки схемы. Попробуйте увеличить свойство проблемы.

    - Вместо использования массовых отступов используется хранимая процедура, которая, как ожидается, может ухудшить производительность. 

- **Решение**. см. статью [Устранение неполадок с производительностью действия копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance-troubleshooting).

### <a name="timeout-or-slow-performance-when-parsing-large-excel-file"></a>Время ожидания или снижение производительности при анализе большого файла Excel

- **Симптомы**:

    - При создании набора данных Excel и импорте схемы из подключения/хранилища, просмотра данных, списка или обновления листов может возникнуть ошибка времени ожидания, если файл Excel имеет большой размер.

    - При использовании действия копирования для копирования данных из большого файла Excel (>= 100 МБ) в другое хранилище данных может наблюдаться снижение производительности или проблем с производительностью.

- **Причина**. 

    - Для таких операций, как импорт схемы, предварительный просмотр данных и вывод списка листов в наборе данных Excel, время ожидания равно 100 s и статическому. Для большого файла Excel эти операции могут не завершаться в течение времени ожидания.

    - Действие копирования ADF считывает весь файл Excel в память, а затем находит указанный лист и ячейки для чтения данных. Это поведение вызвано тем, что в основном ADF-файле пакета SDK используется.

- **Решение**. 

    - Для импорта схемы можно создать файл примера меньшего размера, который является подмножеством исходного файла, и выбрать «импортировать схему из образца файла» вместо «импортировать схему из подключения или хранилища».

    - Для листа списка в раскрывающемся списке лист можно щелкнуть "Изменить" и ввести вместо этого имя или индекс листа.

    - Чтобы скопировать большой файл Excel (>100 МБ) в другое хранилище, можно использовать источник Excel потока данных, который прочитает и выполняет потоковую передачу.
    
## <a name="other-references"></a>Прочие ссылки

Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.

* Хранилище BLOB-объектов Azure. [целевые показатели масштабируемости и производительности для хранилища BLOB-объектов](../storage/blobs/scalability-targets.md) и [производительности и контрольный список масштабируемости для хранилища BLOB-объектов](../storage/blobs/storage-performance-checklist.md).
* Хранилище таблиц Azure: [целевые показатели масштабируемости и производительности для хранилища таблиц](../storage/tables/scalability-targets.md) и [производительности и контрольный список масштабируемости для хранилища таблиц](../storage/tables/storage-performance-checklist.md).
* База данных SQL Azure. Вы можете [отслеживать производительность](../azure-sql/database/monitor-tune-overview.md) и проверять процент использования единиц транзакций базы данных (DTU).
* Azure синапсе Analytics. ее возможности измеряются в единицах использования хранилища данных (Dwu). См. статью [Управление возможностями вычислений в Azure синапсе Analytics (обзор)](../synapse-analytics/sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
* Azure Cosmos DB: [уровни производительности в Azure Cosmos DB](../cosmos-db/performance-levels.md).
* SQL Server: [мониторинг и настройка производительности](/sql/relational-databases/performance/monitor-and-tune-for-performance).
* Локальный файловый сервер: [Настройка производительности файловых серверов](/previous-versions//dn567661(v=vs.85)).

## <a name="next-steps"></a>Дальнейшие действия
См. другие статьи о действии копирования:

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Руководство по производительности и масштабируемости действия копирования](copy-activity-performance.md)
- [Функции оптимизации производительности действий копирования](copy-activity-performance-features.md)
- [Перенос данных из хранилища данных в Azure с помощью фабрики данных Azure](data-migration-guidance-overview.md)
- [Миграция данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)