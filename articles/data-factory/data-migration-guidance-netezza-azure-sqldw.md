---
title: Перенос данных с локального сервера Netezza в Azure
description: Используйте фабрику данных Azure для переноса данных с локального сервера Netezza в Azure.
author: dearandyxu
ms.author: yexu
ms.service: data-factory
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 12/09/2020
ms.openlocfilehash: 36ca7b709e0ec945f1fb4a9a8b745d20e6a58fe1
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "100367781"
---
# <a name="use-azure-data-factory-to-migrate-data-from-an-on-premises-netezza-server-to-azure"></a>Перенос данных с локального сервера Netezza в Azure с помощью фабрики данных Azure 

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

Фабрика данных Azure предоставляет производительный, надежный и экономичный механизм переноса данных с локального сервера Netezza в учетную запись хранения Azure или базу данных Azure синапсе Analytics. 

В этой статье содержатся следующие сведения для специалистов по обработке и анализу данных и разработчиков:

> [!div class="checklist"]
> * Производительность 
> * Устойчивость копирования
> * Безопасность сети
> * Общая архитектура решения 
> * Рекомендации по реализации  

## <a name="performance"></a>Производительность

Фабрика данных Azure предлагает бессерверную архитектуру, обеспечивающую параллелизм на различных уровнях. Если вы являетесь разработчиком, это означает, что вы можете создавать конвейеры для полного использования полосы пропускания сети и базы данных, чтобы максимально увеличить пропускную способность перемещения данных для вашей среды.

![Диаграмма производительности](media/data-migration-guidance-netezza-azure-sqldw/performance.png)

Приведенная выше схема может интерпретироваться следующим образом:

- Одно действие копирования может воспользоваться преимуществами масштабируемых ресурсов вычислений. При использовании Azure Integration Runtime можно указать [до 256 диус](./copy-activity-performance.md#data-integration-units) для каждого действия копирования в бессерверном режиме. С помощью локальной среды выполнения интеграции (с локальным размещением) можно вручную масштабировать компьютер или масштабировать его на несколько компьютеров ([до четырех узлов](./create-self-hosted-integration-runtime.md#high-availability-and-scalability)), и одно действие копирования распределяет свой раздел по всем узлам. 

- Одно действие копирования считывает и выполняет запись в хранилище данных с помощью нескольких потоков. 

- Поток управления фабрики данных Azure может запускать несколько операций копирования параллельно. Например, он может запускать их с помощью [цикла for each](./control-flow-for-each-activity.md). 

Дополнительные сведения см. в разделе Краткое информация о [производительности и масштабируемости действий копирования](./copy-activity-performance.md).

## <a name="resilience"></a>Устойчивость

В рамках одного действия копирования фабрика данных Azure имеет встроенный механизм повторных попыток, позволяющий ему управлять определенным уровнем временных сбоев в хранилищах данных или в базовой сети.

При копировании данных между хранилищами данных источника и приемника с помощью действия копирования фабрики данных Azure существует два способа обработки несовместимых строк. Можно либо прервать, либо завершить действие копирования или продолжить копирование остальных данных, пропуская несовместимые строки данных. Кроме того, чтобы узнать причину сбоя, можно зарегистрировать несовместимые строки в хранилище BLOB-объектов Azure или Azure Data Lake Store, исправить данные в источнике данных и повторить действие копирования.

## <a name="network-security"></a>Безопасность сети 

По умолчанию фабрика данных Azure передает данные с локального сервера Netezza в учетную запись хранения Azure или базу данных Azure синапсе Analytics, используя зашифрованное подключение по протоколу HTTPS. HTTPS обеспечивает шифрование данных при передаче и предотвращает прослушивание трафика и атаки типа "злоумышленник в середине".

Кроме того, если вы не хотите, чтобы данные передавались через общедоступный Интернет, вы можете повысить безопасность, передавая данные через частный пиринг через канал Azure Express Route. 

В следующем разделе описывается достижение более высокого уровня безопасности.

## <a name="solution-architecture"></a>Архитектура решения

В этом разделе обсуждаются два способа переноса данных.

### <a name="migrate-data-over-the-public-internet"></a>Перенос данных через общедоступный Интернет

![Перенос данных через общедоступный Интернет](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-public-network.png)

Приведенная выше схема может интерпретироваться следующим образом:

- В этой архитектуре данные безопасно передаются с помощью протокола HTTPS через общедоступный Интернет.

- Для достижения этой архитектуры необходимо установить среду выполнения интеграции фабрики данных Azure (локальное размещение) на компьютере под управлением Windows, который находится за корпоративным брандмауэром. Убедитесь, что эта среда выполнения интеграции может напрямую обращаться к серверу Netezza. Чтобы полностью использовать пропускную способность сети и хранилища данных для копирования данных, можно вручную увеличить масштаб компьютера или выполнить масштабирование на нескольких компьютерах.

- С помощью этой архитектуры можно перенести исходные данные моментального снимка и разностные данные.

### <a name="migrate-data-over-a-private-network"></a>Перенос данных через частную сеть 

![Перенос данных через частную сеть](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-private-network.png)

Приведенная выше схема может интерпретироваться следующим образом:

- В этой архитектуре данные переносятся по ссылке частного пиринга через экспресс-маршрут Azure, и данные никогда не проходят через общедоступный Интернет. 

- Для достижения этой архитектуры необходимо установить среду выполнения интеграции фабрики данных Azure (локальное размещение) на виртуальной машине Windows в виртуальной сети Azure. Чтобы полностью использовать пропускную способность сети и хранилища данных для копирования данных, можно вручную увеличить масштаб виртуальной машины или выполнить масштабирование на нескольких виртуальных машинах.

- С помощью этой архитектуры можно перенести исходные данные моментального снимка и разностные данные.

## <a name="implement-best-practices"></a>Реализация рекомендаций 

### <a name="manage-authentication-and-credentials"></a>Управление проверкой подлинности и учетными данными 

- Для проверки подлинности в Netezza можно использовать [проверку подлинности ODBC с помощью строки подключения](./connector-netezza.md#linked-service-properties). 

- Для проверки подлинности в хранилище BLOB-объектов Azure: 

   - Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](./connector-azure-blob-storage.md#managed-identity). Управляемые удостоверения, созданные на основе автоматически управляемого удостоверения фабрики данных Azure в Azure Active Directory (Azure AD), позволяют настраивать конвейеры без необходимости указывать учетные данные в определении связанной службы.  

   - Кроме того, вы можете пройти проверку подлинности в хранилище BLOB-объектов Azure, используя [субъект](./connector-azure-blob-storage.md#service-principal-authentication), [подпись общего доступа](./connector-azure-blob-storage.md#shared-access-signature-authentication)или [ключ учетной записи хранения](./connector-azure-blob-storage.md#account-key-authentication). 

- Для проверки подлинности в Azure Data Lake Storage 2-го поколения: 

   - Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](./connector-azure-data-lake-storage.md#managed-identity).
   
   - Также можно использовать [субъект-службу](./connector-azure-data-lake-storage.md#service-principal-authentication) или [ключ учетной записи хранения](./connector-azure-data-lake-storage.md#account-key-authentication). 

- Для аутентификации в Azure синапсе Analytics:

   - Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](./connector-azure-sql-data-warehouse.md#managed-identity).
   
   - Также можно использовать [субъект-службу](./connector-azure-sql-data-warehouse.md#service-principal-authentication) или [проверку подлинности SQL](./connector-azure-sql-data-warehouse.md#sql-authentication).

- Если управляемые удостоверения для ресурсов Azure не используются, настоятельно рекомендуется [хранить учетные данные в Azure Key Vault](./store-credentials-in-key-vault.md) , чтобы упростить централизованное управление ключами и их вращение без изменения связанных служб фабрики данных Azure. Это также одна из [рекомендаций для CI/CD](./continuous-integration-deployment.md#best-practices-for-cicd). 

### <a name="migrate-initial-snapshot-data"></a>Перенос исходных данных моментальных снимков 

Для небольших таблиц (т. е. таблиц с объемом менее 100 ГБ или, которые могут быть перенесены в Azure в течение двух часов) можно создать для каждой таблицы данные загрузки каждого задания копирования. Для повышения пропускной способности можно запустить несколько заданий копирования фабрики данных Azure для параллельной загрузки отдельных таблиц. 

В каждом задании копирования для выполнения параллельных запросов и копирования данных по секциям можно также достичь определенного уровня параллелизма, используя [ `parallelCopies` параметр свойства](./copy-activity-performance.md#parallel-copy) с одним из следующих параметров секции данных:

- Чтобы повысить эффективность, мы рекомендуем начать с среза данных.  Убедитесь, что значение в `parallelCopies` параметре меньше, чем общее число секций срезов данных в таблице на сервере Netezza.  

- Если объем всех секций срезов данных по-прежнему большой (например, 10 ГБ или больше), мы рекомендуем переключиться на динамический раздел диапазона. Этот параметр обеспечивает большую гибкость при определении количества секций и объема каждой секции по столбцу секционирования, верхней и нижней границам.

Для больших таблиц (т. е. таблиц с томом размером 100 ГБ или выше или которые *не могут* быть перенесены в Azure в течение двух часов) рекомендуется секционировать данные по пользовательскому запросу, а затем каждый раз копировать копию задания по одной секции. Для повышения пропускной способности можно одновременно запустить несколько заданий копирования в фабрике данных Azure. Для каждого целевого объекта задания копирования, загружая одну секцию по пользовательскому запросу, можно увеличить пропускную способность, включив параллелизм через срез данных или динамический диапазон. 

В случае сбоя любого задания копирования из-за временной ошибки сети или хранилища данных можно повторно выполнить задание копирования, завершившееся сбоем, чтобы перезагрузить эту конкретную секцию из таблицы. Другие задания копирования, которые загружают другие секции, не затрагиваются.

При загрузке данных в базу данных Azure синапсе Analytics мы рекомендуем включить Polybase в задании копирования с помощью хранилища BLOB-объектов Azure в качестве промежуточного хранения.

### <a name="migrate-delta-data"></a>Перенос разностных данных 

Чтобы указать новые или обновленные строки из таблицы, используйте столбец timestamp или инкрементный ключ в схеме. Затем можно сохранить Последнее значение в качестве верхнего предела во внешней таблице, а затем использовать его для фильтрации разностных данных при следующей загрузке данных. 

Каждая таблица может использовать другой столбец подложки для обнаружения новых или обновленных строк. Мы рекомендуем создать внешнюю таблицу управления. В таблице каждая строка представляет одну таблицу на сервере Netezza с его именем столбца подложки и значением верхнего предела. 

### <a name="configure-a-self-hosted-integration-runtime"></a>Настройка локальной среды выполнения интеграции

Если вы выполняете миграцию данных с сервера Netezza в Azure, независимо от того, находится ли сервер в локальной среде на брандмауэре или в виртуальной сети, необходимо установить локальную IR на компьютере Windows или на виртуальной машине, которая является подсистемой, используемой для перемещения данных. При установке локальной среды IR рекомендуется использовать следующий подход:

- Для каждого компьютера или виртуальной машины Windows Начните с конфигурации 32 виртуальных ЦП и 128 ГБ памяти. Вы можете следить за использованием ЦП и памяти на IR-компьютере во время переноса данных, чтобы узнать, требуется ли дальнейшее масштабирование компьютера для повышения производительности или уменьшения масштаба компьютера, чтобы сэкономить затраты.

- Кроме того, можно выполнить горизонтальное масштабирование, связав до четырех узлов с одним локальным IR. Одно задание копирования, которое выполняется для саморазмещенного IR, автоматически применяет все узлы виртуальной машины для параллельного копирования данных. Для обеспечения высокой доступности Начните с четырех узлов виртуальных машин, чтобы избежать единой точки отказа во время переноса данных.

### <a name="limit-your-partitions"></a>Ограничение секций

Рекомендуется провести проверку концепции производительности с помощью репрезентативного примера набора данных, чтобы можно было определить подходящий размер раздела для каждого действия копирования. Мы рекомендуем загрузить каждую секцию в Azure в течение двух часов.  

Чтобы скопировать таблицу, начните с одного действия копирования с единой, размещенной на собственном компьютере IR. Постепенно увеличивайте значение в `parallelCopies` зависимости от количества секций срезов данных в таблице. Узнайте, можно ли загрузить всю таблицу в Azure в течение двух часов в соответствии с пропускной способностью, полученной в результате задания копирования. 

Если его невозможно загрузить в Azure в течение двух часов, а емкость автономного узла IR и хранилища данных не используется полностью, постепенно увеличивайте количество одновременных операций копирования до тех пор, пока не достигнет ограничения сети или ограничения пропускной способности хранилищ данных. 

Отслеживайте использование ЦП и памяти на автономном IR-компьютере и будьте готовы к увеличению масштаба компьютера или масштабированию на нескольких компьютерах, когда вы видите, что ЦП и память полностью используются. 

При возникновении ошибок регулирования, о которых сообщает действие копирования в фабрике данных Azure, сократите параллелизм или `parallelCopies` настройку в фабрике данных Azure или попробуйте увеличить ограничения пропускной способности или операций ввода-вывода в секунду для хранилищ данных и сети. 


### <a name="estimate-your-pricing"></a>Оценка цен 

Рассмотрим следующий конвейер, который создается для переноса данных с локального сервера Netezza в базу данных Azure синапсе Analytics:

![Ценовой конвейер](media/data-migration-guidance-netezza-azure-sqldw/pricing-pipeline.png)

Предположим, что выполняются следующие условия: 

- Общий объем данных составляет 50 терабайт (ТБ). 

- Мы переносим данные с помощью архитектуры первого решения (сервер Netezza находится в локальной среде, защищенном брандмауэром).

- Том 50 ТБ делится на секции 500, и каждое действие копирования перемещает один раздел.

- Для каждого действия копирования настраивается один автономный IR-объект на четыре компьютера и достигается пропускная способность 20 мегабайт в секунду (Мбит/с). (В рамках действия копирования `parallelCopies` имеет значение 4, и каждый поток для загрузки данных из таблицы достигает пропускной способности 5 Мбит/с.)

- Параметр параллелизма ForEach имеет значение 3, а суммарная пропускная способность — 60 Мбит/с.

- В итоге выполнение миграции займет 243 часа.

На основе приведенных выше предположений мы рассмотрим предполагаемую цену: 

![Таблица цен](media/data-migration-guidance-netezza-azure-sqldw/pricing-table.png)

> [!NOTE]
> В приведенной выше таблице указаны гипотетические цены. Реальная цена зависит от фактической пропускной способности в среде. Цена на компьютере с Windows (с установленным локальным IR) не включена. 

### <a name="additional-references"></a>Дополнительная справка

Дополнительные сведения см. в следующих статьях и руководствах:

- [Перенос данных из локальной базы данных реляционного хранилища данных в Azure с помощью фабрики данных Azure](https://azure.microsoft.com/resources/data-migration-from-on-premise-relational-data-warehouse-to-azure-data-lake-using-azure-data-factory/)
- [Соединитель Netezza](./connector-netezza.md)
- [Соединитель ODBC](./connector-odbc.md)
- [Соединитель хранилища BLOB-объектов Azure](./connector-azure-blob-storage.md)
- [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](./connector-azure-data-lake-storage.md) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
- [Соединитель Azure синапсе Analytics](./connector-azure-sql-data-warehouse.md)
- [Руководство по настройке производительности действия копирования](./copy-activity-performance.md)
- [Создание и настройка локальной среды выполнения интеграции](./create-self-hosted-integration-runtime.md)
- [Высокая доступность и масштабируемость локальной среды выполнения интеграции](./create-self-hosted-integration-runtime.md#high-availability-and-scalability)
- [Вопросы безопасности при перемещении данных](./data-movement-security-considerations.md)
- [Хранение учетных данных в Azure Key Vault](./store-credentials-in-key-vault.md)
- [Добавочное копирование данных из одной таблицы](./tutorial-incremental-copy-portal.md)
- [Добавочное копирование данных из нескольких таблиц](./tutorial-incremental-copy-multiple-tables-portal.md)
- [Страница цен на Фабрику данных Azure](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/)

## <a name="next-steps"></a>Дальнейшие действия

- [Копирование файлов из нескольких контейнеров с помощью фабрики данных Azure](solution-template-copy-files-multiple-containers.md)