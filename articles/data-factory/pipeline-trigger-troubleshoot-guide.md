---
title: Устранение неполадок оркестрации конвейера и триггеров в фабрике данных Azure
description: Используйте различные методы для устранения проблем с триггерами конвейера в фабрике данных Azure.
author: ssabat
ms.service: data-factory
ms.date: 12/15/2020
ms.topic: troubleshooting
ms.author: susabat
ms.reviewer: susabat
ms.openlocfilehash: 1a5f665627da1b08ec57b04863a58f227c673af4
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98944903"
---
# <a name="troubleshoot-pipeline-orchestration-and-triggers-in-azure-data-factory"></a>Устранение неполадок оркестрации конвейера и триггеров в фабрике данных Azure

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Запуск конвейера в службе "Фабрика данных Azure" определяет экземпляр выполнения конвейера. Например, предположим, что у вас есть конвейер, который выполняется в 8:00 AM, 9:00 AM и 10:00 AM. В этом случае существует три отдельных запуска конвейера. Для каждого запуска конвейера предусмотрен уникальный идентификатор. Идентификатор запуска — это глобальный уникальный идентификатор (GUID), определяющий выполнение конкретного конвейера.

Запуск конвейера обычно создается путем передачи аргументов в параметры, определенные в конвейерах. Конвейер можно запустить либо вручную, либо с помощью триггера. Дополнительные сведения см. [в разделе выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md) .

## <a name="common-issues-causes-and-solutions"></a>Распространенные проблемы, причины и решения

### <a name="an-azure-functions-app-pipeline-throws-an-error-with-private-endpoint-connectivity"></a>Конвейер приложения функций Azure вызывает ошибку с подключением к частной конечной точке
 
У вас есть фабрика данных и приложение-функция Azure, выполняющееся в частной конечной точке. Вы пытаетесь запустить конвейер, который взаимодействует с приложением-функцией. Вы предприняли три разных метода, но один возвращает ошибку «Неверный запрос», а другие два метода возвращают ошибку «103 ошибка запрещено».

**Причина**. Сейчас фабрика данных не поддерживает закрытый соединитель конечной точки для приложений-функций. Функции Azure ототклоняют вызовы, так как они настроены на разрешение только соединений из частной связи.

**Решение**. Создайте конечную точку **привателинксервице** и укажите DNS приложения-функции.

### <a name="a-pipeline-run-is-canceled-but-the-monitor-still-shows-progress-status"></a>Выполнение конвейера отменено, но монитор по-прежнему отображает состояние хода выполнения

При отмене выполнения конвейера мониторинг конвейера часто показывает состояние хода выполнения. Это происходит из-за проблемы с кэшем браузера. Кроме того, могут отсутствовать правильные фильтры мониторинга.

**Решение**. Обновите браузер и примените правильные фильтры мониторинга.
 
### <a name="you-see-a-delimitedtextmorecolumnsthandefined-error-when-copying-a-pipeline"></a>При копировании конвейера отображается ошибка "Делимитедтекстмореколумнссандефинед"
 
Если копируемая папка содержит файлы с разными схемами, например переменное число столбцов, различные разделители, параметры символов кавычек или некоторые проблемы с данными, конвейер фабрики данных может вызвать эту ошибку:

`
Operation on target Copy_sks  failed: Failure happened on 'Sink' side.
ErrorCode=DelimitedTextMoreColumnsThanDefined,
'Type=Microsoft.DataTransfer.Common.Shared.HybridDeliveryException,
Message=Error found when processing 'Csv/Tsv Format Text' source '0_2020_11_09_11_43_32.avro' with row number 53: found more columns than expected column count 27.,
Source=Microsoft.DataTransfer.Common,'
`

**Решение**. Выберите параметр **Копировать в двоичном** виде при создании действия копирования. Таким образом, для выполнения операций с массовым копированием или переносом данных из одного Data Lake в другой фабрика данных не будет открывать файлы для чтения схемы. Вместо этого фабрика данных будет обрабатывать каждый файл как двоичный и копировать его в другое расположение.

### <a name="a-pipeline-run-fails-when-you-reach-the-capacity-limit-of-the-integration-runtime"></a>Сбой выполнения конвейера при достижении ограничения емкости среды выполнения интеграции

Сообщение об ошибке:

`
Type=Microsoft.DataTransfer.Execution.Core.ExecutionException,Message=There are substantial concurrent MappingDataflow executions which is causing failures due to throttling under Integration Runtime 'AutoResolveIntegrationRuntime'.
`

**Причина**: достигнуто ограничение емкости среды выполнения интеграции. Возможно, вы используете большой объем потока данных, одновременно используя одну и ту же среду выполнения интеграции. Дополнительные сведения см. [в разделе Подписка Azure и ограничения службы, квоты и ограничения](../azure-resource-manager/management/azure-subscription-service-limits.md#version-2) .

**Решение**.
 
- Запускайте конвейеры в разное время активации.
- Создайте новую среду выполнения интеграции и разделите конвейеры между несколькими средами выполнения интеграции.

### <a name="you-have-activity-level-errors-and-failures-in-pipelines"></a>Ошибки и сбои на уровне действий в конвейерах

Оркестрации фабрики данных Azure позволяет использовать условную логику и позволяет пользователям принимать разные пути в зависимости от результата предыдущего действия. Это позволяет выполнить четыре условных пути: **при успешном выполнении** (по умолчанию) при **сбое**, **после завершения** и **при пропуске**. 

Фабрика данных Azure оценивает результат всех действий конечного уровня. Результаты конвейера выполняются успешно, только если все листья завершились успешно. Если конечное действие пропущено, вместо него вычисляется его родительское действие. 

**Решение**

1. Реализуйте проверки на уровне действий, следуя [процедуре обработки ошибок и ошибок конвейера](https://techcommunity.microsoft.com/t5/azure-data-factory/understanding-pipeline-failures-and-error-handling/ba-p/1630459).
1. Используйте Azure Logic Apps для мониторинга конвейеров через регулярные интервалы [, следующие за запросом фабрики](/rest/api/datafactory/pipelineruns/querybyfactory).

## <a name="monitor-pipeline-failures-in-regular-intervals"></a>Мониторинг ошибок конвейера через равные промежутки времени

Может потребоваться мониторинг конвейеров фабрики данных с ошибками в интервале, скажем 5 минут. Вы можете запрашивать и фильтровать запуски конвейера из фабрики данных с помощью конечной точки. 

Настройте приложение логики Azure для запроса всех конвейеров со сбоями каждые 5 минут, как описано в разделе [запрос по фабрике](/rest/api/datafactory/pipelineruns/querybyfactory). Затем вы можете сообщить о происшествиях в систему билетов.

Дополнительные сведения см. в [разделе Отправка уведомлений из фабрики данных, часть 2](https://www.mssqltips.com/sqlservertip/5962/send-notifications-from-an-azure-data-factory-pipeline--part-2/).

## <a name="next-steps"></a>Дальнейшие действия

Для получения дополнительных сведений об устранении неполадок воспользуйтесь следующими ресурсами:

*  [Блог о Фабрике данных](https://azure.microsoft.com/blog/tag/azure-data-factory/)
*  [Запросы на добавление функции в Фабрику данных](https://feedback.azure.com/forums/270578-data-factory)
*  [Видео по Azure](https://azure.microsoft.com/resources/videos/index/?sort=newest&services=data-factory)
*  [Страница вопросов (раздел вопросов и ответов на сайте Майкрософт)](/answers/topics/azure-data-factory.html)
*  [Сведения о Фабрике данных в Twitter](https://twitter.com/hashtag/DataFactory)