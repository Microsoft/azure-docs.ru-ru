---
title: Устранение неполадок оркестрации конвейера и триггеров в фабрике данных Azure
description: Используйте различные методы для устранения проблем с триггерами конвейера в фабрике данных Azure.
author: ssabat
ms.service: data-factory
ms.date: 03/13/2021
ms.topic: troubleshooting
ms.author: susabat
ms.reviewer: susabat
ms.openlocfilehash: 72f2a5eec25b9acc2aedd7b006fe3380141781c8
ms.sourcegitcommit: f0a3ee8ff77ee89f83b69bc30cb87caa80f1e724
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/26/2021
ms.locfileid: "105563418"
---
# <a name="troubleshoot-pipeline-orchestration-and-triggers-in-azure-data-factory"></a>Устранение неполадок оркестрации конвейера и триггеров в фабрике данных Azure

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Запуск конвейера в службе "Фабрика данных Azure" определяет экземпляр выполнения конвейера. Например, предположим, что у вас есть конвейер, который выполняется в 8:00 AM, 9:00 AM и 10:00 AM. В этом случае существует три отдельных запуска конвейера. Для каждого запуска конвейера предусмотрен уникальный идентификатор. Идентификатор запуска — это глобальный уникальный идентификатор (GUID), определяющий выполнение конкретного конвейера.

Запуск конвейера обычно создается путем передачи аргументов в параметры, определенные в конвейерах. Конвейер можно запустить либо вручную, либо с помощью триггера. Дополнительные сведения см. [в разделе выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md) .

## <a name="common-issues-causes-and-solutions"></a>Распространенные проблемы, причины и решения

### <a name="an-azure-functions-app-pipeline-throws-an-error-with-private-endpoint-connectivity"></a>Конвейер приложения функций Azure вызывает ошибку с подключением к частной конечной точке
 
У вас есть фабрика данных и приложение-функция Azure, выполняющееся в частной конечной точке. Вы пытаетесь запустить конвейер, который взаимодействует с приложением-функцией. Вы предприняли три разных метода, но один возвращает ошибку «Неверный запрос», а другие два метода возвращают ошибку «103 ошибка запрещено».

**Причина**

Сейчас фабрика данных не поддерживает закрытый соединитель конечной точки для приложений-функций. Функции Azure ототклоняют вызовы, так как они настроены на разрешение только соединений из частной связи.

**Решение**

Создайте конечную точку **привателинксервице** и укажите DNS приложения-функции.

### <a name="a-pipeline-run-is-canceled-but-the-monitor-still-shows-progress-status"></a>Выполнение конвейера отменено, но монитор по-прежнему отображает состояние хода выполнения

**Причина**

При отмене выполнения конвейера мониторинг конвейера часто показывает состояние хода выполнения. Это происходит из-за проблемы с кэшем браузера. Кроме того, могут отсутствовать правильные фильтры мониторинга.

**Решение**

Обновите браузер и примените правильные фильтры мониторинга.
 
### <a name="you-see-a-delimitedtextmorecolumnsthandefined-error-when-copying-a-pipeline"></a>При копировании конвейера отображается ошибка "Делимитедтекстмореколумнссандефинед"
 
 **Причина**
 
Если копируемая папка содержит файлы с разными схемами, например переменное число столбцов, различные разделители, параметры символов кавычек или некоторые проблемы с данными, конвейер фабрики данных может вызвать эту ошибку:

`
Operation on target Copy_sks  failed: Failure happened on 'Sink' side.
ErrorCode=DelimitedTextMoreColumnsThanDefined,
'Type=Microsoft.DataTransfer.Common.Shared.HybridDeliveryException,
Message=Error found when processing 'Csv/Tsv Format Text' source '0_2020_11_09_11_43_32.avro' with row number 53: found more columns than expected column count 27.,
Source=Microsoft.DataTransfer.Common,'
`

**Решение**

Выберите параметр **Копировать в двоичном** виде при создании действия копирования. Таким образом, для выполнения операций с массовым копированием или переносом данных из одного Data Lake в другой фабрика данных не будет открывать файлы для чтения схемы. Вместо этого фабрика данных будет обрабатывать каждый файл как двоичный и копировать его в другое расположение.

### <a name="a-pipeline-run-fails-when-you-reach-the-capacity-limit-of-the-integration-runtime-for-data-flow"></a>Сбой выполнения конвейера при достижении ограничения емкости среды выполнения интеграции для потока данных

**Проблема**

Сообщение об ошибке:

`
Type=Microsoft.DataTransfer.Execution.Core.ExecutionException,Message=There are substantial concurrent MappingDataflow executions which is causing failures due to throttling under Integration Runtime 'AutoResolveIntegrationRuntime'.
`

**Причина**

Достигнуто ограничение емкости среды выполнения интеграции. Возможно, вы используете большой объем потока данных, одновременно используя одну и ту же среду выполнения интеграции. Дополнительные сведения см. [в разделе Подписка Azure и ограничения службы, квоты и ограничения](../azure-resource-manager/management/azure-subscription-service-limits.md#version-2) .

**Решение**
 
- Запускайте конвейеры в разное время активации.
- Создайте новую среду выполнения интеграции и разделите конвейеры между несколькими средами выполнения интеграции.

### <a name="how-to-perform-activity-level-errors-and-failures-in-pipelines"></a>Как выполнять ошибки и сбои на уровне действий в конвейерах

**Причина**

Оркестрации фабрики данных Azure позволяет использовать условную логику и позволяет пользователям принимать разные пути в зависимости от результата предыдущего действия. Это позволяет выполнить четыре условных пути: **при успешном выполнении** (по умолчанию) при **сбое**, **после завершения** и **при пропуске**. 

Фабрика данных Azure оценивает результат всех действий конечного уровня. Результаты конвейера выполняются успешно, только если все листья завершились успешно. Если конечное действие пропущено, вместо него вычисляется его родительское действие. 

**Решение**

* Реализуйте проверки на уровне действий, следуя [процедуре обработки ошибок и ошибок конвейера](https://techcommunity.microsoft.com/t5/azure-data-factory/understanding-pipeline-failures-and-error-handling/ba-p/1630459).
* Используйте Azure Logic Apps для мониторинга конвейеров через регулярные интервалы [, следующие за запросом фабрики](/rest/api/datafactory/pipelineruns/querybyfactory).
* [Визуальный мониторинг конвейера](./monitor-visually.md)

### <a name="how-to-monitor-pipeline-failures-in-regular-intervals"></a>Мониторинг ошибок конвейера через равные промежутки времени

**Причина**

Может потребоваться мониторинг конвейеров фабрики данных с ошибками в интервале, скажем 5 минут. Вы можете запрашивать и фильтровать запуски конвейера из фабрики данных с помощью конечной точки. 

**Решение**
* Вы можете настроить приложение логики Azure для запроса всех конвейеров со сбоями каждые 5 минут, как описано в разделе [запрос по фабрике](/rest/api/datafactory/pipelineruns/querybyfactory). Затем можно сообщить о происшествиях в систему билетов.
* [Визуальный мониторинг конвейера](./monitor-visually.md)

### <a name="degree-of-parallelism--increase-does-not-result-in-higher-throughput"></a>Степень увеличения параллелизма не приводит к повышению пропускной способности

**Причина** 

Степень параллелизма в *foreach* фактически является максимальной степенью параллелизма. Мы не можем гарантировать определенное количество выполнений в то же время, но этот параметр гарантирует, что мы никогда не перейдете выше заданного значения. Вы должны увидеть это ограничение, чтобы использовать его при управлении одновременным доступом к источникам и приемникам.

Известные факты о *foreach*
 * Foreach имеет свойство с названием количество пакетов (n), где значение по умолчанию — 20, а максимальное — 50.
 * Число пакетов, n, используется для создания n очередей. Далее мы рассмотрим некоторые сведения о создании этих очередей.
 * Каждая очередь выполняется последовательно, но несколько очередей могут выполняться параллельно.
 * Очереди создаются предварительно. Это означает, что в ходе выполнения не происходит перераспределения очередей.
 * В любой момент времени для каждой очереди будет обрабатываться не более одного элемента. Это означает, что не более n элементов обрабатываются в любое заданное время.
 * Общее время обработки foreach равно времени обработки самой длинной очереди. Это означает, что действие ForEach зависит от того, как создаются очереди.
 
**Решение**

 * Не следует использовать действие *SetVariable* внутри *для каждого* , выполняющегося параллельно.
 * Принимая во внимание способ создания очередей, клиент может повысить производительность foreach, установив несколько элементов, в которых каждый *элемент ForEach будет* иметь элементы с одинаковым временем обработки. Это обеспечит параллельную обработку длительных запусков, а не последовательностей.

 ### <a name="pipeline-status-is-queued-or-stuck-for-a-long-time"></a>Состояние конвейера находится в очереди или зависает в течение длительного времени
 
 **Причина**
 
 Это может происходить по различным причинам, например к ограничениям параллелизма, простоям служб, сбоям сети и т. д.
 
 **Решение**
 
* Ограничение параллелизма. Если у вашего конвейера есть политика параллелизма, убедитесь, что нет выполняющихся старых конвейеров. Максимальная допустимая параллельная обработка конвейера в фабрике данных Azure составляет 10 конвейеров. 
* Ограничения мониторинга: перейдите на холст создания ADF, выберите свой конвейер и определите, назначено ли ему свойство Concurrency. Если это так, перейдите в представление Мониторинг и убедитесь, что в течение прошедших 45 дней нет ничего. Если выполняется какое-либо действие, его можно отменить и запустить новый запуск конвейера.
* Временные проблемы. возможно, ваш запуск повлиял на временную сетевую неполадку, сбои учетных данных, службы и т. д.  В этом случае фабрика данных Azure имеет внутренний процесс восстановления, который отслеживает все запуски и запускает их при обнаружении ошибки. Этот процесс выполняется каждый час, поэтому, если выполнение будет задержано более часа, создайте обращение в службу поддержки.
 
### <a name="longer-start-up-times-for-activities-in-adf-copy-and-data-flow"></a>Больше времени запуска для действий в копии ADF и потоке данных

**Причина**

Это может произойти, если вы не реализовали функцию "срок жизни" для потока данных или оптимизированного шир.

**Решение**

* Если запуск каждого действия копирования занимает до 2 минут и проблема возникает в основном при соединении виртуальной сети (в отличии от Azure IR), это может быть связано с проблемой с производительностью копирования. Чтобы ознакомиться с инструкциями по устранению неполадок, перейдите к статье о [копировании производительности.](./copy-activity-performance-troubleshooting.md)
* Функцию срок жизни можно использовать для сокращения времени запуска кластера для действий потока данных. Проверьте [Integration Runtime потока данных.](./control-flow-execute-data-flow-activity.md#data-flow-integration-runtime)

 ### <a name="hitting-capacity-issues-in-shirself-hosted-integration-runtime"></a>Достижение проблем с емкостью в Шир (Integration Runtime, размещенных на собственном сервере)
 
 **Причина**
 
Это может произойти, если вы не выполнили масштабирование Шир в соответствии с рабочей нагрузкой.

**Решение**

* При возникновении проблемы с емкостью от Шир обновите виртуальную машину, чтобы увеличить размер узла, чтобы сбалансировать действия. Если вы получаете сообщение об ошибке, связанное с локальным неисправностью или ошибкой, локальным обновлением IR или локальными проблемами ИК-подключения, которые могут создать длинную очередь, перейдите к разделу [Устранение неполадок локальной среды выполнения интеграции.](./self-hosted-integration-runtime-troubleshoot-guide.md)

### <a name="error-messages-due-to-long-queues-for-adf-copy-and-data-flow"></a>Сообщения об ошибках из-за длительных очередей для копирования ADF и потока данных

**Причина**

Сообщения об ошибках, связанные с очередью, могут отображаться по различным причинам. 

**Решение**
* Если вы получаете сообщение об ошибке из любого источника или назначения через соединители, которые могут создать длинную очередь, перейдите к [руководству по устранению неполадок соединителя.](./connector-troubleshoot-guide.md)
* Если появится сообщение об ошибке, посвященное сопоставлению потока данных, который может создать длинную очередь, перейдите к [руководству по устранению неполадок потоков данных.](./data-flow-troubleshoot-guide.md)
* При появлении сообщения об ошибке других действий, таких как кирпичы, пользовательские действия или HDI, которые могут создать длинную очередь, перейдите к [руководству по устранению неполадок действий.](./data-factory-troubleshoot-guide.md)
* Если появится сообщение об ошибке, посвященное запуску пакетов служб SSIS, которые могут создать длинную очередь, перейдите к [руководству по устранению неполадок выполнения пакета Azure-SSIS](./ssis-integration-runtime-ssis-activity-faq.md) и [руководству по устранению неполадок управления Integration Runtime.](./ssis-integration-runtime-management-troubleshoot.md)


## <a name="next-steps"></a>Дальнейшие действия

Для получения дополнительных сведений об устранении неполадок воспользуйтесь следующими ресурсами:

*  [Блог о Фабрике данных](https://azure.microsoft.com/blog/tag/azure-data-factory/)
*  [Запросы на добавление функции в Фабрику данных](https://feedback.azure.com/forums/270578-data-factory)
*  [Видео по Azure](https://azure.microsoft.com/resources/videos/index/?sort=newest&services=data-factory)
*  [Страница вопросов (раздел вопросов и ответов на сайте Майкрософт)](/answers/topics/azure-data-factory.html)
*  [Сведения о Фабрике данных в Twitter](https://twitter.com/hashtag/DataFactory)