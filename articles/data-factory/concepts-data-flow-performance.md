---
title: Руководство по настройке производительности потоков данных для сопоставления
description: Узнайте о ключевых факторах, которые влияют на производительность потоков данных для сопоставления в Фабрике данных Azure.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 03/15/2021
ms.openlocfilehash: dd5b857c274e757f70920f244786df61c2770085
ms.sourcegitcommit: 772eb9c6684dd4864e0ba507945a83e48b8c16f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/20/2021
ms.locfileid: "103561691"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Руководство по настройке производительности потоков данных для сопоставления

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Сопоставление потоков данных в фабрике данных Azure обеспечивает интерфейс без кода для проектирования и выполнения преобразований данных в нужном масштабе. Если вы не знакомы с потоками данных для сопоставления, см. статью [Общие сведения о потоках данных для сопоставления](concepts-data-flow-overview.md). В этой статье описываются различные способы настройки и оптимизации потоков данных, чтобы они соответствовали тестам производительности.

Просмотрите приведенное ниже видео, чтобы увидеть некоторые образцы времени преобразования данных с помощью потоков данных.

> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="testing-data-flow-logic"></a>Тестирование логики потока данных

При проектировании и тестировании потоков данных от UI ADF режим отладки позволяет интерактивно тестироваться в динамическом кластере Spark. Это позволяет просматривать данные и выполнять потоки данных без ожидания прогрева кластера. Дополнительные сведения см. в статье [Режим отладки](concepts-data-flow-debug-mode.md).

## <a name="monitoring-data-flow-performance"></a>Отслеживание производительности потоков данных

После проверки логики преобразования с помощью режима отладки выполните сквозной запуск потока данных в качестве действия в конвейере. Потоки данных обновляются в конвейере с помощью [действия "выполнение потока данных](control-flow-execute-data-flow-activity.md)". Действие потока данных имеет уникальные возможности мониторинга по сравнению с другими действиями фабрики данных Azure, которые отображают подробный план выполнения и профиль производительности логики преобразования. Чтобы просмотреть подробные сведения о мониторинге потока данных, щелкните значок очков в выходных данных выполнения действия конвейера. Дополнительные сведения см. в статье [Мониторинг потоков данных для сопоставления](concepts-data-flow-monitoring.md).

![Монитор потока данных](media/data-flow/monitoring-details.png "Монитор потока данных 2")

При наблюдении за производительностью потока данных существует четыре возможных узких места для поиска:

* Время запуска кластера
* Чтение из источника
* Время преобразования
* Запись в приемник 

![Data Flow Monitoring](media/data-flow/monitoring-performance.png "Монитор потока данных 3") (Мониторинг потоков данных)

Время запуска кластера — это время, затрачиваемое на запуск кластера Apache Spark. Это значение находится в правом верхнем углу экрана мониторинга. Потоки данных выполняются в JIT-модели, где каждое задание использует изолированный кластер. Время запуска обычно составляет 3-5 минут. Для последовательных заданий это можно уменьшить, включив значение времени жизни. Дополнительные сведения см. [в разделе оптимизация Azure Integration Runtime](#ir).

Потоки данных используют оптимизатор Spark, который переупорядочивает и выполняет бизнес-логику в "этапах" для максимально быстрого выполнения. Для каждого приемника, в который записывается поток данных, в выходных данных мониторинга указывается длительность каждого этапа преобразования, а также время, затрачиваемое на запись данных в приемник. Время, которое является самым большим, вероятно, является узким местом потока данных. Если стадия преобразования, принимающая большие сведения, содержит источник, то может возникнуть необходимость в дальнейшей оптимизации времени чтения. Если преобразование занимает много времени, может потребоваться повторно секционировать или увеличить размер среды выполнения интеграции. Если время обработки приемника велико, может потребоваться увеличить масштаб базы данных или убедиться, что вы не выводите один файл.

Определив узкие места в потоке данных, используйте приведенные ниже стратегии оптимизации для повышения производительности.

## <a name="optimize-tab"></a>Вкладка оптимизации

Вкладка **Оптимизация** содержит параметры для настройки схемы секционирования кластера Spark. Эта вкладка существует в каждом преобразовании потока данных и указывает, нужно ли повторно секционировать данные **после** завершения преобразования. Настройка секционирования обеспечивает управление распределением данных между узлами вычислений и оптимизацией локализации данных, которые могут иметь как положительные, так и отрицательные последствия для общей производительности потока данных.

![На снимке экрана показана вкладка "оптимизация", включающая параметр секции, тип секции и число секций.](media/data-flow/optimize.png)

По умолчанию выбран параметр *использовать текущее секционирование* , которое указывает, что фабрика данных Azure сохраняет текущее выходное секционирование преобразования. Поскольку перераспределение данных занимает некоторое время, в большинстве случаев рекомендуется *использовать текущее секционирование* . Сценарии, в которых может потребоваться выполнить повторное секционирование данных, включают статистические выражения и объединения, которые значительно набирают данные или при использовании секционирования с исходным кодом в базе данных SQL.

Чтобы изменить секционирование для любого преобразования, перейдите на вкладку **Оптимизация** и установите переключатель **задать секционирование** . Вы увидите ряд вариантов секционирования. Наилучший способ секционирования зависит от объема данных, потенциальных ключей, значений NULL и количества элементов. 

> [!IMPORTANT]
> В одной секции все распределенные данные объединяются в одну секцию. Это очень медленная операция, которая также значительно влияет на все нисходящие преобразования и записи. Фабрика данных Azure настоятельно рекомендует использовать этот параметр, если нет явной бизнес-причины для этого.

Следующие параметры секционирования доступны в каждом преобразовании:

### <a name="round-robin"></a>Циклический перебор 

Циклический перебор распределяет данные равномерно по секциям. Используйте функцию циклического перебора, если у вас нет хороших ключевых кандидатов для реализации высокоплотной интеллектуальной стратегии секционирования. Вы можете задать количество физических секций.

### <a name="hash"></a>Хэш

Фабрика данных Azure создает хэш столбцов для создания универсальных секций, в которых строки с одинаковыми значениями попадают в одну и ту же секцию. При использовании параметра hash проверьте возможное отклонение секций. Вы можете задать количество физических секций.

### <a name="dynamic-range"></a>Динамический диапазон

Динамический диапазон использует динамические диапазоны Spark на основе предоставленных столбцов или выражений. Вы можете задать количество физических секций. 

### <a name="fixed-range"></a>Фиксированный диапазон

Создайте выражение, которое предоставляет фиксированный диапазон значений в столбцах секционированных данных. Чтобы избежать смещения секций, перед использованием этого параметра следует хорошо понимать данные. Значения, вводимые для выражения, используются как часть функции секционирования. Вы можете задать количество физических секций.

### <a name="key"></a>Ключ

Если вы хорошо понимаете количество элементов данных, секционирование ключей может оказаться хорошей стратегией. Секционирование ключей создает секции для каждого уникального значения в столбце. Невозможно задать количество секций, так как число основано на уникальных значениях в данных.

> [!TIP]
> Ручная настройка схемы секционирования переведет данные в случайном порядке и может сместить преимущества оптимизатора Spark. Рекомендуется не устанавливать секционирование вручную, если не требуется.

## <a name="logging-level"></a>Уровень ведения журнала

Если не требуется, чтобы каждое выполнение конвейера действий потока данных полностью запускало все журналы телеметрии, при необходимости можно задать уровень ведения журнала "базовый" или "нет". При выполнении потоков данных в режиме "подробного" (по умолчанию) вы запрашиваете ADF на полную регистрацию на каждом отдельном уровне секций во время преобразования данных. Это может быть дорогостоящей операцией, поэтому только включение подробных сведений при устранении неполадок может повысить общую производительность потока данных и конвейера. В режиме "базовый" будут регистрироваться только длительности преобразования, а "нет" — только сводка длительностей.

![Уровень ведения журнала](media/data-flow/logging.png "Задать уровень ведения журнала")

## <a name="optimizing-the-azure-integration-runtime"></a><a name="ir"></a> Оптимизация Azure Integration Runtime

Потоки данных выполняются в кластерах Spark, которые загружаются во время выполнения. Конфигурация используемого кластера определяется в среде выполнения интеграции (IR) действия. При определении среды выполнения интеграции необходимо выполнить три фактора производительности: тип кластера, размер кластера и время жизни.

Дополнительные сведения о создании среды Integration Runtime см. в статье [Среда выполнения интеграции в Фабрике данных Azure](concepts-integration-runtime.md).

### <a name="cluster-type"></a>Тип кластера

Существует три доступных варианта для типа кластера Spark: общее назначение, оптимизированная для памяти и оптимизированная для вычислений.

Кластеры **общего назначения** являются выбором по умолчанию и будут идеальным решением для большинства рабочих нагрузок потока данных. Это, как правило, лучший баланс производительности и стоимости.

Если поток данных содержит много соединений и уточняющих запросов, может потребоваться использовать **оптимизированный для памяти** кластер. Кластеры, оптимизированные для памяти, могут хранить больше данных в памяти и сокращать любые ошибки нехватки памяти, которые могут возникнуть. Оптимизированная для памяти максимальная цена за ядро, но также обычно приводит к более успешным конвейерам. Если при выполнении потоков данных возникают ошибки нехватки памяти, переключитесь на конфигурацию, оптимизированную для памяти Azure IR. 

**Оптимизация вычислений** не идеально подходит для рабочих процессов ETL и не рекомендуется группой фабрики данных Azure для большинства рабочих нагрузок. Для упрощенных преобразований данных, не требующих больших объемов памяти, таких как фильтрация данных или Добавление производных столбцов, кластеры, оптимизированные для вычислений, можно использовать с более дешевлей ценой за ядро.

### <a name="cluster-size"></a>Размер кластера

Потоки данных распределяют обработку данных по разным узлам в кластере Spark для параллельного выполнения операций. Кластер Spark с большим числом ядер увеличивает количество узлов в среде вычислений. Дополнительные узлы увеличивают вычислительную мощность потока данных. Увеличение размера кластера часто является простым способом уменьшить время обработки.

Размер кластера по умолчанию — четыре узла драйверов и четыре рабочих узла.  При обработке дополнительных данных рекомендуется использовать большие кластеры. Ниже приведены возможные варианты изменения размера.

| Рабочие ядра | Ядра драйверов | Общее число ядер | Примечания |
| ------------ | ------------ | ----------- | ----- |
| 4 | 4 | 8 | Недоступно для оптимизированных для вычислений |
| 8 | 8 | 16 | |
| 16 | 16 | 32 | |
| 32 | 16 | 48 | |
| 64 | 16 | 80 | |
| 128 | 16 | 144 | |
| 256 | 16 | 272 | |

Продаются цены на потоки данных в виртуальное ядро-часы, означающие, что в этот момент используется как размер кластера, так и фактор времени выполнения. При увеличении масштаба стоимость кластера увеличится, но общее время снизится.

> [!TIP]
> Существует пороговое значение того, насколько размер кластера влияет на производительность потока данных. В зависимости от размера данных существует точка, в которой увеличение размера кластера приведет к снижению производительности. Например, если у вас больше узлов, чем разделов данных, добавление дополнительных узлов не поможет. Рекомендуется запускать небольшие и масштабируемые решения в соответствии с потребностями производительности. 

### <a name="time-to-live"></a>Срок жизни

По умолчанию каждое действие потока данных выполняет развертывание нового кластера на основе конфигурации IR. Время запуска кластера занимает несколько минут, и обработка данных не может начаться, пока она не будет завершена. Если конвейеры содержат несколько **последовательных** потоков данных, можно включить значение срока жизни (TTL). Если указать значение срока жизни, кластер будет находиться в активном состоянии в течение определенного периода времени после завершения его выполнения. Если новое задание начинает использовать IR в течение срока жизни, оно будет повторно использовать существующий кластер, и время запуска значительно уменьшится. После завершения второго задания кластер снова будет оставаться активным в течение срока жизни.

Одновременно может выполняться только одно задание в одном кластере. Если имеется доступный кластер, но запущены два потока данных, то только один из них будет использовать динамический кластер. Второе задание будет создавать свой собственный изолированный кластер.

Если большая часть потоков данных выполняется параллельно, не рекомендуется включать TTL. 

> [!NOTE]
> Срок жизни недоступен при использовании автоматического разрешения среды выполнения интеграции

## <a name="optimizing-sources"></a>Оптимизация источников

Для каждого источника, кроме базы данных SQL Azure, рекомендуется **использовать текущее секционирование** в качестве выбранного значения. При чтении из всех других исходных систем потоки данных автоматически распределяют данные в зависимости от размера данных. Новая секция создается для примерно каждые 128 МБ данных. При увеличении размера данных увеличивается количество секций.

Любое пользовательское секционирование выполняется *после* считывания данных Spark и отрицательно сказывается на производительности потока данных. Так как данные равномерно секционированы при чтении, делать это не рекомендуется. 

> [!NOTE]
> Скорость чтения может быть ограничена пропускной способностью исходной системы.

### <a name="azure-sql-database-sources"></a>Источники базы данных SQL Azure

В базе данных SQL Azure имеется уникальный параметр секционирования, называемый "источник". Включение секционирования с исходным кодом может улучшить время чтения из базы данных SQL Azure, включив параллельные подключения в исходной системе. Укажите количество секций и способ секционирования данных. Используйте столбец секционирования с большим количеством элементов. Можно также ввести запрос, соответствующий схеме секционирования исходной таблицы.

> [!TIP]
> При исходном секционировании ввод-вывод SQL Server является узким местом. Добавление слишком большого количества секций может привести к чрезмерной нагрузке базы данных источника. Как правило, при использовании этого параметра идеально подходит четыре или пять секций.

![Исходное секционирование](media/data-flow/sourcepart3.png "Исходное секционирование")

#### <a name="isolation-level"></a>Уровень изоляции

Уровень изоляции считывания в исходной системе Azure SQL оказывает влияние на производительность. Выбор параметра "READ UNCOMMITTED" обеспечит максимальную производительность и предотвращает блокировку базы данных. Дополнительные сведения об уровнях изоляции SQL см. в статье [Основные сведения о уровнях изоляции](/sql/connect/jdbc/understanding-isolation-levels).

#### <a name="read-using-query"></a>Чтение с помощью запроса

Чтение из базы данных SQL Azure можно выполнить с помощью таблицы или SQL-запроса. При выполнении SQL-запроса запрос должен быть завершен до начала преобразования. SQL-запросы могут быть полезны для отправки операций, которые могут выполняться быстрее и сокращают объем данных, считанных из SQL Server таких как инструкции SELECT, WHERE и JOIN. При отправке операций вы теряете возможность контролировать журналы преобразований и производительности преобразования до того, как данные поступают в поток данных.

### <a name="azure-synapse-analytics-sources"></a>Источники Azure синапсе Analytics

При использовании Azure синапсе Analytics в параметрах источника существует параметр **включить промежуточное хранение** . Это позволяет ADF читать из синапсе с помощью ```Staging``` , что значительно повышает производительность чтения. Для включения необходимо ```Staging``` указать хранилище BLOB-объектов Azure или Azure Data Lake Storage промежуточное расположение Gen2 в параметрах действия потока данных.

![Включить промежуточный режим](media/data-flow/enable-staging.png "Включить промежуточный режим")

### <a name="file-based-sources"></a>Файловые источники

Хотя потоки данных поддерживают различные типы файлов, фабрика данных Azure рекомендует использовать собственный формат Spark Parquet для оптимального времени чтения и записи.

Если вы используете один и тот же поток данных для набора файлов, мы рекомендуем считывать данные из папки, используя подстановочные знаки или прочитав список файлов. Выполнение одного действия потока данных может обработать все файлы в пакетной службе. Дополнительные сведения о настройке этих параметров можно найти в документации по соединителю, например в [хранилище BLOB-объектов Azure](connector-azure-blob-storage.md#source-transformation).

По возможности избегайте использования действия For-Each для выполнения потоков данных по набору файлов. Это приведет к тому, что каждый шаг итерации для каждого из них будет использовать свой кластер Spark, который часто необязателен и может быть дорогостоящим. 

## <a name="optimizing-sinks"></a>Оптимизация приемников

Когда потоки данных записываются в приемники, любое пользовательское секционирование будет происходить непосредственно перед записью. Как и источник, в большинстве случаев рекомендуется **использовать текущее секционирование** в качестве выбранного параметра секции. Секционированные данные записываются значительно быстрее, чем несекционированные данные, даже если назначение не секционировано. Ниже приведены отдельные рекомендации для различных типов приемников. 

### <a name="azure-sql-database-sinks"></a>Приемники базы данных SQL Azure

При использовании базы данных SQL Azure секционирование по умолчанию должно работать в большинстве случаев. Существует вероятность, что у приемника может быть слишком много секций для обработки базы данных SQL. Если вы используете эту возможность, сократите число разделов, выводимых приемником базы данных SQL.

#### <a name="impact-of-error-row-handling-to-performance"></a>Влияние обработки строк ошибок на производительность

При включении обработки ошибок строк ("продолжить при ошибке") в преобразовании приемника ADF-файл будет выполнять дополнительный шаг перед записью совместимых строк в целевую таблицу. Этот дополнительный шаг приведет к небольшому снижению производительности, которое может быть в диапазоне 5%, добавленном для этого шага, при этом также добавляется дополнительная незначительное снижение производительности, если параметру также присвоено несовместимые строки в файле журнала.

#### <a name="disabling-indexes-using-a-sql-script"></a>Отключение индексов с помощью скрипта SQL

Отключение индексов перед нагрузкой в базе данных SQL может значительно повысить производительность записи в таблицу. Выполните приведенную ниже команду перед записью в приемник SQL.

`ALTER INDEX ALL ON dbo.[Table Name] DISABLE`

После завершения записи перестройте индексы с помощью следующей команды:

`ALTER INDEX ALL ON dbo.[Table Name] REBUILD`

Они могут выполняться в собственном режиме с помощью сценариев pre и POST-SQL в базе данных SQL Azure или приемника синапсе при сопоставлении потоков данных.

![Отключение индексов](media/data-flow/disable-indexes-sql.png "Отключение индексов")

> [!WARNING]
> При отключении индексов поток данных эффективно управляет базой данных, и запросы в данный момент вряд ли будут выполняться. В результате многие задания ETL активируются в середине ночь, чтобы избежать этого конфликта. Дополнительные сведения см. в статье [ограничения для отключения индексов](/sql/relational-databases/indexes/disable-indexes-and-constraints) .

#### <a name="scaling-up-your-database"></a>Масштабирование базы данных

Запланируйте изменение размеров Базы данных SQL Azure и Хранилища данных SQL Azure, выступающих в роли источника и приемника, перед выполнением конвейера, чтобы увеличить пропускную способность и минимизировать регулирование Azure по достижении ограничений DTU. После завершения выполнения конвейера восстановите нормальные размеры баз данных.

### <a name="azure-synapse-analytics-sinks"></a>Приемники Azure синапсе Analytics

При записи в Azure синапсе Analytics убедитесь, что для параметра **включить промежуточное хранение** задано значение true. Это позволяет ADF записывать с помощью [команды SQL Copy](/sql/t-sql/statements/copy-into-transact-sql) , которая эффективно загружает данные. Необходимо сослаться на Azure Data Lake Storage Gen2 или учетную запись хранилища BLOB-объектов Azure, чтобы выполнить промежуточное хранение данных при использовании промежуточного хранения.

В отличие от промежуточного хранения, те же рекомендации применяются к Azure синапсе Analytics в качестве базы данных SQL Azure.

### <a name="file-based-sinks"></a>Приемники на основе файлов 

Хотя потоки данных поддерживают различные типы файлов, фабрика данных Azure рекомендует использовать собственный формат Spark Parquet для оптимального времени чтения и записи.

Если данные распределены равномерно, **использовать текущее секционирование** будет самый быстрый вариант секционирования для записи файлов.

#### <a name="file-name-options"></a>Параметры имени файла

При записи файлов можно выбрать параметры именования, которые влияют на производительность каждого из них.

![Параметры приемника](media/data-flow/file-sink-settings.png "параметры приемника")

Выбор параметра **по умолчанию** приводит к быстрому написанию. Каждая секция будет эквивалентна файлу с именем по умолчанию Spark. Это полезно, если вы просто читаете данные из папки.

При настройке **шаблона** именования каждый файл раздела будет переименован в более удобное для пользователя имя. Эта операция происходит после записи и немного медленнее, чем выбор значения по умолчанию. Для каждого раздела можно вручную присвоить имя каждой отдельной секции.

Если столбец соответствует тому, как вы хотите выводить данные, можно выбрать **в качестве данных столбец**. Это переведет данные в случайном порядке и может повлиять на производительность, если столбцы распределены неравномерно.

**Вывод в один файл** объединяет все данные в одну секцию. Это ведет к длительному времени записи, особенно для больших наборов данных. Группа фабрики данных Azure настоятельно рекомендует **не** выбирать этот вариант, если нет явной бизнес-причины.

### <a name="cosmosdb-sinks"></a>Приемники CosmosDB

При записи в CosmosDB изменение пропускной способности и размера пакета во время выполнения потока данных может повысить производительность. Эти изменения вступят в силу только во время выполнения действия потока данных и будут возвращаться к исходным параметрам коллекции после завершения. 

**Размер пакета:** Обычно достаточно начать с размера пакета по умолчанию. Для дальнейшей настройки этого значения Вычислите приблизительный размер объекта данных и убедитесь, что размер объекта * размер пакета меньше 2 МБ. Если это так, можно увеличить размер пакета, чтобы получить лучшую пропускную способность.

**Пропускная способность:** Задайте более высокую пропускную способность, чтобы документы можно было быстрее писать в CosmosDB. Учитывайте более высокие затраты на ЕДИНИЦу, исходя из настроек высокой пропускной способности.

**Бюджет пропускной способности записи:** Используйте значение, которое меньше общего числа получателей в минуту. Если у вас есть поток данных с большим количеством секций Spark, Настройка пропускной способности бюджета позволит повысить баланс между этими секциями.

## <a name="optimizing-transformations"></a>Оптимизация преобразований

### <a name="optimizing-joins-exists-and-lookups"></a>Оптимизация соединений, существующих и уточняющих запросов

#### <a name="broadcasting"></a>Трансляции

При преобразовании «объединения», «уточняющие запросы» и «EXISTS», если один или оба потока данных достаточно малы, чтобы вместить их в память рабочего узла, можно оптимизировать производительность, включив **вещание**. Вещание происходит при отправке мелких кадров данных на все узлы в кластере. Это позволяет ядру Spark выполнять соединение, не перегруппировка данные в больших потоках. По умолчанию механизм Spark автоматически решает, следует ли широковещательно передавать одну сторону объединения. Если вы знакомы с входящими данными и знаете, что один поток будет значительно меньше другого, можно выбрать **фиксированное** вещание. Фиксированная трансляция заставляет Spark транслировать выбранный поток. 

Если размер рассылаемых данных слишком велик для узла Spark, может возникнуть ошибка нехватки памяти. Чтобы избежать ошибок нехватки памяти, используйте **оптимизированные для памяти** кластеры. Если во время выполнения потока данных возникают тайм-ауты вещания, можно отключить оптимизацию вещания. Однако это приведет к более медленному выполнению потоков данных.

При работе с источниками данных, для выполнения запросов к которым может потребоваться больше времени, например для больших запросов к базам данных, рекомендуется отключить широковещательную рассылку для соединений. Источник с длительным временем запроса может привести к истечению времени ожидания Spark, когда кластер пытается выполнить широковещательную рассылку на вычисленные узлы. Еще один хороший выбор для выключения вещания — при наличии в потоке данных потока, который выполняет статистическую обработку значений, используемых в преобразовании «Уточняющий запрос» позже. Этот шаблон может запутать оптимизатор Spark и привести к истечению времени ожидания.

![Оптимизация преобразования "Соединение"](media/data-flow/joinoptimize.png "Оптимизация объединения")

#### <a name="cross-joins"></a>Перекрестные с соединения

Если вы используете литеральные значения в условиях JOIN или настроили несколько совпадений по обеим сторонам объединения, Spark запустит соединение как перекрестное соединение. Перекрестное соединение — это полное декартое изделие, которое затем фильтрует объединенные значения. Это значительно медленнее, чем другие типы присоединений. Убедитесь, что имеются ссылки на столбцы с обеих сторон условий объединения, чтобы избежать влияния на производительность.

#### <a name="sorting-before-joins"></a>Сортировка перед соединением

В отличие от таких инструментов, как SQL Server Integration Services, преобразование "Соединение" необязательно является операцией соединения слиянием. Перед преобразованием не требуется выполнять сортировку ключей объединения. Группа фабрики данных Azure не рекомендует использовать преобразования сортировки при сопоставлении потоков данных.

### <a name="window-transformation-performance"></a>Производительность преобразования окна

[Преобразование «окно»](data-flow-window.md) разделяет данные по значению в столбцах, выбранных в качестве части ```over()``` предложения в параметрах преобразования. Существует ряд очень популярных статистических и аналитических функций, доступных в преобразовании Windows. Однако если ваш вариант использования предназначен для создания окна для всего набора данных с целью ранжирования ```rank()``` или номера строки ```rowNumber()``` , рекомендуется вместо этого использовать [Преобразование «ранг](data-flow-rank.md) » и « [суррогатный ключ](data-flow-surrogate-key.md)». Это преобразование будет выполнять более эффективные операции с наборами данных, используя эти функции.

### <a name="repartitioning-skewed-data"></a>Перераспределение отклоненных данных

Некоторые преобразования, такие как соединения и статистические функции, переслучайируют секции данных и иногда могут привести к неравномерному получению данных. Отклоненные данные означают, что данные равномерно распределяются по секциям. Сильно наклоненные данные могут привести к более медленным преобразованиям и записи приемника. Можно проверить асимметрию данных в любой точке выполнения потока данных, щелкнув преобразование в мониторе мониторинга.

![Асимметрия и эксцесс](media/data-flow/skewness-kurtosis.png "Асимметрия и эксцесс")

На экране мониторинга отображается, как данные распределяются по каждой секции вместе с двумя метриками, асимметрией и эксцесс. **Асимметрия** — это мера того, насколько асимметричны данные и могут иметь положительное, нулевое, отрицательное или неопределенное значение. Отрицательный наклон означает, что левый хвост длиннее правого. **Эксцесс** — это мера того, является ли данные тяжелыми или светло-хвостовиками. Высокие значения эксцесс нежелательны. Оптимальные диапазоны асимметрии находятся между-3 и 3, а диапазоны от эксцесс меньше 10. Простой способ интерпретации этих чисел — Просмотр секционированной диаграммы и просмотр того, что 1 гистограмма значительно больше, чем остальная.

Если данные не секционированы равномерно после преобразования, можно использовать [вкладку Оптимизация](#optimize-tab) для повторного секционирования. Перегруппировка данных занимает некоторое время и может не повысить производительность потока данных.

> [!TIP]
> При повторном секционировании данных, но при наличии нисходящих преобразований, которые переключить данные в случайном порядке, следует использовать хэш-секционирование для столбца, используемого в качестве ключа объединения.

## <a name="using-data-flows-in-pipelines"></a>Использование потоков данных в конвейерах 

При создании сложных конвейеров с несколькими потоками данных логический поток может оказать значительное влияние на время и стоимость. В этом разделе рассматривается влияние различных стратегий архитектуры.

### <a name="executing-data-flows-in-parallel"></a>Параллельное исполнение потоков данных

Если параллельно выполняется несколько потоков данных, ADF будет раснимать отдельные кластеры Spark для каждого действия. Это позволяет изолировать и выполнять каждое задание в параллельном режиме, но может привести к одновременному запуску нескольких кластеров.

Если потоки данных выполняются параллельно, рекомендуется не включать Azure IR времени в активное свойство, так как это приведет к многократному неиспользуемому горячему пулу.

> [!TIP]
> Вместо того чтобы выполнять один поток данных несколько раз в каждом действии, разработайте данные в Data Lake и используйте подстановочные пути для обработки данных в одном потоке данных.

### <a name="execute-data-flows-sequentially"></a>Последовательно выполнять потоки данных

Если действия потока данных выполняются последовательно, рекомендуется задать TTL в конфигурации Azure IR. ADF будет повторно использовать ресурсы вычислений, что приведет к более быстрому запуску кластера. Каждое действие по-прежнему будет изолировано получать новый контекст Spark для каждого выполнения.

Выполнение заданий последовательно, скорее всего, займет самое длинное время для выполнения сквозной операции, но обеспечивает четкое разделение логических операций.

### <a name="overloading-a-single-data-flow"></a>Перегрузка одного потока данных

Если вы поместили всю логику в один поток данных, ADF будет выполнять все задания в одном экземпляре Spark. Хотя это может показаться способом снизить затраты, он объединяет разные логические потоки и может быть трудно отслеживать и отлаживать. В случае сбоя одного из компонентов все остальные части задания также завершатся ошибкой. Группа фабрики данных Azure рекомендует упорядочить потоки данных по независимому потоку бизнес-логики. Если поток данных становится слишком большим, разделение его на отдельные компоненты упростит мониторинг и отладку. Хотя количество преобразований в потоке данных не ограничено, слишком много сделает задание сложным.

### <a name="execute-sinks-in-parallel"></a>Параллельное выполнение приемников

Поведением приемников потока данных по умолчанию является выполнение каждого приемника последовательно, в последовательном режиме и для сбоя потока данных при обнаружении ошибки в приемнике. Кроме того, все приемники по умолчанию относятся к одной группе, если вы не перейдете в свойства потока данных и не установите различные приоритеты для приемников.

Потоки данных позволяют группировать приемники в группы со вкладки Свойства потока данных в конструкторе пользовательского интерфейса. Можно настроить порядок выполнения приемников, а также для групповых приемников, используя один и тот же номер группы. Чтобы упростить управление группами, можно попросить ADF запустить приемники в одной группе, чтобы они выполнялись параллельно.

В разделе "Свойства приемника" действия "выполнение потока данных конвейера" можно включить загрузку параллельного приемника. При включении "запускать параллельно" вы указываете, что потоки данных записываются в подключенные приемники в то же время, а не последовательно. Чтобы использовать параметр Parallel, приемники должны быть сгруппированы вместе и подключены к одному и тому же потоку через новую ветвь или условное разбиение.

## <a name="next-steps"></a>Дальнейшие действия

Ознакомьтесь с другими статьями о производительности потоков данных.

- [Действие потока данных](control-flow-execute-data-flow-activity.md)
- [Мониторинг производительности потока данных](concepts-data-flow-monitoring.md)
