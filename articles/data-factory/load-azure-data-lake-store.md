---
title: Загрузка данных в Azure Data Lake Storage 1-го поколения
description: Копирование данных в Azure Data Lake Storage 1-го поколения с помощью службы "Фабрика данных Azure"
ms.author: jingwang
author: linda33wj
ms.service: data-factory
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 01/17/2018
ms.openlocfilehash: 2d307a279bee56440f7354ad2c92664fd2af86b9
ms.sourcegitcommit: d4734bc680ea221ea80fdea67859d6d32241aefc
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/14/2021
ms.locfileid: "100370773"
---
# <a name="load-data-into-azure-data-lake-storage-gen1-by-using-azure-data-factory"></a>Загрузка данных в Azure Data Lake Storage 1-го поколения c помощью службы "Фабрика данных Azure"

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

[Azure Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-overview.md) (ранее известный как Azure Data Lake Store) — это крупномасштабный репозиторий корпоративного уровня для рабочих нагрузок анализа больших данных. Data Lake Storage 1-го поколения позволяет собирать данные любого размера, типа и с любой скоростью приема. Данные эксплуатационной и исследовательской аналитики хранятся в одном месте.

Фабрика данных Azure — это полностью управляемая облачная служба интеграции данных. С ее помощью можно заполнять озера данными из имеющейся системы и сократить время создания решений аналитики.

Фабрика данных Azure предоставляет следующие преимущества загрузки данных в Data Lake Storage 1-го поколения.

* **Простота настройки**: Вам доступен интуитивно понятный 5-этапный мастер без необходимости создавать сценарии.
* **Расширенная поддержка хранилищ данных.** Встроенная поддержка обширного набора локальных и облачных хранилищ данных. Подробный список см. в таблице [Поддерживаемые хранилища данных и форматы](copy-activity-overview.md#supported-data-stores-and-formats).
* **Безопасность и соответствие требованиям**. Данные передаются по протоколу HTTPS или ExpressRoute. Наличие глобальной службы гарантирует, что ваши данные никогда не покинут заданных географических границ.
* **Высокая производительность.** Скорость загрузки данных в Data Lake Storage 1-го поколения — до 1 ГБ/с. Дополнительные сведения см. в руководстве [по настройке производительности действия копирования](copy-activity-performance.md).

В этой статье показано, как с помощью средства копирования данных службы "Фабрика данных" _загружать данные из Amazon S3 в Data Lake Storage 1-го поколения_. Чтобы копировать данные из других типов хранилищ, необходимо выполнить аналогичные шаги.

> [!NOTE]
> Дополнительные сведения см. в статье [Копирование данных в Azure Data Lake Storage Gen1 и из него с помощью фабрики данных Azure](connector-azure-data-lake-store.md).

## <a name="prerequisites"></a>Предварительные требования

* Подписка Azure. Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись](https://azure.microsoft.com/free/), прежде чем начинать работу.
* Учетная запись Data Lake Storage 1-го поколения. Если у вас нет учетной записи Data Lake Storage 1-го поколения, см. раздел [Создание учетной записи Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-get-started-portal.md#create-a-data-lake-storage-gen1-account), чтобы узнать, как создать ее.
* Amazon S3: В этой статье показано, как скопировать данные из Amazon S3. Вы можете использовать другие хранилища данных, выполнив аналогичные действия.

## <a name="create-a-data-factory"></a>Создание фабрики данных

1. В меню слева выберите **Создать ресурс** > **Аналитика** > **Фабрика данных**:
   
   ![Выбор фабрики данных в области "Создать"](./media/quickstart-create-data-factory-portal/new-azure-data-factory-menu.png)

2. В полях на странице **Новая фабрика данных** задайте значения, как показано на следующем изображении: 
      
   ![Страница "Новая фабрика данных"](./media/load-data-into-azure-data-lake-store//new-azure-data-factory.png)
 
    * **Name** (Имя). Введите глобальное уникальное имя фабрики данных Azure. Если отобразится сообщение об ошибке "Имя фабрики данных \"LoadADLSG1Demo\" недоступно", введите другое имя. Например, вы можете использовать имя _**ваше_имя**_**ADFTutorialDataFactory**. Попробуйте создать фабрику данных еще раз. Правила именования артефактов службы "Фабрика данных" см. в [этой](naming-rules.md) статье.
    * **Подписка**: Выберите подписку Azure, в рамках которой нужно создать фабрику данных. 
    * **Группа ресурсов**. Выберите существующую группу ресурсов из раскрывающегося списка или щелкните вариант **Создать новую** и введите имя группы ресурсов. Сведения о группах ресурсов см. в статье, где описывается [использование групп ресурсов для управления ресурсами Azure](../azure-resource-manager/management/overview.md).  
    * **Версия.** Выберите **V2**.
    * **Расположение.** Укажите расположение фабрики данных. В раскрывающемся списке отображаются только поддерживаемые расположения. Хранилища данных, используемые в фабрике данных, могут находиться в других расположениях и регионах. К этим хранилищам данных относятся Data Lake Storage 1-го поколения, Служба хранилища Azure, База данных SQL Azure и т. д.

3. Нажмите кнопку **создания**.
4. После создания перейдите к фабрике данных. Вы увидите домашнюю страницу **фабрики данных**, как показано на следующем изображении: 
   
   ![Домашняя страница фабрики данных](./media/load-data-into-azure-data-lake-store/data-factory-home-page.png)

   Выберите плитку **Создание и мониторинг**, чтобы открыть на отдельной вкладке приложение интеграции данных.

## <a name="load-data-into-data-lake-storage-gen1"></a>Загрузите данные в Azure Data Lake Storage 1-го поколения

1. Чтобы запустить средство копирования данных, на странице **Get started** (Начало работы) выберите плитку **Copy Data** (Копирование данных): 

   ![Плитка средства копирования данных](./media/load-data-into-azure-data-lake-store/copy-data-tool-tile.png)
2. На странице **Properties** (Свойства) укажите **CopyFromAmazonS3ToADLS** в поле **Task name** (Имя задачи) и нажмите кнопку **Далее**.

    ![Страница свойств](./media/load-data-into-azure-data-lake-store/copy-data-tool-properties-page.png)
3. На странице **Исходное хранилище данных** щелкните **Создать новое подключение**.

    ![Страница исходного хранилища данных](./media/load-data-into-azure-data-lake-store/source-data-store-page.png)
    
    Выберите **Amazon S3**, а затем нажмите кнопку **Continue** (Продолжить).
    
    ![Страница "Исходное хранилище данных S3"](./media/load-data-into-azure-data-lake-store/source-data-store-page-s3.png)
    
4. На странице **Specify Amazon S3 connection** (Указать подключение Amazon S3) выполните следующие действия: 
   1. Укажите **идентификатор ключа доступа**.
   2. Укажите **секретный ключ доступа**.
   3. Нажмите кнопку **Готово**.
   
      ![На снимке экрана показана новая область связанной службы, где можно ввести значения.](./media/load-data-into-azure-data-lake-store/specify-amazon-s3-account.png)
   
   4. Вы увидите новое подключение. Выберите **Далее**.
   
   ![На снимке экрана показано новое подключение.](./media/load-data-into-azure-data-lake-store/specify-amazon-s3-account-created.png)
   
5. На странице **Choose the input file or folder** (Выбор файла или папки входных данных) перейдите в папку и файл, которые необходимо скопировать. Выберите папку или файл, щелкните **Выбрать**, а затем нажмите кнопку **Далее**:

    ![Выбор файла или папки входных данных](./media/load-data-into-azure-data-lake-store/choose-input-folder.png)

6. Выберите поведение копирования, установив флажки **Copy files recursively** (Копировать файлы рекурсивно) и **Binary copy** (Двоичное копирование) (скопируйте файлы "как есть"). Нажмите кнопку **Далее**:

    ![На снимке экрана показан выбор входного файла или папки, где можно выбрать параметр Копировать файл рекурсивно и двоичное копирование.](./media/load-data-into-azure-data-lake-store/specify-binary-copy.png)
    
7. На странице **Целевое хранилище данных** щелкните **+Создать подключение**, затем выберите **Azure Data Lake Storage Gen1** и щелкните **Продолжить**.

    ![Страница целевого хранилища данных](./media/load-data-into-azure-data-lake-store/destination-data-storage-page.png)

8. На странице **New Linked Service (Azure Data Lake Storage Gen1)** (Новая связанная служба (Azure Data Lake Storage 1-го поколения)) выполните следующие действия: 

   1. Выберите вашу учетную запись Azure Data Lake Storage 1-го поколения для **имени учетной записи Data Lake Store**.
   2. Укажите **клиента** и щелкните "Готово".
   3. Выберите **Далее**.
   
   > [!IMPORTANT]
   > В этом пошаговом руководстве для аутентификации учетной записи Data Lake Storage 1-го поколения используется управляемое удостоверение для ресурсов Azure. Не забудьте предоставить Управляемому удостоверению службы соответствующие разрешения в Azure Data Lake Storage 1-го поколения, выполнив [эти инструкции](connector-azure-data-lake-store.md#managed-identity).
   
   ![Укажите учетную запись Data Lake Storage 1-го поколения](./media/load-data-into-azure-data-lake-store/specify-adls.png)
9. На странице **Choose the output file or folder** (Выбор целевого файла или папки) введите **copyfroms3** в качестве имени папки с выходными данными, а затем нажмите кнопку **Далее** 

    ![На снимке экрана показан введенный путь к папке.](./media/load-data-into-azure-data-lake-store/specify-adls-path.png)

10. На странице **Settings** (Параметры) нажмите кнопку **Далее**:

    ![Страница «Параметры»](./media/load-data-into-azure-data-lake-store/copy-settings.png)
11. Просмотрите параметры на странице **Summary** (Сводка), а затем нажмите кнопку **Далее**.

    ![Страница "Сводка"](./media/load-data-into-azure-data-lake-store/copy-summary.png)
12. На **странице развертывания** выберите **Monitor** (Мониторинг), чтобы отслеживать конвейер (задачу).

    ![Страница развертывания](./media/load-data-into-azure-data-lake-store/deployment-page.png)
13. Обратите внимание, что слева автоматически выбирается вкладка **Мониторинг**. В столбце **Actions** (Действия) содержатся ссылки на сведения о выполнении действий или повторный запуск конвейера:

    ![Мониторинг выполнений конвейера](./media/load-data-into-azure-data-lake-store/monitor-pipeline-runs.png)
14. Щелкните ссылку **View Activity Runs** (Просмотр выполнений действий) в столбце **Actions** (Действия), чтобы просмотреть выполнения действий, связанные с этим запуском конвейера. В этом конвейере определено только одно действие (действие копирования), поэтому вы увидите только одну запись. Чтобы вернуться к представлению запусков конвейера, щелкните ссылку **Конвейеры** в верхней части окна. Щелкните **Обновить**, чтобы обновить список. 

    ![Мониторинг выполнений действий](./media/load-data-into-azure-data-lake-store/monitor-activity-runs.png)

15. Чтобы отслеживать сведения о выполнении каждого действия копирования, щелкните ссылку **Сведения** в разделе **Actions** (Действия) в представлении мониторинга действия. Вы можете отслеживать такие сведения, как объем данных, копируемых из источника в приемник, пропускная способность данных, шаги выполнения с длительностью и используемые параметры:

    ![Мониторинг сведений о выполнении действия](./media/load-data-into-azure-data-lake-store/monitor-activity-run-details.png)

16. Убедитесь, что данные скопированы в вашу учетную запись Data Lake Storage 1-го поколения. 

    ![Проверка выходных данных Data Lake Storage 1-го поколения](./media/load-data-into-azure-data-lake-store/adls-copy-result.png)

## <a name="next-steps"></a>Дальнейшие действия

Перейдите к следующей статье, чтобы узнать о поддержке Azure Data Lake Storage 1-го поколения. 

> [!div class="nextstepaction"]
>[Соединитель Azure Data Lake Storage 1-го поколения](connector-azure-data-lake-store.md)
