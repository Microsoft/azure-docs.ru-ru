---
title: Сравнение Фабрики данных Azure c Фабрикой данных версии 1
description: В этой статье сравниваются возможности Фабрики данных Azure с возможностями Фабрики данных версии 1.
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: overview
ms.date: 04/09/2018
ms.openlocfilehash: dc5a4c92ee4ac0acd4a69ef94fec0981e328d829
ms.sourcegitcommit: f28ebb95ae9aaaff3f87d8388a09b41e0b3445b5
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/29/2021
ms.locfileid: "100393723"
---
# <a name="compare-azure-data-factory-with-data-factory-version-1"></a>Сравнение Фабрики данных Azure c Фабрикой данных версии 1

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

В этой статье сравниваются возможности Фабрики данных с возможностями Фабрики данных версии 1. Дополнительные сведения о Фабрике данных см. [здесь](introduction.md). Дополнительные сведения о Фабрике данных Azure версии 1 см. в [этой статье](v1/data-factory-introduction.md). 

## <a name="feature-comparison"></a>Сравнение возможностей
В следующей таблице сравниваются возможности двух версий. 

| Компонент | версия 1 | Текущая версия | 
| ------- | --------- | --------- | 
| Наборы данных | Именованное представление данных. Определяет данные, которые будут использоваться в действиях как входные и выходные. Наборы данных представляют данные в разных хранилищах, например в таблицах, файлах, папках и документах. Например, набор данных больших двоичных объектов Azure указывает контейнер больших двоичных объектов и папку в хранилище BLOB-объектов Azure, из которой действие должно считывать данные.<br/><br/>Значение **доступности** определяет модель среза в окне обработки для набора данных (например, каждый час, ежедневно и т. д.). | Наборы данных одинаковы в текущей версии. Но вам не нужно планировать **доступность** для наборов данных. Вы можете определить ресурс триггера, который будет планировать работу конвейеров, используя парадигму планировщика часов. См. дополнительные сведения о [триггерах](concepts-pipeline-execution-triggers.md#trigger-execution) и [наборах данных](concepts-datasets-linked-services.md). | 
| Связанные службы | Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам. | Связанные службы аналогичны службам в Фабрике данных версии 1, но с новым свойством **connectVia** для использования вычислительной среды выполнения интеграции Фабрики данных текущей версии. Дополнительные сведения см. в статье [Среда выполнения интеграции в фабрике данных Azure](concepts-integration-runtime.md) и разделе [Свойства связанной службы](connector-azure-blob-storage.md#linked-service-properties). |
| Конвейеры | Фабрика данных может иметь один или несколько конвейеров. Конвейеры — это логические группы действий, которые вместе отвечают за выполнение задачи. Для планирования и выполнения конвейеров можно использовать значения startTime, endTime и isPaused. | Конвейеры представляют собой группы действий, выполняемых с данными. Но теперь планирование действий в конвейере включено в функции новых ресурсов триггера. Конвейеры в Фабрике данных текущей версии можно рассматривать как единицы рабочих процессов, выполнение которых планируется отдельно с помощью триггеров. <br/><br/>В Фабрике данных текущей версии для конвейеров не предусмотрено выполнение операций в рамках временных окон. Такие базовые значения Фабрики данных версии 1, как startTime, endTime и isPaused, больше не поддерживаются в Фабрике данных текущей версии. Дополнительные сведения см. в статьях [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md) и [Конвейеры и действия в фабрике данных Azure](concepts-pipelines-activities.md). |
| Действия | Действия в конвейере определяют операции с данными. Поддерживаются такие операции, как перемещение данных (действие копирования) и преобразование данных (например, Hive, Pig и MapReduce). | В текущей версии Фабрики данных операции по-прежнему представляют определенные действия, выполняемые в конвейере. В текущей версии Фабрики данных появились новые [действия потоков управления](concepts-pipelines-activities.md#control-flow-activities). Эти действия выполняются в потоке управления (циклическая обработка и ветвление). Действия перемещения и преобразования данных, которые поддерживались в версии 1, поддерживаются и в текущей версии. Действия преобразования в текущей версии можно определить без использования наборов данных. |
| Перенос гибридных данных и диспетчеризация действий | [Шлюз управления данными](v1/data-factory-data-management-gateway.md), теперь именуемый средой выполнения интеграции, поддерживает перемещение данных между локальной и облачной средами.| Шлюз управления данными теперь называется локальной средой выполнения интеграции. Он обеспечивает те же возможности, что и в версии 1. <br/><br/> В текущей версии Фабрики данных Integration Runtime служб Azure-SSIS также поддерживает развертывание и выполнение пакетов SQL Server Integration Services (SSIS) в облаке. Дополнительные сведения см. в статье [Среда выполнения интеграции в фабрике данных Azure](concepts-integration-runtime.md).|
| Параметры | Н/Д | Параметры представлены парами "ключ — значение" параметров конфигурации с доступом только на чтение, которые определены в конвейерах. Вы можете передавать аргументы для параметров конвейера при запуске конвейера вручную. Если вы используете триггер планировщика, он также может передавать значения для параметров. Действия в конвейере используют значения параметров.  |
| Выражения | В фабрике данных версии 1 можно использовать функции и системные переменные в запросах выбора данных и свойствах действий или наборов данных. | В Фабрике данных текущей версии можно использовать выражения в любом месте в строковом значении JSON. Дополнительные сведения см. в статье [Выражения и функции в фабрике данных Azure](control-flow-expression-language-functions.md).|
| Запуски конвейера | Н/Д | Экземпляр выполнения конвейера. Например, у вас есть конвейер, который выполняется в 8:00, 9:00 и 10:00. В этом случае выполняются три отдельных запуска конвейера. Для каждого запуска конвейера предусмотрен уникальный идентификатор. Идентификатор запуска конвейера представляет собой уникальный идентификатор GUID. Запуск конвейера обычно создается путем передачи аргументов в параметры, определенные в конвейерах. |
| Выполнение действия | Н/Д | Экземпляр выполнения действий в конвейере. | 
| Выполнения триггеров | Н/Д | Экземпляр выполнения триггера. Дополнительные сведения см. в описании [триггеров](concepts-pipeline-execution-triggers.md). |
| Планирование | Планирование зависит от времени начала и окончания работы конвейера, а также доступности набора данных. | Триггер или выполнение планировщика с помощью внешнего планировщика. Дополнительные сведения см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md). |

В следующих разделах приведены дополнительные сведения о возможностях текущей версии. 

## <a name="control-flow"></a>Поток управления  
Чтобы обеспечить поддержку разнообразных потоков и шаблонов интеграции в современных хранилищах данных, Фабрика данных текущей версии предлагает новую гибкую модель конвейеров данных, которая теперь не привязана к данным временных рядов. Теперь доступны стандартные потоки, которые раньше не поддерживались. Они описаны в следующих разделах.   

### <a name="chaining-activities"></a>Цепочки действий
Чтобы связать два действия в версии 1, нужно было определять выходные данные одного действия в качестве входных данных другого. В текущей версии вы можете создать в конвейере последовательность действий в виде цепочки. Связать действие с вышестоящим можно с помощью свойства **dependsOn** в определении действия. Дополнительные сведения и пример см. в разделе [Несколько действий в конвейере](concepts-pipelines-activities.md#multiple-activities-in-a-pipeline) и статье [Ветвления и создание цепочки действий в конвейере фабрики данных](tutorial-control-flow.md). 

### <a name="branching-activities"></a>Ветвления
В текущей версии вы можете выполнять действия ветвления в конвейере. Действие [условия If](control-flow-if-condition-activity.md) выполняет те же функции, что и инструкция `if` в языках программирования. Оно определяет набор действий, если условие принимает значение `true`, и другой набор действий, если условие принимает значение `false`. Примеры действий ветвления см. в руководстве о [ветвлении и создании цепочки действий в конвейере фабрики данных](tutorial-control-flow.md).

### <a name="parameters"></a>Параметры 
Вы можете определять параметры на уровне конвейера и передавать аргументы при вызове конвейера по запросу или из триггера. Действия могут использовать аргументы, передаваемые в конвейер. Дополнительные сведения см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md). 

### <a name="custom-state-passing"></a>Передача пользовательского состояния:
Выходные данные действия содержат состояние, которое можно использовать в следующем действии в конвейере. Например, в определении JSON действия получить доступ к выходным данным предыдущего действия можно с помощью следующего синтаксиса: `@activity('NameofPreviousActivity').output.value`. Эта функция позволяет создавать рабочие процессы, в рамках которых значения могут передаваться через действия.

### <a name="looping-containers"></a>Контейнеры зацикливания:
[Действие ForEach](control-flow-for-each-activity.md) определяет повторяющийся поток управления в конвейере. Это действие используется для выполнения итерации коллекции и запускает указанные в цикле действия. Реализация цикла этого действия аналогична структуре цикла Foreach на языках программирования. 

Действие [Until](control-flow-until-activity.md) выполняет те же функции, что и циклическая структура do-until в языках программирования. Оно запускает набор действий в цикле, пока условие, связанное с действием, не получит значение `true`. Можно указать значение времени ожидания для действия until в фабрике данных.  

### <a name="trigger-based-flows"></a>Потоки на основе триггеров:
Конвейеры можно активировать по требованию (на основе событий, то есть blob post) или в определенное время. Дополнительные сведения о триггерах см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md). 

### <a name="invoking-a-pipeline-from-another-pipeline"></a>Вызов конвейера из другого конвейера
[Действие выполнения конвейера](control-flow-execute-pipeline-activity.md) позволяет конвейеру фабрики данных вызвать другой конвейер.

### <a name="delta-flows"></a>Разностные потоки:
Возможность использования ключа в шаблонах извлечения, преобразования и загрузки представлена разностной загрузкой, когда загружаются только те е, которые изменялись с момента последней итерации конвейера. Новые функции в текущей версии, такие как [действие поиска](control-flow-lookup-activity.md), гибкое планирование и поток управления, поддерживают эту возможность естественным образом. Дополнительные сведения см. в статье [Пошаговая загрузка данных из базы данных SQL Azure в хранилище BLOB-объектов Azure](tutorial-incremental-copy-powershell.md).

### <a name="other-control-flow-activities"></a>Другие действия потока управления
Ниже представлены другие действия потока управления, которые поддерживаются Фабрикой данных текущей версии. 

Действие управления | Описание
---------------- | -----------
[Действие ForEach](control-flow-for-each-activity.md) | Определяет повторяющийся поток управления в конвейере. Это действие используется для выполнения итерации коллекции и запускает указанные в цикле действия. Реализация цикла этого действия аналогична структуре цикла Foreach на языках программирования.
[Веб-действие](control-flow-web-activity.md) | Используется для вызова из конвейера фабрики данных пользовательской конечной точки REST. Вы можете передать наборы данных и связанные службы, которые будет использовать это действие и к которым оно будет обращаться. 
[Действие поиска](control-flow-lookup-activity.md) | Считывает или ищет значение имени таблицы или записи из внешнего источника. На эти выходные данные можно затем ссылаться в последующих действиях. 
[Действие получения метаданных](control-flow-get-metadata-activity.md) | Извлекает метаданные всех данных в фабрике данных Azure. 
[Действие ожидания](control-flow-wait-activity.md) | Останавливает работу конвейера на указанный период времени.

## <a name="deploy-ssis-packages-to-azure"></a>Развертывание пакетов служб SSIS в Azure 
Вы можете использовать службы Azure-SSIS, если хотите переместить рабочие нагрузки служб SSIS в облако, создать фабрику данных с помощью текущей версии и подготовить среду выполнения интеграции служб Azure-SSIS.

Среда выполнения интеграции Azure SSIS — это полностью управляемый кластер виртуальных машин (узлов) Azure, выделенных для выполнения пакетов служб SSIS в облаке. Подготовив среду выполнения интеграции Azure SSIS, вы сможете использовать те же средства, с которыми вы работали при развертывании пакетов служб SSIS для служб SSIS в локальной среде. 

Например, вы можете использовать SQL Server Data Tools ​​или SQL Server Management Studio для развертывания пакетов служб SSIS в этой среде выполнения в Azure. Пошаговые инструкции см. в руководстве [Развертывание пакетов служб интеграции SQL Server (SSIS) в Azure](./tutorial-deploy-ssis-packages-azure.md). 

## <a name="flexible-scheduling"></a>Гибкое планирование
В Фабрике данных текущей версии вам не нужно определять расписание обеспечения доступности для наборов данных. Вы можете определить ресурс триггера, который будет планировать работу конвейеров, используя парадигму планировщика часов. Вы также можете передавать параметры в конвейеры из триггера для использования гибкой модели планирования и выполнения. 

В Фабрике данных текущей версии для конвейеров не предусмотрено выполнение операций в рамках временных окон. Такие базовые значения Фабрики данных версии 1, как startTime, endTime и isPaused, больше не поддерживаются в Фабрике данных текущей версии. Дополнительные сведения о том, как создать конвейер в Фабрике данных текущей версии и запланировать его работу, см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md).

## <a name="support-for-more-data-stores"></a>Поддержка нескольких хранилищ данных
Текущая версия поддерживает больше хранилищ данных для двунаправленного копирования, чем версия 1. Список поддерживаемых хранилищ данных см. по следующим ссылкам:

- [для версии 1](v1/data-factory-data-movement-activities.md#supported-data-stores-and-formats);
- [для текущей версии](copy-activity-overview.md#supported-data-stores-and-formats).

## <a name="support-for-on-demand-spark-cluster"></a>Поддержка кластера Spark по запросу
Текущая версия поддерживает создание кластера Azure HDInsight Spark по запросу. Чтобы создать кластер Spark по запросу, укажите тип кластера как Spark в определении связанной службы HDInsight по запросу. Затем можно настроить действие Spark в конвейере для использования этой связанной службы. 

При выполнении действия служба фабрики данных автоматически создает кластер Spark. Дополнительные сведения см. в следующих статьях:

- [Преобразование данных с помощью действия Spark в фабрике данных Azure](transform-data-using-spark.md)
- [Вычислительные среды, поддерживаемые фабрикой данных Azure](compute-linked-services.md#azure-hdinsight-on-demand-linked-service)

## <a name="custom-activities"></a>Пользовательские действия
В версии 1 вы реализуете код действия DotNet (настраиваемый) с помощью создания проекта библиотеки классов .NET, а также используя класс, реализующий метод Execute в интерфейсе IDotNetActivity. Таким образом, необходимо написать настраиваемый код с помощью .NET Framework версии 4.5.2 и запустить его на узлах пула пакетной службы Azure под управлением Windows. 

В настраиваемых действиях текущей версии не нужно реализовывать интерфейс .NET. Все команды, скрипты и пользовательский код можно компилировать и выполнять в виде исполняемого файла. 

Дополнительные сведения см. в разделе [Сравнение настраиваемого действия в фабрике данных Azure версии 2 и (настраиваемого) действия DotNet версии 1](transform-data-using-dotnet-custom-activity.md#compare-v2-v1).

## <a name="sdks"></a>Пакеты SDK
 В текущей версии Фабрики данных доступны разные пакеты SDK, которые можно использовать для создания, администрирования и мониторинга конвейеров.

- **Пакет SDK для .NET**: Пакет SDK для .NET обновлен в текущей версии.

- **PowerShell**: Командлеты PowerShell обновлены в текущей версии. Командлеты текущей версии содержат в имени **DataFactoryV2**. Например, Get-AzDataFactoryV2. 

- **Пакет SDK для Python.** Этот пакет SDK не использовался до текущей версии.

- **REST API.** Интерфейс REST API обновлен в текущей версии. 

Пакеты SDK, которые обновлены в текущей версии, не обладают обратной совместимостью с клиентами версии 1. 

## <a name="authoring-experience"></a>Среда разработки

| | версия 2 | версия 1 |
| ------ | -- | -- | 
| **Портал Azure** | [Да](quickstart-create-data-factory-portal.md) | Нет |
| **Azure PowerShell** | [Да](quickstart-create-data-factory-powershell.md) | [Да](./v1/data-factory-build-your-first-pipeline-using-powershell.md) |
| **Пакет SDK для .NET** | [Да](quickstart-create-data-factory-dot-net.md) | [Да](./v1/data-factory-build-your-first-pipeline-using-vs.md) |
| **REST API** | [Да](quickstart-create-data-factory-rest-api.md) | [Да](./v1/data-factory-build-your-first-pipeline-using-rest-api.md) |
| **Пакет SDK для Python** | [Да](quickstart-create-data-factory-python.md) | Нет |
| **Шаблон Resource Manager** | [Да](quickstart-create-data-factory-resource-manager-template.md) | [Да](./v1/data-factory-build-your-first-pipeline-using-arm.md) | 

## <a name="roles-and-permissions"></a>Роли и разрешения

Роль участника Фабрики данных версии 1 нельзя использовать, чтобы создавать и администрировать ресурсы Фабрики данных текущей версии. Дополнительные сведения см. в разделе [Участник фабрики данных](../role-based-access-control/built-in-roles.md#data-factory-contributor).

## <a name="monitoring-experience"></a>Средства мониторинга
В текущей версии вы можете отслеживать фабрики данных с помощью [Azure Monitor](monitor-using-azure-monitor.md). Новые командлеты PowerShell позволяют отслеживать [среды выполнения интеграции](monitor-integration-runtime.md). Обе версии поддерживают визуальный мониторинг с помощью приложения мониторинга, которое можно запустить на портале Azure.


## <a name="next-steps"></a>Дальнейшие действия
Дополнительные сведения о создании фабрики данных см. в руководствах по [PowerShell](quickstart-create-data-factory-powershell.md), [.NET](quickstart-create-data-factory-dot-net.md), [Python](quickstart-create-data-factory-python.md) и [REST API](quickstart-create-data-factory-rest-api.md).