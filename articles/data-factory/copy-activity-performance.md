---
title: Руководство по производительности и масштабируемости действия копирования
description: Сведения о ключевых факторах, влияющих на производительность перемещения данных в фабрике данных Azure при использовании действия копирования.
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 09/15/2020
ms.openlocfilehash: cba248d3f254c9bb97c66ff7a3d39275b4b912c4
ms.sourcegitcommit: d135e9a267fe26fbb5be98d2b5fd4327d355fe97
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/10/2021
ms.locfileid: "102616083"
---
# <a name="copy-activity-performance-and-scalability-guide"></a>Руководство по производительности и масштабируемости действия копирования

> [!div class="op_single_selector" title1="Выберите версию Фабрики данных, которую вы используете:"]
> * [Версия 1](v1/data-factory-copy-activity-performance.md)
> * [Текущая версия](copy-activity-performance.md)

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Иногда требуется выполнить крупномасштабную миграцию данных из Data Lake или корпоративного хранилища данных (EDW) в Azure. В других случаях требуется получать большие объемы данных из разных источников в Azure для анализа больших данных. В каждом случае крайне важно обеспечить оптимальную производительность и масштабируемость.

Фабрика данных Azure (ADF) предоставляет механизм приема данных. ADF имеет следующие преимущества.

* Обрабатывает большие объемы данных
* Очень производительно
* Является экономичным

Эти преимущества делают ADF идеально подходил для специалистов по работе с данными, желающих создавать масштабируемые конвейеры приема данных, которые являются высокопроизводительными.

После прочтения этой статьи вы сможете ответить на следующие вопросы:

* Какой уровень производительности и масштабируемости можно достичь с помощью действия копирования ADF для переноса данных и сценариев приема данных?
* Какие действия следует предпринять для настройки производительности действия копирования ADF?
* Какие счетчики производительности ADF можно использовать для оптимизации производительности при выполнении одного действия копирования?
* Какие другие факторы выходят за пределы ADF, которые следует учитывать при оптимизации производительности копирования?

> [!NOTE]
> Если вы не знакомы с действием копирования в целом, ознакомьтесь с [обзором действия копирования](copy-activity-overview.md) , прежде чем приступить к ознакомлению с этой статьей.

## <a name="copy-performance-and-scalability-achievable-using-adf"></a>Производительность и масштабируемость копирования, которые додостижимы с помощью ADF

ADF предлагает бессерверную архитектуру, обеспечивающую параллелизм на разных уровнях.

Эта архитектура позволяет разрабатывать конвейеры, которые обеспечивают максимальную пропускную способность перемещения данных для вашей среды. Эти конвейеры полностью используют следующие ресурсы:

* Пропускная способность сети между исходным и целевым хранилищами данных
* Исходные или целевые операции ввода-вывода в секунду и пропускная способность хранилища данных.

Такое полное использование означает, что можно оценить общую пропускную способность, измеряя минимальную пропускную способность, доступную для следующих ресурсов:

* Исходное хранилище данных
* Целевое хранилище данных
* Пропускная способность сети между исходным и целевым хранилищами данных

В следующей таблице вычисляется длительность копирования. Длительность зависит от размера данных, а также от ограничения пропускной способности хранилища сети или данных для вашей среды.

&nbsp;

| Размер данных/ <br/> bandwidth | 50 Мбит/с    | 100 Мбит/с  | 500 Мбит/с  | 1 Гбит/с   | 5 Гбит/с   | 10 Гбит/с  | 50 Гбит/с   |
| --------------------------- | ---------- | --------- | --------- | -------- | -------- | -------- | --------- |
| **1 ГБ**                    | 2,7 мин    | 1,4 мин   | 0,3 мин   | 0,1 мин  | 0,03 мин | 0,01 мин | 0,0 мин   |
| **10 ГБ**                   | 27,3 мин   | 13,7 мин  | 2,7 мин   | 1,3 мин  | 0,3 мин  | 0,1 мин  | 0,03 мин  |
| **100 ГБ**                  | 4,6 часов    | 2,3 часов   | 0,5 часов   | 0,2 часов  | 0,05 часов | 0,02 часов | 0,0 часов   |
| **1 ТБ**                    | 46,6 часов   | 23,3 часов  | 4,7 часов   | 2,3 часов  | 0,5 часов  | 0,2 часов  | 0,05 часов  |
| **10 ТБ**                   | 19,4 дней  | 9,7 дней  | 1,9 дней  | 0,9 дней | 0,2 дней | 0,1 дней | 0,02 дней |
| **100 ТБ**                  | 194,2 дней | 97,1 дней | 19,4 дней | 9,7 дней | 1,9 дней | 1 день    | 0,2 дней  |
| **1 ПБ**                    | 64,7 Mo    | 32,4 Mo   | 6,5 mo    | 3,2 mo   | 0,6 Mo   | 0,3 Mo   | 0,06 Mo   |
| **10 ПБ**                   | 647,3 Mo   | 323,6 Mo  | 64,7 Mo   | 31,6 Mo  | 6,5 mo   | 3,2 mo   | 0,6 Mo    |
| | |  | | |  | | |

Копия ADF масштабируется на разных уровнях:

![как в ADF копируется масштабирование](media/copy-activity-performance/adf-copy-scalability.png)

* Поток управления Фабрики данных Azure может запускать несколько операций копирования параллельно, например с помощью [цикла For Each](control-flow-for-each-activity.md).

* Одно действие копирования может воспользоваться преимуществами масштабируемых ресурсов вычислений.
  * При использовании среды выполнения интеграции Azure (IR) можно указать до [256 единиц интеграции данных (диус)](#data-integration-units) для каждого действия копирования, не бессерверным образом.
  * При использовании локальной среды IR можно использовать один из следующих подходов.
    * Вручную увеличьте масштаб компьютера.
    * Масштабировать на несколько компьютеров ([до 4 узлов](create-self-hosted-integration-runtime.md#high-availability-and-scalability)), и одно действие копирования будет секционировать набор файлов на всех узлах.

* Одно действие копирования считывает и выполняет запись в хранилище данных, используя несколько потоков [параллельно](#parallel-copy).

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Выполните следующие действия, чтобы настроить производительность службы фабрики данных Azure с помощью действия копирования.

1. **Выберите тестовый набор данных и создайте базовый план.**

    Во время разработки протестируйте конвейер с помощью действия копирования в образце репрезентативных данных. Выбранный набор данных должен представлять стандартные шаблоны данных по следующим атрибутам:

    * Структура папок
    * Шаблон файла
    * Схема данных

    Набор данных должен быть достаточно большим, чтобы оценить производительность копирования. Для завершения операции копирования оптимальный размер займет не менее 10 минут. Собирайте сведения о выполнении и характеристики производительности после [мониторинга действий копирования](copy-activity-monitoring.md).

2. **Как повысить производительность одного действия копирования**:

    Рекомендуется сначала повысить производительность с помощью одного действия копирования.

    * **Если действие копирования выполняется в среде выполнения интеграции _Azure_ :**

        Начните со значений по умолчанию для [единиц интеграции данных (Диу)](#data-integration-units) и параметров [параллельного копирования](#parallel-copy) .

    * **Если действие копирования _выполняется в локальной среде выполнения интеграции:_**

        Рекомендуется использовать выделенный компьютер для размещения IR. Компьютер должен быть отделен от сервера, на котором размещено хранилище данных. Начните со значений по умолчанию для параметра [параллельной копии](#parallel-copy) и с помощью одного узла для автономной среды IR.

    Выполните тест производительности. Запомните, что производительность достигнута. Включение фактических значений, например диус и параллельных копий. Сведения о том, как получить результаты выполнения и используемые параметры производительности, см. в статье [мониторинг действий копирования](copy-activity-monitoring.md) . Узнайте, как [устранять производительность действий копирования](copy-activity-performance-troubleshooting.md) , чтобы определить и устранить узкие места.

    Выполните итерации для выполнения дополнительных тестов производительности, следуя указаниям по устранению неполадок и настройке. Как только выполнение одной операции копирования не позволит достичь более высокой пропускной способности, рассмотрите возможность максимально увеличить общую пропускную способность, одновременно выполняя несколько копий. Этот параметр рассматривается в следующем нумерованном маркере.

3. **Как максимально увеличить общую пропускную способность, одновременно выполнив несколько копий:**

    Теперь вы максимально увеличиваете производительность одного действия копирования. Если вы еще не настроили верхние пределы пропускной способности вашей среды, вы можете параллельно запускать несколько действий копирования. Можно выполнять параллельно с помощью конструкций потока управления ADF. Одной из таких конструкций является [цикл for each](control-flow-for-each-activity.md). Дополнительные сведения см. в следующих статьях о шаблонах решений.

    * [Копирование файлов из нескольких контейнеров](solution-template-copy-files-multiple-containers.md)
    * [Перенос данных из Amazon S3 в ADLS 2-го поколения](solution-template-migration-s3-azure.md)
    * [Групповое копирование с помощью таблицы элементов управления](solution-template-bulk-copy-with-control-table.md)

4. **Разверните конфигурацию для всего набора данных.**

    Когда вы удовлетворены результатами выполнения и производительностью, вы можете расширить определение и конвейер, чтобы охватить весь набор данных.

## <a name="troubleshoot-copy-activity-performance"></a>Устранение неполадок с производительностью действия копирования

Выполните [шаги по настройке производительности](#performance-tuning-steps) , чтобы спланировать и провести тест производительности для вашего сценария. И Узнайте, как устранять проблемы производительности выполнения действий копирования в фабрике данных Azure от [устранения неполадок, связанных с действиями копирования](copy-activity-performance-troubleshooting.md).

## <a name="copy-performance-optimization-features"></a>Копирование функций оптимизации производительности

Фабрика данных Azure предоставляет следующие возможности оптимизации производительности.

* [Единицы интеграции данных](#data-integration-units)
* [Масштабируемость локальной среды выполнения интеграции](#self-hosted-integration-runtime-scalability)
* [Параллельное копирование](#parallel-copy)
* [промежуточное копирование](#staged-copy)

### <a name="data-integration-units"></a>Единицы интеграции данных

Единица интеграции данных (Диу) — это мера, представляющая мощь одного блока в фабрике данных Azure. Мощность представляет собой сочетание распределения ресурсов ЦП, памяти и сетевого ресурса. Диу применяется только в [среде выполнения интеграции Azure](concepts-integration-runtime.md#azure-integration-runtime). Диу не применяется к локальной [среде выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime). Дополнительные сведения см. [здесь](copy-activity-performance-features.md#data-integration-units).

### <a name="self-hosted-integration-runtime-scalability"></a>Масштабируемость локальной среды выполнения интеграции

Может потребоваться разместить увеличение параллельной рабочей нагрузки. Или может потребоваться повысить производительность на уровне рабочей нагрузки. Повысить масштаб обработки можно с помощью следующих подходов.

* Можно _масштабировать локально_ размещенное IR, увеличивая число [параллельных заданий](create-self-hosted-integration-runtime.md#scale-up) , которые могут выполняться на узле.  
Увеличение масштаба работает только в том случае, если процессор и память узла меньше, чем используются полностью.
* Можно _масштабировать локально_ размещенное IR, добавляя дополнительные узлы (компьютеры).

Дополнительные сведения см. в разделе:

* [Функции оптимизации производительности действия копирования: масштабируемость локальной среды выполнения интеграции](copy-activity-performance-features.md#self-hosted-integration-runtime-scalability)
* [Создание и Настройка локальной среды выполнения интеграции: рекомендации по масштабированию](create-self-hosted-integration-runtime.md#scale-considerations)

### <a name="parallel-copy"></a>Параллельное копирование

Можно задать свойство, `parallelCopies` чтобы указать параллелизм, который будет использоваться действием копирования. Это свойство следует рассматривать как максимальное число потоков в рамках действия копирования. Потоки работают параллельно. Потоки либо считываются из источника, либо записываются в хранилища данных приемника. [Подробнее.](copy-activity-performance-features.md#parallel-copy)

### <a name="staged-copy"></a>промежуточное копирование

Операция копирования данных может отправить данные _непосредственно_ в хранилище приемника данных. Кроме того, можно выбрать использование хранилища BLOB-объектов в качестве _промежуточного_ хранилища. [Подробнее](copy-activity-performance-features.md#staged-copy).

## <a name="next-steps"></a>Дальнейшие действия

См. другие статьи о действии копирования:

* [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
* [Устранение неполадок с производительностью действия копирования](copy-activity-performance-troubleshooting.md)
* [Функции оптимизации производительности действий копирования](copy-activity-performance-features.md)
* [Перенос данных из хранилища данных в Azure с помощью фабрики данных Azure](data-migration-guidance-overview.md)
* [Миграция данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)
