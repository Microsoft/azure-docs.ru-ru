---
title: Операции пространственного анализа
titleSuffix: Azure Cognitive Services
description: Операции пространственного анализа.
services: cognitive-services
author: aahill
manager: nitinme
ms.service: cognitive-services
ms.subservice: computer-vision
ms.topic: conceptual
ms.date: 01/12/2021
ms.author: aahi
ms.openlocfilehash: fe54c4495e589459fe734f315138cafa8d7cd033
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98934738"
---
# <a name="spatial-analysis-operations"></a>Операции пространственного анализа

Пространственный анализ предоставляет функцию анализа потоковой передачи видео с устройств камеры в режиме реального времени. Для каждой настроенной камеры операции пространственного анализа будут создавать поток вывода сообщений JSON, отправленных в ваш экземпляр Центра Интернета вещей Azure. 

Контейнер пространственного анализа реализует следующие операции:

| Идентификатор операции| Описание|
|---------|---------|
| cognitiveservices. видение. спатиаланалисис-персонкаунт | Подсчитывает количество людей в указанной зоне в поле зрения камеры. Зона должна полностью покрыта одной камерой, чтобы Персонкаунт запись точных итогов. <br> Создает начальное событие _персонкаунтевент_ , а затем _персонкаунтевент_ события при изменении числа.  |
| cognitiveservices. видение. спатиаланалисис-персонкроссинглине | Отслеживает, когда пользователь пересекает определенную строку в поле зрения камеры. <br>Создает событие _персонлинивент_ , когда пользователь пересекает линию и предоставляет сведения о направлении. 
| cognitiveservices. видение. спатиаланалисис-персонкроссингполигон | Создает событие _персонзонинтерекситевент_ , когда пользователь вводит или выходит из зоны и предоставляет сведения о направлении с пронумерованной стороной перекрестной зоны. Создает _персонзонедвеллтимивент_ , когда пользователь выходит из зоны и предоставляет сведения о направлении, а также число миллисекунд, затраченных на работу пользователя в зоне. |
| cognitiveservices. видение. спатиаланалисис-персондистанце | Отслеживает, когда люди нарушают правило расстояния. <br> Периодически создает _персондистанцеевент_ с расположением каждого нарушения расстояния. |

Все операции выше также доступны в `.debug` версии, которая позволяет визуализировать видеокадры по мере их обработки. Необходимо запустить `xhost +` на главном компьютере, чтобы обеспечить визуализацию кадров и событий видео.

| Идентификатор операции| Описание|
|---------|---------|
| cognitiveservices. видение. спатиаланалисис-персонкаунт. Debug | Подсчитывает количество людей в указанной зоне в поле зрения камеры. <br> Создает начальное событие _персонкаунтевент_ , а затем _персонкаунтевент_ события при изменении числа.  |
| cognitiveservices. видение. спатиаланалисис-персонкроссинглине. Debug | Отслеживает, когда пользователь пересекает определенную строку в поле зрения камеры. <br>Создает событие _персонлинивент_ , когда пользователь пересекает линию и предоставляет сведения о направлении. 
| cognitiveservices. видение. спатиаланалисис-персонкроссингполигон. Debug | Создает событие _персонзонинтерекситевент_ , когда пользователь вводит или выходит из зоны и предоставляет сведения о направлении с пронумерованной стороной перекрестной зоны. Создает _персонзонедвеллтимивент_ , когда пользователь выходит из зоны и предоставляет сведения о направлении, а также число миллисекунд, затраченных на работу пользователя в зоне. |
| cognitiveservices. видение. спатиаланалисис-персондистанце. Debug | Отслеживает, когда люди нарушают правило расстояния. <br> Периодически создает _персондистанцеевент_ с расположением каждого нарушения расстояния. |

Пространственный анализ также можно запустить с помощью функции [Live Video Analytics](../../media-services/live-video-analytics-edge/spatial-analysis-tutorial.md) в качестве своего видеомодуля AI. 

<!--more details on the setup can be found in the [LVA Setup page](LVA-Setup.md). Below is the list of the operations supported with Live Video Analytics. -->

| Идентификатор операции| Описание|
|---------|---------|
| cognitiveservices. видение. спатиаланалисис-персонкаунт. ливевидеоаналитикс | Подсчитывает количество людей в указанной зоне в поле зрения камеры. <br> Создает начальное событие _персонкаунтевент_ , а затем _персонкаунтевент_ события при изменении числа.  |
| cognitiveservices. видение. спатиаланалисис-персонкроссинглине. ливевидеоаналитикс | Отслеживает, когда пользователь пересекает определенную строку в поле зрения камеры. <br>Создает событие _персонлинивент_ , когда пользователь пересекает линию и предоставляет сведения о направлении. 
| cognitiveservices. видение. спатиаланалисис-персонкроссингполигон. ливевидеоаналитикс | Создает событие _персонзонинтерекситевент_ , когда пользователь вводит или выходит из зоны и предоставляет сведения о направлении с пронумерованной стороной перекрестной зоны. Создает _персонзонедвеллтимивент_ , когда пользователь выходит из зоны и предоставляет сведения о направлении, а также число миллисекунд, затраченных на работу пользователя в зоне.  |
| cognitiveservices. видение. спатиаланалисис-персондистанце. ливевидеоаналитикс | Отслеживает, когда люди нарушают правило расстояния. <br> Периодически создает _персондистанцеевент_ с расположением каждого нарушения расстояния. |

Операции интерактивной аналитики видео также доступны в `.debug` версии (например, cognitiveservices. видение. спатиаланалисис-персонкаунт. ливевидеоаналитикс. Debug), которая обладает возможностью визуализировать видеокадры как обработанные. Необходимо запустить `xhost +` на главном компьютере, чтобы обеспечить визуализацию кадров и событий видео.

> [!IMPORTANT]
> Модели ИСКУССТВЕНного зрения компьютерных машин обнаруживают и находят присутствие людей в видеоматериалах и выходных данных с помощью ограничивающего прямоугольника вокруг пользовательского текста. Модели искусственного интеллекта не пытаются обнаружить удостоверения или демографические данные отдельных пользователей.

Это параметры, необходимые для каждой из этих операций пространственного анализа.

| параметры операции;| Описание|
|---------|---------|
| Operation ID | Идентификатор операции из таблицы выше.|
| Включено | Логическое значение: true или false|
| VIDEO_URL| URL-адрес RTSP для устройства камеры (пример: `rtsp://username:password@url` ). Пространственный анализ поддерживает поток в кодировке H. 264 либо через протоколы RTSP, HTTP, либо MP4. Video_URL можно указать в виде скрытого строкового значения base64 с помощью шифрования AES, а также если URL-адрес видео замаскирован `KEY_ENV` и должен `IV_ENV` быть предоставлен в виде переменных среды. Пример служебной программы для создания ключей и шифрования можно найти [здесь](/dotnet/api/system.security.cryptography.aesmanaged). |
| VIDEO_SOURCE_ID | Понятное имя для устройства камеры или видеопотока. Он будет возвращен выходными данными события JSON.|
| VIDEO_IS_LIVE| True для устройств камеры; значение false для записанных видео.|
| VIDEO_DECODE_GPU_INDEX| Графический процессор для декодирования кадра видео. По умолчанию он равен 0. Должно совпадать с именем `gpu_index` в другой конфигурации узла `VICA_NODE_CONFIG` , например `DETECTOR_NODE_CONFIG` .|
| INPUT_VIDEO_WIDTH | Ширина кадра входного видео или потока (например, 1920). Его необязательное поле и если предоставленный кадр будет масштабироваться по этому измерению, но все равно сохранит пропорции.|
| DETECTOR_NODE_CONFIG | JSON, указывающий GPU для запуска узла детектора. Должен быть в следующем формате: `"{ \"gpu_index\": 0 }",`|
| SPACEANALYTICS_CONFIG | Конфигурация JSON для зоны и строки, как описано ниже.|
| ENABLE_FACE_MASK_CLASSIFIER | `True` чтобы включить обнаружение людей, людьми маски лиц в видеопотоке, `False` отключите их. По умолчанию это значение отключено. Для обнаружения маски лица требуется, чтобы параметр ввода ширины видео был 1920 `"INPUT_VIDEO_WIDTH": 1920` . Атрибут маски лица не будет возвращен, если обнаружено, что люди не направлены на камеру или слишком далеко от нее. Дополнительные сведения см. в руководстве по [размещению в камере](spatial-analysis-camera-placement.md) . |

Это пример параметров DETECTOR_NODE_CONFIG для всех операций пространственного анализа.

```json
{
"gpu_index": 0,
"do_calibration": true,
"enable_recalibration": true,
"calibration_quality_check_frequency_seconds":86400,
"calibration_quality_check_sampling_num": 80,
"calibration_quality_check_sampling_times": 5,
"calibration_quality_check_sample_collect_frequency_seconds": 300,
"calibration_quality_check_one_round_sample_collect_num":10,
"calibration_quality_check_queue_max_size":1000,
"recalibration_score": 75
}
```

| Название | Тип| Описание|
|---------|---------|---------|
| `gpu_index` | строка| Индекс GPU, в котором будет выполняться эта операция.|
| `do_calibration` | строка | Указывает, что калибровка включена. `do_calibration` для правильной работы **cognitiveservices. концепция. спатиаланалисис-персондистанце** должен иметь значение true. do_calibration по умолчанию имеет значение true. |
| `enable_recalibration` | bool | Указывает, включена ли автоматическая перекалибровка. Значение по умолчанию — `true`.|
| `calibration_quality_check_frequency_seconds` | INT | Минимальное число секунд между проверками качества, чтобы определить, требуется ли перекалибровка. Значение по умолчанию — `86400` (24 часа). Используется, только если `enable_recalibration=True` .|
| `calibration_quality_check_sampling_num` | INT | Число выбранных выборок сохраненных данных для использования при проверке качества. Значение по умолчанию — `80`. Используется, только если `enable_recalibration=True` .|
| `calibration_quality_check_sampling_times` | INT | Количество единиц измерения ошибок, которые будут выполняться для разных наборов выборки данных, выбранных случайным образом, для каждой проверки качества. Значение по умолчанию — `5`. Используется, только если `enable_recalibration=True` .|
| `calibration_quality_check_sample_collect_frequency_seconds` | INT | Минимальное число секунд между сбором новых образцов данных для перекалибровки и проверки качества. Значение по умолчанию — `300` (5 минут). Используется, только если `enable_recalibration=True` .|
| `calibration_quality_check_one_round_sample_collect_num` | INT | Минимальное количество новых выборок данных для сбора по циклу выборки коллекции. Значение по умолчанию — `10`. Используется, только если `enable_recalibration=True` .|
| `calibration_quality_check_queue_max_size` | INT | Максимальное число выборок данных для хранения при калибровке модели камеры. Значение по умолчанию — `1000`. Используется, только если `enable_recalibration=True` .|
| `recalibration_score` | INT | Максимальное значение качества для начала перекалибровки. Значение по умолчанию — `75`. Используется, только если `enable_recalibration=True` . Качество калибровки вычисляется на основе обратной связи с ошибкой РЕПРОЕКЦИИ целевого объекта изображения. Учитывая обнаруженные целевые объекты в кадрах 2D-изображений, целевые объекты проецируются в трехмерное пространство и переносятся обратно к кадру 2D-изображения с использованием существующих параметров калибровки камеры. Ошибка РЕПРОЕКЦИИ измеряется средним расстоянием между обнаруженными целевыми объектами и планируемыми целевыми объектами.|
| `enable_breakpad`| bool | Указывает, нужно ли включить бреакпад, который используется для создания аварийного дампа для использования при отладке. По `false` умолчанию это. Если задано значение `true` , необходимо также добавить `"CapAdd": ["SYS_PTRACE"]` в `HostConfig` часть контейнера `createOptions` . По умолчанию аварийный дамп загружается в приложение [реалтимеперсонтраккинг](https://appcenter.ms/orgs/Microsoft-Organization/apps/RealTimePersonTracking/crashes/errors?version=&appBuild=&period=last90Days&status=&errorType=all&sortCol=lastError&sortDir=desc) аппцентер. Если вы хотите, чтобы аварийные дампы загрузились в собственное приложение аппцентер, можно переопределить переменную среды `RTPT_APPCENTER_APP_SECRET` с помощью секрета приложения приложения.


### <a name="zone-configuration-for-cognitiveservicesvisionspatialanalysis-personcount"></a>Конфигурация зоны для cognitiveservices. видение. спатиаланалисис-персонкаунт

 Это пример входного JSON-файла для параметра SPACEANALYTICS_CONFIG, который настраивает зону. Для этой операции можно настроить несколько зон.

```json
{
"zones":[{
    "name": "lobbycamera",
    "polygon": [[0.3,0.3], [0.3,0.9], [0.6,0.9], [0.6,0.3], [0.3,0.3]],
    "events":[{
        "type": "count",
        "config":{
            "trigger": "event",
            "threshold": 16.00,
            "focus": "footprint"
      }
    }]
}
```

| Название | Тип| Описание|
|---------|---------|---------|
| `zones` | list| Список зон. |
| `name` | строка| Понятное имя для этой зоны.|
| `polygon` | list| Каждая пара значений представляет x, y для вершин многоугольника. Многоугольник представляет области, в которых проводятся или учитываются пользователи, а точки многоугольников основаны на нормализованных координатах (0-1), где левый верхний угол — (0,0, 0,0), а правый нижний угол — (1,0, 1,0).   
| `threshold` | FLOAT| События егрессед, когда достоверность моделей искусственного интеллекта больше или равна этому значению. |
| `type` | строка| Для **cognitiveservices. видение. спатиаланалисис-персонкаунт** это должно быть `count` .|
| `trigger` | строка| Тип триггера для отправки события. Поддерживаемые значения — `event` для отправки событий при периодическом изменении числа или `interval` для периодической отправки событий независимо от того, изменился ли счетчик.
| `interval` | строка| Время в секундах, в течение которого число пользователей будет агрегировано до срабатывания события. Операция продолжит анализировать сцену по постоянной ставке и возвращает наиболее общее число за этот интервал. Интервал агрегирования применим `event` и к, и к `interval` .|
| `focus` | строка| Положение точки в ограничивающем прямоугольнике человека, используемое для вычисления событий. Значение фокуса может быть `footprint` (занимаемое лицом), `bottom_center` (нижний центр ограничивающего прямоугольника человека) `center` (центр ограничивающего прямоугольника пользователя).|

### <a name="line-configuration-for-cognitiveservicesvisionspatialanalysis-personcrossingline"></a>Конфигурация линий для cognitiveservices. видение. спатиаланалисис-персонкроссинглине

Это пример входного JSON-файла для параметра SPACEANALYTICS_CONFIG, который настраивает строку. Для этой операции можно настроить несколько линий пересечения.

```json
{
   "lines": [
       {
           "name": "doorcamera",
           "line": {
               "start": {
                   "x": 0,
                   "y": 0.5
               },
               "end": {
                   "x": 1,
                   "y": 0.5
               }
           },
           "events": [
               {
                   "type": "linecrossing",
                   "config": {
                       "trigger": "event",
                       "threshold": 16.00,
                       "focus": "footprint"
                   }
               }
           ]
       }
   ]
}
```

| Название | Тип| Описание|
|---------|---------|---------|
| `lines` | list| Список строк.|
| `name` | строка| Понятное имя для этой строки.|
| `line` | list| Определение строки. Это направленная линия, позволяющая понять "запись" и "выход".|
| `start` | пара значений| координаты x, y для начальной точки линии. Значения float представляют собой расположение вершины относительно верхнего левого угла. Чтобы вычислить абсолютные значения x, y, необходимо умножить эти значения на размер кадра. |
| `end` | пара значений| координаты x, y для конечной точки линии. Значения float представляют собой расположение вершины относительно верхнего левого угла. Чтобы вычислить абсолютные значения x, y, необходимо умножить эти значения на размер кадра. |
| `threshold` | FLOAT| События егрессед, когда достоверность моделей искусственного интеллекта больше или равна этому значению. Значение по умолчанию — 16. Это рекомендуемое значение для достижения максимальной точности. |
| `type` | строка| Для **cognitiveservices. видение. спатиаланалисис-персонкроссинглине** это должно быть `linecrossing` .|
|`trigger`|строка|Тип триггера для отправки события.<br>Поддерживаемые значения: "Event": срабатывают, когда кто-то пересекает линию.|
| `focus` | строка| Положение точки в ограничивающем прямоугольнике человека, используемое для вычисления событий. Значение фокуса может быть `footprint` (занимаемое лицом), `bottom_center` (нижний центр ограничивающего прямоугольника человека) `center` (центр ограничивающего прямоугольника пользователя). Значение по умолчанию — "объем памяти".|

### <a name="zone-configuration-for-cognitiveservicesvisionspatialanalysis-personcrossingpolygon"></a>Конфигурация зоны для cognitiveservices. видение. спатиаланалисис-персонкроссингполигон

Это пример входного JSON-файла для параметра SPACEANALYTICS_CONFIG, который настраивает зону. Для этой операции можно настроить несколько зон.

 ```json
{
"zones":[
   {
       "name": "queuecamera",
       "polygon": [[0.3,0.3], [0.3,0.9], [0.6,0.9], [0.6,0.3], [0.3,0.3]],
       "events":[{
           "type": "zonecrossing",
           "config":{
               "trigger": "event",
               "threshold": 48.00,
               "focus": "footprint"
               }
           }]
   },
   {
       "name": "queuecamera1",
       "polygon": [[0.3,0.3], [0.3,0.9], [0.6,0.9], [0.6,0.3], [0.3,0.3]],
       "events":[{
           "type": "zonedwelltime",
           "config":{
               "trigger": "event",
               "threshold": 16.00,
               "focus": "footprint"
               }
           }]
   }]
}
```

| Название | Тип| Описание|
|---------|---------|---------|
| `zones` | list| Список зон. |
| `name` | строка| Понятное имя для этой зоны.|
| `polygon` | list| Каждая пара значений представляет x, y для вершин многоугольника. Многоугольник представляет области, в которых выполняется трассировка или подсчет пользователей. Значения float представляют собой расположение вершины относительно верхнего левого угла. Чтобы вычислить абсолютные значения x, y, необходимо умножить эти значения на размер кадра. 
| `threshold` | FLOAT| События егрессед, когда достоверность моделей искусственного интеллекта больше или равна этому значению. Значение по умолчанию — 48, если Type — зонекроссинг и 16, когда Time — Двеллтиме. Эти значения рекомендуются для достижения максимальной точности.  |
| `type` | строка| Для **cognitiveservices. видение. спатиаланалисис-персонкроссингполигон** это должно быть `zonecrossing` или `zonedwelltime` .|
| `trigger`|строка|Тип триггера для отправки события<br>Поддерживаемые значения: "Event": срабатывают, когда пользователь вводит или выходит из зоны.|
| `focus` | строка| Положение точки в ограничивающем прямоугольнике человека, используемое для вычисления событий. Значение фокуса может быть `footprint` (занимаемое лицом), `bottom_center` (нижний центр ограничивающего прямоугольника человека) `center` (центр ограничивающего прямоугольника пользователя). Значение по умолчанию — "объем памяти".|

### <a name="zone-configuration-for-cognitiveservicesvisionspatialanalysis-persondistance"></a>Конфигурация зоны для cognitiveservices. видение. спатиаланалисис-персондистанце

Это пример входного JSON-файла для параметра SPACEANALYTICS_CONFIG, который настраивает зону для **cognitiveservices. видение. спатиаланалисис-персондистанце**. Для этой операции можно настроить несколько зон.

```json
{
"zones":[{
   "name": "lobbycamera",
   "polygon": [[0.3,0.3], [0.3,0.9], [0.6,0.9], [0.6,0.3], [0.3,0.3]],
   "events":[{
    "type": "persondistance",
    "config":{
        "trigger": "event",
        "output_frequency":1,
        "minimum_distance_threshold":6.0,
        "maximum_distance_threshold":35.0,
           "threshold": 16.00,
           "focus": "footprint"
            }
    }]
   }]
}
```

| Название | Тип| Описание|
|---------|---------|---------|
| `zones` | list| Список зон. |
| `name` | строка| Понятное имя для этой зоны.|
| `polygon` | list| Каждая пара значений представляет x, y для вершин многоугольника. Многоугольник представляет области, в которых учитываются люди и измеряется расстояние между людьми. Значения float представляют собой расположение вершины относительно верхнего левого угла. Чтобы вычислить абсолютные значения x, y, необходимо умножить эти значения на размер кадра. 
| `threshold` | FLOAT| События егрессед, когда достоверность моделей искусственного интеллекта больше или равна этому значению. |
| `type` | строка| Для **cognitiveservices. видение. спатиаланалисис-персондистанце** это должно быть `people_distance` .|
| `trigger` | строка| Тип триггера для отправки события. Поддерживаемые значения — `event` для отправки событий при периодическом изменении числа или `interval` для периодической отправки событий независимо от того, изменился ли счетчик.
| `interval` | строка | Время в секундах, в течение которого нарушения будут агрегированы до срабатывания события. Интервал агрегирования применим `event` и к, и к `interval` .|
| `output_frequency` | INT | Скорость, с которой события егрессед. Если `output_frequency` = X, каждое событие x — егрессед, например, `output_frequency` = 2 означает, что каждое другое событие является выходным. Output_frequency применимо как к `event` , так и к `interval` .|
| `minimum_distance_threshold` | FLOAT| Расстояние в футах, которое активирует событие "Туклосе", когда люди меньше этого расстояния.|
| `maximum_distance_threshold` | FLOAT| Расстояние в футах, которое активирует событие "Туфар", когда люди больше этого расстояния.|
| `focus` | строка| Положение точки в ограничивающем прямоугольнике человека, используемое для вычисления событий. Значение фокуса может быть `footprint` (занимаемое лицом), `bottom_center` (нижний центр ограничивающего прямоугольника человека) `center` (центр ограничивающего прямоугольника пользователя).|

Ознакомьтесь с рекомендациями по [размещению камеры](spatial-analysis-camera-placement.md) , чтобы узнать о конфигурациях зон и линий.

## <a name="spatial-analysis-operation-output"></a>Выходные данные операции пространственного анализа

События каждой операции егрессед в центр Интернета вещей Azure в формате JSON.

### <a name="json-format-for-cognitiveservicesvisionspatialanalysis-personcount-ai-insights"></a>Формат JSON для cognitiveservices. видение. спатиаланалисис-персонкаунт AI Insights

Пример JSON для события, выводимого этой операцией.

```json
{
    "events": [
        {
            "id": "b013c2059577418caa826844223bb50b",
            "type": "personCountEvent",
            "detectionIds": [
                "bc796b0fc2534bc59f13138af3dd7027",
                "60add228e5274158897c135905b5a019"
            ],
            "properties": {
                "personCount": 2
            },
            "zone": "lobbycamera",
            "trigger": "event"
        }
    ],
    "sourceInfo": {
        "id": "camera_id",
        "timestamp": "2020-08-24T06:06:57.224Z",
        "width": 608,
        "height": 342,
        "frameId": "1400",
        "cameraCalibrationInfo": {
            "status": "Calibrated",
            "cameraHeight": 10.306597709655762,
            "focalLength": 385.3199462890625,
            "tiltupAngle": 1.0969393253326416
        },
        "imagePath": ""
    },
    "detections": [
        {
            "type": "person",
            "id": "bc796b0fc2534bc59f13138af3dd7027",
            "region": {
                "type": "RECTANGLE",
                "points": [
                    {
                        "x": 0.612683747944079,
                        "y": 0.25340268765276636
                    },
                    {
                        "x": 0.7185954043739721,
                        "y": 0.6425260577285499
                    }
                ]
            },
            "confidence": 0.9559211134910583,
            "centerGroundPoint": {
                "x": 0.0,
                "y": 0.0
            },
            "metadata": {
            "attributes": {
                "face_Mask": 0.99
            }
        }
        },
        {
            "type": "person",
            "id": "60add228e5274158897c135905b5a019",
            "region": {
                "type": "RECTANGLE",
                "points": [
                    {
                        "x": 0.22326200886776573,
                        "y": 0.17830915618361087
                    },
                    {
                        "x": 0.34922296122500773,
                        "y": 0.6297955429344847
                    }
                ]
            },
            "confidence": 0.9389744400978088,
            "centerGroundPoint": {
                "x": 0.0,
                "y": 0.0
            },
            "metadata":{
            "attributes": {
                "face_noMask": 0.99
            }
            }
    }
    ],
    "schemaVersion": "1.0"
}
```

| Имя поля события | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор события|
| `type` | строка| Тип события|
| `detectionsId` | массиве| Массив размера 1 уникального идентификатора обнаружения людей, вызвавшего это событие|
| `properties` | коллекция| Коллекция значений|
| `trackinId` | строка| Уникальный идентификатор обнаруженного человека|
| `zone` | строка | Поле Name (имя) многоугольника, представляющего пересечение зоны.|
| `trigger` | строка| Тип триггера — "Event" или "Interval" в зависимости от значения `trigger` в SPACEANALYTICS_CONFIG|

| Имя поля обнаружений | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор обнаружения|
| `type` | строка| Тип обнаружения|
| `region` | коллекция| Коллекция значений|
| `type` | строка| Тип региона|
| `points` | коллекция| Верхняя левая и Нижняя правая точка, если тип региона — прямоугольник |
| `confidence` | FLOAT| Достоверность алгоритма|
| `face_Mask` | FLOAT | Значение достоверности атрибута с диапазоном (0-1) означает, что обнаруженное лицо является людьми маской лица |
| `face_noMask` | FLOAT | Значение достоверности атрибута с диапазоном (0-1) означает, что обнаруженное лицо **не** людьми маску лица |

| Имя поля Саурцеинфо | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Camera ID (Идентификатор камеры)|
| `timestamp` | Дата| Дата в формате UTC при выдаче полезных данных JSON|
| `width` | INT | Ширина кадра видео|
| `height` | INT | Высота кадра видео|
| `frameId` | INT | Идентификатор кадра|
| `cameraCallibrationInfo` | коллекция | Коллекция значений|
| `status` | строка | Состояние калибровки в формате `state[;progress description]` . Состояние может быть `Calibrating` `Recalibrating` (если включена повторная калибровка) или `Calibrated` . Часть описания хода выполнения допустима только в том случае, если она находится в `Calibrating` `Recalibrating` состоянии и, которая используется для отображения хода выполнения текущего процесса калибровки.|
| `cameraHeight` | FLOAT | Высота камеры над заземлением в футах. Это выводится из автоматической калибровки. |
| `focalLength` | FLOAT | Фокусная длина камеры в пикселях. Это выводится из автоматической калибровки. |
| `tiltUpAngle` | FLOAT | Угол наклона камеры от вертикальной. Это выводится из автоматической калибровки.|

| Имя поля Саурцеинфо | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Camera ID (Идентификатор камеры)|
| `timestamp` | Дата| Дата в формате UTC при выдаче полезных данных JSON|
| `width` | INT | Ширина кадра видео|
| `height` | INT | Высота кадра видео|
| `frameId` | INT | Идентификатор кадра|


### <a name="json-format-for-cognitiveservicesvisionspatialanalysis-personcrossingline-ai-insights"></a>Формат JSON для cognitiveservices. видение. спатиаланалисис-персонкроссинглине AI Insights

Пример JSON для обнаружений, выводимых этой операцией.

```json
{
    "events": [
        {
            "id": "3733eb36935e4d73800a9cf36185d5a2",
            "type": "personLineEvent",
            "detectionIds": [
                "90d55bfc64c54bfd98226697ad8445ca"
            ],
            "properties": {
                "trackingId": "90d55bfc64c54bfd98226697ad8445ca",
                "status": "CrossLeft"
            },
            "zone": "doorcamera"
        }
    ],
    "sourceInfo": {
        "id": "camera_id",
        "timestamp": "2020-08-24T06:06:53.261Z",
        "width": 608,
        "height": 342,
        "frameId": "1340",
        "imagePath": ""
    },
    "detections": [
        {
            "type": "person",
            "id": "90d55bfc64c54bfd98226697ad8445ca",
            "region": {
                "type": "RECTANGLE",
                "points": [
                    {
                        "x": 0.491627341822574,
                        "y": 0.2385801348769874
                    },
                    {
                        "x": 0.588894994635331,
                        "y": 0.6395559924387793
                    }
                ]
            },
            "confidence": 0.9005028605461121,
            "metadata": {
            "attributes": {
                "face_Mask": 0.99
            }
        }
        }
    ],
    "schemaVersion": "1.0"
}
```
| Имя поля события | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор события|
| `type` | строка| Тип события|
| `detectionsId` | массиве| Массив размера 1 уникального идентификатора обнаружения людей, вызвавшего это событие|
| `properties` | коллекция| Коллекция значений|
| `trackinId` | строка| Уникальный идентификатор обнаруженного человека|
| `status` | строка| Направление пересечений строк: "Кросслефт" или "Кроссригхт"|
| `zone` | строка | Поле "Name" строки, которая была пересечением|

| Имя поля обнаружений | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор обнаружения|
| `type` | строка| Тип обнаружения|
| `region` | коллекция| Коллекция значений|
| `type` | строка| Тип региона|
| `points` | коллекция| Верхняя левая и Нижняя правая точка, если тип региона — прямоугольник |
| `confidence` | FLOAT| Достоверность алгоритма|
| `face_Mask` | FLOAT | Значение достоверности атрибута с диапазоном (0-1) означает, что обнаруженное лицо является людьми маской лица |
| `face_noMask` | FLOAT | Значение достоверности атрибута с диапазоном (0-1) означает, что обнаруженное лицо **не** людьми маску лица |

| Имя поля Саурцеинфо | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Camera ID (Идентификатор камеры)|
| `timestamp` | Дата| Дата в формате UTC при выдаче полезных данных JSON|
| `width` | INT | Ширина кадра видео|
| `height` | INT | Высота кадра видео|
| `frameId` | INT | Идентификатор кадра|


> [!IMPORTANT]
> Модель искусственного интеллекта обнаруживает человека независимо от того, находится ли пользователь в сторону или вдали от камеры. Модель искусственного интеллекта не выполняет распознавание лиц и не выдает никаких биометрических сведений. 

### <a name="json-format-for-cognitiveservicesvisionspatialanalysis-personcrossingpolygon-ai-insights"></a>Формат JSON для cognitiveservices. видение. спатиаланалисис-персонкроссингполигон AI Insights

Пример JSON для обнаружений, выводимых этой операцией с `zonecrossing` типом SPACEANALYTICS_CONFIG.

```json
{
    "events": [
        {
            "id": "f095d6fe8cfb4ffaa8c934882fb257a5",
            "type": "personZoneEnterExitEvent",
            "detectionIds": [
                "afcc2e2a32a6480288e24381f9c5d00e"
            ],
            "properties": {
                "trackingId": "afcc2e2a32a6480288e24381f9c5d00e",
                "status": "Enter",
                "side": "1"
            },
            "zone": "queuecamera"
        }
    ],
    "sourceInfo": {
        "id": "camera_id",
        "timestamp": "2020-08-24T06:15:09.680Z",
        "width": 608,
        "height": 342,
        "frameId": "428",
        "imagePath": ""
    },
    "detections": [
        {
            "type": "person",
            "id": "afcc2e2a32a6480288e24381f9c5d00e",
            "region": {
                "type": "RECTANGLE",
                "points": [
                    {
                        "x": 0.8135572734631991,
                        "y": 0.6653949670624315
                    },
                    {
                        "x": 0.9937645761590255,
                        "y": 0.9925406829655519
                    }
                ]
            },
            "confidence": 0.6267998814582825,
        "metadata": {
        "attributes": {
        "face_Mask": 0.99
        }
        }
           
        }
    ],
    "schemaVersion": "1.0"
}
```

Пример JSON для обнаружений, выводимых этой операцией с `zonedwelltime` типом SPACEANALYTICS_CONFIG.

```json
{
    "events": [
        {
            "id": "f095d6fe8cfb4ffaa8c934882fb257a5",
            "type": "personZoneDwellTimeEvent",
            "detectionIds": [
                "afcc2e2a32a6480288e24381f9c5d00e"
            ],
            "properties": {
                "trackingId": "afcc2e2a32a6480288e24381f9c5d00e",
                "status": "Exit",
                "side": "1",
        "durationMs": 7132.0
            },
            "zone": "queuecamera"
        }
    ],
    "sourceInfo": {
        "id": "camera_id",
        "timestamp": "2020-08-24T06:15:09.680Z",
        "width": 608,
        "height": 342,
        "frameId": "428",
        "imagePath": ""
    },
    "detections": [
        {
            "type": "person",
            "id": "afcc2e2a32a6480288e24381f9c5d00e",
            "region": {
                "type": "RECTANGLE",
                "points": [
                    {
                        "x": 0.8135572734631991,
                        "y": 0.6653949670624315
                    },
                    {
                        "x": 0.9937645761590255,
                        "y": 0.9925406829655519
                    }
                ]
            },
            "confidence": 0.6267998814582825,
            "metadataType": ""
        }
    ],
    "schemaVersion": "1.0"
}
```

| Имя поля события | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор события|
| `type` | строка| Тип события. Значение может быть либо _персонзонедвеллтимивент_ , либо _персонзонинтерекситевент_ .|
| `detectionsId` | массиве| Массив размера 1 уникального идентификатора обнаружения людей, вызвавшего это событие|
| `properties` | коллекция| Коллекция значений|
| `trackinId` | строка| Уникальный идентификатор обнаруженного человека|
| `status` | строка| Направление пересечения многоугольников: "Enter" или "Exit"|
| `side` | INT| Номер стороны многоугольника, который пересекается с лицом. Каждая сторона — это пронумерованный край между двумя вершинами многоугольника, представляющими вашу зону. Граница между двумя первыми вершинами многоугольника представляет первую сторону|
| `durationMs` | FLOAT | Количество миллисекунд, представляющих время, затраченное пользователем в зоне. Это поле указывается, если тип события — _персонзонедвеллтимивент_|
| `zone` | строка | Поле Name (имя) многоугольника, представляющего пересечение зоны.|

| Имя поля обнаружений | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор обнаружения|
| `type` | строка| Тип обнаружения|
| `region` | коллекция| Коллекция значений|
| `type` | строка| Тип региона|
| `points` | коллекция| Верхняя левая и Нижняя правая точка, если тип региона — прямоугольник |
| `confidence` | FLOAT| Достоверность алгоритма|
| `face_Mask` | FLOAT | Значение достоверности атрибута с диапазоном (0-1) означает, что обнаруженное лицо является людьми маской лица |
| `face_noMask` | FLOAT | Значение достоверности атрибута с диапазоном (0-1) означает, что обнаруженное лицо **не** людьми маску лица |

### <a name="json-format-for-cognitiveservicesvisionspatialanalysis-persondistance-ai-insights"></a>Формат JSON для cognitiveservices. видение. спатиаланалисис-персондистанце AI Insights

Пример JSON для обнаружений, выводимых этой операцией.

```json
{
    "events": [
        {
            "id": "9c15619926ef417aa93c1faf00717d36",
            "type": "personDistanceEvent",
            "detectionIds": [
                "9037c65fa3b74070869ee5110fcd23ca",
                "7ad7f43fd1a64971ae1a30dbeeffc38a"
            ],
            "properties": {
                "personCount": 5,
                "averageDistance": 20.807043981552123,
                "minimumDistanceThreshold": 6.0,
                "maximumDistanceThreshold": "Infinity",
                "eventName": "TooClose",
                "distanceViolationPersonCount": 2
            },
            "zone": "lobbycamera",
            "trigger": "event"
        }
    ],
    "sourceInfo": {
        "id": "camera_id",
        "timestamp": "2020-08-24T06:17:25.309Z",
        "width": 608,
        "height": 342,
        "frameId": "1199",
        "cameraCalibrationInfo": {
            "status": "Calibrated",
            "cameraHeight": 12.9940824508667,
            "focalLength": 401.2800598144531,
            "tiltupAngle": 1.057669997215271
        },
        "imagePath": ""
    },
    "detections": [
        {
            "type": "person",
            "id": "9037c65fa3b74070869ee5110fcd23ca",
            "region": {
                "type": "RECTANGLE",
                "points": [
                    {
                        "x": 0.39988183975219727,
                        "y": 0.2719132942065858
                    },
                    {
                        "x": 0.5051516984638414,
                        "y": 0.6488402517218339
                    }
                ]
            },
            "confidence": 0.948630690574646,
            "centerGroundPoint": {
                "x": -1.4638760089874268,
                "y": 18.29732322692871
            },
            "metadataType": ""
        },
        {
            "type": "person",
            "id": "7ad7f43fd1a64971ae1a30dbeeffc38a",
            "region": {
                "type": "RECTANGLE",
                "points": [
                    {
                        "x": 0.5200299714740954,
                        "y": 0.2875368218672903
                    },
                    {
                        "x": 0.6457497446160567,
                        "y": 0.6183311060855263
                    }
                ]
            },
            "confidence": 0.8235412240028381,
            "centerGroundPoint": {
                "x": 2.6310102939605713,
                "y": 18.635927200317383
            },
            "metadataType": ""
        }
    ],
    "schemaVersion": "1.0"
}
```

| Имя поля события | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор события|
| `type` | строка| Тип события|
| `detectionsId` | массиве| Массив размера 1 уникального идентификатора обнаружения людей, вызвавшего это событие|
| `properties` | коллекция| Коллекция значений|
| `personCount` | INT| Число людей, обнаруженных при выдаче события|
| `averageDistance` | FLOAT| Среднее расстояние между всеми обнаруженными людьми в футах|
| `minimumDistanceThreshold` | FLOAT| Расстояние в футах, которое активирует событие "Туклосе", когда люди меньше этого расстояния.|
| `maximumDistanceThreshold` | FLOAT| Расстояние в футах, которое активирует событие "Туфар", когда люди больше расстояния.|
| `eventName` | строка| Имя события соответствует `TooClose` `minimumDistanceThreshold` нарушению, `TooFar` когда `maximumDistanceThreshold` нарушается или `unknown` Если автоматическая калибровка не завершена|
| `distanceViolationPersonCount` | INT| Число людей, обнаруженных нарушением `minimumDistanceThreshold` или `maximumDistanceThreshold`|
| `zone` | строка | Поле Name (имя) многоугольника, представляющего зону, отслеживаемую для дистанЦинг между людьми|
| `trigger` | строка| Тип триггера — "Event" или "Interval" в зависимости от значения `trigger` в SPACEANALYTICS_CONFIG|

| Имя поля обнаружений | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Идентификатор обнаружения|
| `type` | строка| Тип обнаружения|
| `region` | коллекция| Коллекция значений|
| `type` | строка| Тип региона|
| `points` | коллекция| Верхняя левая и Нижняя правая точка, если тип региона — прямоугольник |
| `confidence` | FLOAT| Достоверность алгоритма|
| `centerGroundPoint` | 2 значения с плавающей запятой| `x`, `y` значения с координатами определяемого пользователем положения на земле в футах. `x` и `y` являются координатами на плоскости этажей, предполагая, что этаж является уровнем. Расположение камеры является источником. |

При вычислении `centerGroundPoint` `x` — это расстояние от камеры до пользователя вдоль линии, перпендикулярной плоскости с изображением камеры. `y` Расстояние от камеры до пользователя вдоль линии, параллельной плоскости с изображением камеры. 

![Пример точки заземления центра](./media/spatial-analysis/x-y-chart.png) 

В данном примере параметр `centerGroundPoint` находится в состоянии `{x: 4, y: 5}`. Это означает, что у камеры есть человек, находящегося на расстоянии 4 метров, и пять метров вправо, глядя на комнату сверху вниз.


| Имя поля Саурцеинфо | Тип| Описание|
|---------|---------|---------|
| `id` | строка| Camera ID (Идентификатор камеры)|
| `timestamp` | Дата| Дата в формате UTC при выдаче полезных данных JSON|
| `width` | INT | Ширина кадра видео|
| `height` | INT | Высота кадра видео|
| `frameId` | INT | Идентификатор кадра|
| `cameraCallibrationInfo` | коллекция | Коллекция значений|
| `status` | строка | Состояние калибровки в формате `state[;progress description]` . Состояние может быть `Calibrating` `Recalibrating` (если включена повторная калибровка) или `Calibrated` . Часть описания хода выполнения допустима только в том случае, если она находится в `Calibrating` `Recalibrating` состоянии и, которая используется для отображения хода выполнения текущего процесса калибровки.|
| `cameraHeight` | FLOAT | Высота камеры над заземлением в футах. Это выводится из автоматической калибровки. |
| `focalLength` | FLOAT | Фокусная длина камеры в пикселях. Это выводится из автоматической калибровки. |
| `tiltUpAngle` | FLOAT | Угол наклона камеры от вертикальной. Это выводится из автоматической калибровки.|


## <a name="use-the-output-generated-by-the-container"></a>Использование выходных данных, созданных контейнером

Может потребоваться интегрировать в приложение функцию обнаружения пространственных данных или события. Вот несколько подходов, которые следует учитывать: 

* Используйте пакет SDK концентратора событий Azure для выбранного языка программирования, чтобы подключиться к конечной точке центра Интернета вещей Azure и получить события. Дополнительные сведения см. в [статье чтение сообщений с устройства в облако из встроенной конечной точки](../../iot-hub/iot-hub-devguide-messages-read-builtin.md) . 
* Настройте **маршрутизацию сообщений** в центре Интернета вещей Azure, чтобы отправить события в другие конечные точки или сохранить события в хранилище данных. Дополнительные сведения см. в статье [Маршрутизация сообщений центра Интернета вещей](../../iot-hub/iot-hub-devguide-messages-d2c.md) . 
* Настройте Azure Stream Analytics задание для обработки событий в режиме реального времени по мере их поступления и создания визуализаций. 

## <a name="deploying-spatial-analysis-operations-at-scale-multiple-cameras"></a>Развертывание операций пространственного анализа в масштабе (несколько камер)

Чтобы обеспечить максимальную производительность и использование графических процессоров, можно развернуть любые операции пространственного анализа на нескольких камерах с помощью экземпляров графа. Ниже приведен пример выполнения `cognitiveservices.vision.spatialanalysis-personcrossingline` операции на пятнадцать камерах.

```json
  "properties.desired": {
      "globalSettings": {
          "PlatformTelemetryEnabled": false,
          "CustomerTelemetryEnabled": true
      },
      "graphs": {
        "personzonelinecrossing": {
        "operationId": "cognitiveservices.vision.spatialanalysis-personcrossingline",
        "version": 1,
        "enabled": true,
        "sharedNodes": {
            "shared_detector0": {
                "node": "PersonCrossingLineGraph.detector",
                "parameters": {
                    "DETECTOR_NODE_CONFIG": "{ \"gpu_index\": 0, \"batch_size\": 7, \"do_calibration\": true}",
                }
            },
            "shared_detector1": {
                "node": "PersonCrossingLineGraph.detector",
                "parameters": {
                    "DETECTOR_NODE_CONFIG": "{ \"gpu_index\": 0, \"batch_size\": 8, \"do_calibration\": true}",
                }
            }
        },
        "parameters": {
            "VIDEO_DECODE_GPU_INDEX": 0,
            "VIDEO_IS_LIVE": true
        },
        "instances": {
            "1": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector0",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 1>",
                    "VIDEO_SOURCE_ID": "camera 1",
                    "SPACEANALYTICS_CONFIG": "{\"zones\":[{\"name\":\"queue\",\"polygon\":[[0,0],[1,0],[0,1],[1,1],[0,0]]}]}"
                }
            },
            "2": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector0",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 2>",
                    "VIDEO_SOURCE_ID": "camera 2",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "3": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector0",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 3>",
                    "VIDEO_SOURCE_ID": "camera 3",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "4": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector0",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 4>",
                    "VIDEO_SOURCE_ID": "camera 4",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "5": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector0",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 5>",
                    "VIDEO_SOURCE_ID": "camera 5",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "6": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector0",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 6>",
                    "VIDEO_SOURCE_ID": "camera 6",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "7": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector0",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 7>",
                    "VIDEO_SOURCE_ID": "camera 7",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "8": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 8>",
                    "VIDEO_SOURCE_ID": "camera 8",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "9": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 9>",
                    "VIDEO_SOURCE_ID": "camera 9",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "10": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 10>",
                    "VIDEO_SOURCE_ID": "camera 10",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "11": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 11>",
                    "VIDEO_SOURCE_ID": "camera 11",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "12": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 12>",
                    "VIDEO_SOURCE_ID": "camera 12",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "13": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 13>",
                    "VIDEO_SOURCE_ID": "camera 13",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "14": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 14>",
                    "VIDEO_SOURCE_ID": "camera 14",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            },
            "15": {
                "sharedNodeMap": {
                    "PersonCrossingLineGraph/detector": "shared_detector1",
                },
                "parameters": {
                    "VIDEO_URL": "<Replace RTSP URL for camera 15>",
                    "VIDEO_SOURCE_ID": "camera 15",
                    "SPACEANALYTICS_CONFIG": "<Replace the zone config value, same format as above>"
                }
            }
          }
        },
      }
  }
  ```
| Название | Тип| Описание|
|---------|---------|---------|
| `batch_size` | INT | Указывает число камер, которые будут использоваться в операции. |

## <a name="next-steps"></a>Дальнейшие действия

* [Развертывание веб-приложения инвентаризации людей](spatial-analysis-web-app.md)
* [Ведение журнала и устранение неполадок](spatial-analysis-logging.md)
* [Путеводитель по размещению камеры](spatial-analysis-camera-placement.md)
* [Рекомендации по размещению зон и строк](spatial-analysis-zone-line-placement.md)
