---
title: Режим области — Персонализация
description: Узнайте, как использовать режим области для получения уверенности в модели без изменения кода.
ms.service: cognitive-services
ms.subservice: personalizer
ms.topic: conceptual
ms.date: 05/01/2020
ms.openlocfilehash: 531917d9c48915f71354b4cd35747ecd9d33a6f8
ms.sourcegitcommit: d4734bc680ea221ea80fdea67859d6d32241aefc
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/14/2021
ms.locfileid: "100385036"
---
# <a name="use-apprentice-mode-to-train-personalizer-without-affecting-your-existing-application"></a>Использование режима области для обучения персонализации без влияния на существующее приложение

Из-за природы **практического** обучения подкреплением модель персонализации может быть обучена только в рабочей среде. При развертывании нового варианта использования модель персонализации не работает эффективно, так как она занимает некоторое время, чтобы модель была достаточно обучена.  **Режим области** — это режим обучения, который упрощает эту ситуацию и позволяет получить уверенность в модели — без изменения кода разработчиком.

[!INCLUDE [Important Blue Box - Apprentice mode pricing tier](./includes/important-apprentice-mode.md)]

## <a name="what-is-apprentice-mode"></a>Что такое режим области?

Аналогично тому, как области узнает от главного, и с опытом может быть лучше. Режим области — это _поведение_ , которое позволяет персонализации узнать, просматривая результаты, полученные из существующей логики приложения.

Обучение персонализации с помощью копируя те же выходные данные, что и приложение. Как и поток событий, Персонализация может _перехватывать_ существующее приложение, не влияя на существующую логику и результаты. Метрики, доступные в портал Azure и API, помогают понять производительность по мере изучения модели.

Когда персонализация изучила и пристига определенного уровня понимания, разработчик может изменить поведение режима области в режим «в сети». В это время Персонализация начинает влиять на действия в API ранжирования.

## <a name="purpose-of-apprentice-mode"></a>Назначение режима области

Режим области обеспечивает доверие в службе персонализации и ее функциях машинного обучения, а также гарантирует, что служба отправляет сведения, которые могут быть получены из-за риска сетевого трафика.

Ниже приведены две основные причины использования режима области:

* Устранение **холодных запусков**. режим области помогает управлять и оценивать стоимость "нового" времени обучения модели, когда он не возвращает лучшее действие и не достигает удовлетворительного уровня эффективности около 60-80%.
* **Проверка функций действий и контекста**. функции, отправляемые в действиях и контексте, могут быть недостаточными, слишком большими, неправильными или слишком специфичными для обучения персонализации, чтобы достичь идеального процента эффективности. Использование [оценки функций](concept-feature-evaluation.md) для поиска и устранения проблем с функциями.

## <a name="when-should-you-use-apprentice-mode"></a>Когда следует использовать режим области?

Используйте режим области для обучения персонализации, чтобы повысить его эффективность с помощью следующих сценариев, в то время как не затронет работу пользователей, не затронутых персонализацией:

* Вы реализуете персонализацию в новом варианте использования.
* Вы значительно изменили функции, которые вы отправляете в контексте или действиях.
* Вы значительно изменили время и то, как Вычислите вознаграждения.

Режим области не является эффективным способом измерения персонализации влияния на результаты наград. Чтобы определить, насколько эффективно работает Персонализация при выборе оптимального действия для каждого вызова ранжирования, используйте [автономные вычисления](concepts-offline-evaluation.md).

## <a name="who-should-use-apprentice-mode"></a>Кто должен использовать режим области?

Режим области полезен для разработчиков, специалистов по обработке и анализу данных и руководителей, ответственных за принятие решений.

* **Разработчики** могут использовать режим области, чтобы убедиться в правильности использования API ранжирования и наград в приложении, а также о том, что функции, отправляемые в персонализацию из приложения, не содержат ошибок или несоответствующих функций, таких как timestamp или элемент UserID.

* **Специалисты** по обработке и анализу данных могут использовать режим области, чтобы проверить, что функции эффективны для обучения моделей персонализации, что время ожидания вознаграждений не слишком длинное или короткое.

* **Менеджеры по бизнес-решениям** могут использовать режим области, чтобы оценить потенциал персонализации, чтобы улучшить результаты (т. е. вознаграждения) по сравнению с существующей бизнес-логикой. Это позволяет им принимать обоснованное решение, влияющее на взаимодействие с пользователем, когда реальный доход и удовлетворенность пользователей находятся на заявляйте.

## <a name="comparing-behaviors---apprentice-mode-and-online-mode"></a>Сравнение поведений — режим области и режим "в сети"

Обучение в режиме области отличается от режима "в сети" следующими способами.

|Область|Режим ученика|Сетевой режим|
|--|--|--|
|Влияние на взаимодействие с пользователем|Вы можете использовать существующее поведение пользователя для обучения персонализации, разрешив ему (не влияет) **действие по умолчанию** и полученное вознаграждение. Это означает, что ваши пользователи и результаты бизнеса не будут затронуты.|Отображение верхнего действия, возвращенного при вызове ранжирования, для изменения поведения пользователя.|
|Скорость обучения|Персонализация будет более медленной в режиме области, чем при обучении в интерактивном режиме. Режим области может изучать только, просматривая преимущества, полученные с помощью **действия по умолчанию**, что ограничивает скорость обучения, так как просмотр не может быть выполнен.|Быстрее научиться, поскольку она может использовать текущую модель и исследовать новые тенденции.|
|Эффективность обучения "ceiling"|Персонализация может быть приблизительным, очень редко совпадать и никогда не превышать производительность базовой бизнес-логики (сумма вознаграждений достигается **действием по умолчанию** для каждого вызова ранжирования). Этот приблизительный потолк сокращается за счет исследования. Например, при исследовании на 20% это очень маловероятно, что производительность области режима будет превышать 80%, а 60% — разумным целевым объектом, на котором можно перевестися в режим «в сети».|Персонализация должна превысить базовые показатели приложений, и со временем, в течение которого она останавливается, следует провести автономную оценку и оценку компонентов, чтобы продолжить получать улучшения модели. |
|Значение API ранжирования для Ревардактионид|Работа пользователей не затронута, так как _ревардактионид_ всегда является первым действием, которое вы отправляете в запросе на ранжирование. Иными словами, API ранжирования не делает ничего видимого для приложения во время области режима. API-интерфейсы поощрений в приложении не должны изменять способ использования API-интерфейса наград между одним режимом и другим.|Работа пользователей будет изменена _ревардактионид_ , который используется персонализацией для вашего приложения. |
|Оценок|Персонализация обеспечивает сравнение итоговых сумм наград, получаемых бизнес-логикой по умолчанию, и персонализации в режиме "в сети" будут возобновлены в этом месте. Сравнение доступно в портал Azure для этого ресурса|Оцените эффективность персонализации, запустив [автономные вычисления](concepts-offline-evaluation.md), которые позволяют сравнить общее число возможностей с потенциальными преимуществами базовых показателей приложения.|

Примечание о эффективности режима области:

* Эффективность персонализации в режиме области практически не достигает 100% от базовых показателей приложения. и никогда не превышают его.
* Передовые методики не попытаются достичь 100%. но диапазон из 60% – 80% должен быть целевым в зависимости от варианта использования.

## <a name="using-apprentice-mode-to-train-with-historical-data"></a>Использование режима области для обучения с историческими данными

При наличии большого количества исторических данных, которые вы хотите использовать для обучения персонализации, можно использовать режим области для воспроизведения данных с помощью персонализации.

Настройте персонализацию в режиме области и создайте скрипт, вызывающий ранжирование с помощью функций и контекста из исторических данных. Вызовите API наград на основе вычислений записей в этих данных. Для просмотра результатов потребуется примерно 50 000 исторических событий, но для большей уверенности в результатах рекомендуется использовать 500 000.

При обучении из исторических данных рекомендуется отправлять данные (функции для контекста и действий, их макет в JSON, используемый для ранжирования запросов, а также вычисление вознаграждений в этом наборе обучающих данных), которые соответствуют данным (функциям и вычислению вознаграждений), доступным в существующем приложении.

Автономные и пост-факто данные, как правило, являются более неполными и заметные и отличаются в разных форматах. Во время обучения из исторических данных результаты выполнения этих действий могут быть неточными, а не хорошим прогнозом того, насколько хорошо будет изучать Персонализация, особенно в том случае, если функции отличаются от предыдущих данных и от существующего приложения.

Обычно для персонализации, по сравнению с историческими данными, изменение поведения в режиме области и обучение из существующего приложения — более эффективный путь для эффективной модели с меньшими трудозатратами, проектированием данных и очисткой.

## <a name="using-apprentice-mode-versus-ab-tests"></a>Использование режима области и тестов/B

Рекомендуется выполнять A/B-тесты персонализации использование после ее проверки и изучения в интерактивном режиме. В режиме области используется только **действие по умолчанию** . Это означает, что все пользователи будут видеть возможности управления.

Даже если персонализация является просто сложной _задачей, то_ при проверке данных хорошо подходит для персонализации. Вместо этого можно использовать режим области с 100% трафика, а все пользователи получают возможность управления (без изменений).

Если у вас есть вариант использования, используя средства персонализации и обучения в Интернете, эксперименты/B позволяют управлять когорты и экспоненциальным сравнением результатов, которые могут быть более сложными, чем сигналы, используемые для вознаграждения. Ниже приведен пример вопроса, на который может ответить тест A/B: `In a retail website, Personalizer optimizes a layout and gets more users to _check out_ earlier, but does this reduce total revenue per transaction?`

## <a name="next-steps"></a>Следующие шаги

* Сведения об [активных и неактивных событиях](concept-active-inactive-events.md)
