---
title: Несколько внешних интерфейсов — Azure Load Balancer
description: По этой схеме обучения приступите к обзору нескольких внешних интерфейсов на Azure Load Balancer
services: load-balancer
documentationcenter: na
author: asudbring
ms.service: load-balancer
ms.custom: seodec18
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: infrastructure-services
ms.date: 08/07/2019
ms.author: allensu
ms.openlocfilehash: 5c2072d13cab9839a276c0437747d7075918e78a
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "94696886"
---
# <a name="multiple-frontends-for-azure-load-balancer"></a>Несколько внешних интерфейсов для Azure Load Balancer

Azure Load Balancer позволяет выполнять балансировку нагрузки между службами на нескольких портах, нескольких IP-адресах или обоими этими способами. Вы можете воспользоваться определениями общедоступного и внутреннего балансировщика нагрузки для выполнения балансировки потоков в наборе виртуальных машин.

В этой статье описываются основные принципы данной функции, важные понятия и ограничения. Если вы собираетесь размещать службы только на одном IP-адресе, то см. упрощенные инструкции для настройки [общедоступного](./quickstart-load-balancer-standard-public-portal.md) или [внутреннего](./quickstart-load-balancer-standard-internal-portal.md) балансировщика нагрузки. Добавление нескольких внешних интерфейсов является действием, дополняющим конфигурацию с одним внешним интерфейсом. С помощью принципов, изложенных в этой статье, можно в любой момент расширить упрощенную конфигурацию.

При определении Azure Load Balancer интерфейсный и внутренний пулы связываются правилами. Проба работоспособности, на которую ссылается правило, позволяет определить, как новые потоки направляются на узел во внутреннем пуле. Внешний интерфейс (виртуальный IP-адрес) определяется с помощью сочетания 3-кортежей: IP-адреса (общедоступного или внутреннего), транспортного протокола (UDP или TCP) и номера порта из правила балансировки нагрузки. Внутренний пул — это совокупность IP-конфигураций виртуальных машин (часть ресурса сетевого адаптера), которые ссылаются на внутренний пул Load Balancer.

В следующей таблице приведены некоторые примеры интерфейсных конфигураций:

| Внешний интерфейс | IP-адрес | protocol | порт |
| --- | --- | --- | --- |
| 1 |65.52.0.1 |TCP |80 |
| 2 |65.52.0.1 |TCP |*8080* |
| 3 |65.52.0.1 |*UDP* |80 |
| 4 |*65.52.0.2* |TCP |80 |

В таблице представлены четыре разных внешних интерфейса. Внешние интерфейсы 1, 2 и 3 — это один внешний интерфейс с несколькими правилами. Используется один IP-адрес, но порт или протокол отличаются для каждого внешнего интерфейса. Внешние интерфейсы 1 и 4 являются примерами нескольких внешних интерфейсов, где один интерфейсный протокол и один порт повторно используются для разных внешних интерфейсов.

Azure Load Balancer обеспечивает гибкость при определении правил балансировки нагрузки. Правило объявляет, каким образом адрес и порт во внешнем интерфейсе сопоставляются с адресом и портом назначения в серверной части. Будут ли внутренние порты повторно использоваться в нескольких правилах зависит от типа правил. Каждый тип правил имеет определенные требования, которые могут повлиять на конфигурацию узла и конструкцию пробы. Существует два типа правил:

1. Правило по умолчанию, в котором внутренние порты повторно не используются.
2. Правило плавающего IP-адреса, в котором внутренние порты используются повторно.

Azure Load Balancer позволяет сочетать оба типа правил в одной конфигурации балансировщика нагрузки. Балансировщик нагрузки может использовать их одновременно для определенной виртуальной машины или в любой комбинации; главное, чтобы соблюдались ограничения правила. Выбор типа правил зависит от требований вашего приложения и сложности поддержки созданной конфигурации. Следует оценить, какие типы правил лучше подходят для конкретного сценария.

Мы рассмотрим возможные сценарии далее в этой статье, а начнем с поведения по умолчанию.

## <a name="rule-type-1-no-backend-port-reuse"></a>Тип правил 1: внутренние порты повторно не используются

![Иллюстрация нескольких внешних интерфейсов: зеленый и сиреневый](./media/load-balancer-multivip-overview/load-balancer-multivip.png)

В этом сценарии внешние интерфейсы настроены следующим образом:

| Внешний интерфейс | IP-адрес | protocol | порт |
| --- | --- | --- | --- |
| ![зеленый интерфейс](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) 1 |65.52.0.1 |TCP |80 |
| ![сиреневый интерфейс](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) 2 |*65.52.0.2* |TCP |80 |

Выделенный IP-адрес (DIP) — это назначение входящего потока. Во внутреннем пуле каждая виртуальная машина размещает нужную службу на уникальном порте в DIP. Эта служба связывается с внешним интерфейсом посредством определения правил.

Мы определим два правила:

| Правило | Сопоставить внешний интерфейс | С внутренним пулом |
| --- | --- | --- |
| 1 |![зеленый интерфейс](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) Frontend1:80 |![Зеленая Серверная часть](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) DIP1:80, ![Зеленая Серверная часть](./media/load-balancer-multivip-overview/load-balancer-rule-green.png)  DIP2:80 |
| 2 |![Виртуальный IP-адрес](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) Frontend2:80 |![Фиолетовая Серверная часть](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) DIP1:81, ![Фиолетовая Серверная часть](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png)  DIP2:81 |

Полное сопоставление в Azure Load Balancer теперь выглядит следующим образом:

| Правило | Интерфейсный IP-адрес | protocol | порт | Назначение | порт |
| --- | --- | --- | --- | --- | --- |
| ![правило зеленого интерфейса](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) 1 |65.52.0.1 |TCP |80 |Выделенный IP-адрес (DIP) |80 |
| ![правило сиреневого интерфейса](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) 2 |65.52.0.2 |TCP |80 |Выделенный IP-адрес (DIP) |81 |

Каждое правило должно создавать поток с уникальным сочетанием конечного IP-адреса и конечного порта. Изменив конечный порт потока, можно с помощью нескольких правил направить потоки на один DIP на разных портах.

Пробы работоспособности всегда направлены на DIP виртуальной машины. Убедитесь, что проба отражает состояние работоспособности виртуальной машины.

## <a name="rule-type-2-backend-port-reuse-by-using-floating-ip"></a>Тип правил 2: внутренние порты используются повторно с помощью плавающего IP-адреса

Azure Load Balancer обеспечивает гибкость, позволяя повторно использовать интерфейсный порт на нескольких внешних интерфейсах независимо от того, какой тип правил используется. Кроме того, в некоторых сценариях приложений использование одного порта несколькими экземплярами приложения на одной виртуальной машине во внутреннем пуле является предпочтительным или обязательным. К распространенным примерам повторного использования портов относятся виртуальные сетевые устройства, кластеризация для обеспечения высокой доступности и размещение нескольких конечных точек TLS без повторного шифрования.

Если вы хотите, чтобы внутренний порт повторно использовался в нескольких правилах, то в определении правила необходимо активировать плавающий IP-адрес.

Согласно терминологии Azure, плавающий IP-адрес — это часть метода, известного как прямой ответ от сервера (DSR). DSR состоит из двух частей: топологии потока и схемы сопоставления IP-адресов. На уровне платформы Azure Load Balancer всегда работает в топологии потока DSR независимо от того, активирован ли плавающий IP-адрес. Это означает, что исходящая часть потока всегда правильно перезаписывается в поток непосредственно обратно в источник.

Для удобства применения Azure предоставляет традиционную схему сопоставления IP-адресов балансировки нагрузки, используя тип правил по умолчанию. Активация плавающего IP-адреса изменяет схему сопоставления IP-адресов для обеспечения дополнительной гибкости, как описано ниже.

Эта конфигурация представлена на следующей схеме:

![Иллюстрация нескольких внешних интерфейсов (зеленый и сиреневый) с прямым ответом от сервера](./media/load-balancer-multivip-overview/load-balancer-multivip-dsr.png)

В этом сценарии каждая виртуальная машина во внутреннем пуле имеет три сетевых интерфейса:

* DIP: виртуальная сетевая карта, связанная с виртуальной машиной (IP-конфигурация ресурса сетевой карты Azure).
* Внешний интерфейс 1: интерфейс замыкания на себя в гостевой ОС, настроенной с IP-адресом внешнего интерфейса 1.
* Внешний интерфейс 2: интерфейс замыкания на себя в гостевой ОС, настроенной с IP-адресом внешнего интерфейса 2.

Для каждой виртуальной машины во внутреннем пуле выполните следующие команды в командной строке Windows.

Чтобы получить список имен интерфейсов на виртуальной машине, введите следующую команду:

```console
netsh interface show interface 
```

Для сетевого адаптера виртуальной машины (под управлением Azure) введите следующую команду:

```console
netsh interface ipv4 set interface “interfacename” weakhostreceive=enabled
```

(замените InterfaceName именем этого интерфейса)

Для каждого добавленного интерфейса замыкания на себя повторите следующие команды:

```console
netsh interface ipv4 set interface “interfacename” weakhostreceive=enabled 
```

(замените InterfaceName на имя этого интерфейса замыкания на себя)

```console
netsh interface ipv4 set interface “interfacename” weakhostsend=enabled 
```

(замените InterfaceName на имя этого интерфейса замыкания на себя)

> [!IMPORTANT]
> Настройка интерфейсов замыкания на себя выполняется в гостевой ОС. Эта настройка не выполняется и не управляется Azure. Без данной настройки правила не будут функционировать. Определения проб работоспособности используют выделенный IP-адрес (DIP) виртуальной машины, а не интерфейс замыкания на себя, представляющий интерфейс с прямым ответом от сервера. Поэтому служба должна предоставить на порте DIP ответы проб, которые отражают состояние службы, предлагаемое на интерфейсе замыкания на себя, представляющем интерфейс с прямым ответом от сервера.


Предположим, что интерфейсная конфигурация такая же, как в предыдущем сценарии:

| Внешний интерфейс | IP-адрес | protocol | порт |
| --- | --- | --- | --- |
| ![зеленый интерфейс](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) 1 |65.52.0.1 |TCP |80 |
| ![сиреневый интерфейс](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) 2 |*65.52.0.2* |TCP |80 |

Мы определим два правила:

| Правило | Внешний интерфейс | Сопоставление с внутренним пулом |
| --- | --- | --- |
| 1 |![правило зеленого интерфейса](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) Frontend1:80 |![Зеленая Серверная часть](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) Frontend1:80 (на виртуальной машине 1 и 2) |
| 2 |![правило сиреневого интерфейса](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) Frontend2:80 |![Фиолетовая Серверная часть](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) Frontend2:80 (на виртуальной машине 1 и 2) |

Следующая таблица демонстрирует полное сопоставление в балансировщике нагрузки:

| Правило | Интерфейсный IP-адрес | protocol | порт | Назначение | порт |
| --- | --- | --- | --- | --- | --- |
| ![правило зеленого интерфейса](./media/load-balancer-multivip-overview/load-balancer-rule-green.png) 1 |65.52.0.1 |TCP |80 |такое, как у внешнего интерфейса (65.52.0.1) |такое, как у внешнего интерфейса (80) |
| ![правило сиреневого интерфейса](./media/load-balancer-multivip-overview/load-balancer-rule-purple.png) 2 |65.52.0.2 |TCP |80 |такое, как у внешнего интерфейса (65.52.0.2) |такое, как у внешнего интерфейса (80) |

Местом назначения входящего потока является интерфейсный IP-адрес в интерфейсе замыкания на себя на виртуальной машине. Каждое правило должно создавать поток с уникальным сочетанием конечного IP-адреса и конечного порта. Изменив конечный IP-адрес потока, можно разрешить повторное использование портов на одной виртуальной машине. Служба предоставляется балансировщику нагрузки через привязку к интерфейсному IP-адресу и порту соответствующего интерфейса замыкания на себя.

Обратите внимание, что в этом примере не изменяется конечный порт. Несмотря на то, что этот сценарий использует плавающий IP-адрес, Azure Load Balancer также поддерживает определение правила, которое перезаписывает внутренний конечный порт и делает его отличным от интерфейсного конечного порта.

Тип правил с плавающим IP-адресом лежит в основе нескольких шаблонов конфигураций балансировщика нагрузки. Одним из примеров, доступных в данный момент, является конфигурация [SQL AlwaysOn with Multiple Listeners](../azure-sql/virtual-machines/windows/availability-group-listener-powershell-configure.md) (SQL AlwaysOn с несколькими прослушивателями). В будущем мы опишем больше сценариев.

## <a name="limitations"></a>Ограничения

* Конфигурации с несколькими внешними интерфейсами поддерживаются только при использовании виртуальных машин IaaS.
* При использовании правила с плавающим IP-адресом приложение должно использовать основную IP-конфигурацию для исходящих потоков SNAT. Если ваше приложение привязывается к интерфейсному IP-адресу, настроенному в интерфейсе замыкания на себя гостевой ОС, то исходящая SNAT Azure не будет доступна для перезаписи исходящего потока, и поток завершится ошибкой.  Проверьте [сценарии исходящего трафика](load-balancer-outbound-connections.md).
* Плавающий IP-адрес в настоящее время не поддерживается во вторичных IP-конфигурациях для сценариев с использованием внутренней балансировки нагрузки.
* Общедоступные IP-адреса оказывают влияние на выставление счетов. Дополнительные сведения см. в статье [Цены на IP-адреса](https://azure.microsoft.com/pricing/details/ip-addresses/).
* Действуют ограничения подписки. Дополнительные сведения см. в разделе [Ограничения определенных служб](../azure-resource-manager/management/azure-subscription-service-limits.md#networking-limits).

## <a name="next-steps"></a>Дальнейшие действия

- Просмотрите статью [Исходящие подключения в Azure](load-balancer-outbound-connections.md), чтобы понять, как влияют несколько внешних интерфейсов на поведение исходящих подключений.