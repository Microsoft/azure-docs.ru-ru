---
title: Рекомендации по использованию Azure Data Lake Storage Gen1 | Документация Майкрософт
description: Ознакомьтесь с рекомендациями по приему и безопасности данных, а также по производительности, связанные с использованием Azure Data Lake Storage Gen1 (прежнее название — Azure Data Lake Store).
services: data-lake-store
documentationcenter: ''
author: sachinsbigdata
manager: mtillman
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.date: 06/27/2018
ms.author: sachins
ms.openlocfilehash: 9a5c5f9a4033b70a664071d6077a69f38c905093
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "96452223"
---
# <a name="best-practices-for-using-azure-data-lake-storage-gen1"></a>Рекомендации по использованию Azure Data Lake Storage Gen1

[!INCLUDE [data-lake-storage-gen1-rename-note.md](../../includes/data-lake-storage-gen1-rename-note.md)]

Из этой статьи вы узнаете о лучших методиках и рекомендациях по использованию Azure Data Lake Storage 1-го поколения. В этом руководстве приводятся сведения о безопасности, производительности, отказоустойчивости и мониторинге для Data Lake Storage 1-го поколения. До появления Data Lake Storage 1-го поколения работа с большими данными в таких службах, как Azure HDInsight, представляла значительные сложности. Нужно было сегментировать данные в нескольких учетных записях хранения больших двоичных объектов, чтобы обеспечить хранение петабайтовых файлов и оптимальную производительность в этом масштабе. С появлением Data Lake Storage 1-го поколения большинство жестких ограничений размера и производительности исчезли. В этой статье рассматриваются некоторые методики по обеспечению высокой производительности при работе с Data Lake Storage 1-го поколения.

## <a name="security-considerations"></a>Вопросы безопасности

Azure Data Lake Storage 1-го поколения предлагает элементы управления доступом POSIX и подробный аудит для пользователей, групп и субъектов-служб Azure Active Directory (Azure AD). Эти элементы управления доступом можно настроить для имеющихся файлов и папок. Их также можно использовать для создания значений по умолчанию, которые можно применить к новым файлам или папкам. Если для имеющихся папок и дочерних объектов установлены разрешения, их нужно рекурсивно распространить на каждый объект. Если файлов очень много, распространение разрешений может занять много времени. Затраченное время может варьироваться между 30–50 объектами, обрабатываемыми за секунду. Следовательно, необходимо соответствующим образом упорядочить структуру папок и создать группы пользователей. В противном случае это может вызвать непредвиденные задержки и проблемы при работе с данными.

Предположим, у вас есть папка, содержащая 100 000 дочерних объектов. Если взять нижнюю границу — 30 объектов, обрабатываемых за секунду, то обновление разрешения для всей папки может занять час. См. дополнительные сведения о [списках управления доступом для Data Lake Storage 1-го поколения](data-lake-store-access-control.md). Для повышения производительности при рекурсивном назначении списков управления доступом можно использовать программу командной строки Azure Data Lake. Программа создает несколько потоков и рекурсивную навигационную логику для быстрого применения списков ACL к миллионам файлов. Она доступна для Linux и Windows, а [документацию](https://github.com/Azure/data-lake-adlstool) и [файлы для скачивания](https://aka.ms/adlstool-download) можно найти на сайте GitHub. Такие улучшения производительности можно включить собственными средствами, написанными с использованием пакетов SDK для Data Lake Storage 1-го поколения для [.NET](data-lake-store-data-operations-net-sdk.md) и [Java](data-lake-store-get-started-java-sdk.md).

### <a name="use-security-groups-versus-individual-users"></a>Сравнение использования групп безопасности и отдельных пользователей

При работе с большими данными в Data Lake Storage 1-го поколения субъект-служба, скорее всего, будет использоваться для предоставления службам, таким как Azure HDInsight, разрешения работать с данными. Однако встречаются случаи, когда доступ к данным также необходимо предоставить отдельным пользователям. В таких случаях нужно использовать группы безопасности [Azure Active Directory](data-lake-store-secure-data.md#create-security-groups-in-azure-active-directory) вместо назначения отдельных пользователей папкам и файлам.

Когда группе безопасности назначены разрешения, для добавления или удаления пользователей из группы не требуются какие-либо обновления Data Lake Storage 1-го поколения. Так вы не превысите ограничение в [32 списка ACL (списки для доступа и списки по умолчанию)](../azure-resource-manager/management/azure-subscription-service-limits.md#data-lake-storage-limits). Сюда входят четыре списка ACL типа POSIX, которые всегда связаны со всеми файлами и папками: [пользователь-владелец](data-lake-store-access-control.md#the-owning-user), [группа-владелец](data-lake-store-access-control.md#the-owning-group), [маска](data-lake-store-access-control.md#the-mask)и др.

### <a name="security-for-groups"></a>Безопасность для групп

Как уже отмечалось, когда пользователям нужен доступ к Data Lake Storage 1-го поколения, лучше всего использовать группы безопасности Azure Active Directory. Мы рекомендуем начать с таких групп, как **ReadOnlyUsers**, **WriteAccessUsers** и **FullAccessUsers**, на корневом уровне учетной записи, а также назначить отдельные группы для основных подпапок. Если есть другие ожидаемые группы пользователей, которые нужно будет добавить позже, но они еще не определены, можно рассмотреть создание пустых групп безопасности с доступом к определенным папкам. Использование группы безопасности — гарантия того, что вам позже не потребуется длительное время обработки для назначения новых разрешений тысячам файлов.

### <a name="security-for-service-principals"></a>Безопасность для субъектов-служб

Субъекты-службы Azure Active Directory обычно используются такими службами, как Azure HDInsight, для доступа к данным в Data Lake Storage 1-го поколения. В зависимости от требований к доступности нескольких рабочих нагрузок стоит рассмотреть обеспечение безопасности внутри организации и за ее пределами. Для многих клиентов может быть достаточно одного субъекта-службы Azure Active Directory, которому назначен полный набор прав в корневой папке Data Lake Storage 1-го поколения. Другим клиентам может потребоваться несколько кластеров с разными субъектами-службами, где у одного кластера будет полный доступ к данным, а у другого — только доступ на чтение. Как и в случае с группами безопасности, после создания учетной записи Data Lake Storage 1-го поколения можно создать субъект-службу для каждого ожидаемого сценария использования (чтение, запись, полный доступ).

### <a name="enable-the-data-lake-storage-gen1-firewall-with-azure-service-access"></a>Включение брандмауэра для Data Lake Storage 1-го поколения с доступом к службе Azure

Data Lake Storage 1-го поколения позволяет включить брандмауэр и ограничить доступ только службами Azure, что очень полезно для сужения вектора атаки на случай внешних вторжений. Брандмауэр можно включить в учетной записи Data Lake Storage 1-го поколения в портал Azure **через брандмауэр**  >  **включить брандмауэр (вкл.)**  >  **Разрешить доступ к параметрам служб Azure** .

![Параметры брандмауэра в Data Lake Storage 1-го поколения](./media/data-lake-store-best-practices/data-lake-store-firewall-setting.png "Параметры брандмауэра в Data Lake Storage 1-го поколения")

После включения брандмауэра доступ к Data Lake Storage 1-го поколения могут получить только службы Azure, такие как HDInsight, фабрика данных, Azure синапсе Analytics и т. д. Из-за внутреннего преобразования сетевых адресов в Azure брандмауэр Data Lake Storage 1-го поколения не поддерживает ограничения по IP-адресу для конкретных служб и предназначается только для ограничения по конечным точкам за пределами Azure, например в локальной среде.

## <a name="performance-and-scale-considerations"></a>Рекомендации по производительности и масштабируемости

Одна из самых мощных возможностей Data Lake Storage 1-го поколения заключается в устранении жестких ограничений пропускной способности данных. Благодаря этому клиенты могут увеличивать размер данных и расширять соответствующие требования к производительности без необходимости сегментировать данные. Один из наиболее важных аргументов в пользу оптимизации производительности Data Lake Storage 1-го поколения заключается в том, что производительность напрямую зависит от параллелизма.

### <a name="improve-throughput-with-parallelism"></a>Повышение пропускной способности при параллелизме

Оптимальную пропускную способность чтения и записи можно получить при использовании 8–12 потоков на ядро. Это объясняется блокировкой операций чтения и записи в одном потоке, а большее количество потоков могут обеспечить более высокий параллелизм на виртуальной машине. Для обеспечения работоспособности уровней и повышения параллелизма необходимо отслеживать использование ЦП виртуальной машины.

### <a name="avoid-small-file-sizes"></a>Не используйте файлы небольшого размера

Разрешения и аудит POSIX в Data Lake Storage 1-го поколения сопровождаются накладными расходами, которые становятся очевидными при работе со множеством файлов небольшого размера. Лучше упаковать данные в файлы большего размера, чем сохранять тысячи или миллионы небольших файлов в Data Lake Storage 1-го поколения. Использование файлов большего размера предоставляет следующие преимущества:

* снижение числа проверок подлинности для большого количества файлов;
* уменьшение числа подключений к открытым файлам;
* более быстрые копирование или репликация;
* меньшее количество файлов для обработки при обновлении разрешений POSIX в Data Lake Storage 1-го поколения.

В зависимости от того, в каких службах и рабочих нагрузках используются данные, советуем использовать файлы размером 256 МБ и больше. Если файлы невозможно упаковать при размещении в Data Lake Storage 1-го поколения, вы можете использовать отдельное задание сжатия, которое объединит эти файлы в более крупные по размеру. Дополнительные сведения и рекомендации по размерам файлов и упорядочиванию данных в Data Lake Storage 1-го поколения см. в разделе [Структура набора данных](data-lake-store-performance-tuning-guidance.md#structure-your-data-set).

### <a name="large-file-sizes-and-potential-performance-impact"></a>Файлы больших размеров и возможное влияние на производительность

Хотя Data Lake Storage 1-го поколения поддерживает файлы размером до нескольких петабайт, для оптимальной производительности обычно лучше не превышать средний размер в 2 ГБ, с учетом особенностей процесса, считывающего данные. Например, при использовании операции **Distcp** для копирования данных между расположениями или разными учетными записями хранения, файлы представляют собой самый нижний уровень детализации, используемый для определения задач сопоставления. Итак, если вы копируете 10 файлов по 1 ТБ каждый, выделяется не более 10 модулей сопоставления. Кроме того, если у вас много файлов с назначенными модулями сопоставления, эти модули изначально работают параллельно для перемещения файлов больших размеров. Тем не менее, когда задание начинает завершаться, доступными остаются всего несколько модулей сопоставления и может даже остаться только один модуль, назначенный файлу большого размера. Корпорация Майкрософт оптимизировала Distcp для решения этой проблемы в будущих версиях Hadoop.

Также стоит обратить внимание на использование Azure Data Lake Analytics с Data Lake Storage 1-го поколения. В зависимости от обработки, выполняемой средством извлечения, может ухудшиться производительность некоторых файлов размером свыше 2 ГБ, которые нельзя разделить (например, XML-, JSON-файлы). В случаях, когда файлы можно разделить с помощью средства извлечения (например, CSV-файлы), файлы больших размеров являются оптимальными.

### <a name="capacity-plan-for-your-workload"></a>Планирование емкости для рабочей нагрузки

Azure Data Lake Storage 1-го поколения устраняет жесткие ограничения регулирования операций ввода-вывода, установленные в учетных записях хранения больших двоичных объектов. Тем не менее по-прежнему применяются некоторые нестрогие ограничения, которые стоит учитывать. Ограничения регулирования входящего и исходящего трафика по умолчанию удовлетворяют потребностям большинства сценариев. Если для вашей рабочей нагрузки нужно увеличить ограничения, мы рекомендуем обратиться в службу поддержки Майкрософт. Кроме того, ознакомьтесь с ограничениями на этапе работы в экспериментальной среде, чтобы не достичь ограничений регулирования операций ввода-вывода при использовании в рабочей среде. В противном случае вам придется ждать некоторое время, пока сотрудник службы поддержки Майкрософт не увеличит ограничения вручную. При регулировании операций ввода-вывода Azure Data Lake Storage 1-го поколения возвращает код ошибки 429, и в идеале должна быть выполнена повторная попытка с использованием соответствующей политики экспоненциального откладывания.

### <a name="optimize-writes-with-the-data-lake-storage-gen1-driver-buffer"></a>Оптимизация операций записи с помощью буфера драйвера Data Lake Storage 1-го поколения

Чтобы оптимизировать производительность и уменьшить количество операций ввода-вывода в секунду при записи в Data Lake Storage 1-го поколения из Hadoop, размер операций записи должен быть как можно ближе к размеру буфера драйвера Data Lake Storage 1-го поколения. Старайтесь не превышать размер буфера перед очисткой, например при потоковой передаче с помощью рабочих нагрузок потоковой передачи Spark или Apache Storm. При записи в Data Lake Storage 1-го поколения из HDInsight или Hadoop важно знать, что в Data Lake Storage 1-го поколения есть драйвер с буфером размером 4 МБ. Как и многие драйверы файловой системы, этот буфер можно вручную очистить до достижения размера 4 МБ. Если этого не сделать, его содержимое будет перенесено в хранилище, если следующая операция записи превышает максимальный размер буфера. По возможности нужно избегать переполнения или недостаточного заполнения буфера при синхронизации или переносе содержимого по количеству или временному окну.

## <a name="resiliency-considerations"></a>Рекомендации по обеспечению устойчивости

При разработке системы с Data Lake Storage 1-го поколения или любой облачной службой нужно оценить требования к доступности и способы реагирования на возможные перерывы в обслуживании. Проблему можно локализовать на уровне конкретного экземпляра или даже всего региона, поэтому важно учесть все в комплексе. В зависимости от **цели времени восстановления** и **цели** соглашения об уровне обслуживания для рабочей нагрузки можно выбрать более или менее агрессивную стратегию для обеспечения высокого уровня доступности и аварийного восстановления.

### <a name="high-availability-and-disaster-recovery"></a>Высокая доступность и аварийное восстановление

Высокий уровень доступности (HA) и аварийное восстановление (DR) иногда можно сочетать, хотя связанные стратегии немного отличаются, особенно при работе с данными. Data Lake Storage 1-го поколения уже обрабатывает трехкратную репликацию в фоновом режиме, чтобы защитить от локальных сбоев оборудования. Но так как отсутствует встроенная репликация по регионам, вам нужно выполнить ее самостоятельно. Составляя план для обеспечения высокого уровня доступности, в случае прерывания работы службы нужно как можно быстрее предоставить для рабочей нагрузки доступ к последним данным, выполнив переключение на отдельно реплицированный экземпляр в локальной среде или новом регионе.

В стратегии аварийного восстановления, чтобы подготовиться к маловероятному событию катастрофического отказа региона, также важно реплицировать данные в другой регион. Эти данные изначально должны быть такими же, как и реплицированные данные для обеспечения высокого уровня доступности. Тем не менее стоит также рассмотреть требования для таких пограничных случаев, как повреждение данных, когда может понадобиться создать периодические моментальные снимки, чтобы вернуться к ним. В зависимости от важности и размера данных рассмотрите возможность развертывания разностных моментальных снимков с интервалом времени 1, 6 и 24 часа в локальном или дополнительном хранилище в соответствии с допусками риска.

Для обеспечения устойчивости данных в Azure Data Lake Storage 1-го поколения рекомендуется выполнять георепликацию данных в отдельный регион с частотой, которая соответствует вашим требованиям к высокой доступности и аварийному восстановлению, в идеале — каждый час. Эта частота репликации минимизирует массивные перемещения данных с возможными конкурирующими требованиями к пропускной способности в отношении основной системы и требованиями к оптимальной целевой точке восстановления (RPO). Обдумайте также, как организовать для приложения, которое использует Data Lake Storage 1-го поколения, автоматическую отработку отказа в дополнительную учетную запись на основе триггеров мониторинга или длительности завершившихся сбоем попыток, или по меньшей мере отправку уведомлений администраторам для устранения неполадок вручную. Имейте в виду, что есть компромисс — выполнить отработку отказа, а не ждать, когда служба снова станет работоспособной. Если репликация не закончена, отработка отказа может привести к потере данных, несогласованности или сложному слиянию данных.

Ниже приводятся три оптимальных варианта организации репликации между учетными записями Data Lake Storage 1-го поколения и основные различия между ними.

|  |Distcp  |Фабрика данных Azure  |AdlCopy  |
|---------|---------|---------|---------|
|**Ограничения масштабирования**     | Ограничивается рабочими узлами        | Ограничивается максимальным количеством единиц перемещения облачных данных        | Ограничивается единицами аналитики        |
|**Поддержка копирования изменений**     |   Да      | Нет         | Нет         |
|**Встроенная оркестрация**     |  Отсутствует (используйте Oozie Airflow или задания Cron)       | Да        | Отсутствует (используйте службу автоматизации Azure или планировщик задач Windows)         |
|**Поддерживаемые файловые системы**     | ADL, HDFS, WASB, S3, GS, CFS        |Много. Дополнительные сведения см. в статье [Копирование данных в хранилище BLOB-объектов Azure и обратно с помощью фабрики данных Azure](../data-factory/connector-azure-blob-storage.md).         | ADL в ADL, WASB в ADL (только в одном регионе)        |
|**Поддержка ОС**     |Любая ОС, где выполняется Hadoop         | Н/Д          | Windows 10         |

### <a name="use-distcp-for-data-movement-between-two-locations"></a>Использование программы Distcp для перемещения данных между двумя расположениями

Distcp, сокращение от "распределенное копирование", представляет собой программу командной строки Linux, которая входит в состав Hadoop, и обеспечивает распределенное перемещение данных между двумя расположениями. Этими расположениями могут быть Data Lake Storage 1-го поколения, HDFS, WASB или S3. В программе используются задания MapReduce в кластере Hadoop (например, HDInsight) для масштабирования на всех узлах. Distcp считается самым быстрым способом перемещения больших данных без специальных устройств сетевого сжатия. Это средство также позволяет обновлять разностные данные между двумя расположениями, обрабатывать автоматические повторные попытки, а также применять динамическое масштабирование к вычислениям. Этот подход невероятно эффективен, когда, например, речь идет о реплицировании таблиц Hive и Spark, которые могут содержать много файлов больших размеров в одном каталоге, и вы хотите копировать только измененные данные. Именно поэтому Distcp является наиболее рекомендуемым инструментом для копирования данных между хранилищами больших данных.

Задания копирования могут запустить рабочие процессы Apache Oozie, использующие триггеры частоты или данных, а также задания Cron в Linux. Для интенсивных задач репликации рекомендуется развернуть отдельный кластер HDInsight Hadoop, который можно настроить и масштабировать специально для заданий копирования. Таким образом задания копирования и критические задания не будут влиять на работу друг друга. При выполнении репликации с достаточно широким интервалом кластер может прекращать работу между выполнением каждого задания. При выполнении отработки отказа в дополнительный регион в этом регионе нужно развернуть другой кластер для репликации новых данных обратно в основную учетную запись Data Lake Storage 1-го поколения, когда она возобновит свою работу. Примеры использования Distcp см. в руководстве по [использованию Distcp для копирования данных между Azure Storage Blob и Azure Data Lake Storage 1-го поколения](data-lake-store-copy-data-wasb-distcp.md).

### <a name="use-azure-data-factory-to-schedule-copy-jobs"></a>Использование фабрики данных Azure для планирования заданий копирования

Фабрика данных Azure также может использоваться для планирования заданий копирования с помощью **действия копирования** и даже для настройки частоты с помощью **мастера копирования**. Имейте в виду, что для фабрики данных Azure есть ограничение единиц перемещения облачных данных (DMU) и в конечном итоге ограничение пропускной способности или вычислительной мощности рабочих нагрузок с большими данными. Кроме того, Фабрика данных Azure сейчас не предлагает обновление разностных данных между учетными записями Data Lake Storage 1-го поколения, поэтому для таких папок, как таблицы Hive, требуется полная репликация. Дополнительные сведения о копировании с помощью фабрики данных см. в статье [Руководство по настройке производительности действия копирования](../data-factory/copy-activity-performance.md).

### <a name="adlcopy"></a>AdlCopy

AdlCopy — это программа командной строки Windows, которая позволяет копировать данные между двумя учетными записями Data Lake Storage 1-го поколения только в пределах региона. Средство AdlCopy предоставляет вариант изолированного использования или возможность использовать учетную запись Azure Data Lake Analytics для выполнения задания копирования. Хотя изначально это средство было создано для копирования по запросу, а не для надежной репликации, оно предлагает еще один вариант выполнения распределенного копирования между учетными записями Data Lake Storage 1-го поколения в пределах одного региона. Для обеспечения надежности рекомендуется использовать службу Data Lake Analytics уровня "Премиум" для любой нагрузки в рабочей среде. Изолированная версия может возвращать ответы о занятости службы и включает ограниченные масштабируемость и мониторинг.

Как и в случае с Distcp, AdlCopy нужно управлять с помощью службы автоматизации Azure или планировщика задач Windows. Как и в случае с фабрикой данных, AdlCopy не поддерживает копирование только обновленных файлов. Он повторно копирует и перезаписывает имеющиеся файлы. Дополнительные сведения и примеры использования AdlCopy см. в руководстве по [копированию данных из Azure Storage Blob в Data Lake Storage 1-го поколения](data-lake-store-copy-data-azure-storage-blob.md).

## <a name="monitoring-considerations"></a>Рекомендации по мониторингу

Azure Data Lake Storage 1-го поколения предоставляет подробные журналы диагностики и возможность аудита, а также некоторые базовые метрики на портале Azure, в разделе учетной записи Data Lake Storage 1-го поколения и в Azure Monitor. Сведения о доступности Data Lake Storage 1-го поколения отображаются на портале Azure. Однако эта метрика обновляется каждые семь минут, и ее нельзя запросить через общедоступный API-интерфейс. Чтобы получить самое актуальное состояние доступности для учетной записи Data Lake Storage 1-го поколения, нужно запустить собственные искусственные тесты для проверки доступности. Обновление других метрик, например общего использования хранилища, запросов на чтение и запись, а также показателей входящего и исходящего трафика, может занять до 24 часов. Таким образом, более актуальные метрики нужно получить самостоятельно с помощью программ командной строки Hadoop или путем агрегирования сведений журналов. Самый быстрый способ получить самые актуальные сведения об использовании хранилища — запустить команду HDFS ниже с узла кластера Hadoop (например, головного узла):

```console
hdfs dfs -du -s -h adl://<adlsg1_account_name>.azuredatalakestore.net:443/
```

### <a name="export-data-lake-storage-gen1-diagnostics"></a>Экспорт диагностики Data Lake Storage 1-го поколения

Один из самых быстрых способов получить доступ к журналам с возможностью поиска из Data Lake Storage 1-го поколения — включить для учетной записи Data Lake Storage 1-го поколения доставку журналов в **Log Analytics** в колонке **Диагностика**. Это обеспечит немедленный доступ к входящим журналам с фильтрами времени и содержимого, а также параметрам оповещения (электронная почта или веб-перехватчик), которые запускаются с интервалом в 15 минут. Дополнительные сведения см. в руководстве по [получения доступа к журналам диагностики Azure Data Lake Storage 1-го поколения](data-lake-store-diagnostic-logs.md).

Чтобы получать оповещения в режиме реального времени и получить больший контроль над размещением журналов, журналы можно экспортировать в Azure EventHub, где содержимое можно проанализировать отдельно или с учетом временного окна для отправки уведомлений в режиме реального времени в очередь. Отдельное приложение, например [приложение логики](../connectors/connectors-create-api-azure-event-hubs.md), может затем использовать эти оповещения и передавать их в соответствующий канал, а также отправлять метрики в средства мониторинга, такие как NewRelic, Datadog или AppDynamics. Кроме того, если вы используете сторонний инструмент, такой как ElasticSearch, вы можете экспортировать журналы в хранилище BLOB-объектов и использовать [подключаемый модуль Azure Logstash](https://github.com/Azure/azure-diagnostics-tools/tree/master/Logstash/logstash-input-azureblob) для использования данных в стеке Elasticsearch, Kibana и Logstash (ELK).

### <a name="turn-on-debug-level-logging-in-hdinsight"></a>Включение ведения журнала на уровне отладки в HDInsight

Если доставка журналов Data Lake Storage 1-го поколения отключена, Azure HDInsight также предоставляет возможность включить [ведение журнала на стороне клиента для Data Lake Storage 1-го поколения](data-lake-store-performance-tuning-mapreduce.md) с помощью log4j. Необходимо задать следующее свойство в конфигурациях **Ambari**  >  **YARN**  >  **config**  >  **Advanced YARN-log4j**:

`log4j.logger.com.microsoft.azure.datalake.store=DEBUG`

Установив это свойство и перезагрузив узлы, вы направите данные диагностики Data Lake Storage 1-го поколения в журналы YARN на узлах (/tmp/\<user\>/yarn.log) и сможете отслеживать такие важные данные, как ошибки или регулирование (код ошибки HTTP 429). Эти же сведения также можно отслеживать в журналах Azure Monitor или в любом месте, куда отправляются журналы, в колонке [Диагностика](data-lake-store-diagnostic-logs.md) учетной записи Data Lake Storage 1-го поколения. Мы рекомендуем включить по меньшей мере ведение журнала на стороне клиента или использовать возможность доставки журнала в Data Lake Storage 1-го поколения, чтобы обеспечить оперативную видимость и упростить отладку.

### <a name="run-synthetic-transactions"></a>Запуск искусственных транзакций

Сейчас метрика доступности службы для Data Lake Storage 1-го поколения на портале Azure имеет 7-минутное окно обновления. Кроме того, ее нельзя запросить с помощью общедоступного API-интерфейса. По этим причинам мы рекомендуем создать базовое приложение, которое выполняет искусственные транзакции в Data Lake Storage 1-го поколения, чтобы контролировать доступность с точностью до минуты. Например, можно создать приложение WebJob, приложение логики или приложение-функцию Azure для чтения, создания и обновления данных в Data Lake Storage 1-го поколения и отправки результатов в выбранное решение для мониторинга. Эти операции могут выполняться во временной папке, а затем удаляться после теста, который может запускаться каждые 30–60 секунд в зависимости от требований.

## <a name="directory-layout-considerations"></a>Рекомендации в отношении структуры каталога

При размещении данных в Data Lake важно заранее спланировать структуру данных, чтобы можно было эффективно использовать безопасность, секционирование и обработку. Многие из рекомендаций ниже можно использовать в Azure Data Lake Storage 1-го поколения, хранилище BLOB-объектов или HDFS. Каждая рабочая нагрузка включает разные требования к способу использования данных. Ниже приводятся некоторые общие шаблоны, которые следует учесть при работе с пакетными сценариями и Центром Интернета вещей.

### <a name="iot-structure"></a>Структура Центра Интернета вещей

В рабочих нагрузках Центра Интернета вещей большое количество данных может размещаться в хранилище данных, которое охватывает множество продуктов, устройств, организаций и клиентов. Важно заранее спланировать структуру каталога для организации, обеспечения безопасности и эффективной обработки данных для нисходящих потребителей. Ниже приведен общий шаблон, который стоит рассмотреть.

```console
{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/
```

Например, каталог размещения телеметрии для авиационного двигателя в Великобритании может выглядеть так:

```console
UK/Planes/BA1293/Engine1/2017/08/11/12/
```

Есть важная причина размещения даты в конце структуры папки. Если вы хотите заблокировать определенные регионы и типы данных для пользователей или групп, это можно легко сделать с помощью разрешений POSIX. В противном случае, если возникла необходимость ограничить определенную группу безопасности — предоставить возможность просматривать только данные Великобритании или определенных самолетов с датой в начале структуры папки — потребуется отдельное разрешение для нескольких папок в папке, создаваемой каждый час. Кроме того, при наличии структуры даты в начале количество папок будет экспоненциально увеличиваться с течением времени.

### <a name="batch-jobs-structure"></a>Структура пакетных заданий

На высоком уровне широко используемым подходом в пакетной обработке является размещение данных во вложенной папке. Как только данные будут обработаны, поместите новые данные во внешнюю папку для использования нисходящими процессами. Эта структура каталогов иногда наблюдается в случае заданий, требующих обработки отдельных файлов и не требующих массовой параллельной обработки больших наборов данных. Как и структура Центра Интернета вещей, рекомендованная выше, оптимальная структура каталога включает папки на родительском уровне для региона и прочего (например, организации, продукта или производителя). Эта структура помогает обеспечить безопасность данных в организации и оптимизировать управление данными в рабочих нагрузках. Кроме того, рассмотрите дату и время в структуре, чтобы обеспечить лучшую организацию, отфильтрованные поисковые запросы, безопасность и автоматизацию в процессе обработки. Уровень детализации структуры даты определяется интервалом, с которым данные загружаются или обрабатываются, например ежечасно, ежедневно или даже ежемесячно.

Иногда обработка файлов завершается сбоем из-за повреждения данных или непредвиденных форматов. В таких случаях в структуре каталога целесообразно использовать папку **/bad**, чтобы перемещать в нее файлы для дальнейшей проверки. Пакетное задание также может обрабатывать отчет или уведомление об этих *недопустимых* файлах для устранения проблем вручную. Рассмотрите следующую структуру:

```console
{Region}/{SubjectMatter(s)}/In/{yyyy}/{mm}/{dd}/{hh}/
{Region}/{SubjectMatter(s)}/Out/{yyyy}/{mm}/{dd}/{hh}/
{Region}/{SubjectMatter(s)}/Bad/{yyyy}/{mm}/{dd}/{hh}/
```

Например, маркетинговая фирма ежедневно получает извлечения данных клиентских обновлений от своих клиентов в Северной Америке. Она может выглядеть, как приведенный ниже фрагмент кода, перед обработкой и после нее:

```console
NA/Extracts/ACMEPaperCo/In/2017/08/14/updates_08142017.csv
NA/Extracts/ACMEPaperCo/Out/2017/08/14/processed_updates_08142017.csv
```

В общем случае пакетных данных, обрабатываемых непосредственно в таких базах данных, как Hive или традиционных базах данных SQL, нет необходимости в папке **/in** или **/out**, так как результаты уже выводятся в отдельную папку для таблицы Hive или внешней базы данных. Например, ежедневные извлечения данных от клиентов будут размещаться в их соответствующих папках, а при управлении с помощью фабрики данных Azure, Apache Oozie или Apache Airflow будет ежедневно выполняться задание Hive или Spark для обработки и записи данных в таблицу Hive.

## <a name="next-steps"></a>Дальнейшие действия

* [Общие сведения об Azure Data Lake Storage Gen1](data-lake-store-overview.md)
* [Контроль доступа в Azure Data Lake Storage 1-го поколения](data-lake-store-access-control.md)
* [Безопасность в Azure Data Lake Storage 1-го поколения](data-lake-store-security-overview.md)
* [Настройка Azure Data Lake Storage 1-го поколения для повышения производительности](data-lake-store-performance-tuning-guidance.md)
* [Рекомендации по настройке производительности для Spark в HDInsight и Azure Data Lake Storage 1-го поколения](data-lake-store-performance-tuning-spark.md)
* [Рекомендации по настройке производительности для Hive в HDInsight и Azure Data Lake Storage 1-го поколения](data-lake-store-performance-tuning-hive.md)
* [Создание кластеров HDInsight, использующих Data Lake Storage 1-го поколения](data-lake-store-hdinsight-hadoop-use-portal.md)
