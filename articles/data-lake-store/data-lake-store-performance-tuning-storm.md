---
title: Настройка производительности — комплекс с Azure Data Lake Storage 1-го поколения
description: Изучите факторы, которые следует учитывать при настройке производительности топологии в Azure, включая устранение распространенных проблем.
author: twooley
ms.service: data-lake-store
ms.topic: how-to
ms.date: 12/19/2016
ms.author: twooley
ms.openlocfilehash: 95619c75d332ec1bf68af97fc3dddbc67b6706ed
ms.sourcegitcommit: a4533b9d3d4cd6bb6faf92dd91c2c3e1f98ab86a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/22/2020
ms.locfileid: "97725043"
---
# <a name="performance-tuning-guidance-for-storm-on-hdinsight-and-azure-data-lake-storage-gen1"></a>Рекомендации по настройке производительности для Storm в HDInsight и Azure Data Lake Storage 1-го поколения

Изучите факторы, которые важны для настройки производительности в топологии Azure Storm. Например, нужно понимать характеристики работы, выполняемой элементами spout и bolt (в случае, когда работа связана с интенсивными рабочими нагрузками ввода-вывода или активным использованием памяти). В этой статье рассматривается ряд рекомендаций по улучшению производительности, в том числе по устранению типичных неполадок.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**. См. страницу [бесплатной пробной версии Azure](https://azure.microsoft.com/pricing/free-trial/).
* **Учетная запись Azure Data Lake Storage 1-го поколения**. За инструкциями по созданию учетной записи обращайтесь к статье [Начало работы с Azure Data Lake Storage 1-го поколения](data-lake-store-get-started-portal.md).
* **Кластер Azure HDInsight** с доступом к учетной записи Data Lake Storage 1-го поколения. Дополнительные сведения см. в статье [Создание кластеров HDInsight, использующих Data Lake Store, с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md). Убедитесь, что вы включили удаленный рабочий стол для кластера.
* **Запущенный кластер Storm в Data Lake Storage 1-го поколения**. Дополнительные сведения см. в разделе о чем больше [в HDInsight](../hdinsight/storm/apache-storm-overview.md).
* **Рекомендации по настройке производительности для Data Lake Storage 1-го поколения**.  Общие вопросы производительности описаны в [рекомендациях по настройке производительности Data Lake Storage 1-го поколения](./data-lake-store-performance-tuning-guidance.md).  

## <a name="tune-the-parallelism-of-the-topology"></a>Настройка параллелизма топологии

Возможно, повысить производительность поможет увеличение степени параллелизма операций ввода-вывода для Data Lake Storage 1-го поколения. Топология Storm имеет набор конфигураций, которые определяют параллелизм:
* Количество рабочих процессов. Рабочие роли равномерно распределяются между виртуальными машинами.
* Количество экземпляров исполнителей spout.
* Количество экземпляров исполнителей bolt.
* Количество задач spout.
* Количество задач bolt.

Предположим, что в кластере с 4 виртуальными машинами и 4 рабочими процессами работают 32 исполнителя и 32 задачи для элемента spout, а также 256 исполнителей и 512 задач для элемента bolt. Для этой ситуации справедливо следующее.

Каждый супервизор, то есть рабочий узел, имеет один рабочий процесс виртуальной машины Java (JVM). Этот процесс JVM управляет 4-мя потоками spout и 64-ю потоками bolt. Внутри каждого потока задачи выполняются последовательно. В приведенной выше конфигурации каждый поток spout имеет одну задачу, и каждый поток молнии имеет две задачи.

Ниже приведены компоненты Storm, участвующие в процессе, и их влияние на итоговый уровень параллелизма.
* Головной узел (называемый в Storm Nimbus) используется для отправки заданий и управления ими. Эти узлы не оказывают влияния на степень параллелизма.
* Узлы супервизора. Этот объект HDInsight соответствует рабочему узлу на виртуальной машине Azure.
* Рабочие задачи — это процессы Storm, выполняемые на виртуальных машинах. Каждая рабочая задача соответствует экземпляру виртуальной машины Java. Storm распределяет указанное число рабочих процессов между рабочими узлами максимально равномерно.
* Количество экземпляров исполнителей spout и bolt. Каждый экземпляр исполнителя соответствует потоку, который выполняется в рабочих процессах (на виртуальных машинах Java).
* Задачи Storm. Это логические задачи, которые выполняет каждый из потоков. Это не меняет уровень параллелизма, поэтому следует оценить, нужны ли вам несколько задач на каждый исполнитель.

### <a name="get-the-best-performance-from-data-lake-storage-gen1"></a>Достижение максимальной производительности Data Lake Storage 1-го поколения

Чтобы достичь оптимальной производительности при работе с Data Lake Storage 1-го поколения, следует сделать следующее.
* Объедините маленькие добавления в пакеты большего размера (в идеале размером по 4 МБ).
* Выполняйте максимально возможное количество одновременных запросов. Так как каждый поток элементов bolt выполняет чтение с блокировкой, желательно выполнять от 8 до 12 потоков на каждое ядро. Это позволит сохранить хорошую нагрузку на сетевой адаптер и ЦП. Крупная виртуальная машина позволяет выполнять большее число параллельных запросов.  

### <a name="example-topology"></a>Пример топологии

Предположим, что у вас есть восемь кластеров рабочих узлов с виртуальной машиной D13v2 Azure. Эта виртуальная машина имеет восемь ядер, так что между восемью рабочими узлами у вас есть 64 общих ядер.

Предположим, что у нас есть восемь молний на ядро. Так как у нас есть 64 ядра, мы получаем 512 экземпляров исполнителей элемента bolt (т. е. потоков). Например, мы начинаем с одной виртуальной машины Java на каждую виртуальную машину, а для достижения параллелизма используем в основном параллелизм потоков внутри виртуальной машины Java. Это означает, что нам требуется восемь рабочих задач (по одной на каждую виртуальную машину Azure) и 512-исполнители. Учитывая эту конфигурацию, оно пытается равномерно распределить рабочие процессы между рабочими узлами (также известными как узлы супервизора), предоставляя каждому рабочему узлу один ВИРТУАЛЬНОЙ машины Java. Теперь в пределах руководителей все пытается распределить исполнители между администраторами, каждый из которых (т. е. ВИРТУАЛЬНОЙ машины Java) будет иметь восемь потоков.

## <a name="tune-additional-parameters"></a>Настройка дополнительных параметров
Когда будет готова базовая топология, можно обдумать настройку следующих параметров.
* **Число виртуальных машин Java на рабочий узел.** Если вы размещаете в памяти структуру данных большого объема (например, таблицу подстановки), потребуется отдельный экземпляр этой структуры для каждой виртуальной машины Java. Кроме того, можно распределить структуру данных на несколько потоков, если число виртуальных машин Java сравнительно невелико. Количество виртуальных машин Java не так сильно влияет на производительность операций ввода-вывода элементов bolt, как число потоков на этих машинах. Мы рекомендуем использовать простое правило: выделять одну виртуальную машину Java для каждой рабочей роли. Это количество можно изменять в зависимости от того, какие функции выполняет объект bolt, и какая нужна обработка в приложении.
* **Количество экземпляров исполнителей spout.** В примере выше элементы bolt используются для записи в Data Lake Storage 1-го поколения, поэтому количество элементов spout не влияет непосредственным образом на производительность элементов bolt. В зависимости от объема обработки или операций ввода-вывода в элементе spout, для повышения производительности можно попробовать изменить количество spout. Убедитесь, что у вас есть достаточно элементов spout, чтобы загрузить все элементы bolt. Скорость вывода элементов spout должна соответствовать пропускной способности элементов bolt. Итоговая конфигурация зависит от работы spout.
* **Число задач.** Каждый элемент bolt выполняется как один поток. Увеличение количества задач для каждого элемента bolt не повышает уровень параллелизма. Они могут обеспечить преимущество только в том случае, если на процесс подтверждения кортежа затрачивается большая часть времени выполнения элемента bolt. Рекомендуется сгруппировать множество кортежей к более крупному добавлению перед отправкой подтверждения от молнии. Поэтому в большинстве случаев увеличение количества задач не дает дополнительных преимуществ.
* **Локальное группирование или группирование в случайном порядке.** Если включить этот параметр, все кортежи отправляются в bolt в одном рабочем процессе. Это уменьшает межпроцессное взаимодействие и количество сетевых вызовов. Мы рекомендуем использовать этот параметр для большинства топологий.

Такой вариант хорошо подойдет в качестве базового. Проверьте его производительность на конкретных данных и измените описанные выше параметры так, чтобы оптимизировать эту производительность.

## <a name="tune-the-spout"></a>Настройка spout

Можно изменить следующие параметры для настройки spout.

- **Время ожидания кортежа: topology.message.timeout.secs**. Этот параметр определяет время, необходимое для завершения сообщения и получения подтверждения, прежде чем оно будет считаться неудачным.

- **Максимальный объем памяти для каждого рабочего процесса: worker.childopts**. Этот параметр позволяет указать дополнительные параметры командной строки для рабочих ролей Java. Наиболее часто используемый здесь параметр — XmX, который определяет максимальный объем памяти, выделенный для кучи виртуальных машин Java.

- **Максимальное количество ожидающих spout: topology.max.spout.pending**. Этот параметр определяет максимально допустимое число активных (не подтвержденных на всех узлах в топологии) кортежей для каждого потока spout в любой момент времени.

  Мы рекомендуем оценить размер каждого кортежа. и разобраться, сколько памяти выделяется для потока spout. Общий выделенный для потока объем памяти, разделенный на это значение, обозначит верхнюю границу для максимального количества ожидающих spout.

## <a name="tune-the-bolt"></a>Настройка bolt
При записи в Data Lake Storage 1-го поколения установите для политики размера синхронизации (буфер на стороне клиента) значение 4 МБ. Очистка или операция HSYNC () выполняется только в том случае, если размер буфера равен этому значению. Драйвер Data Lake Storage 1-го поколения на виртуальных машинах рабочих ролей автоматически выполняет эту буферизацию, если пользователь не выполняет операцию hsync() явным образом.

По умолчанию в Data Lake Storage 1-го поколения для объекта bolt Storm определен параметр политики размера синхронизации (fileBufferSize), который можно использовать для настройки этого параметра.

В топологиях с интенсивным выполнением операций ввода-вывода желательно настроить запись в отдельный файл для каждого потока bolt и установить политику ротации файлов (fileRotationSize). Когда файл достигает определенного размера, поток автоматически очищается и выполняется запись в новый файл. Рекомендуемый размер файла для ротации составляет 1 ГБ.

### <a name="handle-tuple-data"></a>Обработка данных кортежа

В Storm элемент spout удерживает кортеж, пока не получит явное подтверждение от элемента bolt. Если bolt уже прочитал кортеж, но не подтвердил его, для spout не гарантируется сохранение данных в серверной части Data Lake Storage 1-го поколения. После подтверждения кортежа элемент bolt гарантированно сохраняет данные, поэтому элемент spout может удалить исходные данные, независимо от того, откуда он их считывает.  

Для обеспечения максимальной производительности Data Lake Storage 1-го поколения настройте в bolt буфер для данных кортежа размером 4 МБ. Затем выполните запись в Data Lake Storage 1-го поколения серверной части как 1 4 МБ записи. После успешной записи данных в хранилище (путем вызова hflush()) элемент bolt может отправить элементу spout подтверждение обработки данных. Это выполняет приведенный здесь пример элемента bolt. Вполне допустимо удерживать большее количество кортежей до вызова hflush() и подтверждения кортежей. Однако это увеличивает число активных кортежей, которые должен удерживать элемент spout. Таким образом увеличивается объем памяти, необходимый для каждой виртуальной машины Java.

> [!NOTE]
> Иногда приложения обязаны подтверждать кортежи чаще (при размере данных меньше 4 МБ) по причинам, не связанным с производительностью. Это может негативно повлиять на пропускную способность ввода-вывода для сервера хранилища. Тщательно взвесьте такие последствия в сравнении с производительностью операций ввода-вывода для bolt.

Если скорости поступления кортежей недостаточно и буфер на 4 МБ заполняется долго, это можно исправить следующими способами.
* Уменьшите количество элементов bolt, чтобы заполнять меньше буферов.
* Создайте политику на основе времени или на основе количества, которая будет запускать операцию hflush() после каждых x операций сброса данных или через каждые y миллисекунд, а затем подтверждать накопленные кортежи.

Пропускная способность в этом случае меньше, но при низкой скорости событий максимальная пропускная способность в любом случае не является крупнейшим показателем. Эти меры помогут снизить общее время передачи кортежа в хранилище. Это будет полезно, если конвейер должен работать в режиме реального времени даже при низкой частоте событий. Обратите внимание, что при низкой скорости входящего кортежа следует настроить параметр topology.message.timeout_secs таким образом, чтобы не истекал срок ожидания кортежа, пока он буферизуется или обрабатывается.

## <a name="monitor-your-topology-in-storm"></a>Мониторинг топологии в Storm  
Выполнение топологии можно отслеживать в пользовательском интерфейсе Storm. Вот основные параметры, на которые следует обращать внимание.

* **Общая задержка выполнения процесса.** Это среднее время, за которое один кортеж создается элементом spout, обрабатывается элементом bolt и подтверждается.

* **Общая задержка процесса bolt.** Это среднее время, потраченное кортежом на молнию до получения подтверждения.

* **Общая задержка выполнения bolt.** Это среднее время, затраченное элементом bolt на выполнение метода execute.

* **Количество сбоев.** Это число кортежей, которые не удалось полностью обработать прежде, чем истекло время их ожидания.

* **Ресурсов.** Это мера занятости вашей системы. Если это значение равно 1, элементы bolt работают с максимально возможной скоростью. Если это значение меньше 1, необходимо увеличить параллелизм. Если значение больше 1, уменьшите параллелизм.

## <a name="troubleshoot-common-problems"></a>Устранение распространенных неполадок
Здесь описано несколько типичных сценариев устранения неполадок.
* **Время ожидания многих кортежей истекло.** Взгляните на каждый узел в топологии, чтобы определить, где находится узкое место. Чаще всего такая проблема связана с тем, что производительность элементов bolt ниже, чем у элементов spout. Это приводит к тому, что ожидающие обработки кортежи переполняют внутренние буферы. Попробуйте увеличить время ожидания или уменьшить максимальное количество ожидающих spout.

* **Высокая общая задержка выполнения процесса, но при этом низкая задержка процесса bolt.** В этом случае, возможно, кортежи не были подтверждены достаточно быстро. Убедитесь, что имеется достаточное количество подтверждающих. Второй вариант — кортежи ожидают в очереди слишком долго, прежде чем элементы bolt начинают их обрабатывать. Уменьшите максимальное время ожидания элемента spout.

* **Высокая задержка выполнения bolt.** Это означает, что метод execute() элемента bolt выполняется слишком долго. Оптимизируйте код или изучите настройки размеров и процессов для записи.

### <a name="data-lake-storage-gen1-throttling"></a>Регулирование Data Lake Storage 1-го поколения
Если вы достигнете пределов пропускной способности, предоставленной Data Lake Storage 1-го поколения, вы увидите сбои задач. Проверьте журналы задач на наличие ошибок регулирования. Вы можете уменьшить параллелизм, увеличив размер контейнера.    

Чтобы проверить, применяется ли для вас регулирование, включите ведение журнала отладки на стороне клиента.

1. В   >    >  **файле config** Ambari  >  **с расширенным набором данных-Worker-log4j** измените значение **&lt; корневого &gt; уровня = "info"** на **&lt; root &gt; Level = "Отладка"**. Перезапустите все узлы и службы, чтобы изменения конфигурации вступили в силу.
2. Отслеживайте журналы топологии на рабочих узлах Storm (в разделе /var/log/storm/worker-artifacts/&lt;TopologyName&gt;/&lt;port&gt;/worker.log) на предмет наличия исключений регулирования Data Lake Storage 1-го поколения.

## <a name="next-steps"></a>Дальнейшие действия
В [этом блоге](/archive/blogs/shanyu/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs)можно ссылаться на дополнительную настройку производительности для работы с ними.

Дополнительный пример для запуска есть [в этом разделе GitHub](https://github.com/hdinsight/storm-performance-automation).