---
title: Оптимизация Azure Data Lake Storage 2-го поколения для повышения производительности | Документация Майкрософт
description: Узнайте, как оптимизировать Azure Data Lake Storage 2-го поколения для повышения производительности. Прием данных, структурирование набора данных и многое другое.
author: normesta
ms.subservice: data-lake-storage-gen2
ms.service: storage
ms.topic: how-to
ms.date: 11/18/2019
ms.author: normesta
ms.reviewer: stewu
ms.openlocfilehash: f0f64d910d03e42008c5fe6fef28a5b9c0917abd
ms.sourcegitcommit: 772eb9c6684dd4864e0ba507945a83e48b8c16f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "97814471"
---
# <a name="optimize-azure-data-lake-storage-gen2-for-performance"></a>Оптимизация Azure Data Lake Storage 2-го поколения для повышения производительности

Azure Data Lake Storage 2-го поколения поддерживает высокую пропускную способность при анализе с интенсивным использованием ввода-вывода и перемещением данных.  В Data Lake Storage 2-го поколения важно использовать всю доступную пропускную способность (объем данных, которые можно читать или записывать в секунду), чтобы обеспечить высокую производительность.  Для этого нужно выполнить как можно больше операций чтения и записи параллельно.

![Производительность Data Lake Storage 2-го поколения](./media/data-lake-storage-performance-tuning-guidance/throughput.png)

Data Lake Storage 2-го поколения можно масштабировать, чтобы обеспечить необходимую пропускную способность для всех сценариев аналитики. По умолчанию учетная запись Data Lake Storage 2-го поколения обеспечивает достаточную пропускную способность в конфигурации по умолчанию в соответствии с потребностями широкого спектра вариантов использования. В случаях, когда клиенты достигают лимита по умолчанию, учетную запись Data Lake Storage 2-го поколения можно настроить для предоставления большей пропускной способности, связавшись с [поддержкой Azure](https://azure.microsoft.com/support/faq/).

## <a name="data-ingestion"></a>Прием данных

При приеме данных из исходной системы в Data Lake Storage 2-го поколения важно учитывать, что исходное оборудование, исходное сетевое оборудование или сетевое подключение к Data Lake Storage 2-го поколения может быть узким местом.  

![Схема, на которой показаны факторы, которые следует учитывать при приеме данных из исходной системы в Data Lake Storage 2-го поколения.](./media/data-lake-storage-performance-tuning-guidance/bottleneck.png)

Очень важно убедиться, что перемещение данных не зависит от следующих факторов.

### <a name="source-hardware"></a>Исходное оборудование

При использовании локальных компьютеров или виртуальных машин в Azure следует тщательно выбирать соответствующее оборудование. В качестве исходного дискового оборудования следует использовать SSD, а не жесткие диски, поэтому выбирайте дисковое оборудование с быстро работающими шпинделями. В качестве исходного сетевого оборудования используйте самые быстрые сетевые адаптеры.  В Azure мы советуем виртуальные машины Azure D14 с соответствующим мощным диском и сетевым оборудованием.

### <a name="network-connectivity-to-data-lake-storage-gen2"></a>Сетевое подключение к Data Lake Storage 2-го поколения

Сетевое подключение между исходными данными и Data Lake Storage 2-го поколения иногда может быть узким местом. Если исходные данные находятся в локальной среде, рассмотрите возможность использования выделенной ссылки с помощью [Azure ExpressRoute](https://azure.microsoft.com/services/expressroute/). Если исходные данные находятся в Azure, вы сможете обеспечить лучшую производительность, если разместите данные в том же регионе Azure, что и учетную запись Data Lake Storage 2-го поколения.

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a>Настройка средств приема данных для обеспечения максимальной параллелизации

Решив проблему с узкими местами исходного оборудования и сетевого подключения, можно приступить к настройке средств приема. В следующей таблице перечислены ключевые параметры нескольких популярных средств приема и предоставлены подробные статьи по настройке производительности для них.  Дополнительные сведения о выборе подходящего средства для вашего сценария см. в [этой статье](data-lake-storage-data-scenarios.md).

| Инструмент               | Параметры | Дополнительные сведения                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| DistCp            | -m (mapper)   | [Ссылка](data-lake-storage-use-distcp.md#performance-considerations-while-using-distcp)                             |
| Фабрика данных Azure| parallelCopies    | [Ссылка](../../data-factory/copy-activity-performance.md)                          |
| Sqoop           | fs.azure.block.size, -m (mapper)    |   [Ссылка](/archive/blogs/shanyu/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs)        |

## <a name="structure-your-data-set"></a>Структура набора данных

При хранении данных в Data Lake Storage 2-го поколения размер файла, число файлов и структура папок влияют на производительность.  В следующем разделе описаны рекомендации в этих областях.  

### <a name="file-size"></a>Размер файла

Как правило, у модулей аналитики, таких как HDInsight и Azure Data Lake Analytics, нагрузка зависит от количества файлов. Если вы храните данные в большом количестве небольших файлов, это может отрицательно сказаться на производительности. Упорядочивайте свои данные в файлы большего размера для лучшей производительности (от 256 МБ до 100 ГБ). В некоторых подсистемах и приложениях могут возникнуть проблемы с эффективной обработкой файлов размером более 100 ГБ.

В некоторых случаях конвейеры данных имеют ограниченный контроль над необработанными данными, которые содержат множество небольших файлов. Как правило, рекомендуется, чтобы система имела некоторый процесс объединения мелких файлов в более крупные приложения для использования в подчиненных приложениях.

### <a name="organizing-time-series-data-in-folders"></a>Упорядочение данных временных рядов в папки

Для рабочих нагрузок Hive удаление секций данных временных рядов может помочь некоторым запросам считывать только подмножество данных, что улучшает производительность.    

Конвейеры, принимающие данные временных рядов, часто помещают свои файлы с сильно структурированными именами файлов и папок. Ниже приведен обычный пример для данных, структурированных по дате:

*\Датасет\ииии\мм\дд\ datafile_YYYY_MM_DD. TSV*

Обратите внимание, что данные времени и даты отображаются и как папки, и в имени файла.

Ниже приведен распространенный шаблон для даты и времени:

*\Датасет\ииии\мм\дд\хх\мм\ datafile_YYYY_MM_DD_HH_mm. TSV*

Выбор, который вы делаете с помощью упорядочения папки и файлов, должен быть оптимизирован для больших размеров файлов и разумного количества файлов в каждой папке.

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a>Оптимизация заданий с интенсивными вычислениями ввода-вывода для рабочих нагрузок Hadoop и Spark в HDInsight

Задания можно отнести к одной из трех категорий:

* **Интенсивно использующие ЦП.**  Эти задания имеют долгое время вычисления с минимальным временем ввода-вывода.  Примеры включают машинное обучение и задания обработки естественных языков.  
* **Интенсивное выполнение памяти.**  Эти задания используют большой объем памяти.  Примеры включают PageRank и задания аналитики в реальном времени.  
* **С большим количеством операций ввода-вывода.**  Эти задания большую часть своего времени выполняют операции ввода-вывода.  Распространенным примером является задание копирования, которое использует только операции чтения и записи.  Другие примеры включают задания подготовки данных, которые считывают большое количество данных, выполняют некоторую трансформацию данных, а затем записывают данные обратно в хранилище.  

Следующее руководство применяется только к заданиям с большим объемом операций ввода-вывода.

## <a name="general-considerations"></a>Общие рекомендации

У вас может быть задание, которое считывает или записывает до 100 МБ за одну операцию, но буфер такого размера может снизить производительность.
Для оптимизации производительности попытайтесь сохранить размер операции ввода-вывода в пределах 4–16 МБ.

### <a name="general-considerations-for-an-hdinsight-cluster"></a>Общие рекомендации, связанные с кластером HDInsight

* **Версии HDInsight.** Для повышения производительности используйте последний выпуск HDInsight.
* **Регионах.** Разместите учетную запись Data Lake Storage 2-го поколения в том же регионе, что и кластер HDInsight.  

Кластер HDInsight An состоит из двух головных узлов и нескольких рабочих узлов. Каждый рабочий узел предоставляет определенное количество ядер и памяти, которые определяют тип виртуальной машины.  При выполнении задания YARN выступает в качестве согласователя ресурсов, который выделяет доступную память и ядра для создания контейнеров.  Каждый контейнер выполняет задачи, которые необходимы для выполнения задания.  Контейнеры выполняются параллельно для быстрой обработки задачи. Таким образом производительность повышается за счет выполнения максимально возможного количества контейнеров параллельно.

В пределах кластера HDInsight имеется три уровня, которые можно настроить, чтобы увеличить число контейнеров и использовать всю доступную пропускную способность.  

* **Физический уровень**
* **Слой YARN**
* **Уровень рабочей нагрузки**

### <a name="physical-layer"></a>Физический уровень

**Запустите кластер с большим количеством узлов и/или на виртуальной машине большего размера.**  Больший кластер позволит вам выполнять дополнительные контейнеры YARN, как это показано на рисунке ниже.

![Схема, показывающая, как кластер большего размера позволяет запускать больше контейнеров YARN.](./media/data-lake-storage-performance-tuning-guidance/VM.png)

**Используйте виртуальные машины с большей пропускной способностью сети.**  Пропускная способность сети может быть узким местом, если она меньше, чем пропускная способность Data Lake Storage 2-го поколения.  У различных виртуальных машин будет разная пропускная способность сети.  Выберите тип виртуальной машины с самой большой пропускной способностью сети.

### <a name="yarn-layer"></a>Уровень YARN

**Используйте контейнеры YARN меньшего размера.**  Уменьшите размер каждого контейнера YARN, чтобы создать больше контейнеров с тем же объемом ресурсов.

![Схема, показывающая результат при уменьшении размера каждого контейнера YARN для создания большего числа контейнеров.](./media/data-lake-storage-performance-tuning-guidance/small-containers.png)

В зависимости от рабочей нагрузки минимальный необходимый размер контейнера YARN будет иметься всегда. Если выбрать слишком маленький контейнер, у заданий будут возникать проблемы из-за нехватки памяти. Как правило, контейнеры YARN должны быть размером не менее 1 ГБ. Обычно можно увидеть контейнеры YARN размером 3 ГБ. Для некоторых рабочих нагрузок могут потребоваться контейнеры YARN большего размера.  

**Увеличьте количество ядер на контейнер YARN.**  Увеличьте количество ядер, выделенных для каждого контейнера, чтобы увеличить число параллельных задач, которые выполняются в каждом контейнере.  Это работает для приложений, которые выполняют несколько задач на контейнер, например Spark.  Для приложений, например Hive, которые выполняют один поток в каждом контейнере, лучше иметь несколько контейнеров, а не больше ядер на контейнер.

### <a name="workload-layer"></a>Уровень рабочей нагрузки

**Используйте все доступные контейнеры.**  Задайте число задач равное или большее количества доступных контейнеров, чтобы использовать все ресурсы.

![Схема, на которой показано использование всех контейнеров.](./media/data-lake-storage-performance-tuning-guidance/use-containers.png)

**Незавершенные задачи ресурсоемки.** Если у каждой задачи есть большой объем данных для обработки, неудачное выполнение задачи приводит к дорогостоящей повторной попытке.  Поэтому лучше создавать дополнительные задачи, каждая из которых обрабатывает небольшой объем данных.

Помимо общих рекомендаций, приведенных выше, каждое приложение имеет различные параметры, которые можно настроить для каждого конкретного приложения. В следующей таблице перечислены некоторые параметры и ссылки для начала работы с настройкой производительности для каждого приложения.

| Рабочая нагрузка | Параметры для настройки задач |
|----------|------------------------|
| [Spark в HDInsight](data-lake-storage-performance-tuning-spark.md) | <ul><li>Num-executors</li><li>Executor-memory</li><li>Executor-cores</li></ul> |
| [Hive в HDInsight](data-lake-storage-performance-tuning-hive.md) | <ul><li>hive.tez.container.size</li></ul> |
| [MapReduce в HDInsight](data-lake-storage-performance-tuning-mapreduce.md) | <ul><li>Mapreduce.map.memory</li><li>Mapreduce.job.maps</li><li>Mapreduce.reduce.memory</li><li>Mapreduce.job.reduces</li></ul> |
| [Storm в HDInsight](data-lake-storage-performance-tuning-storm.md)| <ul><li>Количество рабочих процессов</li><li>Количество экземпляров исполнителей воронки</li><li>Количество экземпляров исполнителей сита </li><li>Количество задач воронки</li><li>Количество задач сита</li></ul>|

## <a name="see-also"></a>См. также раздел
* [Общие сведения об Azure Data Lake Storage 2-го поколения](data-lake-storage-introduction.md)
