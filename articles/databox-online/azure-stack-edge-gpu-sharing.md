---
title: Совместное использование GPU на устройстве GPU Pro на Azure Stack
description: Описывает подходы к совместному использованию графических процессоров на устройстве с Azure Stack ребра Pro GPU.
services: databox
author: alkohli
ms.service: databox
ms.subservice: edge
ms.topic: how-to
ms.date: 03/05/2021
ms.author: alkohli
ms.openlocfilehash: 6683e39cfa3601b1ae1fbbe02e69e4dc0a54e8e7
ms.sourcegitcommit: 772eb9c6684dd4864e0ba507945a83e48b8c16f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/20/2021
ms.locfileid: "103565276"
---
# <a name="gpu-sharing-on-your-azure-stack-edge-pro-gpu-device"></a>Совместное использование GPU на устройстве с Azure Stack ребра Pro GPU

Графический процессор (GPU) — это специализированный обработчик, предназначенный для ускорения отрисовки графики. GPU может одновременно обрабатывать много фрагментов данных, что делает их полезными для машинного обучения, редактирования видео и игровых приложений. Помимо ЦП для вычислений общего назначения, устройства GPU Azure Stack пограничных устройств с графическим процессором могут содержать один или два графических процессора NVIDIA Tesla T4 для рабочих нагрузок с большим объемом вычислений, таких как аппаратное ускорение. Дополнительные сведения см. в разделе [GPU Tesla T4 NVIDIA](https://www.nvidia.com/data-center/tesla-t4/).


## <a name="about-gpu-sharing"></a>Сведения о совместном использовании GPU

Для многих машинного обучения или других вычислений может не потребоваться выделенный графический процессор. Графические процессоры могут совместно использовать графические процессоры и обмениваться ими между контейнерными или рабочими нагрузками виртуальных машин, что позволяет увеличить использование GPU без существенного влияния на производительность GPU.  

## <a name="using-gpu-with-vms"></a>Использование GPU с виртуальными машинами

На устройстве Azure Stack пограничной Pro общий доступ к GPU не может быть предоставлен при развертывании рабочих нагрузок виртуальных машин. GPU можно сопоставить только с одной виртуальной машиной. Это означает, что на устройстве может быть только одна виртуальная машина GPU с одним GPU и двумя виртуальными машинами на устройстве, оснащенном двумя GPU. При использовании виртуальных машин GPU на устройстве с Kubernetes, настроенным для контейнерных рабочих нагрузок, необходимо учитывать и другие факторы. Дополнительные сведения см. в статье о [виртуальных машинах GPU и Kubernetes](azure-stack-edge-gpu-deploy-gpu-virtual-machine.md#gpu-vms-and-kubernetes).


## <a name="using-gpu-with-containers"></a>Использование GPU с контейнерами

При развертывании контейнерных рабочих нагрузок можно совместно использовать GPU на уровне оборудования и программного обеспечения несколькими способами. С помощью GPU Tesla T4 на устройстве Azure Stack ребра Pro мы ограничены совместным использованием программного обеспечения. На устройстве используются следующие два подхода к совместному использованию программного обеспечения GPU: 

- Первый подход включает использование переменных среды для указания количества графических процессоров, которые могут быть общими для времени. При использовании такого подхода учитывайте следующие предостережения.

    - С помощью этого метода можно указать один или оба GPU. Невозможно указать дробное использование.
    - Несколько модулей могут сопоставляться с одним GPU, но один и тот же модуль не может быть сопоставлен более чем с одним GPU.
    - С помощью выхода NVIDIA SMI можно увидеть общую загрузку GPU, включая использование памяти.
    
    Дополнительные сведения см. в статье [Развертывание модуля IOT EDGE, использующего GPU](azure-stack-edge-gpu-configure-gpu-modules.md) на устройстве.

- Второй подход требует включения многопроцессной службы на GPU NVIDIA. MPS — это служба времени выполнения, которая позволяет нескольким процессам, использующим CUDA, выполняться параллельно на одном общем GPU. MPS позволяет перекрывать операции ядра и мемкопи из разных процессов GPU для достижения максимальной нагрузки. Дополнительные сведения см. в разделе [Многопроцессная служба](https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf).

    При использовании такого подхода учитывайте следующие предостережения.
    
    - MPS позволяет указать дополнительные флаги в развертывании GPU.
    - Можно указать использование доли с помощью MPS, таким образом ограничивая использование каждого приложения, развернутого на устройстве. Можно указать процент использования GPU для каждого приложения в `env` разделе, `deployment.yaml` добавив следующий параметр: 

    ```yml
    // Example: application wants to limit gpu percentage to 20%
    
        env:
              - name: CUDA_MPS_ACTIVE_THREAD_PERCENTAGE 
                value: "20"    
    ```

## <a name="gpu-utilization"></a>Использование GPU
 
При совместном использовании графического процессора на контейнерных рабочих нагрузках, развернутых на устройстве, можно использовать интерфейс управления системами NVIDIA (NVIDIA-SMI). NVIDIA-SMI — это служебная программа командной строки, которая помогает управлять устройствами NVIDIA GPU и осуществлять их мониторинг. Дополнительные сведения см. в разделе [интерфейс управления системами NVIDIA](https://developer.nvidia.com/nvidia-system-management-interface).

Чтобы просмотреть сведения об использовании GPU, сначала подключитесь к интерфейсу PowerShell устройства. Выполните `Get-HcsNvidiaSmi` команду и просмотрите выходные данные NVIDIA SMI. Вы также можете просмотреть изменения в использовании GPU, включив MPS, а затем развернув несколько рабочих нагрузок на устройстве. Дополнительные сведения см. в разделе [Включение многопроцессной службы](azure-stack-edge-gpu-connect-powershell-interface.md#enable-multi-process-service-mps).


## <a name="next-steps"></a>Следующие шаги

- [Совместное использование GPU для развертываний Kubernetes на Azure Stack крае Pro](azure-stack-edge-gpu-deploy-kubernetes-gpu-sharing.md).
- [Совместное использование GPU для развертываний IOT на Azure Stack крае Pro](azure-stack-edge-gpu-deploy-iot-edge-gpu-sharing.md).
