---
title: Руководство. Выполнение скриптов Python с помощью Фабрики данных
description: Сведения о том, как выполнять скрипты Python в составе конвейера с помощью Фабрики данных Azure и пакетной службы Azure.
author: pkshultz
ms.devlang: python
ms.topic: tutorial
ms.date: 03/12/2021
ms.author: peshultz
ms.custom: mvc, devx-track-python
ms.openlocfilehash: 241a47ccf9021c6065fea907b4d9914744a64972
ms.sourcegitcommit: afb9e9d0b0c7e37166b9d1de6b71cd0e2fb9abf5
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/14/2021
ms.locfileid: "103461697"
---
# <a name="tutorial-run-python-scripts-through-azure-data-factory-using-azure-batch"></a>Руководство по Выполнение скриптов Python с помощью Фабрики данных Azure в пакетной службе Azure

В этом руководстве описано следующее:

> [!div class="checklist"]
> * Проверка подлинности с помощью учетных записей хранения и пакетной службы.
> * Разработка и запуск скрипта на языке Python
> * Создание пула вычислительных узлов для запуска приложения.
> * Планирование рабочих нагрузок Python
> * Мониторинг конвейера аналитики
> * Доступ к файлам журналов

Приведенный ниже пример выполняет скрипт Python, который получает входные данные в формате CSV из контейнера хранилища BLOB-объектов, выполняет процесс обработки данных и записывает результат в отдельный контейнер хранилища BLOB-объектов.

Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись Azure](https://azure.microsoft.com/free/), прежде чем начинать работу.

## <a name="prerequisites"></a>Предварительные требования

* Установленный дистрибутив [Python](https://www.python.org/downloads/) для локального тестирования.
* Пакет `pip` [azure-storage-blob](https://pypi.org/project/azure-storage-blob/).
* [Набор данных iris.csv](https://github.com/Azure-Samples/batch-adf-pipeline-tutorial/blob/master/iris.csv)
* учетная запись пакетной службы Azure и связанная учетная запись службы хранилища Azure. Дополнительные сведения о том, как создать учетные записи пакетной службы и связать их с учетными записями хранения, см. в статье [Создание учетной записи Пакетной службы](quick-create-portal.md#create-a-batch-account).
* Учетная запись Фабрики данных Azure. В статье [Создание фабрики данных](../data-factory/quickstart-create-data-factory-portal.md#create-a-data-factory) представлены дополнительные сведения о том, как создать фабрику данных на портале Azure.
* [Batch Explorer](https://azure.github.io/BatchExplorer/).
* [Обозреватель службы хранилища Azure](https://azure.microsoft.com/features/storage-explorer/).

## <a name="sign-in-to-azure"></a>Вход в Azure

Войдите на портал Azure по адресу [https://portal.azure.com](https://portal.azure.com).

[!INCLUDE [batch-common-credentials](../../includes/batch-common-credentials.md)]

## <a name="create-a-batch-pool-using-batch-explorer"></a>Создание пула пакетной службы с помощью Batch Explorer

В этом разделе описано, как с помощью Batch Explorer создать пул пакетной службы, который будет использоваться в конвейере Фабрики данных Azure. 

1. Войдите в Batch Explorer, используя свои учетные данные Azure.
1. Выберите учетную запись пакетной службы
1. Создайте пул, выбрав **Пулы** на левой боковой панели, а затем нажав кнопку **Добавить** над формой поиска. 
    1. Выберите идентификатор и отображаемое имя. В этом примере мы используем имя `custom-activity-pool`.
    1. Установите тип масштаба **Фиксированный размер** и задайте количество выделенных узлов равное 2.
    1. В разделе **Обработка и анализ данных** выберите операционную систему **Dsvm Windows**.
    1. Выберите размер виртуальной машины `Standard_f2s_v2`.
    1. Включите задачу запуска и добавьте команду `cmd /c "pip install azure-storage-blob pandas"`. Вы можете сохранить указанное по умолчанию удостоверение пользователя **Пользователь пула**.
    1. Щелкните **ОК**.

## <a name="create-blob-containers"></a>Создание контейнеров больших двоичных объектов

Здесь вы создадите контейнеры больших двоичных объектов, в которых будут храниться ваши входные и выходные файлы для пакетного задания распознавания текста.

1. Войдите в Обозреватель службы хранилища с помощью своих учетных данных Azure.
1. Используя учетную запись хранения, связанную с вашей учетной записью Пакетной службы, создайте два контейнера больших двоичных объектов (один для входных файлов, а другой для выходных), выполнив шаги, описанные в разделе о [создании контейнера больших двоичных объектов](../vs-azure-tools-storage-explorer-blobs.md#create-a-blob-container).
    * В этом примере мы будем вызывать наш входной (`input`) и выходной (`output`) контейнеры.
1. Передайте [`iris.csv`](https://github.com/Azure-Samples/batch-adf-pipeline-tutorial/blob/master/iris.csv) во входной контейнер `input` с помощью Обозревателя службы хранилища, выполнив инструкции из раздела [Управление большими двоичными объектами в контейнере](../vs-azure-tools-storage-explorer-blobs.md#managing-blobs-in-a-blob-container).

## <a name="develop-a-script-in-python"></a>Разработка скрипта на языке Python

Следующий скрипт Python загружает набор данных `iris.csv` из контейнера `input`, выполняет процесс обработки данных и записывает результат обратно в контейнер `output`.

``` python
# Load libraries
from azure.storage.blob import BlobClient
import pandas as pd

# Define parameters
connectionString = "<storage-account-connection-string>"
containerName = "output"
outputBlobName  = "iris_setosa.csv"

# Establish connection with the blob storage account
blob = BlobClient.from_connection_string(conn_str=connectionString, container_name=containerName, blob_name=outputBlobName)

# Load iris dataset from the task node
df = pd.read_csv("iris.csv")

# Take a subset of the records
df = df[df['Species'] == "setosa"]

# Save the subset of the iris dataframe locally in task node
df.to_csv(outputBlobName, index = False)

with open(outputBlobName, "rb") as data:
    blob.upload_blob(data)
```

Сохраните этот скрипт с именем `main.py` и отправьте его в контейнер **службы хранилища Azure** `input`. Не забудьте проверить его функциональность локально, прежде чем передавать скрипт в контейнер больших двоичных объектов.

``` bash
python main.py
```

## <a name="set-up-an-azure-data-factory-pipeline"></a>Настройка конвейера Фабрики данных Azure

В этом разделе вы создадите и проверите конвейер с помощью скрипта Python.

1. Выполните процедуру "Создание фабрики данных" из [этой статьи](../data-factory/quickstart-create-data-factory-portal.md#create-a-data-factory).
1. На панели **Ресурсы фабрики** нажмите кнопку + (плюс) и выберите **Конвейер**.
1. На вкладке **Общие** задайте конвейеру имя "Выполнение Python".

    ![На вкладке "Общие" задайте конвейеру имя "Выполнение Python".](./media/run-python-batch-azure-data-factory/create-pipeline.png)

1. На панели **Действия** разверните узел **Пакетная служба**. Перетащите пользовательское действие с панели элементов **Действия** в область конструктора конвейера. Заполните поля на следующих вкладках для настраиваемого действия:
    1. На вкладке **Общие** укажите **testPipeline** в поле "Имя". ![Указание testPipeline в поле "Имя"](./media/run-python-batch-azure-data-factory/create-custom-task.png)
    1. На вкладке **Пакетная служба Azure** добавьте **учетную запись пакетной службы**, которую вы создали на предыдущих шагах и выполните **тестирование подключения**.
    ![На вкладке "Пакетная служба Azure" добавьте учетную запись пакетной службы, которую вы создали на предыдущих шагах, и протестируйте подключение.](./media/run-python-batch-azure-data-factory/integrate-pipeline-with-azure-batch.png)
    1. На вкладке **Параметры** сделайте следующее:
        1. В поле **Команда** укажите `python main.py`.
        1. В поле **Resource Linked Service** (Служба, связанная с ресурсом) выберите учетную запись хранения, которую вы создали на предыдущих шагах. Проверьте успешность создания подключения к серверу.
        1. В поле **Путь к папке** выберите имя контейнера **хранилища BLOB-объектов Azure**, который содержит нужный скрипт Python и входные данные для него. Это действие приводит к скачиванию выбранных файлов из контейнера в экземпляры узлов пула перед выполнением скрипта Python.

        ![В поле "Путь к папке" задайте имя контейнера Хранилища BLOB-объектов Azure](./media/run-python-batch-azure-data-factory/create-custom-task-py-script-command.png)

1. На панели инструментов конвейера над холстом щелкните **Проверка**, чтобы проверить параметры конвейера. Убедитесь, что проверка конвейера прошла успешно. Чтобы закрыть результаты проверки, нажмите кнопку &gt;&gt; (стрелка вправо).
1. Щелкните **Отладка**, чтобы проверить конвейер и убедиться в правильности его работы.
1. Щелкните **Опубликовать**, чтобы опубликовать этот конвейер.
1. Щелкните **Активировать**, чтобы выполнить скрипт Python в рамках пакетного процесса.

    ![Щелкните "Активировать", чтобы выполнить скрипт Python в рамках пакетного процесса](./media/run-python-batch-azure-data-factory/create-custom-task-py-success-run.png)

### <a name="monitor-the-log-files"></a>Мониторинг файлов журналов

Если при выполнении скрипта создаются предупреждения или ошибки, вы можете получить дополнительные сведения о выходных данных из `stdout.txt` и `stderr.txt`.

1. Выберите раздел **Задания** слева в окне Batch Explorer.
1. Выберите задание, созданное фабрикой данных. Если вы присвоили пулу имя `custom-activity-pool`, выберите `adfv2-custom-activity-pool`.
1. Щелкните задачу, для которой указан код завершения с ошибкой.
1. Просмотрите `stdout.txt` и `stderr.txt`, чтобы изучить и диагностировать проблему.

## <a name="clean-up-resources"></a>Очистка ресурсов

Вы не оплачиваете задания и задачи, но платите за используемые вычислительные узлы. Поэтому рекомендуется выделять пулы только при необходимости. При удалении пула удаляются все выходные данные задачи на узлах. Однако входные и выходные файлы сохраняются в учетной записи хранения. Если учетная запись пакетной службы и учетная запись хранения вам больше не нужны, можно их удалить.

## <a name="next-steps"></a>Дальнейшие действия

В этом руководстве вы узнали, как выполнять следующие задачи:

> [!div class="checklist"]
> * Проверка подлинности с помощью учетных записей хранения и пакетной службы.
> * Разработка и запуск скрипта на языке Python
> * Создание пула вычислительных узлов для запуска приложения.
> * Планирование рабочих нагрузок Python
> * Мониторинг конвейера аналитики
> * Доступ к файлам журналов

Подробное описание Фабрики данных Azure см. здесь:

> [!div class="nextstepaction"]
> [Общие сведения о Фабрике данных Azure](../data-factory/introduction.md)
