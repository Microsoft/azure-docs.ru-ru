---
title: Обнаружение аномалий в Azure Stream Analytics
description: В этой статье объясняется, как обнаруживать аномалии с помощью Azure Stream Analytics в сочетании со службой "Машинное обучение Azure".
ms.service: stream-analytics
author: jseb225
ms.author: jeanb
ms.topic: how-to
ms.date: 06/21/2019
ms.openlocfilehash: ec37ea6cbb1c1c6693aab1f6855948d32b85e95b
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/20/2021
ms.locfileid: "102441199"
---
# <a name="anomaly-detection-in-azure-stream-analytics"></a>Обнаружение аномалий в Azure Stream Analytics

Azure Stream Analytics, доступный в облаке и в Azure IoT Edge, предлагает встроенные возможности обнаружения аномалий на основе машинного обучения, которые можно использовать для мониторинга двух наиболее часто встречающихся аномалий: временной и постоянной. С помощью функций **AnomalyDetection_SpikeAndDip** и **AnomalyDetection_ChangePoint** можно выполнять обнаружение аномалий непосредственно в задании Stream Analytics.

Модели машинного обучения предполагают наличие временных рядов с равномерной выборкой. Если временные ряды неоднородны, можно вставить шаг агрегирования с "переворачивающимся" окном перед вызовом обнаружения аномалий.

В настоящее время операции машинного обучения не поддерживают сезонностиные тенденции и несколько вариате корреляций.

## <a name="anomaly-detection-using-machine-learning-in-azure-stream-analytics"></a>Обнаружение аномалий с помощью машинного обучения в Azure Stream Analytics

В следующем видео показано, как определить аномалию в режиме реального времени с помощью функций машинного обучения в Azure Stream Analytics. 

> [!VIDEO https://channel9.msdn.com/Shows/Internet-of-Things-Show/Real-Time-ML-Based-Anomaly-Detection-In-Azure-Stream-Analytics/player]

## <a name="model-behavior"></a>Поведение модели

Как правило, точность модели повышается с увеличением количества данных в скользящем окне. Данные в указанном скользящем окне обрабатываются как часть нормального диапазона значений для этого интервала времени. Модель рассматривает историю событий только через скользящее окно, чтобы проверить, является ли текущее событие аномальным. При перемещении скользящего окна старые значения удаляются из обучения модели.

Функции работают, устанавливая определенную норму, основанную на наблюдениях на этом этапе. Выбросы определяются путем сравнения с установленной нормой в пределах уровня достоверности. Размер окна должен основываться на минимальных событиях, необходимых для обучения модели нормальному поведению, чтобы при возникновении аномалии она могла его распознать.

Время отклика модели увеличивается с учетом размера журнала, так как его необходимо сравнить с большим числом прошлых событий. Рекомендуется включать только необходимое количество событий, чтобы повысить эффективность.

Разрывы во временных рядах могут произойти, потому что модель не получает события в определенные моменты времени. Эта ситуация обрабатывается Stream Analytics с помощью логики добавления отсутствующих. Размер журнала, а также продолжительность времени для одного и того же скользящего окна используются для расчета средней скорости, с которой ожидаются события.

[Доступный генератор](https://aka.ms/asaanomalygenerator) аномалий можно использовать для передачи центра Интернета вещей с данными с разными шаблонами аномалии. Задание ASA можно настроить с помощью этих функций обнаружения аномалий для чтения из этого центра Интернета вещей и обнаружения аномалий.

## <a name="spike-and-dip"></a>Пики и спады

Временные аномалии в потоке событий временных рядов называются пиками и спадами. Пики и спады можно отслеживать с помощью оператора Машинного обучения [AnomalyDetection_SpikeAndDip](/stream-analytics-query/anomalydetection-spikeanddip-azure-stream-analytics
).

![Пример аномалии пика и спада](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-spike-dip.png)

В том же скользящем окне, если второй пик меньше первого, вычисленная оценка меньшего пика, вероятно, недостаточно значительна по сравнению с оценкой первого пика в пределах указанного уровня достоверности. Можно попытаться уменьшить уровень достоверности модели, чтобы выявить такие аномалии. Однако если предупреждений становится слишком много, можно использовать более высокий интервал достоверности.

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 2-минутном скользящем окне с журналом со 120 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 95 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_SpikeAndDip(CAST(temperature AS float), 95, 120, 'spikesanddips')
            OVER(LIMIT DURATION(second, 120)) AS SpikeAndDipScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'Score') AS float) AS
    SpikeAndDipScore,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'IsAnomaly') AS bigint) AS
    IsSpikeAndDipAnomaly
INTO output
FROM AnomalyDetectionStep
```

## <a name="change-point"></a>Изменение точки

Постоянные аномалии в потоке событий временных рядов — это изменения в распределении значений в потоке событий, такие как изменения уровня и тенденции. В Stream Analytics такие аномалии обнаруживаются с помощью оператора [AnomalyDetection_ChangePoint](/stream-analytics-query/anomalydetection-changepoint-azure-stream-analytics), основанного на Машинном обучении.

Постоянные изменения длятся гораздо дольше, чем пики и спады, и могут указывать на катастрофические события. Постоянные изменения обычно не видны невооруженным глазом, но их легко обнаружить с помощью оператора **AnomalyDetection_ChangePoint**.

На следующем рисунке показан пример изменения уровня:

![Пример аномалии изменения уровня](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-level-change.png)

На следующем рисунке показан пример изменения тенденции:

![Пример аномалии изменения тенденции](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-trend-change.png)

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 20-минутном скользящем окне с журналом с 1200 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 80 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_ChangePoint(CAST(temperature AS float), 80, 1200) 
        OVER(LIMIT DURATION(minute, 20)) AS ChangePointScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(ChangePointScores, 'Score') AS float) AS
    ChangePointScore,
    CAST(GetRecordPropertyValue(ChangePointScores, 'IsAnomaly') AS bigint) AS
    IsChangePointAnomaly
INTO output
FROM AnomalyDetectionStep

```

## <a name="performance-characteristics"></a>Характеристики производительности

Производительность этих моделей зависит от размера журнала, длительности окна, загрузки событий, а также от того, используется ли секционирование на уровне функции. В этом разделе обсуждаются эти конфигурации и приведены примеры того, как поддерживать скорости приема событий 1000, 5 КБ и 10000 в секунду.

* **Размер журнала** — эти модели работают линейно с **размером журнала**. Чем дольше размер журнала, тем дольше модели принимаются в качестве оценки нового события. Это обусловлено тем, что модели сравнивают новое событие с каждым из предыдущих событий в буфере журнала.
* **Длительность окна** — **длительность окна** должна отражать, сколько времени займет получение столько событий, сколько указано размером журнала. Без большого числа событий в окне Azure Stream Analytics аппроксимация недостающие значения. Таким образом, использование ЦП является функцией размера журнала.
* **Загрузка событий** — чем больше **нагрузка на событие**, тем больший объем работы, выполняемый моделями, который влияет на потребление ресурсов ЦП. Задание можно масштабировать, делая его непараллельным, предполагая, что бизнес-логика использует больше входных секций.
* Секционирование на уровне **функций**  -  **Секционирование на уровне функций** осуществляется с помощью ```PARTITION BY``` вызова функции обнаружения аномалий. Этот тип секционирования добавляет дополнительную нагрузку, так как состояние должно поддерживаться для нескольких моделей одновременно. Секционирование на уровне функций используется в таких сценариях, как секционирование на уровне устройства.

### <a name="relationship"></a>Связь
Размер журнала, длительность окна и общая нагрузка события связаны следующим образом:

Виндовдуратион (в мс) = 1000 * Хисторисизе/(всего входных событий в секунду/число входных секций)

При секционировании функции по deviceId добавьте "PARTITION BY deviceId" в вызов функции обнаружения аномалий.

### <a name="observations"></a>Рассмотрен
В следующей таблице приведены наблюдения за пропускной способностью для одного узла (6 SU) для несекционированного варианта:

| Размер журнала (события)    | Длительность окна (МС) | Всего входных событий в секунду |
| --------------------- | -------------------- | -------------------------- |
| 60 | 55 | 2 200 |
| 600 | 728 | 1 650 |
| 6000 | 10 910 | 1100 |

В следующей таблице приведены наблюдения за пропускной способностью для одного узла (6 SU) для секционированного варианта:

| Размер журнала (события) | Длительность окна (МС) | Всего входных событий в секунду | Число устройств |
| --------------------- | -------------------- | -------------------------- | ------------ |
| 60 | 1 091 | 1100 | 10 |
| 600 | 10 910 | 1100 | 10 |
| 6000 | 218 182 | <550 | 10 |
| 60 | 21 819 | 550 | 100 |
| 600 | 218 182 | 550 | 100 |
| 6000 | 2 181 819 | <550 | 100 |

Пример кода для выполнения несекционированных конфигураций, описанных выше, находится в репозитории в разделе " [потоковая передача](https://github.com/Azure-Samples/streaming-at-scale/blob/f3e66fa9d8c344df77a222812f89a99b7c27ef22/eventhubs-streamanalytics-eventhubs/anomalydetection/create-solution.sh) " примеров Azure. Код создает задание Stream Analytics без секционирования на уровне функций, которое использует концентратор событий в качестве входных и выходных данных. Входная нагрузка создается с помощью тестовых клиентов. Каждое событие ввода — это 1 КБ документ JSON. События имитируют устройство Интернета вещей, отправляющее данные JSON (для 1000 устройств). Размер журнала, длительность окна и общая нагрузка события изменяются по 2 входным секциям.

> [!Note]
> Чтобы получить более точную оценку, настройте примеры в соответствии с имеющимся сценарием.

### <a name="identifying-bottlenecks"></a>Определение узких мест
Для выявления узких мест в конвейере можно воспользоваться панелью "Метрики" в задании Azure Stream Analytics. Просмотрите параметры **События ввода и вывода** с данными о пропускной способности и [Предельная задержка](https://azure.microsoft.com/blog/new-metric-in-azure-stream-analytics-tracks-latency-of-your-streaming-pipeline/) или **Отложенные события**, чтобы узнать, выполняется ли задание в соответствии с входной скоростью. Чтобы просмотреть метрики Центра событий, проверьте раздел **Регулируемые запросы** и соответствующим образом скорректируйте единицы порогового значения. Чтобы просмотреть метрики Cosmos DB, проверьте параметр **Максимальное количество потребляемых единиц запросов/с в диапазоне ключей секций** в разделе пропускной способности, чтобы убедиться в равномерном использовании диапазонов ключей секций. Чтобы просмотреть метрики для базы данных SQL Azure, см. разделы **Операции ввода-вывода журнала** и **ЦП**.

## <a name="next-steps"></a>Дальнейшие действия

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](/rest/api/streamanalytics/)