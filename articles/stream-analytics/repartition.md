---
title: Использование повторного секционирования для оптимизации заданий Azure Stream Analytics
description: В этой статье описывается использование повторного секционирования для оптимизации Azure Stream Analytics заданий, которые не могут быть параллельными.
ms.service: stream-analytics
author: sidramadoss
ms.author: sidram
ms.date: 03/04/2021
ms.topic: conceptual
ms.custom: mvc
ms.openlocfilehash: 95749f2acea6b605cfdba5a4f3d4f5526e751c5a
ms.sourcegitcommit: 24a12d4692c4a4c97f6e31a5fbda971695c4cd68
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/05/2021
ms.locfileid: "102182542"
---
# <a name="use-repartitioning-to-optimize-processing-with-azure-stream-analytics"></a>Использование повторного секционирования для оптимизации обработки с помощью Azure Stream Analytics

В этой статье показано, как использовать повторное секционирование для масштабирования запроса Azure Stream Analytics для сценариев, которые не могут быть полностью [параллельными](stream-analytics-scale-jobs.md).

Использование [параллелизации](stream-analytics-parallelization.md) может оказаться невозможным, если:

* Ключ секции для входного потока не контролируется.
* Источник «аэрографов» для нескольких секций, которые позднее необходимо объединить.

Повторное секционирование или перегруппировка требуется при обработке данных в потоке, не сегментированном в соответствии с естественной схемой ввода, например **PartitionId** для концентраторов событий. При повторном секционировании каждый сегмент может обрабатываться независимо, что позволяет линейно масштабировать конвейер потоковой передачи. 

## <a name="how-to-repartition"></a>Повторное секционирование
Вы можете повторно разделить входные данные двумя способами:
1. Использовать отдельное задание Stream Analytics, которое выполняет повторное секционирование
2. Использовать одно задание, но сначала выполнить повторное секционирование перед логикой пользовательской аналитики

### <a name="creating-a-separate-stream-analytics-job-to-repartition-input"></a>Создание отдельного задания Stream Analytics для повторного секционирования входных данных
Можно создать задание, которое считывает входные данные и выполняет запись в выходные данные концентратора событий с помощью ключа секции. Этот концентратор событий затем может использоваться в качестве входных данных для другого Stream Analytics задания, в котором реализуется логика аналитики. При настройке выходных данных концентратора событий в задании необходимо указать ключ секции, по которому Stream Analytics будет ресекционировать данные. 
```sql
-- For compat level 1.2 or higher
SELECT * 
INTO output
FROM input

--For compat level 1.1 or lower
SELECT *
INTO output
FROM input PARTITION BY PartitionId
```

### <a name="repartition-input-within-a-single-stream-analytics-job"></a>Повторное разделение входных данных в рамках одного Stream Analytics задания
Можно также ввести шаг в запросе, который сначала пересекционует входные данные, а затем можно использовать другие шаги в запросе. Например, если вы хотите повторно секционировать входные данные на основе **DeviceID**, запрос будет выглядеть следующим образом:
```sql
WITH RepartitionedInput AS 
( 
SELECT * 
FROM input PARTITION BY DeviceID
)

SELECT DeviceID, AVG(Reading) as AvgNormalReading  
INTO output
FROM RepartitionedInput  
GROUP BY DeviceId, TumblingWindow(minute, 1)  
```

Следующий пример запроса соединяет два потока секционированных данных. При соединении двух потоков пересекционированных данных потоки должны иметь одинаковый ключ секции и количество. Результат — это поток, имеющий ту же схему секционирования.

```sql
WITH step1 AS (SELECT * FROM input1 PARTITION BY DeviceID),
step2 AS (SELECT * FROM input2 PARTITION BY DeviceID)

SELECT * INTO output FROM step1 PARTITION BY DeviceID UNION step2 PARTITION BY DeviceID
```

Выходная схема должна соответствовать ключу и количеству схемы потока, чтобы каждый из подпотоков можно было сбрасывать отдельно. Поток можно также объединить и повторно секционировать с другой схемой перед очисткой, но следует избегать этого метода, так как он увеличивает общую задержку обработки и увеличивает использование ресурсов.

## <a name="streaming-units-for-repartitions"></a>Единицы потоковой передачи для повторного секционирования

Экспериментируйте и следите за использованием ресурсов задания, чтобы определить точное необходимое количество разделов. Количество [единиц потоковой передачи (SU)](stream-analytics-streaming-unit-consumption.md) должно быть скорректировано в соответствии с физическими ресурсами, необходимыми для каждой секции. Как правило, для каждой секции требуется шесть служб SUs. Если этому заданию не хватает ресурсов, система применит его только в том случае, если это будет выгодно для задания.

## <a name="repartitions-for-sql-output"></a>Повторное секционирование для выходных данных SQL

Если задание использует базу данных SQL для вывода, используйте явное повторное секционирование, чтобы оно соответствовало оптимальному количеству разделов, чтобы обеспечить максимальную пропускную способность. Так как SQL лучше работает с восемью модулями записи, при повторном секционировании потока до восьми перед очисткой или при последующей восходящей передаче данных производительность задания может быть выгоднее. 

При наличии более чем 8 секций входных данных может быть нецелесообразно использовать наследование схемы секционирования входных данных. Рассмотрите возможность использования [Into](/stream-analytics-query/into-azure-stream-analytics#into-shard-count) в запросе для явного указания числа модулей записи вывода. 

Следующий пример считывает из входных данных, независимо от того, выполняется его естественное секционирование, и выполняет повторное секционирование потока десятикратное в соответствии с измерением DeviceID и очищает данные для вывода. 

```sql
SELECT * INTO [output] FROM [input] PARTITION BY DeviceID INTO 10
```

Дополнительные сведения см. в статье [Вывод данных Azure Stream Analytics в базу данных SQL Azure](stream-analytics-sql-output-perf.md).


## <a name="next-steps"></a>Дальнейшие действия

* [Приступая к работе с Azure Stream Analytics: выявление мошенничества в режиме реального времени](stream-analytics-introduction.md)
* [Использование параллелизации запросов в Azure Stream Analytics](stream-analytics-parallelization.md)
