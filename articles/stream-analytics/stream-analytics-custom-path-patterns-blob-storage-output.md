---
title: Секционирование выходных данных пользовательского большого двоичного объекта Azure Stream Analytics
description: В статье описываются пользовательские шаблоны пути даты и времени и возможности настраиваемого поля или атрибутов для выходных данных хранилища больших двоичных объектов, поступающих из заданий Azure Stream Analytics.
author: enkrumah
ms.author: ebnkruma
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 12/15/2020
ms.custom: seodec18
ms.openlocfilehash: cb9d8edd24dcc8809f2b207a4db80653b0e140e4
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98014042"
---
# <a name="azure-stream-analytics-custom-blob-output-partitioning"></a>Секционирование выходных данных пользовательского большого двоичного объекта Azure Stream Analytics

Azure Stream Analytics поддерживает секционирование выходных данных пользовательского большого двоичного объекта с использованием настраиваемых полей или атрибутов и пользовательских шаблонов пути даты и времени. 

## <a name="custom-field-or-attributes"></a>Настраиваемое поле или атрибуты

Настраиваемое поле или входные атрибуты улучшают рабочие нисходящие процессы обработки данных и отчетность, позволяя больше управлять выходными данными.

### <a name="partition-key-options"></a>Параметры ключа раздела

Ключ секции или имя столбца, используемые для секционирования входных данных, могут содержать любой символ, который принимается для [имен больших двоичных объектов](/rest/api/storageservices/Naming-and-Referencing-Containers--Blobs--and-Metadata). Нельзя использовать вложенные поля в качестве ключа секции, если только они не используются вместе с псевдонимами, но для создания иерархии файлов можно использовать определенные символы. Например, следующий запрос можно использовать для создания столбца, который объединяет данные из двух других столбцов для создания уникального ключа секции.

```sql
SELECT name, id, CONCAT(name, "/", id) AS nameid
```

Ключ секции должен иметь тип NVARCHAR (MAX), BIGINT, FLOAT или BIT (уровень совместимости 1,2 или выше). Типы DateTime, Array и Records не поддерживаются, но могут использоваться в качестве ключей секций, если они преобразуются в строки. Дополнительные сведения см. в разделе [типы данных Azure Stream Analytics](/stream-analytics-query/data-types-azure-stream-analytics).

### <a name="example"></a>Пример

Предположим, что задание берет входные данные из сеансов пользователя в реальном времени, подключенного к службе внешних компьютерных игр, где полученные данные содержат столбец **client_id** для идентификации сеансов. Чтобы разделить данные по **client_id**, установите в поле шаблона пути BLOB-объекта **{client_id}** маркера раздела в свойствах выходных данных большого двоичного объекта при создании задания. Поскольку данные с различными значениями **client_id** проходят через задание Stream Analytics, данные сохраняются в отдельных папках, в зависимости от единого значения **client_id**, предназначенного папке.

![Шаблон пути с идентификатором клиента](./media/stream-analytics-custom-path-patterns-blob-storage-output/stream-analytics-path-pattern-client-id.png)

Аналогично если входные данные задания были данными из миллионов датчиков, где каждый из них содержал свой **sensor_id**, шаблон пути был равен значению **{sensor_id}** , чтобы разделить данные каждого датчика в разные папки.  


С помощью REST API раздел выходных данных файла JSON, используемый для данного запроса, может выглядеть следующим образом.  

![Выходные данные REST API](./media/stream-analytics-custom-path-patterns-blob-storage-output/stream-analytics-rest-output.png)

Когда задание запустится, контейнер *clients* может выглядеть следующим образом:  

![Контейнер "clients"](./media/stream-analytics-custom-path-patterns-blob-storage-output/stream-analytics-clients-container.png)

Каждая папка может содержать несколько больших двоичных объектов, где каждый из них содержит одну или несколько записей. В приведенном выше примере имеется один большой двоичный объект в папке с меткой "06000000" со следующим содержимым:

![Содержимое большого двоичного объекта](./media/stream-analytics-custom-path-patterns-blob-storage-output/stream-analytics-blob-contents.png)

Обратите внимание, что каждая запись в большом двоичном объекте содержит столбец **client_id**, который соответствует названию папки, так как столбец, используемый для разделения выходных данных в выходном пути, был обозначен как **client_id**.

### <a name="limitations"></a>Ограничения

1. В свойстве выходных данных большого двоичного объекта шаблона пути допускается только один пользовательский ключ раздела. Следующие шаблоны пути являются допустимыми:

   * cluster1/{date}/{aFieldInMyData}  
   * cluster1/{time}/{aFieldInMyData}  
   * cluster1/{aFieldInMyData}  
   * cluster1/{date}/{time}/{aFieldInMyData} 
   
2. Ключи раздела нечувствительны к регистру, поэтому ключи раздела "John" и "john" являются эквивалентными. В качестве ключей раздела также запрещено использовать выражения. Например, **{columnA + columnB}** не работает.  

3. Если входной поток состоит из записей с кратностью ключа разделения до 8000, записи будут добавляться на существующие большие двоичные объекты и при необходимости создавать новые. Если кратность превышает 8000, нет никакой гарантии, что существующие большие двоичные объекты будут записаны, а новые не будут создаваться для произвольного числа записей с одинаковым ключом разделения.

4. Если выходные данные большого двоичного объекта [настроены как неизменяемые](../storage/blobs/storage-blob-immutable-storage.md), Stream Analytics создаст новый большой двоичный объект каждый раз, когда отправляются данные.

## <a name="custom-datetime-path-patterns"></a>Пользовательские шаблоны пути даты и времени

Пользовательские шаблоны даты и времени в пути позволяют указать формат выходных данных, который соответствует соглашениям о потоковой передаче Hive, предоставляя Azure Stream Analytics возможность отправлять данные в Azure HDInsight и Azure Databricks для последующей обработки. Пользовательские шаблоны даты и времени в пути легко реализуются, если ввести в поле "Префикс пути" выходных данных хранилища BLOB-объектов ключевое слово `datetime` вместе со спецификатором формата. Например, `{datetime:yyyy}`.

### <a name="supported-tokens"></a>Поддерживаемые токены

Следующие токены спецификатора формата могут использоваться отдельно или в комбинациях для настройки пользовательских форматов даты и времени:

|Спецификатор формата   |Описание   |Результаты для примера 2018-01-02T10:06:08|
|----------|-----------|------------|
|{datetime:yyyy}|Год как четырехзначное число|2018|
|{datetime:MM}|Месяц от 01 до 12|01|
|{datetime:M}|Месяц от 1 до 12|1|
|{datetime:dd}|День от 01 до 31|02|
|{datetime:d}|День от 1 до 31|2|
|{datetime:HH}|Часы в 24-часовом формате, от 00 до 23|10|
|{datetime:mm}|Минуты от 00 до 60|06|
|{datetime:m}|Минуты от 0 до 60|6|
|{datetime:ss}|Секунды от 00 до 60|08|

Если вы не хотите использовать пользовательские шаблоны даты и времени, можно добавить токен {date} и (или) {time} в префикс пути, чтобы создать раскрывающийся список со встроенными форматами даты и времени.

![Старые форматы даты и времени Stream Analytics](./media/stream-analytics-custom-path-patterns-blob-storage-output/stream-analytics-old-date-time-formats.png)

### <a name="extensibility-and-restrictions"></a>Расширяемость и ограничения

Вы можете использовать столько токенов `{datetime:<specifier>}` в шаблоне пути, сколько нужно, пока не достигнете предельного числа знаков в префиксе пути. Спецификаторы формата не могут быть объединены в один токен, за исключением комбинаций, уже перечисленных в раскрывающемся списке даты и времени. 

Для раздела пути `logs/MM/dd`:

|Допустимое выражение   |Недопустимое выражение   |
|----------|-----------|
|`logs/{datetime:MM}/{datetime:dd}`|`logs/{datetime:MM/dd}`|

Вы можете использовать один и тот же спецификатор формата несколько раз в префиксе пути. Токен должен повторяться каждый раз.

### <a name="hive-streaming-conventions"></a>Соглашения для потоковой передачи Hive

Пользовательские шаблоны пути для хранилища BLOB-объектов могут использоваться с соглашением для потоковой передачи Hive, в которой ожидается, что в имени папки будет пометка `column=`.

Например, `year={datetime:yyyy}/month={datetime:MM}/day={datetime:dd}/hour={datetime:HH}`.

Пользовательский тип выходных данных устраняет проблему изменения таблиц и добавления разделов для передачи данных между Azure Stream Analytics и Hive вручную. Вместо этого многие папки можно добавлять автоматически, используя:

```SQL
MSCK REPAIR TABLE while hive.exec.dynamic.partition true
```

### <a name="example"></a>Пример

Создайте учетную запись хранения, группу ресурсов, Stream Analytics задание и источник входных данных в соответствии с кратким руководством по [Azure Stream Analytics портал Azure](stream-analytics-quick-create-portal.md) . Используйте те же примеры данных, которые используются в кратком руководстве, также доступном на сайте [GitHub](https://raw.githubusercontent.com/Azure/azure-stream-analytics/master/Samples/GettingStarted/HelloWorldASA-InputStream.json).

Создайте приемник выходных данных больших двоичных объектов со следующей конфигурацией:

![Создание приемника выходных данных больших двоичных объектов Stream Analytics](./media/stream-analytics-custom-path-patterns-blob-storage-output/stream-analytics-create-output-sink.png)

Шаблон полного пути выглядит следующим образом:


`year={datetime:yyyy}/month={datetime:MM}/day={datetime:dd}`


Когда вы запускаете задание, в контейнере больших двоичных объектов создается структура папок, основанная на шаблоне пути. Вы можете детализировать до уровня дня.

![Выходные данные больших двоичных объектов Stream Analytics с пользовательским шаблоном пути](./media/stream-analytics-custom-path-patterns-blob-storage-output/stream-analytics-blob-output-folder-structure.png)

## <a name="next-steps"></a>Дальнейшие действия

* [Описание выходных данных из Azure Stream Analytics](stream-analytics-define-outputs.md)
