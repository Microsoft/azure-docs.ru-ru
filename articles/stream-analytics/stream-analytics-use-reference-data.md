---
title: Использование эталонных данных для уточняющих запросов в Azure Stream Analytics
description: В этой статье описано использование эталонных данных для уточняющих запросов или корреляции в конструкторе запросов для заданий Azure Stream Analytics.
author: jseb225
ms.author: jeanb
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 12/18/2020
ms.openlocfilehash: e05a4cbbc5fefbfe8a92914ef480f32bdf43ca37
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "99560212"
---
# <a name="using-reference-data-for-lookups-in-stream-analytics"></a>Использование эталонных данных для уточняющих запросов в Stream Analytics

Ссылочные данные (также известные как таблица подстановки) — это конечный набор данных, который является статическим или медленно изменяющимся по сути, используется для поиска или расширения потоков данных. Например, в сценарии Интернета вещей вы могли бы сохранить метаданные о датчиках (которые часто не изменяются) в ссылочных данных и соединить их с потоками данных Интернета вещей в режиме реального времени. Azure Stream Analytics загружает эталонные данные в память, чтобы сократить задержки при обработке потока. Чтобы использовать эталонные данные в задании Azure Stream Analytics, в запросе обычно используется [соединение ссылочных данных](/stream-analytics-query/reference-data-join-azure-stream-analytics) . 

## <a name="example"></a>Пример  
Вы можете создать поток событий в реальном времени, когда автомобили пройдут бесплатный стенд. Бесплатный стенд может захватить форму лицензии в режиме реального времени и присоединиться к статическому набору данных, который содержит сведения о регистрации, чтобы выявление просроченных форм лицензий.  
  
```SQL  
SELECT I1.EntryTime, I1.LicensePlate, I1.TollId, R.RegistrationId  
FROM Input1 I1 TIMESTAMP BY EntryTime  
JOIN Registration R  
ON I1.LicensePlate = R.LicensePlate  
WHERE R.Expired = '1'
```  

Stream Analytics поддерживает хранилище BLOB-объектов Azure и Базу данных SQL Azure как слой хранилища для эталонных данных. Вы также можете преобразовать или копировать эталонные данные в хранилище BLOB-объектов из Фабрики данных Azure, чтобы использовать [любое количество облачных и локальных хранилищ данных](../data-factory/copy-activity-overview.md).

## <a name="azure-blob-storage"></a>Хранилище BLOB-объектов Azure

Ссылочные данные моделируются как последовательность больших двоичных объектов (с учетом конфигурации входных данных) в порядке возрастания даты и времени, указанных в имени большого двоичного объекта. Они добавляются **только** в конец последовательности, для чего используется **более поздние** дата и время, чем в последнем большом двоичном объекте в последовательности. Дополнительные сведения см. в статье [использование ссылочных данных из хранилища BLOB-объектов для задания Azure Stream Analytics](data-protection.md).

### <a name="configure-blob-reference-data"></a>Настройка эталонных данных большого двоичного объекта

Чтобы настроить **ссылочные данные**, необходимо сначала создать входные данные соответствующего типа. В таблице ниже описано каждое свойство, которое необходимо указать во время создания входных ссылочных данных.

|**Имя свойства**  |**Описание**  |
|---------|---------|
|Псевдоним входных данных   | Понятное имя, с помощью которого запрос задания будет ссылаться на эти входные данные.   |
|Учетная запись хранения   | Имя учетной записи хранения, в которой находятся большие двоичные объекты. Если учетная запись расположена в одной подписке с заданием Stream Analytics, то ее имя можно выбрать из раскрывающегося списка.   |
|Ключ учетной записи хранения   | Секретный ключ, связанный с учетной записью хранения. Заполняется автоматически, если учетная запись хранения расположена в одной подписке с заданием Stream Analytics.   |
|Контейнер хранилища   | Контейнеры обеспечивают логическую группировку BLOB-объектов, хранящихся в службе BLOB-объектов Microsoft Azure. При передаче BLOB-объекта в службу BLOB-объектов для него необходимо указать контейнер.   |
|Шаблон пути   | Это обязательное свойство, которое используется для нахождение больших двоичных объектов в указанном контейнере. В пути можно указать один или несколько экземпляров следующих двух переменных:<BR>{date}, {time}<BR>Пример 1: products/{date}/{time}/product-list.csv<BR>Пример 2: products/{date}/product-list.csv<BR>Пример 3: product-list.csv<BR><br> Если большой двоичный объект не существует по указанному пути, задание Stream Analytics будет бесконечно ожидать, пока он не станет доступным.   |
|Формат даты (необязательное свойство)   | Если в указанном шаблоне пути использовалась переменная {date}, то из раскрывающегося списка поддерживаемых форматов можно выбрать формат даты для упорядочивания больших двоичных объектов.<BR>Например: ГГГГ/ММ/ДД, ММ/ДД/ГГГГ и т. д.   |
|Формат времени (необязательное свойство)   | Если в указанном шаблоне пути использовалась переменная {time}, то из раскрывающегося списка поддерживаемых форматов можно выбрать формат времени для упорядочивания больших двоичных объектов.<BR>Примеры: ЧЧ, ЧЧ/мм или ЧЧ-мм.  |
|Формат сериализации событий   | Чтобы запросы работали как следует, в задании Stream Analytics нужно указать, какой формат сериализации используется для потоков входящих данных. Поддерживаемые форматы для ссылочных данных: CSV и JSON.  |
|Кодирование   | В настоящее время единственным поддерживаемым форматом кодировки является UTF-8.  |

### <a name="static-reference-data"></a>Статические ссылочные данные

Если ссылочные данные не будут изменяться, поддержку статических данных можно настроить, указав статический путь в конфигурации входных данных. Azure Stream Analytics будет обрабатывать BLOB-объекты по указанному пути. Токены подстановки {date} и {time} можно не использовать, Так как ссылочные данные являются неизменяемыми в Stream Analytics, не рекомендуется перезаписывать данные статического двоичного объекта эталонных данных.

### <a name="generate-reference-data-on-a-schedule"></a>Создание эталонных данных по расписанию

Если ссылочные данные являются медленно изменяющимся набором данных, вы можете включить поддержку обновления ссылочных данных. Для этого укажите соответствующий шаблон пути во входной конфигурации, используя токены подстановки {date} и {time}. На основе этого свойства path pattern служба Stream Analytics будет выбирать обновленные определения ссылочных данных. Например, шаблон `sample/{date}/{time}/products.csv` с форматом даты **"гггг-мм-дд"** и форматом времени **"hh-mm"** предписывает Stream Analytics получения обновленного большого двоичного объекта `sample/2015-04-16/17-30/products.csv` по адресу 5:30 в 16 апреля, 2015 часового пояса в формате UTC.

Azure Stream Analytics каждую минуту автоматически проверяет BLOB-объекты со ссылочными данными на наличие изменений. Если большой двоичный объект с меткой времени 10:30:00 отправляется с небольшой задержкой (например, 10:30:30), вы заметите небольшую задержку в Stream Analytics задание, ссылающееся на этот большой двоичный объект. Чтобы избежать таких ситуаций, рекомендуется передать большой двоичный объект раньше целевого эффективного времени (10:30:00 в этом примере), чтобы Stream Analytics задание было достаточно времени для обнаружения и загрузки в памяти и выполнения операций. 

> [!NOTE]
> В настоящее время задания Stream Analytics ищут обновления больших двоичных объектов, только если время, закодированное в имени большого двоичного объекта, отстает от времени компьютера. Например, задание будет искать `sample/2015-04-16/17-30/products.csv` как можно раньше, но не ранее 17:30 16 апреля 2015 г. в часовом поясе UTC. Оно *никогда* не будет искать большой двоичный объект, закодированное имя которого опережает время в имени последнего обнаруженного большого двоичного объекта.
> 
> Например, после того, как задание найдет большой двоичный объект, `sample/2015-04-16/17-30/products.csv` он будет игнорировать все файлы с кодированной датой, предшествующими 5:30 апреля, 2015, поэтому, если в `sample/2015-04-16/17-25/products.csv` том же контейнере создается большой двоичный объект с поздним поступлением, задание не будет использовать его.
> 
> Аналогичным образом, если `sample/2015-04-16/17-30/products.csv` создается в 22:03 16 апреля 2015 г., но в контейнере нет большого двоичного объекта с более ранней датой, задание будет использовать этот файл начиная с 22:03 16 апреля 2015 г., а до этого времени будет использовать ссылочные данные за прошедшее время.
> 
> Исключение составляют случаи, когда заданию необходимо повторно обработать данные за прошлые периоды или когда задание запускается впервые. В начале выполнения задание ищет самый новый большой двоичный объект, созданный до указанного времени запуска задания. Это позволяет обеспечить наличие **непустого** набора ссылочных данных на момент начала задания. Если его не удалось найти, задание будет показывать следующие данные диагностики: `Initializing input without a valid reference data blob for UTC time <start time>`.

[Фабрика данных Azure](https://azure.microsoft.com/documentation/services/data-factory/) может использоваться для управления заданием по созданию обновленных больших двоичных объектов, необходимых службе Stream Analytics для обновления определений ссылочных данных. Фабрика данных представляет собой облачную службу интеграции информации, которая организует и автоматизирует перемещение и преобразование данных. Фабрика данных позволяет [подключаться к большому количеству облачных и локальных хранилищ данных](../data-factory/copy-activity-overview.md), а также легко перемещать данные по заданному расписанию. Дополнительные сведения и пошаговые инструкции, с помощью которых можно настроить конвейер фабрики данных и создать ссылочные данные для службы Stream Analytics, обновляемые по заданному расписанию, см. в этом [примере на сайте GitHub](https://github.com/Azure/Azure-DataFactory/tree/master/SamplesV1/ReferenceDataRefreshForASAJobs).

### <a name="tips-on-refreshing-blob-reference-data"></a>Советы по обновлению эталонных данных большого двоичного объекта

1. Не перезаписывайте BLOB-объекты ссылочных данных, так как они не должны изменяться.
2. Обновлять ссылочные данные рекомендуется такими способами:
    * использовать {date} и {time} в шаблоне пути;
    * добавить новый BLOB-объект, используя тот же контейнер и шаблон пути, которые определены во входных данных задания;
    * использовать дату и время, **большие**, чем дата и время, указанные в последнем BLOB-объекте в последовательности.
3. Большие двоичные объекты ссылочных данных **не** упорядочиваются по времени последнего изменения BLOB-объекта, но только по времени и дате, указанным в имени большого двоичного объекта с помощью подстановок {Date} и {Time}.
3. Чтобы не отобразилось слишком большое количество больших двоичных объектов, попробуйте удалить очень старые большие двоичные объекты, которые больше не будут обрабатываться. Обратите внимание на то, что ASA может быть понадобиться повторно обработать несколько больших двоичных объектов в таких сценариях, как перезагрузка.

## <a name="azure-sql-database"></a>База данных SQL Azure

Эталонные данные базы данных SQL Azure извлекаются заданием Stream Analytics и хранятся в памяти в виде моментального снимка для обработки. Моментальный снимок эталонных данных также хранится в контейнере в учетной записи хранения, указанной в параметрах конфигурации. Контейнер создается автоматически при запуске задания. Если задание остановлено или переходит в состояние сбоя, при его перезапуске автоматически созданные контейнеры удаляются.  

Если ссылочные данные являются медленно изменяющимся набором данных, необходимо периодически обновлять моментальный снимок, который используется в задании. Stream Analytics позволяет задать частоту обновления при настройке входного подключения к базе данных SQL Azure. Среда выполнения Stream Analytics будет запрашивать базу данных SQL Azure в интервале, заданном частотой обновления. Наиболее быстрая частота обновления, которая поддерживается — один раз в минуту. Для каждого обновления Stream Analytics сохраняет новый моментальный снимок в указанной учетной записи хранения.

Stream Analytics предоставляет два варианта выполнения запросов к базе данных SQL Azure. Запрос моментального снимка является обязательным, и его необходимо включить в каждое задание. Stream Analytics выполняет запрос моментального снимка периодически, в зависимости от интервала обновления, и использует результат запроса (моментального снимка) в качестве эталонного набора данных. Запрос моментального снимка должен соответствовать большинству сценариев, но при возникновении проблем с производительностью с большими наборами данных и быстрой частотой обновления, можете использовать параметр разностного запроса. Запросы, которые используют более 60 секунд для возврата эталонного набора данных, приведут к превышению времени ожидания.

С параметром разностных запросов Stream Analytics выполняет запрос моментального снимка изначально, чтобы получить базовый набор эталонных данных. После чего Stream Analytics выполняет разностный запрос, в зависимости от интервала обновления, чтобы получить добавочные изменения. Эти добавочные изменения постоянно применяются к эталонному набору данных, чтобы обновлять его. Благодаря разностному запросу сократите затраты на хранение и сетевые операции ввода-вывода.

### <a name="configure-sql-database-reference"></a>Настройка ссылки на Базу данных SQL

Чтобы настроить эталонные данные в Базе данных SQL, необходимо сначала создать входные **Эталонные данные**. В указанной ниже таблице описано каждое свойство, которое необходимо предоставить во время создания входных эталонных данных. Дополнительные сведения см. в статье [Use reference data from a SQL Database for an Azure Stream Analytics job (Preview)](sql-reference-data.md) (Использование эталонных данных из Базы данных SQL для задания Azure Stream Analytics (предварительная версия)).

Вы можете использовать [управляемый экземпляр Azure SQL](../azure-sql/managed-instance/sql-managed-instance-paas-overview.md) в качестве входных ссылочных данных. Необходимо [настроить общедоступную конечную точку в управляемый экземпляр SQL](../azure-sql/managed-instance/public-endpoint-configure.md) , а затем вручную настроить следующие параметры в Azure Stream Analytics. Виртуальная машина Azure, на которой работает SQL Server с подключенной базой данных, также дополнительно настраивается вручную с использованием параметров ниже.

|**Имя свойства**|**Описание**  |
|---------|---------|
|Псевдоним входных данных|Понятное имя, с помощью которого запрос задания будет ссылаться на эти входные данные.|
|Subscription|Выберите свою подписку|
|База данных|База данных SQL Azure с эталонными данными. Для SQL Управляемый экземпляр необходимо указать порт 3342. Например, *sampleserver.public.database.windows.net,3342*|
|Имя пользователя|Имя пользователя, связанное с базой данных SQL Azure.|
|Пароль|Пароль, связанный с базой данных SQL Azure.|
|Периодическое обновление|Этот параметр позволяет выбрать частоту обновления. Выбор "Вкл." позволит вам указать частоту обновления в формате ДД:ЧЧ:MM.|
|Запрос моментального снимка|Это параметр запроса по умолчанию, который извлекает ссылочные данные из Базы данных SQL.|
|Разностный запрос|Для более сложных сценариев с большими наборами данных и краткой частотой обновления выберите это, чтобы добавить разностной запрос.|

## <a name="size-limitation"></a>Ограничение размера

Для лучшей производительности рекомендуется использовать эталонные наборы данных размером менее 300 МБ. Наборы данных с 5 ГБ или ниже поддерживаются в заданиях с 6 пакетами SUs или более. Использование очень больших ссылочных данных может повлиять на конечную задержку задания. Когда сложность запросов возрастает и они включают в себя обработку с отслеживанием состояния, например оконные агрегатные функции, темпоральные соединения и темпоральные аналитические функции, ожидается, что поддерживаемый объем эталонных данных снизится. Если Azure Stream Analytics не сможет загружать эталонные данные и выполнять сложные операции, заданию не хватит памяти и оно завершится сбоем. В таких случаях показатель использования единиц потоковой передачи в процентах достигнет 100 %.    

|**Количество единиц потоковой передачи**  |**Рекомендуемый размер**  |
|---------|---------|
|1   |50 МБ или ниже   |
|3   |150 МБ или ниже   |
|6 и более   |5 ГБ или ниже.    |

Для ссылочных данных сжатие не поддерживается.

## <a name="joining-multiple-reference-datasets-in-a-job"></a>Соединение нескольких наборов данных-ссылок в задании
В одном шаге запроса можно объединить только один потоковый вход с одним входным ссылочным данными. Однако можно объединить несколько эталонных наборов данных, разбивая запрос на несколько шагов. Ниже приведен пример такого файла.

```SQL  
With Step1 as (
    --JOIN input stream with reference data to get 'Desc'
    SELECT streamInput.*, refData1.Desc as Desc
    FROM    streamInput
    JOIN    refData1 ON refData1.key = streamInput.key 
)
--Now Join Step1 with second reference data
SELECT *
INTO    output 
FROM    Step1
JOIN    refData2 ON refData2.Desc = Step1.Desc 
``` 

## <a name="iot-edge-jobs"></a>Задания IoT Edge

Для заданий Stream Analytics пограничных устройств поддерживаются только локальные ссылочные данные. Когда задание развертывается на устройстве IoT Edge, оно загружает эталонные данные из определенного пользователем пути к файлу. Подготовьте на устройстве файл с эталонными данными. Для контейнера Windows поместите файл с эталонными данными на локальный диск и предоставьте доступ к этому диску контейнеру Docker. Для контейнера Linux создайте том Docker и разместите на нем файл с данными.

Справочные данные по обновлению IoT Edge запускаются развертыванием. После активации модуль Stream Analytics выбирает обновленные данные без остановки выполняющегося задания.

Есть два способа обновить эталонные данные:

* Обновите путь к ссылочным данным в задании Stream Analytics из портал Azure.

* обновить развертывание IoT Edge.

## <a name="next-steps"></a>Дальнейшие действия
> [!div class="nextstepaction"]
> [Краткое руководство. по созданию задания Stream Analytics с помощью портала Azure](stream-analytics-quick-create-portal.md)

<!--Link references-->
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md
[stream.analytics.scale.jobs]: stream-analytics-scale-jobs.md
[stream.analytics.introduction]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.get.started]: ./stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: /stream-analytics-query/stream-analytics-query-language-reference
[stream.analytics.rest.api.reference]: /rest/api/streamanalytics/
