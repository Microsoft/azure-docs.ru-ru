---
title: Выходные данные Azure Stream Analytics в Azure Cosmos DB
description: Из этой статьи вы узнаете, как с помощью Azure Stream Analytics сохранять выходные данные в Azure Cosmos DB в формате JSON, что позволяет архивировать данные и уменьшать задержки запросов в отношении неструктурированных данных JSON.
author: enkrumah
ms.author: ebnkruma
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 02/2/2020
ms.custom: seodec18
ms.openlocfilehash: 2d00d489ff248ecf5599d78e0a351c93248cf8ee
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98018095"
---
# <a name="azure-stream-analytics-output-to-azure-cosmos-db"></a>Выходные данные Azure Stream Analytics в Azure Cosmos DB  
Azure Stream Analytics дает возможность направлять выходные данные в формате JSON в [Azure Cosmos DB](https://azure.microsoft.com/services/documentdb/), позволяя архивировать данные и уменьшать задержки запросов в отношении неструктурированных данных JSON. В этом документе представлены некоторые рекомендации по реализации данной конфигурации. Рекомендуется задать для задания уровень совместимости 1,2 при использовании Azure Cosmos DB в качестве выходных данных.

Если вы не знакомы с Azure Cosmos DB, для начала работы обратитесь к [документации Azure Cosmos DB](../cosmos-db/index.yml). 

> [!Note]
> В настоящее время Stream Analytics поддерживает соединение с Azure Cosmos DB только при помощи *SQL API*.
> Другие API Azure Cosmos DB в данный момент не поддерживаются. Если указать модулю Stream Analytics учетные записи Azure Cosmos DB, созданные при помощи других API, это может привести к неправильному сохранению данных. 

## <a name="basics-of-azure-cosmos-db-as-an-output-target"></a>Основное об Azure Cosmos DB как о целевом объекте выходных данных
Вывод данных Stream Analytics в Azure Cosmos DB позволяет записывать результаты обработки потока данных в контейнеры Azure Cosmos DB в формате JSON. 

Stream Analytics не создает контейнеры в базе данных. Вам необходимо создать их заранее. После этого вы можете контролировать расходы на выставление счетов за контейнеры Azure Cosmos DB. Кроме того, можно настроить производительность, согласованность и емкость контейнеров напрямую через [API Azure Cosmos DB](/rest/api/cosmos-db/).

> [!Note]
> Необходимо добавить 0.0.0.0 в список разрешенных IP-адресов брандмауэра Azure Cosmos DB.

В следующих разделах подробно описаны некоторые параметры контейнера Azure Cosmos DB.

## <a name="tuning-consistency-availability-and-latency"></a>Настройка согласованности, доступности и задержки
Для соответствия требованиям вашего приложения служба Azure Cosmos DB дает возможность настроить базу данных и контейнеры и создать оптимальный баланс между согласованностью, доступностью, задержкой и пропускной способностью. 

В зависимости от того, какие уровни согласованности чтения потребуются вашему сценарию для чтения и записи задержки, вы можете выбирать уровень согласованности в своей учетной записи базы данных. Можно повысить пропускную способность, увеличив количество единиц запроса (EЗ) для контейнера. 

Кроме того, Azure Cosmos DB по умолчанию активирует синхронное индексирование для каждой операции CRUD в вашем контейнере. Это еще один полезный параметр для контроля производительности операций чтения и записи в Azure Cosmos DB. 

Дополнительные сведения см. в статье об [уровнях согласованности базы данных и запросов](../cosmos-db/consistency-levels.md).

## <a name="upserts-from-stream-analytics"></a>Вставка и обновление Upsert в Stream Analytics
Интеграция Stream Analytics с Azure Cosmos DB позволяет вставлять или обновлять записи в контейнере с помощью заданного столбца **Идентификатор документа**. Это так называемый *upsert*.

Stream Analytics использует подход оптимистичного upsert. Обновления происходят, только если вставка завершается ошибкой с конфликтом идентификатора документа. 

При уровне совместимости 1.0 Stream Analytics выполняет это обновление как операцию исправления, что обеспечивает частичные обновления документа. Stream Analytics добавляет новые свойства или постепенно заменяет существующее свойство. Тем не менее изменение значений свойств массива в документе JSON приводит к перезаписи всего массива. То есть массивы не объединяются. 

При уровне 1.2 поведение upsert изменяется на вставку или замену документа. Подробно это поведение описано ниже, в разделе об уровне совместимости 1.2.

Если входящий документ JSON имеет существующее поле ID, это поле автоматически используется в качестве столбца **Идентификатор документа** в Azure Cosmos DB. Все последующие операции записи обрабатываются так же, что приводит к одной из следующих ситуаций.

- Для уникальных идентификаторов выполняется вставка.
- При совпадении идентификаторов и значении **Идентификатор документа**, выставленном по **ID**, выполняется upsert.
- При совпадении идентификаторов и невыставленном значении **Идентификатор документа** после первого документа возникает ошибка.

Если вы хотите сохранить *все документы*, включая те, которые имеют дублирующийся идентификатор, переименуйте поле идентификатора в запросе (с помощью ключевого слова **AS**). Позвольте Azure Cosmos DB создать поле идентификатора или замените идентификатор другим значением столбца (с помощью ключевого слова **AS** или параметра **Идентификатор документа**).

## <a name="data-partitioning-in-azure-cosmos-db"></a>Секционирование в Azure Cosmos DB
Azure Cosmos DB автоматически масштабирует секции в зависимости от рабочей нагрузки. Поэтому мы рекомендуем [неограниченные](../cosmos-db/partitioning-overview.md) контейнеры в качестве подхода к секционированию данных. При записи в неограниченные контейнеры Stream Analytics использует столько же параллельных модулей записи, сколько на предыдущем шаге запроса или в схеме секционирования входных данных.

> [!NOTE]
> Azure Stream Analytics поддерживает только неограниченные контейнеры с ключами секции на верхнем уровне. Например, `/region` поддерживается. Вложенные ключи секции (например, `/region/name`) не поддерживаются. 

В зависимости от выбранного ключа секции может появиться следующее _предупреждение_:

`CosmosDB Output contains multiple rows and just one row per partition key. If the output latency is higher than expected, consider choosing a partition key that contains at least several hundred records per partition key.`

Важно выбрать свойство ключа секции, имеющее несколько уникальных значений. Это позволяет равномерно распределить рабочую нагрузку по этим значениям. Как естественный артефакт секционирования, запросы, включающие один и тот же ключ секции, ограничиваются максимальной пропускной способностью одной секции. 

Размер хранилища для документов, принадлежащих одному значению ключа секции, ограничен 20 ГБ ( [ограничение размера физической секции](../cosmos-db/partitioning-overview.md) составляет 50 ГБ). [Идеальный ключ секции](../cosmos-db/partitioning-overview.md#choose-partitionkey) — это тот, который часто встречается как фильтр в запросах и имеет достаточно элементов для обеспечения масштабируемости решения.

Ключи секций, используемые для запросов Stream Analytics и Cosmos DB, не должны совпадать. В полностью параллельных топологиях рекомендуется использовать *входной ключ секции*, в `PartitionId` качестве ключа секции Stream Analytics запроса, но это может быть не рекомендуемым выбором для ключа секции Cosmos DB контейнера.

Ключ секции также является границей для транзакций в хранимых процедурах и триггерах для Azure Cosmos DB. Выбирайте ключ секции так, чтобы документы, которые вместе появляются в транзакциях, использовали одно и то же значение ключа секции. Статья [Секционирование в Azure Cosmos DB](../cosmos-db/partitioning-overview.md) содержит дополнительные сведения о выборе ключа секции.

Для фиксированных контейнеров Azure Cosmos DB после их заполнения Stream Analytics не позволяет увеличить или уменьшить масштаб. Они имеют верхний предел в 10 ГБ и 10 000 ЕЗ/с для пропускной способности. Чтобы перенести данные из фиксированного контейнера в неограниченный контейнер (например, с ключом секции и пропускной способностью не менее 1000 ЕЗ/с), используйте [средство миграции данных](../cosmos-db/import-data.md) или [библиотеку канала изменений](../cosmos-db/change-feed.md).

Возможность записи в несколько фиксированных контейнеров является устаревшей. Мы не рекомендуем использовать ее для масштабирования задания Stream Analytics.

## <a name="improved-throughput-with-compatibility-level-12"></a>Улучшенная пропускная способность с уровнем совместимости 1.2
При уровне совместимости 1.2 Stream Analytics поддерживает встроенную интеграцию для массовой записи в Azure Cosmos DB. Эта интеграция позволяет эффективно вести запись в Azure Cosmos DB, обеспечивая максимальную пропускную способность и эффективную обработку запросов регулирования. 

Улучшенный механизм записи доступен на новом уровне совместимости из-за разницы в поведении upsert. С уровнями ниже 1.2 upsert выполняет вставку или объединение документа. При уровне 1.2 поведение upsert изменяется на вставку или замену документа.

С уровнями ниже 1.2 Stream Analytics использует пользовательскую хранимую процедуру для массовой операции upsert документов для каждого ключа секции в Azure Cosmos DB. В этом случае пакет записывается как транзакция. Даже если одна запись сталкивается с временной ошибкой (регулирование), приходится повторить весь пакет. Это делает сценарии даже с умеренным регулированием относительно медленными.

В следующем примере показаны два идентичных задания Stream Analytics, считывающие одни и те же входные данные с концентраторов событий Azure. Оба задания Stream Analytics [полностью секционированы](./stream-analytics-parallelization.md#embarrassingly-parallel-jobs) сквозным запросом и записывают в идентичные контейнеры Azure Cosmos DB. Метрики слева относятся к заданию с уровнем совместимости 1.0. Метрики справа получены при уровне 1.2. Ключом секции контейнера Azure Cosmos DB является глобально уникальный идентификатор GUID, который поступает из входного события.

![Сравнение метрик Stream Analytics](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-3.png)

Частота входящих событий в концентраторах событий вдвое выше чем та, на прием которой настроены контейнеры Azure Cosmos DB (20 000 ЕЗ), поэтому регулирование ожидается в Azure Cosmos DB. Однако задание с уровнем 1.2 постоянно выполняет запись с более высокой пропускной способностью (выходные события в минуту), а также с меньшим средним использованием единиц потоковой передачи SU%. В вашей среде это различие будет зависеть еще от нескольких факторов. Эти факторы включают в себя формат события, размер входного события или сообщения, ключи секций и запросы.

![Сравнение метрик Azure Cosmos DB](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-2.png)

C уровнем 1.2 Stream Analytics более интеллектуально использует 100 процентов доступной пропускной способности Azure Cosmos DB при очень малой повторной отправке из-за регулирования или ограничения частоты. Это положительно сказывается на других рабочих нагрузках, таких как запросы, одновременно выполняемые в контейнере. Если вы хотите увидеть, как Stream Analytics масштабируется с Azure Cosmos DB в качестве приемника для 1000–10 000 сообщений в секунду, попробуйте [этот пример проекта Azure](https://github.com/Azure-Samples/streaming-at-scale/tree/main/eventhubs-streamanalytics-cosmosdb).

Пропускная способность вывода данных в Azure Cosmos DB идентична для уровней 1.0 и 1.1. Мы *настоятельно рекомендуем* использовать уровень совместимости 1.2 в Stream Analytics при работе с Azure Cosmos DB.

## <a name="azure-cosmos-db-settings-for-json-output"></a>Параметры Azure Cosmos DB для выходных данных JSON

При настройке вывода данных Stream Analytics в Azure Cosmos DB появляется следующее окно запроса информации.

![Поля информации для потока вывода в Azure Cosmos DB](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-1.png)

|Поле           | Описание|
|-------------   | -------------|
|Псевдоним выходных данных    | Псевдоним для ссылки на эти выходные данные в запросе Stream Analytics.|
|Подписка    | Подписка Azure.|
|Идентификатор учетной записи      | Имя или универсальный код ресурса (URI) конечной точки учетной записи Azure Cosmos DB.|
|Ключ учетной записи     | Общедоступный ключ доступа к учетной записи Azure Cosmos DB.|
|База данных        | Имя базы данных Azure Cosmos DB.|
|Имя контейнера | Имя контейнера, например `MyContainer`. Должен существовать один контейнер с именем `MyContainer`.  |
|Идентификатор документа     | Необязательный параметр. Имя столбца в выходных событиях используется как уникальный ключ, на котором должны основываться операции вставки или обновления. Если оставить это поле пустым, все события будут вставлены без возможности обновления.|

После настройки вывода данных в Azure Cosmos DB можно использовать его в запросе в качестве целевого объекта предложения [INTO](/stream-analytics-query/into-azure-stream-analytics). Когда вы используете вывод данных в Azure Cosmos DB таким образом, [необходимо явно задать ключ секции](./stream-analytics-parallelization.md#partitions-in-inputs-and-outputs). 

Выходная запись должна содержать столбец с учетом регистра, названный так же, как ключ секции в Azure Cosmos DB. Для достижения большей параллелизации в запросе может потребоваться[ предложение PARTITION BY](./stream-analytics-parallelization.md#embarrassingly-parallel-jobs), использующее тот же столбец.

Вот пример запроса:

```SQL
    SELECT TollBoothId, PartitionId
    INTO CosmosDBOutput
    FROM Input1 PARTITION BY PartitionId
``` 

## <a name="error-handling-and-retries"></a>Обработка ошибок и повторные попытки

Если временная ошибка, недоступность службы или регулирование происходит, когда Stream Analytics отправляет события в Azure Cosmos DB, Stream Analytics продолжает попытки завершить операцию неограниченно долго. Однако повторных попыток не будет при следующих ошибках:

- Unauthorized (код ошибки HTTP 401)
- NotFound (код ошибки HTTP 404)
- Forbidden (код ошибки HTTP 403)
- BadRequest (код ошибки HTTP 400)

## <a name="common-issues"></a>Распространенные проблемы

1. В коллекцию добавляется уникальное ограничение индекса, а выходные данные из Stream Analytics нарушают это ограничение. Убедитесь, что выходные данные из Stream Analytics не нарушают ограничения UNIQUE или не удаляют ограничения. Дополнительные сведения см. [в разделе ограничения уникального ключа в Azure Cosmos DB](../cosmos-db/unique-keys.md).

2. `PartitionKey`Столбец не существует.

3. `Id`Столбец не существует.

## <a name="next-steps"></a>Дальнейшие действия

* [Описание выходных данных из Azure Stream Analytics](stream-analytics-define-outputs.md) 
* [Вывод данных Azure Stream Analytics в базу данных SQL Azure](stream-analytics-sql-output-perf.md)
* [Секционирование выходных данных пользовательского большого двоичного объекта Azure Stream Analytics](stream-analytics-custom-path-patterns-blob-storage-output.md)