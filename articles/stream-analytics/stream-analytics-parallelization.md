---
title: Использование параллелизации запросов и масштабирования в Azure Stream Analytics
description: В этой статье объясняется, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи.
author: JSeb225
ms.author: jeanb
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 05/04/2020
ms.openlocfilehash: 9149413d070bbb5eb8d0f8d0c99fe5ff705bcefb
ms.sourcegitcommit: 42a4d0e8fa84609bec0f6c241abe1c20036b9575
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/08/2021
ms.locfileid: "98012331"
---
# <a name="leverage-query-parallelization-in-azure-stream-analytics"></a>Использование параллелизации запросов в Azure Stream Analytics
В этой статье показано, как воспользоваться преимуществами параллелизма в Azure Stream Analytics. Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки аналитики определения запроса.
Предварительно может потребоваться ознакомиться с концепцией потоковой единицы, которая описана в статье [Оптимизация задания для эффективного использования единиц потоковой передачи](stream-analytics-streaming-unit-consumption.md).

## <a name="what-are-the-parts-of-a-stream-analytics-job"></a>Из каких частей состоит задание службы Stream Analytics?
Определение задания Stream Analytics включает как минимум один запрос, а также входы и выходы для потоковой передачи. Входные данные — это точки, откуда задания считывают данные из потока. Запрос используется для преобразования потока входных данных, а выходные данные являются точками, куда направляются результаты задания.

## <a name="partitions-in-inputs-and-outputs"></a>Секции во входах и выходах
Секционирование позволяет разделить данные на подмножества на основе [ключа секции](../event-hubs/event-hubs-scalability.md#partitions). Если входы (например, Центры событий) секционированы по ключу, настоятельно рекомендуется указать этот ключ секции при добавлении входов в задание Stream Analytics. Масштабирование задания Stream Analytics реализует преимущества использования секций во входах или выходах. Задание Stream Analytics может получать и записывать различные секции параллельно, тем самым повышая пропускную способность. 

### <a name="inputs"></a>Входные данные
Все входные данные в Azure Stream Analytics могут использовать преимущества секционирования:
-   Центр событий (если используется уровень совместимости 1.1 или ниже, требуется явно задать ключ секции с помощью ключевого слова PARTITION BY).
-   Центр Интернета вещей (если используется уровень совместимости 1.1 или ниже, требуется явно задать ключ раздела с помощью ключевого слова PARTITION BY).
-   Хранилище BLOB-объектов

### <a name="outputs"></a>Выходные данные

При работе со Stream Analytics можно воспользоваться преимуществами секционирования в концентраторах событий и выходных данных:
-   Azure Data Lake Storage
-   Функции Azure
-   таблице Azure
-   Хранилище BLOB-объектов (требуется явно задать ключ раздела).
-   Cosmos DB (требуется явно задать ключ раздела).
-   Центры событий (требуется явно задать ключ раздела).
-   Центр Интернета вещей (требуется явно задать ключ раздела).
-   Служебная шина
- SQL и Azure синапсе Analytics с дополнительным секционированием. Дополнительные сведения см. на [странице "выходные данные для базы данных SQL Azure](./stream-analytics-sql-output-perf.md)".

Power BI не поддерживает секционирование. Однако можно по-прежнему секционировать входные данные как описано в [этом разделе](#multi-step-query-with-different-partition-by-values). 

Дополнительные сведения об этих секциях см. в следующих статьях:

* [Обзор функций Центров событий](../event-hubs/event-hubs-features.md#partitions)
* [Секционирование данных](/azure/architecture/best-practices/data-partitioning)


## <a name="embarrassingly-parallel-jobs"></a>Задания с усложненным параллелизмом
Задание с *усложненным параллелизмом* — это самый масштабируемый сценарий в Azure Stream Analytics. Он соединяет один раздел входных данных с одним экземпляром запроса и одним разделом выходных данных. Такой параллелизм имеет следующие требования:

1. Если в логике запроса применяется ключ, который обрабатывается тем же экземпляром запроса, необходимо только проследить за тем, чтобы события попадали в ту же секцию входных данных. При использовании Центров событий или Центра Интернета вещей это означает, что для данных событий должно быть задано значение **PartitionKey**. Кроме того, можно использовать секционированные отправители. Для хранилища BLOB-объектов это означает, что события отправляются в папку той же секции. Примером может служить экземпляр запроса, который агрегирует данные по userID, где входной Центр событий секционирован с использованием userID в качестве ключа секции. Однако если логика запроса не требует обработки ключа тем же экземпляром запроса, это требование можно проигнорировать. В качестве примера такой логики можно привести простой запрос select, project или filter.  

2. Следующий шаг заключается в секционировании раздела. Для заданий с уровнем совместимости 1.2 или выше (рекомендуется) в параметрах входа можно указать пользовательский столбец в качестве ключа секции, и задание будет паралеллизовано автоматически. Для заданий с уровнем совместимости 1.0 или 1.1 необходимо использовать **PARTITION BY PartitionId** во всех шагах запроса. Этапов может быть несколько, но на каждом из них должен использоваться один и тот же ключ. 

3. Большинство выходов, поддерживаемых в Stream Analytics, могут использовать преимущества секционирования. При использовании типа выхода, который не поддерживает секционирование, задание не будет считаться заданием с *усложненным параллелизмом*. Для выходов Центра событий убедитесь, что в **столбце ключа секции** задан тот же ключ секции, который использовался в запросе. Дополнительные сведения см. в [этом разделе](#outputs).

4. Число секций входных данных должно совпадать с числом секций выходных данных. Выходные данные хранилища BLOB-объектов могут поддерживать секции и наследуют схему секционирования вышестоящего запроса. Если для хранилища BLOB-объектов указан ключ секции, то данные секционируются по входным секциям, поэтому результат по-прежнему вычисляется параллельно. Примеры значений секций, позволяющие выполнять задания с полной параллельной обработкой:

   * 8 секций входных данных концентраторов событий и 8 секций выходных данных концентраторов событий;
   * 8 секций входных данных концентраторов событий и выходные данные хранилища BLOB-объектов;
   * 8 входных секций концентраторов событий и выходные данные хранилища BLOB-объектов, секционированные по пользовательскому полю с произвольной кратностью;
   * 8 секций входных данных хранилища BLOB-объектов и выходные данные хранилища BLOB-объектов;
   * 8 секций входных данных хранилища BLOB-объектов и 8 секций выходных данных концентраторов событий.

Далее рассмотрим примеры сценариев с усложненным параллелизмом.

### <a name="simple-query"></a>Простой запрос

* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: Центр событий с 8 секциями ("столбец ключа секции" должен использовать "PartitionId").

Запрос:

```SQL
    --Using compatibility level 1.2 or above
    SELECT TollBoothId
    FROM Input1
    WHERE TollBoothId > 100
    
    --Using compatibility level 1.0 or 1.1
    SELECT TollBoothId
    FROM Input1 PARTITION BY PartitionId
    WHERE TollBoothId > 100
```

Этот запрос является простым фильтром. Поэтому нам не нужно беспокоиться о секционировании входных данных, которые передаются в концентратор событий. Обратите внимание, что для удовлетворения требованию 2 задания с уровнем совместимости, предшествующим 1.2, должны содержать предложение **PARTITION BY PartitionId**. Выходные данные концентраторов событий необходимо настроить, указав значение **PartitionId** в качестве ключа секции. Последняя проверка: число секций входных данных должно быть равно числу секций выходных данных.

### <a name="query-with-a-grouping-key"></a>Запрос с ключом группирования

* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: Хранилище BLOB-объектов

Запрос:

```SQL
    --Using compatibility level 1.2 or above
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
    
    --Using compatibility level 1.0 or 1.1
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Этот запрос содержит ключ группирования. Поэтому события, сгруппированные вместе, должны быть отправлены в одну секцию концентратора событий. Так как в этом примере выполняется группирование по TollBoothID, необходимо убедиться, что TollBoothID используется в качестве ключа секции при отправке событий в концентратор событий. Затем в ASA, можно использовать **PARTITION BY PartitionId** для наследования этой схемы разделов и обеспечения полной паралеллизации. Так как выходными данными является хранилище BLOB-объектов, не нужно беспокоиться о настройке значения ключа секции, как описано в требовании 4.

## <a name="example-of-scenarios-that-are-not-embarrassingly-parallel"></a>Примеры сценариев *без* усложненного параллелизма

В предыдущем разделе мы рассмотрели сценарии с усложненным параллелизмом. В этом разделе обсуждаются сценарии, которые не соответствуют всем показателям усложненного параллелизма. 

### <a name="mismatched-partition-count"></a>Несоответствие в числе секций
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 32 секциями.

Если число секций входа не совпадает с числом секций выхода, топология не является топологией с усложненным параллелизмом независимо от запроса. Однако по-прежнему можно получить определенный уровень или параллелизацию.

### <a name="query-using-non-partitioned-output"></a>Запрос с использованием несекционированных выходных данных
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: Power BI

В настоящее время выходные данные Power BI не поддерживают секционирование. Таким образом этот сценарий не считается сценарием с усложненным параллелизмом.

### <a name="multi-step-query-with-different-partition-by-values"></a>Многоэтапный запрос с разными значениями параметра PARTITION BY
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: концентратор событий с 8 секциями.
* Уровень совместимости: 1.0 или 1.1.

Запрос:

```SQL
    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By TollBoothId
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Как видите, на втором этапе в качестве ключа секционирования используется **TollBoothId** . Он не совпадает с ключом в первом шаге, а значит, потребует перетасовки. 

### <a name="multi-step-query-with-different-partition-by-values"></a>Многоэтапный запрос с разными значениями параметра PARTITION BY
* Входные данные: концентратор событий с 8 секциями.
* Выходные данные: Центр событий с 8 секциями ("столбец ключа секции" должен использовать "TollBoothId").
* Уровень совместимости — 1.2 и выше.

Запрос:

```SQL
    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Уровень совместимости 1.2 и выше обеспечивает параллельное выполнение запросов по умолчанию. Например, запрос из предыдущего раздела будет секционирован до тех пор, пока в качестве входного ключа секции задан столбец "TollBoothId". Предложение PARTITION BY PartitionId не требуется.

## <a name="calculate-the-maximum-streaming-units-of-a-job"></a>Расчет максимального количества единиц потоковой передачи для задания
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### <a name="steps-in-a-query"></a>Шаги в запросе
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова **WITH**. Запрос за рамками ключевого слова **WITH** (только один запрос) также учитывается в качестве шага (например, инструкция **SELECT** в следующем запросе).

Запрос:

```SQL
    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )
    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute,3), TollBoothId
```

Этот запрос включает 2 шага.

> [!NOTE]
> Этот запрос будет описан далее в этой статье.
>  

### <a name="partition-a-step"></a>Разделы шага
Разделение шага требует наличия следующих условий.

* Источник входных данных должен быть секционирован. 
* Инструкция **SELECT** запроса должна читаться из разделенного источника входных данных.
* Запрос внутри шага должен включать ключевое слово **PARTITION BY**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### <a name="calculate-the-max-streaming-units-for-a-job"></a>Рассчитайте максимальное количество единиц потоковой передачи для задания
Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Помимо этого можно добавить 6 единиц потоковой передачи для каждой секции на шаге секционирования.
Дополнительные **примеры** можно просмотреть в таблице ниже.

| Запрос                                               | Максимальное количество единиц потоковой передачи для задания |
| --------------------------------------------------- | ------------------- |
| <ul><li>Запрос содержит один шаг.</li><li>Шаг не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 16.</li><li>Запрос содержит один шаг.</li><li>Шаг является секционированным.</li></ul> | 96 (6 * 16 секций) |
| <ul><li>Запрос состоит из двух шагов.</li><li>Ни один из шагов не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 3.</li><li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li><li>Инструкция <strong>SELECT</strong> считывает из секционированных входных данных.</li></ul> | 24 (18 и 6 секционированных и несекционированных шагов соответственно) |

### <a name="examples-of-scaling"></a>Примеры масштабирования

Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии секции потока данных, равной 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

```SQL
    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
```

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **GROUP BY** не является ключом секции во входном потоке данных. Например, поле **TollBoothId** в предыдущем запросе не является ключом секции **Input1**. В результате данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций **Input1** будет обрабатываться отдельно с помощью Stream Analytics. В результате будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив несекционированные действия для вычисления значений по секциям, например:

```SQL
    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId
```

Этот запрос можно увеличить до 24 единиц потоковой передачи.

> [!NOTE]
> При объединении двух потоков убедитесь, что потоки разделены с помощью ключа секции столбца, используемого для объединения. Также убедитесь, что количество секций в обоих потоках одинаковое.
> 
> 

## <a name="achieving-higher-throughputs-at-scale"></a>Достижение более высокой пропускной способности в большом масштабе

Задание [с усложненным параллелизмом](#embarrassingly-parallel-jobs) является необходимым, но недостаточным для обеспечения высокой пропускной способности в большом масштабе. В каждой системе хранения и ее соответствующем выходе Stream Analytics доступны различные возможности для достижения наилучшей пропускной способности записи. Как и в любом крупномасштабном сценарии, существуют некоторые проблемы, которые можно устранить с помощью правильных конфигураций. В этом разделе рассматриваются конфигурации для нескольких распространенных выходов и приводятся примеры для поддержки скорости приема 1000, 5000 и 10 000 событий в секунду.

В следующих наблюдениях используется задание Stream Analytics с запросом без отслеживания состояния, базовая определяемая пользователем функция JavaScript, которая выполняет запись в Центр событий, базу данных SQL Azure или Cosmos DB.

#### <a name="event-hub"></a>Концентратор событий

|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные ресурсы  |
|--------|---------|---------|
| 1000     |    1    |  2 единицы пропускной способности   |
| 5000     |    6    |  6 единиц пропускной способности   |
| 10000    |    12   |  10 единиц пропускной способности  |

Решение [Центра событий](https://github.com/Azure-Samples/streaming-at-scale/tree/main/eventhubs-streamanalytics-eventhubs) масштабируется линейно относительно единиц потоковой передачи (SU) и пропускной способности, что делает его наиболее эффективным и производительным способом анализа и потоковой передачи данных из Stream Analytics. Задания можно масштабировать до 192 SU, что означает обработку со скоростью примерно до 200 МБ/с или 19 трлн событий в день.

#### <a name="azure-sql"></a>Azure SQL
|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные ресурсы  |
|---------|------|-------|
|    1000   |   3  |  S3   |
|    5000   |   18 |  P4   |
|    10000  |   36 |  P6   |

[Azure SQL](https://github.com/Azure-Samples/streaming-at-scale/tree/main/eventhubs-streamanalytics-azuresql) поддерживает параллельную запись, называемую наследованием секционирования, но по умолчанию она отключена. Однако включение наследования секционирования вместе с полностью параллельным запросом может быть недостаточно для достижения более высоких значений пропускной способности. Пропускная способность записи SQL значительно зависит от конфигурации базы данных и схемы таблицы. Дополнительные сведения о параметрах, позволяющих максимально увеличить пропускную способность записи, см. в статье о [выводе в базу данных SQL](./stream-analytics-sql-output-perf.md). Как отмечалось в статье [Вывод данных Azure Stream Analytics в базу данных SQL Azure](./stream-analytics-sql-output-perf.md#azure-stream-analytics), линейное масштабирование этого решения в виде полностью параллельного конвейера не выходит за рамки 8 секций, и перед выводом SQL может потребоваться повторное секционирование решения (см. раздел [INTO](/stream-analytics-query/into-azure-stream-analytics#into-shard-count)). Для обеспечения высоких скоростей ввода-вывода, а также минимизации издержек резервного копирования журналов, происходящего каждые несколько минут, необходимы номера SKU ценовой категории "Премиум".

#### <a name="cosmos-db"></a>Cosmos DB
|Скорость приема (событий в секунду) | Единицы потоковой передачи | Выходные ресурсы  |
|-------|-------|---------|
|  1000   |  3    | 20000 ЕЗ  |
|  5000   |  24   | 60000 ЕЗ  |
|  10000  |  48   | 120000 ЕЗ |

Выходные данные [Cosmos DB](https://github.com/Azure-Samples/streaming-at-scale/tree/main/eventhubs-streamanalytics-cosmosdb) из Stream Analytics были обновлены для использования встроенной интеграции на [уровне совместимости 1.2](./stream-analytics-documentdb-output.md#improved-throughput-with-compatibility-level-12). Уровень совместимости 1.2 обеспечивает значительно более высокую пропускную способность и сокращает потребление ЕЗ по сравнению с уровнем 1.1, который является уровнем совместимости по умолчанию для новых заданий. Решение использует контейнеры CosmosDB, секционированные по /deviceId, а остальная часть решения настроена аналогичным образом.

Все [потоковая передача в примерах масштабирования Azure](https://github.com/Azure-Samples/streaming-at-scale) использует концентратор событий в качестве входных данных, которые подаются при помощи моделирования нагрузки для тестовых клиентов. Каждое входное событие — это документ JSON размером 1 КБ, который легко преобразует настроенные скорости приема в скорости пропускной способности (1 МБ/с, 5 МБ/с и 10 МБ/с). События имитируют устройство Центра Интернета вещей, отправляющее следующие данные JSON (в сокращенной форме) для 1000 устройств:

```
{
    "eventId": "b81d241f-5187-40b0-ab2a-940faf9757c0",
    "complexData": {
        "moreData0": 51.3068118685458,
        "moreData22": 45.34076957651598
    },
    "value": 49.02278128887753,
    "deviceId": "contoso://device-id-1554",
    "type": "CO2",
    "createdAt": "2019-05-16T17:16:40.000003Z"
}
```

> [!NOTE]
> Поскольку в решениях могут использоваться различные компоненты, конфигурации могут быть изменены. Чтобы получить более точную оценку, настройте примеры в соответствии с имеющимся сценарием.

### <a name="identifying-bottlenecks"></a>Выявление узких мест

Для выявления узких мест в конвейере можно воспользоваться панелью "Метрики" в задании Azure Stream Analytics. Просмотрите параметры **События ввода и вывода** с данными о пропускной способности и [Предельная задержка](https://azure.microsoft.com/blog/new-metric-in-azure-stream-analytics-tracks-latency-of-your-streaming-pipeline/) или **Отложенные события**, чтобы узнать, выполняется ли задание в соответствии с входной скоростью. Чтобы просмотреть метрики Центра событий, проверьте раздел **Регулируемые запросы** и соответствующим образом скорректируйте единицы порогового значения. Чтобы просмотреть метрики Cosmos DB, проверьте параметр **Максимальное количество потребляемых единиц запросов/с в диапазоне ключей секций** в разделе пропускной способности, чтобы убедиться в равномерном использовании диапазонов ключей секций. Чтобы просмотреть метрики для базы данных SQL Azure, см. разделы **Операции ввода-вывода журнала** и **ЦП**.

## <a name="get-help"></a>Получить справку

Для получения дополнительной помощи воспользуйтесь [страницей вопросов и ответов Майкрософт об Azure Stream Analytics](/answers/topics/azure-stream-analytics.html).

## <a name="next-steps"></a>Дальнейшие действия
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Справочник по языку запросов Azure Stream Analytics](/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](/rest/api/streamanalytics/)

<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor-NewPortal.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings-NewPortal.png   

<!--Link references-->

[microsoft.support]: https://support.microsoft.com
[azure.event.hubs.developer.guide]: /previous-versions/azure/dn789972(v=azure.100)

[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: /stream-analytics-query/stream-analytics-query-language-reference
[stream.analytics.rest.api.reference]: /rest/api/streamanalytics/