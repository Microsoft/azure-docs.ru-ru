---
title: Azure Data Lake Storage вывода Gen 1 из Azure Stream Analytics
description: В этой статье описывается Azure Data Lake Storage Gen 1 в качестве варианта вывода для Azure Stream Analytics.
author: enkrumah
ms.author: ebnkruma
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 08/25/2020
ms.openlocfilehash: 629a154c89ad301a3e200b1d6cd04c62057d9959
ms.sourcegitcommit: 42a4d0e8fa84609bec0f6c241abe1c20036b9575
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/08/2021
ms.locfileid: "98016547"
---
# <a name="azure-data-lake-storage-gen-1-output-from-azure-stream-analytics"></a>Azure Data Lake Storage вывода Gen 1 из Azure Stream Analytics

Stream Analytics поддерживает выходные данные [Azure Data Lake Storage Gen 1](../data-lake-store/data-lake-store-overview.md) . Azure Data Lake Storage — это гипермасштабируемый репозиторий корпоративного уровня для аналитических рабочих нагрузок больших данных. Azure Data Lake Storage позволяет сохранять данные с любым размером, типом и скоростью приема в одном месте для эксплуатационной и исследовательской аналитики. Stream Analytics необходимо разрешение на доступ к Azure Data Lake Storage.

Azure Data Lake Storage выходные данные из Stream Analytics недоступны в регионах Azure для Китая и Германии (T-Systems Международная).

## <a name="output-configuration"></a>Конфигурация выходных данных

В таблице ниже перечислены имена свойств и их описания для настройки выходных данных Data Lake Storage 1-го поколения.

| Имя свойства | Описание |
| --- | --- |
| Псевдоним выходных данных | Понятное имя, которое используется в запросах для направления выходных данных запроса в Azure Data Lake Storage. |
| Подписка | Подписка, содержащая учетную запись Azure Data Lake Storage. |
| Имя учетной записи | Имя учетной записи Azure Data Lake Storage, в которую отправляются выходные данные. Появится раскрывающийся список учетных записей Azure Data Lake Storage, доступных в вашей подписке. |
| Шаблон префикса пути | Путь к файлу, используемый для записи файлов в указанной учетной записи Azure Data Lake Storage. Вы можете указать один или несколько экземпляров переменных {date} и {time}.<br /><ul><li>Пример 1. folder1/logs/{дата}/{время}</li><li>Пример 2. folder1/logs/{дата}</li></ul><br />Метка времени создаваемой структуры папок соответствует времени UTC, а не местному времени.<br /><br />Если шаблон пути к файлу не содержит символ "/", то последний шаблон в пути к файлу будет рассматриваться в качестве префикса имени файла. <br /><br />Новые файлы создаются в следующих ситуациях:<ul><li>изменения в схеме выходных данных;</li><li>внешний или внутренний перезапуск задания.</li></ul> |
| Формат даты | Необязательный параметр. Если в префиксе пути используется маркер даты, вы можете выбрать формат даты для упорядочивания своих файлов. Пример ГГГГ/ММ/ДД |
|Формат времени | Необязательный параметр. Если в префиксе пути используется маркер времени, укажите формат времени для упорядочивания своих файлов. В настоящее время поддерживается только один формат — ЧЧ. |
| Формат сериализации событий | Формат сериализации для выходных данных. Поддерживаются форматы JSON, CSV и Avro.|
| Кодирование | Если используется формат CSV или JSON, необходимо указать формат кодирования. В настоящее время единственным поддерживаемым форматом кодировки является UTF-8.|
| Разделитель | Применяется только для сериализации в формате CSV. Служба Stream Analytics позволяет использовать ряд распространенных разделителей для сериализации данных в формате CSV. Поддерживаются такие разделители: запятая, точка с запятой, пробел, табуляция и вертикальная черта.|
| Формат | Применяется только для сериализации в формате JSON. Вариант **строки-разделители** предусматривает форматирование выходных данных таким образом, что каждый объект JSON будет отделен новой строкой. Если выбрать вариант **строки-разделители**, то JSON считывает по одному объекту за раз. Все содержимое само по себе не будет допустимым форматом JSON.  Вариант **массив** означает, что выходные данные будут отформатированы как массив объектов JSON. Этот массив будет закрыт только в том случае, если выполнение задания будет остановлено или Stream Analytics перейдет в следующее временное окно. В общем рекомендуется использовать JSON-файл со строками-разделителями, так как для него не требуется никакой специальной обработки. При этом по-прежнему выполняется запись в выходной файл.|
| Режим проверки подлинности | Вы можете авторизовать доступ к учетной записи Data Lake Storage с помощью [управляемого удостоверения](stream-analytics-managed-identities-adls.md) (Предварительная версия) или токена пользователя. После предоставления доступ можно отозвать, изменив пароль учетной записи пользователя, удалив выходные данные Data Lake Storage для этого задания или удалив задание Stream Analytics. |

## <a name="partitioning"></a>Секционирование

Для ключа секции Используйте токены {Date} и {Time} в шаблоне префикса пути. Выберите формат даты, например гггг/мм/дд, дд/мм/гггг или мм-дд-гггг. Используйте HH в качестве формата времени. Количество модулей записи вывода соответствует входному секционированию для [полностью параллелизуемые запросов](stream-analytics-scale-jobs.md).

## <a name="output-batch-size"></a>Размер выходного пакета

Максимальный размер сообщения см. в разделе [ограничения Data Lake Storage](../azure-resource-manager/management/azure-subscription-service-limits.md#data-lake-storage-limits). Чтобы оптимизировать размер пакета, используйте до 4 МБ на операцию записи.

## <a name="next-steps"></a>Дальнейшие действия

* [Проверка подлинности Stream Analytics для Azure Data Lake Storage 1-го поколения с использованием управляемых удостоверений (Предварительная версия)](stream-analytics-managed-identities-adls.md)
* [Краткое руководство. по созданию задания Stream Analytics с помощью портала Azure](stream-analytics-quick-create-portal.md)