---
title: Повышение производительности при пропускной способности базы данных SQL Azure от Azure Stream Analytics
description: Сведения о выводе данных в SQL Azure из Azure Stream Analytics, а также об увеличении пропускной способности операций записи.
author: chetanmsft
ms.author: chetang
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 03/18/2019
ms.openlocfilehash: 8baa33c8d9622ff76db04345f5c6c465f026e261
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98020236"
---
# <a name="increase-throughput-performance-to-azure-sql-database-from-azure-stream-analytics"></a>Повышение производительности при пропускной способности базы данных SQL Azure от Azure Stream Analytics

В этой статье обсуждаются советы по повышению производительности записи при загрузке данных в базу данных SQL Azure с помощью Azure Stream Analytics.

При выводе данных в SQL из Azure Stream Analytics поддерживается запись в параллельном режиме. Эта возможность реализует топологии заданий с [полной параллельной обработкой](stream-analytics-parallelization.md#embarrassingly-parallel-jobs), когда несколько секций выходных данных могут записывать в целевую таблицу в параллельном режиме. Включение этого параметра в Azure Stream Analytics, однако, может быть недостаточно для достижения более высоких пропускной способности, так как это сильно зависит от конфигурации базы данных и схемы таблицы. Выбранные индексы, ключ кластеризации, коэффициент заполнения индекса и сжатие влияют на время загрузки таблиц. Дополнительные сведения о том, как оптимизировать базу данных для повышения производительности запросов и нагрузки на основе внутренних нагрузочных тестов, см. в [статье Руководство по производительности базы данных SQL](../azure-sql/database/performance-guidance.md). Порядок операций записи не гарантируется при параллельной записи в базу данных SQL.

Ниже приведены некоторые конфигурации каждой службы, которые позволяют повысить общую пропускную способность решения.

## <a name="azure-stream-analytics"></a>Azure Stream Analytics

- **Секционирование по наследованию**. Этот вариант конфигурации выходных данных SQL позволяет наследовать схему секционирования, используемую на предыдущем шаге запроса или с предыдущими входными данными. Если этот параметр включен, выполняется запись в таблицу на диске и присутствует задание с топологией [полной параллельной обработки](stream-analytics-parallelization.md#embarrassingly-parallel-jobs), будет прослеживаться лучшая пропускная способность. Такое секционирование автоматически выполняется для многих других [выходных данных](stream-analytics-parallelization.md#partitions-in-inputs-and-outputs). Блокировка таблицы (TABLOCK) также отключается для массовой вставки, выполняемой при использовании этого параметра.

> [!NOTE] 
> При наличии более чем 8 секций входных данных может быть нецелесообразно использовать наследование схемы секционирования входных данных. Это максимальное ограничение было обнаружено в таблице с одним столбцом идентификаторов и кластеризованным индексом. В этом случае рекомендуется использовать [в](/stream-analytics-query/into-azure-stream-analytics#into-shard-count) запросе 8, чтобы явно указать число модулей записи вывода. В зависимости от этой схемы и выбранных индексов, результаты отличаются.

- **Размер пакета.** Конфигурация выходных данных SQL позволяет указать максимальный размер пакета выходных данных Azure Stream Analytics в зависимости от характера целевой таблицы или рабочей нагрузки. Размер пакета равен максимальному числу записей, отправляемых с каждой транзакцией массовой вставки. В кластеризованных индексах columnstore для пакетов с числом строк около [100 000](/sql/relational-databases/indexes/columnstore-indexes-data-loading-guidance) можно использовать дополнительную параллелизацию, выполнять минимальное ведение журнала и блокировки. Оптимальным выбором могут быть таблицы на диске с 10 000 строк (по умолчанию) или меньше, так как большие размеры пакетов могут привести к укрупнению блокировки во время операции массовой вставки.

- **Настройка входных сообщений.** Если вы выполнили оптимизацию с использованием секционирования по наследованию и размера пакета, путем увеличения количества входных событий в сообщении на секцию можно дополнительно повысить пропускную способность записи. Путем настройки входных сообщений размеры пакетов в Azure Stream Analytics можно увеличивать вплоть до указанного размера, тем самым повышая пропускную способность. Это можно сделать с помощью [сжатия](stream-analytics-define-inputs.md) или увеличения размеров входящих сообщений в EventHub или большом двоичном объекте.

## <a name="sql-azure"></a>SQL Azure

- **Секционированная таблица и индексы.** Если использовать [секционированные](/sql/relational-databases/partitions/partitioned-tables-and-indexes) таблицу SQL и индексы для таблицы с тем же столбцом в качестве ключа секции (например, PartitionId), можно значительно уменьшить состязания между секциями во время операций записи. Для секционированной таблицы потребуется создать [функцию](/sql/t-sql/statements/create-partition-function-transact-sql) и [схему](/sql/t-sql/statements/create-partition-scheme-transact-sql) секционирования в первичной файловой группе. Это приведет к повышению уровня доступности имеющихся данных при загрузке новых данных. Может быть достигнуто ограничение операций ввода-вывода журнала в зависимости от количества секций, которые можно увеличить, обновив номер SKU.

- **Предупреждение нарушений уникальных ключей.** Если в журнале действий Azure Stream Analytics появилось [несколько предупреждающих сообщений о нарушении ключа](stream-analytics-troubleshoot-output.md#key-violation-warning-with-azure-sql-database-output), убедитесь, что на ваше задание не повлияли нарушения ограничений, которые могут произойти во время восстановления. Этого можно избежать, установив для индексов параметр [IGNORE\_DUP\_KEY](stream-analytics-troubleshoot-output.md#key-violation-warning-with-azure-sql-database-output).

## <a name="azure-data-factory-and-in-memory-tables"></a>Служба "Фабрика данных Azure" и таблицы в памяти

- **Таблица в памяти как временная таблица** — [таблицы в памяти](/sql/relational-databases/in-memory-oltp/in-memory-oltp-in-memory-optimization) обеспечивают высокую скорость загрузки данных, но данные должны помещаться в памяти. Тесты производительности демонстрируют, что массовая загрузка из таблицы в памяти в таблицу на диске примерно в 10 раз быстрее, чем во время непосредственной массовой вставки с помощью одного средства записи в дисковой таблице со столбцом идентификаторов и кластеризованным индексом. Чтобы использовать производительность массовой вставки, настройте [задание копирования с использованием службы "Фабрика данных Azure"](../data-factory/connector-azure-sql-database.md), позволяющее копировать данные из таблицы в памяти в таблицу на диске.

## <a name="avoiding-performance-pitfalls"></a>Предотвращение ловушек производительности
Выполнение операций ввода данных с помощью одной операции вставки выполняется гораздо быстрее, чем загрузка данных с отдельными вставками из-за неповторяемых издержек при передаче данных, анализе инструкции INSERT, выполнении инструкции и выдаче записи транзакции. Вместо этого в подсистеме хранилища используется более эффективный путь для потоковой передачи данных. Стоимость установки этого пути, тем не менее, намного выше, чем одна инструкция INSERT в таблице на диске. Как правило, точка останова обычно обходится около 100 строк, а это, помимо прочего, почти всегда более эффективно. 

Если частота входящих событий низкая, она позволяет легко создавать размеры пакетов, меньшие чем 100 строк, что делает неэффективным использование неэффективной групповой вставки и использует слишком много места на диске. Чтобы обойти это ограничение, можно выполнить одно из следующих действий.
* Создайте [триггер](/sql/t-sql/statements/create-trigger-transact-sql) INSTEAD для, чтобы использовать простую вставку для каждой строки.
* Используйте In-Memoryную временную таблицу, как описано в предыдущем разделе.

Другой такой сценарий происходит при записи в некластеризованный индекс columnstore (NCCI), где небольшие операции вставки могут создать слишком много сегментов, что может вызвать сбой индекса. В этом случае рекомендуется использовать кластеризованный индекс columnstore.

## <a name="summary"></a>Итоги

Таким образом, если использовать функцию секционирования выходных данных в Azure Stream Analytics для выходных данных SQL, согласованная параллелизация задания с секционированной таблицей в SQL Azure может обеспечить значительные усовершенствования пропускной способности. Использование службы "Фабрика данных Azure" для оркестрации перемещения данных из таблицы в памяти в таблицы на диске позволяет достичь значительного увеличения пропускной способности. Если это целесообразно, повышение плотности сообщений также может быть важным фактором для улучшения общей пропускной способности.
