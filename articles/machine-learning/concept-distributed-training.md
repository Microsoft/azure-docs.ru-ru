---
title: Что такое распределенное обучение?
titleSuffix: Azure Machine Learning
description: Узнайте, какой тип распределенных обучающих Машинное обучение Azure поддерживает, а также интеграции с платформой с открытым исходным кодом, доступными для распределенного обучения.
services: machine-learning
ms.service: machine-learning
author: nibaccam
ms.author: nibaccam
ms.subservice: core
ms.topic: conceptual
ms.date: 03/27/2020
ms.openlocfilehash: f87175500fcf5bdbcf9a5c2f499f6bab96b37b63
ms.sourcegitcommit: 15d27661c1c03bf84d3974a675c7bd11a0e086e6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/09/2021
ms.locfileid: "102498971"
---
# <a name="distributed-training-with-azure-machine-learning"></a>Распределенное обучение с помощью Машинное обучение Azure

В этой статье вы узнаете о распределенном обучении и о том, как Машинное обучение Azure поддерживает его для моделей глубокого обучения. 

В распределенном обучении Рабочая нагрузка для обучения модели разделяется и совместно используется несколькими мини-процессорами, называемыми рабочими узлами. Эти рабочие узлы работают параллельно, чтобы ускорить обучение модели. Распределенное обучение можно использовать для традиционных моделей МАШИНного обучения, но оно лучше подходит для вычислений и ресурсоемких задач, таких как [глубокое обучение](concept-deep-learning-vs-machine-learning.md) для обучения глубоко нейронных сетей. 

## <a name="deep-learning-and-distributed-training"></a>Глубокое обучение и распределенное обучение 

Существует два основных типа распределенного обучения: [параллелизм данных](#data-parallelism) и [параллелизм моделей](#model-parallelism). Для распределенного обучения по моделям глубокого обучения [пакет SDK для машинное обучение Azure в Python](/python/api/overview/azure/ml/intro) поддерживает интеграцию с популярными платформами, PyTorch и TensorFlow. Обе платформы используют параллелизм данных для распределенного обучения и могут использовать [хоровод](https://horovod.readthedocs.io/en/latest/summary_include.html) для оптимизации скорости вычислений. 

* [Распределенное обучение с использованием PyTorch](how-to-train-pytorch.md#distributed-training)

* [Распределенное обучение с помощью TensorFlow](how-to-train-tensorflow.md#distributed-training)

Для моделей ML, для которых не требуется распределенное обучение, см. статью [обучение моделей с помощью машинное обучение Azure](concept-train-machine-learning-model.md#python-sdk) для различных способов обучения моделей с использованием пакета SDK для Python.

## <a name="data-parallelism"></a>Параллелизм данных

Параллелизм данных — это самый простой способ реализации двух подходов к распределенному обучению, который достаточно для большинства вариантов использования.

При таком подходе данные делятся на секции, где количество секций равно общему количеству доступных узлов в кластере вычислений. Модель копируется на каждый из этих рабочих узлов, и каждый рабочий процесс работает с собственным подмножеством данных. Помните, что каждый узел должен иметь емкость для поддержки модели, для которой выполняется обучение, то есть модель должна полностью соответствовать каждому узлу. На следующей схеме показана визуальная демонстрация этого подхода.

![Data-parallelism-концепция-схема](./media/concept-distributed-training/distributed-training.svg)

Каждый узел независимо рассчитывает ошибки между прогнозами для учебных примеров и выходных данных с метками. В свою очередь, каждый узел обновляет свою модель на основе ошибок и должен передать все изменения на другие узлы, чтобы обновить соответствующие модели. Это означает, что рабочие узлы должны синхронизировать параметры модели или градиенты в конце пакетного вычисления, чтобы убедиться в том, что они обучены единообразной моделью. 

## <a name="model-parallelism"></a>Параллелизм модели

В случае параллелизма модели, также известной как параллелизм сети, модель делится на разные части, которые могут выполняться параллельно на разных узлах, и каждый из них будет выполняться на одних и тех же данных. Масштабируемость этого метода зависит от степени параллелизации алгоритма задачей, и ее реализация сложнее, чем параллелизм данных. 

В случае параллелизма модели рабочие узлы должны синхронизировать общие параметры, как правило, один раз для каждого этапа перенаправления вперед или обратного распространения. Кроме того, более крупные модели не являются проблемой, так как каждый узел работает с подразделом модели для тех же обучающих данных.

## <a name="next-steps"></a>Дальнейшие действия

* Узнайте, как [использовать целевые объекты вычислений для обучения модели](how-to-set-up-training-targets.md) с помощью пакета SDK для Python.
* Технический пример см. в статье [сценарий эталонной архитектуры](/azure/architecture/reference-architectures/ai/training-deep-learning).
* [Обучение моделей ml с помощью TensorFlow](how-to-train-tensorflow.md).
* [Обучение моделей ml с помощью PyTorch](how-to-train-pytorch.md).