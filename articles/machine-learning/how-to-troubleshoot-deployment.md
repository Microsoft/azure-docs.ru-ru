---
title: Устранение неполадок при удаленном развертывании моделей
titleSuffix: Azure Machine Learning
description: Узнайте, как обойти и устранить некоторые распространенные ошибки развертывания DOCKER с помощью службы Kubernetes Azure и экземпляров контейнеров Azure.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
author: gvashishtha
ms.author: gopalv
ms.date: 11/25/2020
ms.topic: troubleshooting
ms.custom: contperf-fy20q4, devx-track-python, deploy, contperf-fy21q2
ms.openlocfilehash: 8bec083e62bec6a0311487c1e64e780ad14f451b
ms.sourcegitcommit: e6de1702d3958a3bea275645eb46e4f2e0f011af
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/20/2021
ms.locfileid: "102518269"
---
# <a name="troubleshooting-remote-model-deployment"></a>Устранение неполадок при удаленном развертывании моделей 

Узнайте, как устранять неполадки и устранять распространенные ошибки, которые могут возникнуть при развертывании модели в службе "экземпляры контейнеров Azure" (ACI) и Azure Kubernetes Service (AKS) с помощью Машинное обучение Azure.

> [!NOTE]
> При развертывании модели в службе Kubernetes Azure (AKS) мы рекомендуем включить [Azure Monitor](../azure-monitor/containers/container-insights-enable-existing-clusters.md) для этого кластера. Это поможет понять общую работоспособность кластера и использование ресурсов. Вы также можете найти следующие полезные ресурсы:
>
> * [Проверка событий Работоспособность ресурсов, влияющих на кластер AKS](../aks/aks-resource-health.md)
> * [Диагностика службы Kubernetes Azure](../aks/concepts-diagnostics.md)
>
> Если вы пытаетесь развернуть модель в неработоспособном или перегруженном кластере, то ожидается проблема. Если вам нужна помощь в устранении неполадок с кластером AKS, обратитесь в службу поддержки AKS.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**. Попробуйте [бесплатную или платную версию Машинного обучения Azure](https://aka.ms/AMLFree).
* [Пакет SDK для Машинного обучения Azure](/python/api/overview/azure/ml/install).
* [Интерфейс командной строки Azure](/cli/azure/install-azure-cli).
* [Расширение CLI для Машинного обучения Azure](reference-azure-machine-learning-cli.md).

## <a name="steps-for-docker-deployment-of-machine-learning-models"></a>Шаги для развертывания DOCKER в моделях машинного обучения

При развертывании модели для нелокальных вычислений в Машинное обучение Azure происходят следующие действия.

1. Dockerfile, указанный в объекте среды в Инференцеконфиг, отправляется в облако вместе с содержимым исходного каталога.
1. Если ранее созданный образ в реестре контейнеров недоступен, новый образ DOCKER создается в облаке и сохраняется в реестре контейнеров по умолчанию для рабочей области.
1. Образ DOCKER из реестра контейнеров загружается в целевой объект вычислений.
1. Хранилище больших двоичных объектов по умолчанию подключено к целевому объекту вычислений, предоставляя доступ к зарегистрированным моделям.
1. Веб-сервер инициализируется путем запуска функции сценария записи. `init()`
1. Когда развернутая модель получает запрос, `run()` функция обрабатывает этот запрос.

Основное различие при использовании локального развертывания состоит в том, что образ контейнера строится на локальном компьютере, поэтому для локального развертывания необходимо установить DOCKER.

Понимание этих общих шагов должно помочь понять, где возникают ошибки.

## <a name="get-deployment-logs"></a>Получение журналов развертывания

Первым шагом при отладке ошибок является получение журналов развертывания. Сначала следуйте [инструкциям](how-to-deploy-and-where.md#connect-to-your-workspace) по подключению к рабочей области.

# <a name="azure-cli"></a>[Azure CLI](#tab/azcli)

Чтобы получить журналы из развернутой службы WebService, сделайте следующее:

```bash
az ml service get-logs --verbose --workspace-name <my workspace name> --name <service name>
```

# <a name="python"></a>[Python](#tab/python)


При условии, что имеется объект типа с `azureml.core.Workspace` именем `ws` , можно сделать следующее:

```python
print(ws.webservices)

# Choose the webservice you are interested in

from azureml.core import Webservice

service = Webservice(ws, '<insert name of webservice>')
print(service.get_logs())
```

---

## <a name="debug-locally"></a>Отладка в локальной среде

Если при развертывании модели в ACI или AKS возникли проблемы, разверните ее как локальную веб-службу. Использование локальной веб-службы упрощает устранение неполадок. Чтобы устранить неполадки развертывания локально, см. [статью об устранении неполадок в локальной](./how-to-troubleshoot-deployment-local.md)среде.

## <a name="container-cannot-be-scheduled"></a>Контейнер невозможно запланировать

При развертывании службы в целевой объект вычислений Службы Azure Kubernetes Машинное обучение Azure попытается запланировать службу с запрошенным количеством ресурсов. Если в кластере нет доступных узлов с соответствующим объемом ресурсов через 5 минут, развертывание завершится сбоем. Сообщение об ошибке: `Couldn't Schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00` . Эту ошибку можно решить, добавив дополнительные узлы, изменив номера SKU узлов или изменив требования к ресурсам службы. 

Сообщение об ошибке обычно указывает, какой ресурс требуется больше, например, если отображается сообщение об ошибке, указывающее на то, `0/3 nodes are available: 3 Insufficient nvidia.com/gpu` что для службы требуются GPU, а в кластере есть три узла, на которых нет доступных графических процессоров. Эту проблему можно решить, добавив больше узлов при использовании SKU-номера GPU. В противном случае переключитесь на SKU с поддержкой GPU или измените среду, убрав необходимость использования GPU.  

## <a name="service-launch-fails"></a>Сбой запуска службы

После успешной сборки образа система пытается запустить контейнер с использованием конфигурации развертывания. В ходе процесса запуска контейнера системой вызывается функция `init()` в скрипте оценки. При наличии неперехваченных исключений в функции `init()` в сообщении об ошибке может появиться ошибка **CrashLoopBackOff**.

Используйте сведения в статье [Проверка журнала DOCKER](how-to-troubleshoot-deployment-local.md#dockerlog) .

## <a name="function-fails-get_model_path"></a>Ошибка выполнения функции: get_model_path()

Часто в рамках функции `init()` в скрипте оценки вызывается функция [Model.get_model_path()](/python/api/azureml-core/azureml.core.model.model#get-model-path-model-name--version-none---workspace-none-), чтобы найти файл модели или папку с файлами модели в контейнере. Если файл или папку модели найти не удается, происходит сбой функции. Самый простой способ устранить эту ошибку — это выполнить приведенный ниже код Python в оболочке контейнера.

```python
from azureml.core.model import Model
import logging
logging.basicConfig(level=logging.DEBUG)
print(Model.get_model_path(model_name='my-best-model'))
```

Этот пример выводит локальный путь (относительно `/var/azureml-app`) в контейнер, где скрипт оценки ожидает найти файл модели или папку с файлами. Затем можно проверить, действительно ли файл или папка находится там, где нужно.

При установке уровня ведения журнала DEBUG (для отладки) в нем может регистрироваться дополнительная информация, которая может быть полезна для определения причины сбоя.

## <a name="function-fails-runinput_data"></a>Ошибка выполнения функции: run(input_data)

Если служба успешно развернута, но аварийно завершает работу при публикации данных в конечную точку оценки, можно добавить оператор для перехвата ошибок в функцию `run(input_data)`, чтобы она возвращала подробное сообщение об ошибке. Пример:

```python
def run(input_data):
    try:
        data = json.loads(input_data)['data']
        data = np.array(data)
        result = model.predict(data)
        return json.dumps({"result": result.tolist()})
    except Exception as e:
        result = str(e)
        # return error message back to the client
        return json.dumps({"error": result})
```

**Примечание.** Возврат сообщений об ошибках из вызова `run(input_data)` следует выполнять только в целях отладки. Из соображений безопасности сообщения об ошибках не нужно возвращать таким способом в рабочей среде.

## <a name="http-status-code-502"></a>Код состояния HTTP 502

Код состояния 502 указывает, что в службе создано исключение или в методе `run()` файла score.py произошла ошибка. Используйте сведения из этой статьи для отладки файла.

## <a name="http-status-code-503"></a>Код состояния HTTP 503

Развертывания Службы контейнеров Azure поддерживают автомасштабирование, что позволяет добавлять реплики для поддержки дополнительной загрузки. Автомасштабирование предназначено для управления **постепенной** сменой нагрузки. В случае высоких скачков в запросах в секунду клиенты могут получить код состояния HTTP 503. Несмотря на то, что Автомасштабирование реагирует быстро, для создания дополнительных контейнеров требуется AKS значительное количество времени.

Решения для увеличения или уменьшения масштаба основываются на использовании текущих реплик контейнеров. Количество занятых реплик (обработка запроса), деленное на общее число текущих реплик, является текущим использованием. Если это число превышает `autoscale_target_utilization` , то создаются дополнительные реплики. Если он меньше, то реплики будут сокращены. Решения по добавлению реплик выполняются быстро и быстрее (около 1 секунды). Решения об удалении реплик являются консервативными (около 1 минуты). По умолчанию для автомасштабирования используется значение **70%**. Это означает, что служба может обслуживать пиковые значения в запросах в секунду (RPS) **до 30%**.

Предотвратить появление кода состояния 503 можно двумя способами:

> [!TIP]
> Эти два подхода можно использовать по отдельности или в сочетании.

* Измените уровень использования, при котором автоматическое масштабирование создает новые реплики. Вы можете настроить целевое использование, задав для `autoscale_target_utilization` более низкое значение.

    > [!IMPORTANT]
    > Это изменение не *ускорит* создание реплик. Просто они будут создаваться с более низким порогом использования. Вместо того, чтобы ждать, пока служба использует реплики на 70 %, измените значения на 30 %. Таким образом реплики будут создаваться при использовании 30 %.
    
    Если веб-служба уже использует все текущие реплики, а код состояния 503 не исчезает, увеличьте значение `autoscale_max_replicas`, чтобы повысить максимальное количество реплик.

* Измените минимальное количество реплик. Увеличение минимального количества реплик обеспечивает больший пул для обработки входящих пиков.

    Чтобы увеличить минимальное количество реплик, задайте для `autoscale_min_replicas` более высокое значение. Вы можете рассчитать необходимое количество реплик с помощью следующего кода, указав необходимые для вашего проекта значения:

    ```python
    from math import ceil
    # target requests per second
    targetRps = 20
    # time to process the request (in seconds)
    reqTime = 10
    # Maximum requests per container
    maxReqPerContainer = 1
    # target_utilization. 70% in this example
    targetUtilization = .7

    concurrentRequests = targetRps * reqTime / targetUtilization

    # Number of container replicas
    replicas = ceil(concurrentRequests / maxReqPerContainer)
    ```

    > [!NOTE]
    > Если пики запроса будут превышать новое минимальное количество реплик, снова отобразится код 503. Например, по мере увеличения трафика, поступающего в вашу службу, может потребоваться увеличение минимального количества реплик.

Дополнительные сведения о настройке `autoscale_target_utilization`, `autoscale_max_replicas` и `autoscale_min_replicas` см. на [этой странице](/python/api/azureml-core/azureml.core.webservice.akswebservice).

## <a name="http-status-code-504"></a>Код состояния HTTP 504

Код состояния 504 указывает на истечение времени ожидания запроса. Время ожидания по умолчанию составляет 1 минуту.

Вы можете увеличить время ожидания или попытаться ускорить службу, изменив файл score.py для удаления ненужных вызовов. Если проблема не исчезнет, используйте сведения из этой статьи для отладки файла score.py. Код может находиться в неотвечающем состоянии или в бесконечном цикле.

## <a name="other-error-messages"></a>Другие сообщения об ошибках

Выполните следующие действия для следующих ошибок:

|Ошибка  | Решение  |
|---------|---------|
|Ошибка при создании образа при развертывании веб-службы     |  Добавьте "Пинакл = = 1.2.1" в качестве зависимости PIP к файлу Conda для конфигурации образа.       |
|`['DaskOnBatch:context_managers.DaskOnBatch', 'setup.py']' died with <Signals.SIGKILL: 9>`     |   Измените номер SKU для виртуальных машин, используемых в развертывании, на один с большим объемом памяти. |
|Сбой FPGA     |  Вы не сможете развернуть модели на FPGA до тех пор, пока не будет запрошена и одобрена квота FPGA. Чтобы запросить доступ, заполните форму запроса квоты: https://aka.ms/aml-real-time-ai       |

## <a name="advanced-debugging"></a>Расширенная отладка

Возможно, потребуется интерактивная отладка кода Python, содержащегося в развертывании модели. Например, если начальный сценарий не работает и причину невозможно определить с помощью дополнительного ведения журнала. С помощью Visual Studio Code и дебугпи можно присоединяться к коду, выполняющемуся в контейнере DOCKER.

Дополнительные сведения см. в [разделе Интерактивная Отладка в VS Code Guide](how-to-debug-visual-studio-code.md#debug-and-troubleshoot-deployments).

## <a name="model-deployment-user-forum"></a>[Форум пользователя по развертыванию модели](/answers/topics/azure-machine-learning-inference.html)

## <a name="next-steps"></a>Дальнейшие действия

Дополнительные сведения о развертывании см. в статьях, представленных ниже.

* [Развертывание моделей с помощью Службы машинного обучения Azure](how-to-deploy-and-where.md)
* [Руководство. Обучение и развертывание моделей](tutorial-train-models-with-aml.md)
* [Локальное выполнение экспериментов и их отладка](./how-to-debug-visual-studio-code.md)