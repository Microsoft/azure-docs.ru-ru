---
title: 'ML Studio (классическая модель): импорт обучающих данных в Azure'
description: Импорт данных в Машинное обучение Azure Studio (классическая модель) из различных источников данных. Узнайте, какие типы данных и форматы данных поддерживаются.
services: machine-learning
ms.service: machine-learning
ms.subservice: studio-classic
ms.topic: how-to
author: likebupt
ms.author: keli19
ms.custom: previous-author=heatherbshapiro, previous-ms.author=hshapiro
ms.date: 02/01/2019
ms.openlocfilehash: db5f3cc4b9530c4aeac40786756b36cc0ac98728
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "100520380"
---
# <a name="import-your-training-data-into-azure-machine-learning-studio-classic-from-various-data-sources"></a>Импорт обучающих данных в Машинное обучение Azure Studio (классическая модель) из различных источников данных

**ПРИМЕНИМО К:**  ![Применимо к.](../../../includes/media/aml-applies-to-skus/yes.png)Студия машинного обучения (классическая)   ![Неприменимо к.](../../../includes/media/aml-applies-to-skus/no.png)[Машинное обучение Azure](../overview-what-is-machine-learning-studio.md#ml-studio-classic-vs-azure-machine-learning-studio)


Чтобы использовать собственные данные в Машинное обучение Studio (классическая модель) для разработки и обучения решения для прогнозной аналитики, можно использовать следующие данные: 

* **локальный файл**, заранее отправляйте данные из жесткого диска, чтобы создать модуль набора данных в рабочей области;
* **источники данных в Интернете**, чтобы получать данные в ходе эксперимента с помощью модуля [Импорт данных][import-data];
* **Эксперименты машинное обучение Studio (классическая модель)** — использование данных, сохраненных в качестве набора данных в машинное обучение Studio (классическая модель)
* [**SQL Server база**](use-data-from-an-on-premises-sql-server.md) данных — использование данных из базы данных SQL Server без необходимости вручную копировать данные

> [!NOTE]
> В Машинное обучение Studio (классическая модель) доступно несколько примеров наборов данных, которые можно использовать для обучения. Дополнительные сведения см. в разделе [Использование образцов наборов данных в машинное обучение Azure Studio (классическая модель)](use-sample-datasets.md).

## <a name="prepare-data"></a>Подготовка данных

Машинное обучение Studio (классическая модель) предназначен для работы с прямоугольными или табличными данными, такими как текстовые данные с разделителями или структурированными данными из базы данных, хотя в некоторых обстоятельствах могут использоваться непрямоугольные данные.

Рекомендуется, чтобы данные были относительно очищены перед импортом в Studio (классическая модель). Например, обратите внимание на строки без кавычек.

Однако в среде Studio (классическая модель) доступны модули, которые позволяют реализовать некоторую обработку данных в эксперименте после импорта данных. В зависимости от алгоритмов машинного обучения, которые вы будете использовать, необходимо решить, как будут обрабатываться структурные трудности в данных, например отсутствующие значения и разреженные данные, и существуют ли модули, которые могут здесь помочь. В разделе **Преобразование данных** палитры модулей найдите модули, которые выполняют такие функции.

В любой точке вашего эксперимента можно просмотреть или скачать данные, созданные модулем, щелкнув правой кнопкой мыши порт вывода. В зависимости от модуля могут быть доступны различные варианты загрузки, или вы можете визуализировать данные в веб-браузере в среде Studio (классическая модель).

## <a name="supported-data-formats-and-data-types"></a>Поддерживаемые форматы и типы данных

В свой эксперимент можно импортировать значительное количество типов данных, в зависимости от того, какая система используется для импорта данных и каков источник этих данных:

* Обычный текст (TXT)
* Текст с разделителями-запятыми с заголовком (CSV) или без заголовка (NH.CSV)
* Текст с разделителями-табуляциями с заголовком (TSV) или без заголовка (NH.TSV)
* Файл Excel
* Таблица Azure
* Таблица Hive
* Таблицы базы данных SQL
* Значения OData
* данные SVMLight (SVMLIGHT) (подробнее о формате см. в [определении SVMLight](http://svmlight.joachims.org/));
* данные в формате ARFF (подробнее о формате см. в [определении ARFF](https://www.cs.waikato.ac.nz/ml/weka/arff.html));
* ZIP-файл (ZIP)
* Файл объекта или рабочей области R (RData)

При импорте данных в формате, например ARFF, содержащем метаданные, в студии (классическая модель) эти метаданные используются для определения заголовка и типа данных каждого столбца.

При импорте данных, например формата TSV или CSV, которые не включают эти метаданные, Studio (классическая модель) выводит тип данных для каждого столбца, выполнив выборку данных. Если в данных нет заголовков столбцов, в студии (классическая модель) будут указаны имена по умолчанию.

Вы можете явно указать или изменить заголовки и типы данных для столбцов с помощью модуля [Изменить метаданные][edit-metadata].

Следующие типы данных распознаются в студии (классическая модель):

* Строка
* Целое число
* Double
* Логический
* DateTime
* TimeSpan

Для передачи данных между модулями Студия использует внутренний тип данных, который называется ***Таблица данных***. Данные можно явно преобразовать в формат таблицы данных с использованием модуля [преобразования в набор данных][convert-to-dataset].

Любой модуль, который принимает форматы, отличные от таблицы данных, перед передачей данных в следующий модуль преобразует данные в формат таблицы данных без вмешательства пользователя.

При необходимости можете преобразовать формат таблицы данных обратно в формат CSV, TSV, ARFF или SVMLight, используя другие модули преобразования.
Узнать о модулях, которые выполняют эти функции, можно узнать в разделе **Преобразование форматов данных** палитры модулей.

## <a name="data-capacities"></a>Емкости данных

Модули в Машинное обучение Studio (классическая модель) поддерживают наборы данных размером до 10 ГБ, которые используются для распространенных вариантов использования. Если модуль принимает несколько видов входных данных, то их общий объем должен составлять 10 ГБ. Вы можете создать выборку больших наборов данных с помощью запросов Hive или Базы данных SQL Azure или предварительной обработки модуля "Обучение на основе счетчиков" перед импортом данных.  

Следующие типы данных можно развернуть в большие наборы данных при нормализации признаков. Максимальный объем этих данных — менее 10 ГБ:

* разреженные;
* категориальные;
* Строки
* Двоичные данные

В следующих модулях можно использовать наборы данных объемом менее 10 ГБ:

* модули системы рекомендаций;
* модуль метода увеличения числа примеров миноритарного класса с помощью синтетических объектов (SMOTE);
* модули написания сценариев: R, Python, SQL;
* модули, в которых объем выходных данных может превышать объем входных данных, такие как "Слияние" или "Хэширование признаков";
* "Перекрестная проверка", "Гиперпараметры модели настройки", "Порядковая регрессия" и "Многоклассовая классификация «один — все»", когда число итераций очень велико.

Для наборов данных объемом больше, чем несколько гигабайт, требуется передать данные в службу хранилища Azure или Базу данных SQL Azure либо использовать HDInsight, а не отправлять данные прямо из локального файла.

Вы можете найти сведения о данных изображений в ссылке на модуль [Импорт образов](/azure/machine-learning/studio-module-reference/import-images#bkmk_Notes).

## <a name="import-from-a-local-file"></a>Импорт из локального файла

Вы можете передать файл данных с жесткого диска, чтобы использовать его в качестве обучающих данных в студии (классическая модель). При импорте файла данных, можете создать модуль набора данных, который готов для использования в экспериментах рабочей области.

Чтобы импортировать данные из локального жесткого диска, выполните следующие действия:

1. В нижней части окна Studio (классическая модель) щелкните **+ создать** .
2. Выберите **Набор данных** и **From local file** (Из локального файла).
3. В диалоговом окне **отправить новый набор данных** перейдите к файлу, который необходимо передать.
4. Введите имя, укажите тип данных и, при необходимости, введите описание. Рекомендуем ввести описание — оно позволяет записать все характеристики данных, которые необходимо помнить при использовании данных в будущем.
5. Флажок **Это новая версия существующего набора данных** позволяет обновить существующий набор данных новыми данными. Чтобы выполнить это, установите флажок, а затем введите имя существующего набора данных.

![Передача нового набора данных](./media/import-data/upload-dataset-from-local-file.png)

Время передачи зависит от объема данных и скорости подключения к службе. Если известно, что файл займет много времени, вы можете выполнять другие задачи в среде Studio (классическая модель). Тем не менее закрытие браузера до завершения загрузки данных приведет к ошибке передачи данных.

После загрузки данные сохраняются в модуле набора данных и доступны для любого эксперимента в рабочей области.

При редактировании эксперимента вы можете найти ранее отправленные наборы данных в списке **My Datasets** (Мои наборы данных), который входит в список **Saved Datasets** (Сохраненные наборы данных), в палитре модулей. Перетащите набор данных на холст эксперимента, где нужно использовать эти данные для последующего анализа и машинного обучения.

## <a name="import-from-online-data-sources"></a>Импорт из сетевых источников данных

Используя модуль [Импорт данных][import-data], ваш эксперимент может импортировать данные из различных подключенных источников данных во время проведения эксперимента.

> [!NOTE]
> Эта статья содержит общие сведения о модуле [Импорт данных][import-data]. Дополнительные сведения о типах данных, к которым можно получить доступ, форматах, параметрах, а также ответы на часто задаваемые вопросы см. в разделе справки по модулю [Импорт данных][import-data].

Вы можете получить доступ к данным из одного из нескольких подключенных источников данных во время запуска эксперимента с помощью модуля [Импорт данных][import-data].

* URL-адрес с использованием HTTP;
* Hadoop с использованием HiveQL
* хранилище BLOB-объектов Azure.
* Таблица Azure
* База данных SQL Azure. Управляемый экземпляр SQL или SQL Server
* поставщик веб-канала данных (в настоящее время OData).
* Azure Cosmos DB

Так как доступ к этим данным для обучения осуществляется во время эксперимента, они доступны только в рамках этого эксперимента. Для сравнения: данные, хранящиеся в модуле набора данных, доступны для любого эксперимента в рабочей области.

Чтобы получить доступ к сетевым источникам данных в эксперименте Studio (классическая модель), добавьте модуль [Импорт данных][import-data] в эксперимент. Затем выберите **Запустить мастер импорта данных** в разделе **Свойства**, чтобы получить пошаговые инструкции по выбору и настройке источника данных. Кроме того, вы можете вручную выбрать **Источник данных** в разделе **Свойства** и указать параметры, необходимые для доступа к данным.

Поддерживаемые сетевые источники данных описаны в таблице ниже. Кроме того, в этой таблице перечислены поддерживаемые форматы файлов и параметры, используемые для доступа к данным.

> [!IMPORTANT]
> В настоящее время модули [Импорт данных][import-data] и [Экспорт данных][export-data] могут читать и записывать только данные в службе хранилища Azure, созданной с помощью классической модели развертывания. Другими словами, новый тип учетной записи хранилища BLOB-объектов Azure, предоставляющий "горячий" или "холодный" уровень доступа к хранилищу, не еще поддерживается.
>
> Как правило, это не повлияет на учетные записи хранения Azure, созданные до появления данного уровня служб.
> Если необходимо создать учетную запись, выберите **классическую** модель развертывания или используйте Resource Manager и в качестве **типа учетной записи** выберите **Общее назначение**, а не **Хранилище BLOB-объектов**.
>
> Дополнительные сведения см. в разделе [Хранилище BLOB-объектов Azure: "горячий" и "холодный" уровни хранилища](../../storage/blobs/storage-blob-storage-tiers.md).

### <a name="supported-online-data-sources"></a>Поддерживаемые сетевые источники данных
Модуль **импорта данных** машинное обучение Azure Studio (классический) поддерживает следующие источники данных:

| Источник данных | Описание | Параметры |
| --- | --- | --- |
| URL-адрес с использованием протокола HTTP |Считывает данные в файлах с разделителями-запятыми (CSV), файлах с разделителями-табуляциями (TSV), а также в файлах в формате ARFF и SVM-light из любого URL-адреса, использующего протокол HTTP. |<b>URL-адрес</b>. Задает полное имя файла, включая URL-адрес сайта и имя файла с любым расширением. <br/><br/><b>Формат данных</b>. Задает один из поддерживаемых форматов данных: CSV, TSV, ARFF или SVM-light. Если данные содержат строку заголовков, она используется для назначения имен столбцов. |
| Hadoop/HDFS |Считывает данные из распределенного хранилища в Hadoop. Необходимые вам данные можно указать с помощью HiveQL, языка запросов на основе SQL. HiveQL также можно использовать для агрегирования данных и выполнения фильтрации данных перед добавлением данных в студию Studio (классическая модель). |<b>Hive database query</b> (Запрос к базе данных Hive). Указывает запрос Hive, используемый для создания данных.<br/><br/><b>HCatalog server URI</b> (URI сервера HCatalog). Задает имя кластера в формате *&lt;имя_кластера&gt;.azurehdinsight.net*.<br/><br/><b>Hadoop user account name</b> (Имя учетной записи пользователя Hadoop). Задает имя учетной записи пользователя Hadoop для подготовки кластера.<br/><br/><b>Hadoop user account password</b> (Пароль учетной записи пользователя Hadoop). Задает учетные данные, используемые при подготовке кластера. Дополнительные сведения см. в статье [Создание кластеров Hadoop в HDInsight](../../hdinsight/hdinsight-hadoop-provision-linux-clusters.md).<br/><br/><b>Location of output data</b> (Расположение выходных данных). Указывает, где хранятся данные: в распределенной файловой системе Hadoop (HDFS) или в Azure. <br/><ul>Если выходные данные хранятся в HDFS, укажите универсальный код ресурса (URI) сервера HDFS. (не забудьте указать имя кластера HDInsight без префикса HTTPS://). <br/><br/>Если выходные данные хранятся в Azure, необходимо указать имя учетной записи хранения Azure, ключ доступа к хранилищу и имя контейнера хранилища.</ul> |
| База данных SQL |Считывает данные, хранящиеся в базе данных SQL Azure, Управляемый экземпляр SQL или в SQL Server базе данных, работающей на виртуальной машине Azure. |<b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><ul>Если используется база данных SQL Azure, введите создаваемое имя сервера. Обычно он имеет форму *&lt; generated_identifier &gt; . Database.Windows.NET.* <br/><br/>В случае с SQL Server, размещенным на виртуальной машине Azure *, введите TCP: &lt; DNS-имя виртуальной машины &gt; , 1433*</ul><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Server user account name</b> (Имя учетной записи пользователя сервера). Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Server user account password</b> (Пароль учетной записи пользователя сервера). Задает пароль для учетной записи указанного пользователя.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| Локальная база данных SQL |Считывает данные, хранящиеся в базе данных SQL. |<b>Шлюз данных</b>. Задает имя шлюза управления данными, установленного на компьютере, имеющем доступ к базе данных SQL Server. Сведения о настройке шлюза см. в статье [Выполнение расширенной аналитики с помощью машинное обучение Azure Studio (классическая модель) с использованием данных из SQL Server](use-data-from-an-on-premises-sql-server.md).<br/><br/><b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Server user account name</b> (Имя учетной записи пользователя сервера). Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Имя пользователя и пароль</b>. Чтобы ввести учетные данные базы данных, щелкните <b>Введите значения</b>. Можно использовать встроенную проверку подлинности Windows или проверку подлинности SQL Server в зависимости от настройки SQL Server.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| таблице Azure |Считывает данные из службы таблиц в хранилище Azure.<br/><br/>Если вам нечасто требуется считывание больших объемов данных, используйте службу таблиц Azure. Это недорогое и гибкое нереляционное (NoSQL) решение хранилища с высокой степенью масштабируемости и доступности. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account. Каждое из этих значений имеет собственный набор параметров. <br/><br/><b>Public or Shared Access Signature (SAS) URI</b> (URI общедоступного или подписанного URL-адреса (SAS)). Используются следующие параметры.<br/><br/><ul><b>Table URI</b> (URI таблицы). Задает общедоступный или подписанный URL-адрес (SAS) таблицы.<br/><br/><b>Specifies the rows to scan for property names</b> (Указывает строки для поиска имен свойств). Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице. <br/><br/>Если данные однородные и прогнозируемые, рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы с использованием наборов свойств, которые различаются в зависимости от глубины и положения таблицы, выберите параметр *ScanAll* для сканирования всех строк. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/></ul><b>Private Storage Account</b> (Частная учетная запись хранения). Параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей таблицу, выбранную для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Имя таблицы</b>. Указывает имя таблицы, содержащей данные для чтения.<br/><br/><b>Rows to scan for property names</b> (Строки для поиска имен свойств). Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице.<br/><br/>Если данные однородные и прогнозируемые, то рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы с использованием наборов свойств, которые различаются в зависимости от глубины и положения таблицы, выберите параметр *ScanAll* для сканирования всех строк. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/> |
| хранилище BLOB-объектов Azure |Считывает данные, хранящиеся в службе больших двоичных объектов в хранилище Azure, включая изображения, неструктурированные текстовые данные и двоичные данные.<br/><br/>Службу BLOB-объектов можно использовать для предоставления общего доступа к данным или для закрытого хранения данных приложения. Доступ к данным можно получить из любого места, подключившись через протокол HTTP или HTTPS. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account.<br/><br/><b>Public or Shared Access Signature (SAS) URI</b> (URI общедоступного или подписанного URL-адреса (SAS)). Используются следующие параметры.<br/><br/><ul><b>Универсальный код ресурса (URI)</b>. Задает общедоступный или подписанный URL-адрес (SAS) большого двоичного объекта службы хранилища.<br/><br/><b>Формат файла</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы: CSV, TSV и ARFF.<br/><br/></ul><b>Private Storage Account</b> (Частная учетная запись хранения). Параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей большой двоичный объект, выбранный для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Path to container, directory, or blob</b> (Путь к контейнеру, каталогу или большому двоичному объекту). Задает имя большого двоичного объекта, содержащего данные для чтения.<br/><br/><b>Формат файла BLOB-объекта</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы данных: CSV, TSV, ARFF, CSV с заданной кодировкой и Excel. <br/><br/><ul>Если используется формат CSV или TSV, обязательно укажите, содержит ли файл строку заголовка.<br/><br/>Для чтения данных из книги Excel можно использовать параметр Excel. Для параметра <i>Формат данных Excel</i> укажите расположение данных: в диапазоне листа Excel или в таблице Excel. В параметре <i>Excel sheet or embedded table</i> (Лист или внедренная таблица Excel) укажите имя листа или таблицы для считывания данных.</ul><br/> |
| Поставщик веб-канала данных |Считывает данные, получаемые от поддерживаемого поставщика веб-канала. В настоящее время поддерживается только формат Open Data Protocol (OData). |<b>Data content type</b> (Тип содержимого данных). Задает формат OData.<br/><br/><b>Исходный URL-адрес</b>. Указывает полный URL-адрес веб-канала данных. <br/>Например, этот URL-адрес позволяет считывать данные из примера базы данных Northwind: https://services.odata.org/northwind/northwind.svc/. |

## <a name="import-from-another-experiment"></a>Импорт из другого эксперимента

Иногда понадобится получить в эксперименте промежуточный результат, который будет использоваться в другом эксперименте. Для этого сохраните модуль как набор данных, выполнив указанные ниже действия.

1. Щелкните выходные данные модуля, которые требуется сохранить в виде набора данных.
2. Щелкните **Сохранить как набор данных**.
3. При появлении запроса введите имя и описание, которое позволит легко идентифицировать набор данных.
4. Установите флажок **ОК** .

После завершения сохранения набор данных будет доступен для использования в любом эксперименте в рабочей области. Его можно найти в списке **Сохраненные наборы данных** в палитре модулей.

## <a name="next-steps"></a>Дальнейшие действия

[Развертывание веб-служб Машинное обучение Azure Studio, использующих модули импорта и экспорта данных](web-services-that-use-import-export-modules.md)


<!-- Module References -->
[import-data]: /azure/machine-learning/studio-module-reference/import-data
[export-data]: /azure/machine-learning/studio-module-reference/export-data


<!-- Module References -->
[convert-to-dataset]: /azure/machine-learning/studio-module-reference/convert-to-dataset
[edit-metadata]: /azure/machine-learning/studio-module-reference/edit-metadata
[import-data]: /azure/machine-learning/studio-module-reference/import-data