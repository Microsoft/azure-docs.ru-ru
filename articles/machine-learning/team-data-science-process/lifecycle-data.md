---
title: Получение и анализ данных в командном процессе обработки и анализа данных
description: Цели, задачи и конечные результаты на этапе получения и анализа данных проектов обработки и анализа данных
services: machine-learning
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 11/17/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: fffb52e333bea1b2be11b127a9eab6656dc1d1f5
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "94740334"
---
# <a name="data-acquisition-and-understanding-stage-of-the-team-data-science-process"></a>Этап получения и анализа данных в командном процессе обработки и анализа данных

В этой статье описаны цели, задачи и конечные результаты, связанные с этапом получения и анализа данных процесса обработки и анализа данных группы (TDSP). Этот процесс выполняется в рамках рекомендуемого жизненного цикла, позволяя структурировать проекты по обработке и анализу данных. Этот жизненный цикл представляет основные этапы, которые обычно выполняются проектами, часто итеративно:

   1. **Бизнес-понимание**
   2. **Получение и понимание данных**
   3. **Моделирование**
   4. **Deployment**
   5. **Приемка клиентом**

Визуальное представление жизненного цикла процесса обработки и анализа данных группы: 

![Жизненный цикл процесса обработки и анализа данных группы](./media/lifecycle/tdsp-lifecycle2.png) 


## <a name="goals"></a>Цели
* Создать чистый высококачественный набор данных, связь с целевыми переменными которого понятна. Разместить набор данных в соответствующей среде аналитики, чтобы можно было приступать к моделированию.
* Разработать архитектуру решения для конвейера данных, который будет регулярно обновлять и оценивать данные.

## <a name="how-to-do-it"></a>Способ выполнения
На этом этапе нужно решить три основные задачи.

   * **Прием данных** в целевую аналитическую среду.
   * **Просмотр данных** для проверки того, позволяет ли качество данных ответить на поставленный вопрос. 
   * **Настройка конвейера данных** для оценки новых или регулярно обновляемых данных.

### <a name="ingest-the-data"></a>Прием данных
Выполните подготовку к перемещению данных из исходных расположений в целевые, где будут выполняться аналитические операции, например обучение и прогнозирование. Технические сведения и описание операций с перемещением данных см. в статье [Загрузка данных в среды хранения для аналитики](ingest-data.md). 

### <a name="explore-the-data"></a>Изучение данных
Прежде чем начинать обучение модели, нужно хорошо изучить имеющиеся данные. Наборы реальных данных часто характеризуются наличием шума и отсутствием нужных значений. Кроме того, такие данные бывают несогласованными. Чтобы оценить качество данных, можно использовать сводную информацию и визуализацию. Это снабдит вас информацией, необходимой для обработки данных в ходе подготовки к моделированию. Часто этот процесс итеративный. Рекомендации по очистке данных см. в статье [Задачи по подготовке данных для расширенного машинного обучения](prepare-data.md).  

Когда вы будете удовлетворены качеством очищенных данных, переходите к анализу тенденций в данных. Этот анализ данных помогает выбрать и разработать соответствующую прогнозную модель для целевого объекта. Ищите свидетельства, подтверждающие наличие связи между данными и целями, а также убедитесь в том, что у вас достаточно информации для перехода к следующим шагам моделирования. Этот процесс также часто бывает итеративным. Возможно, вам понадобятся новые источники информации с более точными или релевантными данными, которые дополнят уже определенный набор данных. 

### <a name="set-up-a-data-pipeline"></a>Настройка конвейера данных
Наряду с исходным процессом приема и очистки данных, как правило, требуется настроить еще и процесс оценки новых данных или их регулярного обновления в ходе обучения. Оценка может быть выполнена с помощью конвейера данных или рабочего процесса. В статье [Перемещение данных из SQL Server экземпляра в базу данных SQL Azure с помощью фабрики данных Azure](move-sql-azure-adf.md) приводится пример настройки конвейера с помощью [фабрики данных Azure](https://azure.microsoft.com/services/data-factory/). 

На этом этапе создается архитектура решения для конвейера данных. Разработка конвейера происходит параллельно со следующей стадией обработки и анализа данных проекта. В зависимости от потребностей бизнеса и ограничений существующих систем, в которых интегрировано это решение, конвейер может быть одним из следующих вариантов: 

   * пакетный;
   * выполняющий потоковую передачу или работающий в режиме реального времени; 
   * гибридный. 

## <a name="artifacts"></a>Artifacts
Ниже представлены некоторые примеры конечных результатов для этого этапа:

   * [Отчет о качестве данных](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Data_Report/DataSummaryReport.md). Этот отчет включает сводную информацию о данных, связи каждого атрибута с целевым объектом, ранжирование переменных и т. д. 
   * **Архитектура решения**. Это может быть схема или описание конвейера данных, используемого для оценки или прогнозирования на основе новых данных после создания модели. Также сюда входит конвейер для повторного обучения модели на основе новых данных. Если вы используете шаблон структуры каталогов TDSP, храните документ в каталоге [Project](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Project).
   * **Решение "контрольная точка**". перед началом полного проектирования и создания модели можно переоценить проект, чтобы определить, достаточно ли ожидаемое значение для дальнейшего его выполнения. Возможно, вы уже готовы продолжать или вам нужны дополнительные данные, или от проекта пора отказаться из-за отсутствия данных, необходимых для получения ответа.

## <a name="next-steps"></a>Дальнейшие действия

Ниже приведены ссылки на каждый этап жизненного цикла процесса обработки и анализа данных группы:

   1. [Коммерческий аспект](lifecycle-business-understanding.md)
   2. [Получение и понимание данных](lifecycle-data.md)
   3. [Моделирование](lifecycle-modeling.md)
   4. [Deployment](lifecycle-deployment.md)
   5. [Приемка клиентом](lifecycle-acceptance.md)

Мы предоставляем полные пошаговые руководства, демонстрирующие все этапы процесса для конкретных сценариев. Статья [Пошаговые руководства по процессу обработки и анализа данных группы](walkthroughs.md) содержит список сценариев, ссылки и описания эскизов. В пошаговых руководствах показано, как объединить облачные, локальные инструменты и службы в единый рабочий процесс или конвейер, чтобы создать интеллектуальное приложение. 

Примеры выполнения шагов в процессе обработки и анализа данных группы, который использует среду "Студия машинного обучения Azure", см. в статье [Командный процесс обработки и анализа данных с использованием службы "Машинное обучение Azure"]().
