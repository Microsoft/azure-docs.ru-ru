---
title: Устранение неполадок конвейеров машинного обучения
titleSuffix: Azure Machine Learning
description: Устранение неполадок при получении ошибок при выполнении конвейера машинного обучения. Распространенные ошибки и советы, помогающие в отладке сценариев до и во время удаленного выполнения.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
author: lobrien
ms.author: laobri
ms.date: 10/22/2020
ms.topic: troubleshooting
ms.custom: troubleshooting, devx-track-python, contperf-fy21q2
ms.openlocfilehash: 0f27688e31f772cc8d784371aa570d55c41f5695
ms.sourcegitcommit: 431bf5709b433bb12ab1f2e591f1f61f6d87f66c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/12/2021
ms.locfileid: "98131820"
---
# <a name="troubleshooting-machine-learning-pipelines"></a>Устранение неполадок конвейеров машинного обучения

В этой статье вы узнаете, как устранять неполадки при возникновении ошибок, связанных с запуском [конвейера машинного обучения](concept-ml-pipelines.md) в [машинное обучение Azure SDK](/python/api/overview/azure/ml/intro?preserve-view=true&view=azure-ml-py) и [конструкторе машинное обучение Azure](./concept-designer.md). 

## <a name="troubleshooting-tips"></a>Советы по устранению неполадок

В следующей таблице приведены распространенные проблемы во время разработки конвейера с потенциальными решениями.

| Проблема | Возможное решение |
|--|--|
| Не удалось передать данные в `PipelineData` Каталог | Убедитесь, что в скрипте создан каталог, который соответствует расположению выходных данных шага в конвейере. В большинстве случаев входной аргумент определяет выходной каталог, а затем создает каталог явным образом. Используйте `os.makedirs(args.output_dir, exist_ok=True)` для создания выходного каталога. См. [руководство](tutorial-pipeline-batch-scoring-classification.md#write-a-scoring-script) по примеру сценария оценки, в котором показан этот шаблон разработки. |
| Ошибки зависимостей | Если в удаленном конвейере отображаются ошибки зависимостей, которые не возникали при локальном тестировании, проверьте зависимости удаленной среды и версии, совпадающие с параметрами в тестовой среде. (См. раздел [Создание среды, кэширование и повторное использование](./concept-environments.md#environment-building-caching-and-reuse)|
| Неоднозначные ошибки с целевыми объектами вычислений | Попробуйте удалить и повторно создать целевые объекты вычислений. Повторное создание целевых объектов вычислений является быстрым и может решить некоторые временные проблемы. |
| Конвейер не использует повторно шаги | Повторное использование шага включено по умолчанию, но убедитесь, что вы не отключили его на этапе конвейера. Если повторное использование отключено, `allow_reuse` параметр на шаге будет установлен в значение `False` . |
| Конвейер перезапускается без необходимости | Чтобы обеспечить повторный запуск шагов только при изменении базовых данных или скриптов, следует разделить Каталоги исходного кода на каждый шаг. Если один и тот же исходный каталог используется для нескольких шагов, может возникнуть ненужное повторное использование. Используйте `source_directory` параметр для объекта шага конвейера, чтобы указать на свой изолированный каталог для этого шага, и убедитесь, что вы не используете один и тот же `source_directory` путь для нескольких шагов. |
| Шаг с замедлением при обучении эпохи обучения или другое поведение цикла | Попробуйте переключить записи файлов, включая ведение журнала, с `as_mount()` на `as_upload()` . Режим **подключения** использует удаленную виртуальную файловую систему и загружает весь файл каждый раз, когда он добавляется к. |
| Целевой объект вычислений занимает много времени | Образы DOCKER для целевых объектов вычислений загружаются из реестра контейнеров Azure (запись контроля доступа). По умолчанию Машинное обучение Azure создает запись контроля доступа, которая использует уровень служб " *базовый* ". Изменение записи контроля доступа для рабочей области на уровень "Стандартный" или "Премиум" может сократить время, затрачиваемое на сборку и загрузку образов. Дополнительные сведения см в статье [Уровни службы Реестра контейнеров Azure](../container-registry/container-registry-skus.md). |

### <a name="authentication-errors"></a>Ошибки проверки подлинности

При выполнении операции управления на целевом объекте вычислений из удаленного задания вы получите одну из следующих ошибок: 

```json
{"code":"Unauthorized","statusCode":401,"message":"Unauthorized","details":[{"code":"InvalidOrExpiredToken","message":"The request token was either invalid or expired. Please try again with a valid token."}]}
```

```json
{"error":{"code":"AuthenticationFailed","message":"Authentication failed."}}
```

Например, вы получите сообщение об ошибке, если попытаетесь создать или вложить целевой объект вычислений из конвейера Машинного обучения, который передается для удаленного выполнения.
## <a name="troubleshooting-parallelrunstep"></a>Выявлен `ParallelRunStep` 

Скрипт для `ParallelRunStep` *должен содержать* две функции:
- `init()`: Эта функция применяется для всех затратных или повторяющихся операций подготовки к последующему выводу. Например, в ней можно загружать модель в глобальный объект. Эта функция будет вызываться только один раз в начале процесса.
-  `run(mini_batch)`: Эта функция будет выполняться для каждого экземпляра `mini_batch`.
    -  `mini_batch`: `ParallelRunStep` вызывает метод run и передает ему в качестве аргумента список либо Pandas `DataFrame`. Каждая запись в mini_batch содержит одно из следующих значений: путь к файлу для входных данных в формате `FileDataset` или Pandas `DataFrame` для входных данных в формате `TabularDataset`.
    -  `response`: метод run() должен возвращать Pandas `DataFrame` или массив. Для append_row output_action эти возвращаемые элементы добавляются в общий выходной файл. Для summary_only содержимое элементов игнорируется. Для всех выходных действий каждый возвращаемый элемент обозначает один успешный запуск входного элемента во входном мини-пакете. Убедитесь в том, что в результат выполнения включено достаточно данных, чтобы сопоставить входные данные с результатом вывода. Выходные данные будут записаны в выходной файл, и для них не гарантируется правильный порядок. Для сопоставления со входными данными нужно использовать какой-либо ключ.

```python
%%writefile digit_identification.py
# Snippets from a sample script.
# Refer to the accompanying digit_identification.py
# (https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/machine-learning-pipelines/parallel-run)
# for the implementation script.

import os
import numpy as np
import tensorflow as tf
from PIL import Image
from azureml.core import Model


def init():
    global g_tf_sess

    # Pull down the model from the workspace
    model_path = Model.get_model_path("mnist")

    # Construct a graph to execute
    tf.reset_default_graph()
    saver = tf.train.import_meta_graph(os.path.join(model_path, 'mnist-tf.model.meta'))
    g_tf_sess = tf.Session()
    saver.restore(g_tf_sess, os.path.join(model_path, 'mnist-tf.model'))


def run(mini_batch):
    print(f'run method start: {__file__}, run({mini_batch})')
    resultList = []
    in_tensor = g_tf_sess.graph.get_tensor_by_name("network/X:0")
    output = g_tf_sess.graph.get_tensor_by_name("network/output/MatMul:0")

    for image in mini_batch:
        # Prepare each image
        data = Image.open(image)
        np_im = np.array(data).reshape((1, 784))
        # Perform inference
        inference_result = output.eval(feed_dict={in_tensor: np_im}, session=g_tf_sess)
        # Find the best probability, and add it to the result list
        best_result = np.argmax(inference_result)
        resultList.append("{}: {}".format(os.path.basename(image), best_result))

    return resultList
```

Если у вас есть другой файл или папка в том же каталоге, что и скрипт вывода, можно сослаться на него, найдя текущий рабочий каталог.

```python
script_dir = os.path.realpath(os.path.join(__file__, '..',))
file_path = os.path.join(script_dir, "<file_name>")
```

### <a name="parameters-for-parallelrunconfig"></a>Параметры для Параллелрунконфиг

`ParallelRunConfig` — это основная конфигурация для экземпляра `ParallelRunStep` в конвейере Машинного обучения Azure. Он пригодится вам как оболочка скрипта для настройки необходимых параметров, включая перечисленные ниже записи:
- `entry_script`: Локальный путь к пользовательскому скрипту, который будет выполняться параллельно на нескольких узлах. Если присутствует `source_directory`, используйте относительный путь. В противном случае используйте любой путь, доступный на компьютере.
- `mini_batch_size`: Размер мини-пакета, который передается в одном вызове `run()`. (Необязательный параметр; по умолчанию заданы `10` файлов для `FileDataset` и `1MB` для `TabularDataset`.)
    - Для `FileDataset` здесь указывается количество файлов; минимальное допустимое значение — `1`. Несколько файлов можно объединить в один мини-пакет.
    - Для `TabularDataset` здесь указывается размер данных. Примеры допустимых значений: `1024`, `1024KB`, `10MB` и `1GB`. Мы рекомендуем использовать значение `1MB`. Мини-пакет из `TabularDataset` никогда не пересекает границы файлов. Предположим, что у вас есть CSV-файлы с разными размерами в пределах от 100 КБ до 10 МБ. Если задать `mini_batch_size = 1MB`, все файлы с размером меньше 1 МБ будут рассматриваться как один мини-пакет. Файлы с размером, превышающим 1 МБ, будут разбиты на несколько мини-пакетов.
- `error_threshold`: Количество ошибок записи для `TabularDataset` и сбоев чтения файлов для `FileDataset`, которые следует игнорировать во время обработки. Если общее количество ошибок для всего объема входных данных превысит это значение, задание будет прервано. Пороговое количество ошибок применяется к общему объему входных данных, а не к отдельному мини-пакету, которые передаются в метод `run()`. Используется диапазон `[-1, int.max]`. Часть `-1` указывает на то, что следует игнорировать все сбои во время обработки.
- `output_action`: Одно из следующих значений указывает, как будут организованы выходные данные.
    - `summary_only`: Выходные данные сохраняются в пользовательском скрипте. `ParallelRunStep` использует выходные данные только для вычисления порога ошибок.
    - `append_row`: Для всех входных данных в выходной папке будет создан только один файл, куда будут добавляться все выходные данные, разделенные пустой строкой.
- `append_row_file_name`: Чтобы настроить имя выходного файла для append_row output_action (необязательно; значение по умолчанию — `parallel_run_step.txt`).
- `source_directory`: Пути к папкам, которые содержат все файлы для выполнения в целевом объекте вычислений (необязательно).
- `compute_target`: Поддерживается только `AmlCompute`.
- `node_count`: Количество вычислительных узлов, которые будут использоваться для выполнения пользовательского скрипта.
- `process_count_per_node`: Количество процессов на каждом узле. Рекомендуется устанавливать в значение, равное количеству GPU или ЦП на одном узле (необязательно; значение по умолчанию — `1`).
- `environment`: Определение среды Python. Вы можете настроить использование существующей среды Python или временной среды. Также это определение может задавать необходимые зависимости приложения (необязательно).
- `logging_level`: Детализация журнала. Значения уровня детализации в порядке увеличения: `WARNING`, `INFO` и `DEBUG`. (необязательный параметр; по умолчанию используется значение `INFO`.)
- `run_invocation_timeout`: Время вызова метода `run()` в секундах. (необязательный параметр, значение по умолчанию — `60`)
- `run_max_try`: Максимальное число попыток `run()` для mini-batch. Сбой `run()` при возникновении исключения или если при достижении `run_invocation_timeout` ничего не возвращается (необязательно; значение по умолчанию — `3`). 

Можно указать `mini_batch_size`, `node_count`, `process_count_per_node`, `logging_level`, `run_invocation_timeout` и `run_max_try` как `PipelineParameter`, чтобы при повторной отправке запуска конвейера можно было точно настроить значения параметров. В этом примере используется `PipelineParameter` для `mini_batch_size` и `Process_count_per_node`, и эти значения будут изменены при повторной отправке позже. 

### <a name="parameters-for-creating-the-parallelrunstep"></a>Параметры для создания Параллелрунстеп

Создайте ParallelRunStep, используя скрипт, конфигурацию среды и параметры. Укажите целевой объект вычислений, который уже подключен к рабочей области, в качестве целевого объекта для выполнения скрипта вывода. Используйте `ParallelRunStep`, чтобы создать шаг конвейера пакетного вывода, который принимает все следующие параметры.
- `name`: Имя шага со следующими ограничениями на именование: уникальность, от 3 до 32 символов, соответствие регулярному выражению ^\[a-z\]([-a-z0-9]*[a-z0-9])?$.
- `parallel_run_config`: Объект `ParallelRunConfig`, как определено ранее.
- `inputs`: Один или несколько однотипных наборов данных Машинного обучения Azure, которые должны быть секционированы для параллельной обработки.
- `side_inputs`: Один или несколько эталонных данных или наборов данных, используемых в качестве дополнительных входных данных без необходимости секционирования.
- `output`: `OutputFileDatasetConfig` Объект, соответствующий выходному каталогу.
- `arguments`: Список аргументов, переданных в пользовательский скрипт. Используйте unknown_args, чтобы получить их в начальном сценарии (необязательно).
- `allow_reuse`: Указывает, должен ли шаг повторно использовать предыдущие результаты при запуске с теми же параметрами и входными данными. Если этот параметр имеет значение `False`, то во время выполнения конвейера для этого шага всегда будет создаваться новый запуск. (необязательный параметр; по умолчанию используется значение `True`.)

```python
from azureml.pipeline.steps import ParallelRunStep

parallelrun_step = ParallelRunStep(
    name="predict-digits-mnist",
    parallel_run_config=parallel_run_config,
    inputs=[input_mnist_ds_consumption],
    output=output_dir,
    allow_reuse=True
)
```

## <a name="debugging-techniques"></a>Методы отладки

Существует три основных метода отладки конвейеров: 

* Отладка отдельных шагов конвейера на локальном компьютере
* Использование ведения журналов и Application Insights для изоляции и диагностики источника проблемы
* Подключение удаленного отладчика к конвейеру, выполняющемуся в Azure

### <a name="debug-scripts-locally"></a>Локальная отладка скриптов

Одной из наиболее распространенных сбоев в конвейере является то, что сценарий домена не выполняется должным образом или содержит ошибки времени выполнения в удаленном контексте вычислений, которые трудно отладить.

Сами по себе конвейеры не могут выполняться локально, но выполнение сценариев на локальном компьютере позволяет выполнять отладку быстрее, поскольку не нужно ждать процесса сборки вычислений и среды. Для этого требуется выполнить некоторые действия по разработке:

* Если данные находятся в облачном хранилище данных, необходимо скачать данные и сделать их доступными для скрипта. Использование небольшого примера данных — хороший способ сократить время выполнения и получить отзыв о поведении сценария.
* При попытке имитировать промежуточный шаг конвейера может потребоваться вручную создать типы объектов, которые определенный сценарий ожидает на предыдущем шаге.
* Также потребуется определить собственную среду и реплицировать зависимости, определенные в удаленной среде вычислений.

После установки сценария для запуска в локальной среде гораздо проще выполнять задачи отладки, такие как:

* Присоединение пользовательской конфигурации отладки
* Приостановка выполнения и проверка состояния объекта
* Перехват типов или логических ошибок, которые не будут предоставляться до времени выполнения

> [!TIP] 
> Убедившись в том, что сценарий выполняется должным образом, на следующем шаге выполняется сценарий в одношаговом конвейере, прежде чем пытаться запустить его в конвейере с несколькими шагами.

## <a name="configure-write-to-and-review-pipeline-logs"></a>Настройка, запись и проверка журналов конвейера

Локальное тестирование скриптов — это отличный способ отладки основных фрагментов кода и сложной логики, прежде чем приступить к созданию конвейера, но в какой-то момент вам, скорее всего, придется отлаживать сценарии во время выполнения собственно конвейера, особенно при диагностике поведения, возникающего во время взаимодействия между этапами конвейера. Мы рекомендуем свободно использовать `print()` инструкции в сценариях шагов, чтобы видеть состояние объекта и ожидаемые значения во время удаленного выполнения, аналогично отладке кода JavaScript.

### <a name="logging-options-and-behavior"></a>Параметры ведения журнала и поведение

В таблице ниже приведены сведения о различных параметрах отладки для конвейеров. Он не является исчерпывающим списком, так как существуют другие варианты, кроме только Машинное обучение Azure, Python и Опенценсус, показанных здесь.

| Библиотека                    | Тип   | Пример                                                          | Назначение                                  | Ресурсы                                                                                                                                                                                                                                                                                                                    |
|----------------------------|--------|------------------------------------------------------------------|----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| пакет SDK для Машинного обучения Azure; | Метрика | `run.log(name, val)`                                             | Пользовательский интерфейс портала Машинное обучение Azure             | [Как отвести эксперименты](how-to-track-experiments.md)<br>[класс azureml. Core. Run](/python/api/azureml-core/azureml.core.run%28class%29?preserve-view=true&view=azure-ml-py)                                                                                                                                                 |
| Печать и ведение журнала Python    | Журнал    | `print(val)`<br>`logging.info(message)`                          | Журналы драйверов, конструктор Машинное обучение Azure | [Как отвести эксперименты](how-to-track-experiments.md)<br><br>[Ведение журнала Python](https://docs.python.org/2/library/logging.html)                                                                                                                                                                       |
| Python для OpenCensus          | Журнал    | `logger.addHandler(AzureLogHandler())`<br>`logging.log(message)` | Application Insights трассировки                | [Отладка конвейеров в Application Insights](./how-to-log-pipelines-application-insights.md)<br><br>[Агенты OpenCensus Azure Monitor Exporter](https://github.com/census-instrumentation/opencensus-python/tree/master/contrib/opencensus-ext-azure)<br>[Cookbook ведения журнала Python](https://docs.python.org/3/howto/logging-cookbook.html) |

#### <a name="logging-options-example"></a>Пример параметров ведения журнала

```python
import logging

from azureml.core.run import Run
from opencensus.ext.azure.log_exporter import AzureLogHandler

run = Run.get_context()

# Azure ML Scalar value logging
run.log("scalar_value", 0.95)

# Python print statement
print("I am a python print statement, I will be sent to the driver logs.")

# Initialize python logger
logger = logging.getLogger(__name__)
logger.setLevel(args.log_level)

# Plain python logging statements
logger.debug("I am a plain debug statement, I will be sent to the driver logs.")
logger.info("I am a plain info statement, I will be sent to the driver logs.")

handler = AzureLogHandler(connection_string='<connection string>')
logger.addHandler(handler)

# Python logging with OpenCensus AzureLogHandler
logger.warning("I am an OpenCensus warning statement, find me in Application Insights!")
logger.error("I am an OpenCensus error statement with custom dimensions", {'step_id': run.id})
``` 

## <a name="azure-machine-learning-designer"></a>Конструктор Машинного обучения Azure

Для конвейеров, созданных в конструкторе, файл **70_driver_log** можно найти либо на странице Создание, либо на странице сведения о выполнении конвейера.

### <a name="enable-logging-for-real-time-endpoints"></a>Включение ведения журнала для конечных точек в реальном времени

Для устранения неполадок и отладки конечных точек в режиме реального времени в конструкторе необходимо включить ведение журнала Application Insights с помощью пакета SDK. Ведение журнала позволяет устранять неполадки и отлаживать проблемы развертывания и использования модели. Дополнительные сведения см. в разделе [ведение журнала для развернутых моделей](./how-to-enable-app-insights.md). 

### <a name="get-logs-from-the-authoring-page"></a>Получение журналов со страницы "Создание и Настройка"

При отправке выполнения конвейера и остаться на странице Создание и настройка можно найти файлы журналов, созданные для каждого модуля по мере завершения выполнения каждого модуля.

1. Выберите модуль, который завершил выполнение на холсте разработки.
1. На правой панели модуля перейдите на вкладку  **выходные данные + журналы** .
1. Разверните правую панель и выберите **70_driver_log.txt** , чтобы просмотреть файл в браузере. Кроме того, можно скачать журналы локально.

    ![Развернутая область вывода в конструкторе](./media/how-to-debug-pipelines/designer-logs.png)? View = Azure-ML-корректировка&сохранить-просмотреть = true)? View = Azure-ML-Корр&Preserve-View = true)

### <a name="get-logs-from-pipeline-runs"></a>Получение журналов из запусков конвейера

Файлы журналов для конкретных запусков можно также найти на странице сведений о запуске конвейера, которую можно найти в разделе **конвейеры** или **эксперименты** в студии.

1. Выберите Запуск конвейера, созданный в конструкторе.

    ![Страница выполнения конвейера](./media/how-to-debug-pipelines/designer-pipelines.png)

1. Выберите модуль в области просмотра.
1. На правой панели модуля перейдите на вкладку  **выходные данные + журналы** .
1. Разверните правую панель, чтобы просмотреть файл **70_driver_log.txt** в браузере, или выберите файл, чтобы скачать журналы локально.

> [!IMPORTANT]
> Чтобы обновить конвейер со страницы сведения о выполнении конвейера, необходимо **клонировать** выполнение конвейера в новый черновик конвейера. Запуск конвейера — это моментальный снимок конвейера. Он аналогичен файлу журнала и не может быть изменен. 

## <a name="application-insights"></a>Application Insights
Дополнительные сведения об использовании библиотеки Опенценсус Python таким образом см. в разделе [Отладка и устранение неполадок конвейеров машинного обучения в Application Insights](./how-to-log-pipelines-application-insights.md)

## <a name="interactive-debugging-with-visual-studio-code"></a>Интерактивная Отладка с помощью Visual Studio Code

В некоторых случаях может потребоваться интерактивно отлаживать код Python, используемый в конвейере машинного обучения. С помощью Visual Studio Code (VS Code) и дебугпи можно присоединяться к коду, как он выполняется в среде обучения. Дополнительные сведения см. в [разделе Интерактивная Отладка в VS Code Guide](how-to-debug-visual-studio-code.md#debug-and-troubleshoot-machine-learning-pipelines).

## <a name="next-steps"></a>Дальнейшие действия

* Полный учебник по использованию см `ParallelRunStep` . в разделе [учебник. создание конвейера машинное обучение Azure для пакетной оценки](tutorial-pipeline-batch-scoring-classification.md).

* Полный пример, в котором показано автоматизированное машинное обучение в конвейерах МАШИНного обучения, см. в статье [Использование автоматического ML в конвейере машинное обучение Azure в Python](how-to-use-automlstep-in-pipelines.md).

* Обратитесь к Справочнику по пакету SDK, чтобы получить справку по пакету [azureml-конвейеры-Core](/python/api/azureml-pipeline-core/?preserve-view=true&view=azure-ml-py) и пакету [azureml-конвейеры-этапов](/python/api/azureml-pipeline-steps/?preserve-view=true&view=azure-ml-py) .

* См. список [исключений и кодов ошибок конструктора](algorithm-module-reference/designer-error-codes.md).