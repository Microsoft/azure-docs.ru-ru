---
title: Оценка результатов экспериментов Аутомл
titleSuffix: Azure Machine Learning
description: Узнайте, как просматривать и оценивать диаграммы и метрики для каждого из автоматических запусков экспериментов машинного обучения.
services: machine-learning
author: gregorybchris
ms.author: chgrego
ms.reviewer: nibaccam
ms.service: machine-learning
ms.subservice: core
ms.date: 12/09/2020
ms.topic: conceptual
ms.custom: how-to, contperf-fy21q2, automl
ms.openlocfilehash: 6d8c56bc306a7ab0bf118d04f64d6523fc385cdd
ms.sourcegitcommit: 956dec4650e551bdede45d96507c95ecd7a01ec9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/09/2021
ms.locfileid: "102520784"
---
# <a name="evaluate-automated-machine-learning-experiment-results"></a>Оценка результатов автоматического эксперимента машинного обучения

Из этой статьи вы узнаете, как оценивать и сравнивать модели, обученные автоматическим экспериментом машинного обучения (автоматизированное обучение). В ходе автоматического эксперимента ML создаются многие запуски, и каждый запуск создает модель. Для каждой модели автоматический ML создает метрики и диаграммы оценки, которые помогают измерять производительность модели. 

Например, автоматический ML создает следующие диаграммы на основе типа эксперимента.

| Классификация| Регрессия и прогнозирования |
| ----------------------------------------------------------- | ---------------------------------------- |
| [Матрица неточностей](#confusion-matrix)                       | [Гистограмма остатков](#residuals)        |
| [Кривая операционной характеристики получателя (ROC)](#roc-curve) | [Предсказанные и значения true](#predicted-vs-true) |
| [Кривая точности-отзыва (PR)](#precision-recall-curve)      |                                          |
| [кривая точности прогнозов](#lift-curve);                                   |                                          |
| [Кривая совокупных выигрышей](#cumulative-gains-curve)           |                                          |
| [Кривая калибровки](#calibration-curve)                     |                     


## <a name="prerequisites"></a>Предварительные требования

- Подписка Azure. (Если у вас нет подписки Azure, [Создайте бесплатную учетную запись](https://aka.ms/AMLFree) , прежде чем начинать работу).
- Машинное обучение Azure эксперимент, созданный с помощью:
  - [Машинное обучение Azure Studio](how-to-use-automated-ml-for-ml-models.md) (код не требуется)
  - [Пакет SDK для машинное обучение Azure Python](how-to-configure-auto-train.md)

## <a name="view-run-results"></a>Просмотреть результаты выполнения

После завершения автоматического эксперимента ML журнал запусков можно найти через:
  - Браузер с [машинное обучение Azure Studio](overview-what-is-machine-learning-studio.md)
  - Записная книжка Jupyter с помощью мини-приложения [Рундетаилс Jupyter](/python/api/azureml-widgets/azureml.widgets.rundetails)

В следующих шагах и видео показано, как просмотреть показатели выполнения и метрики оценки модели и диаграммы в студии.

1. [Войдите в студию студии](https://ml.azure.com/) и перейдите к рабочей области.
1. В меню слева выберите **эксперименты**.
1. Выберите эксперимент из списка экспериментов.
1. В таблице в нижней части страницы выберите автоматический запуск ML.
1. На вкладке **модели** выберите **имя алгоритма** для модели, которую необходимо вычислить.
1. На вкладке **метрики** используйте флажки слева, чтобы просмотреть метрики и диаграммы.

![Действия по просмотру метрик в студии](./media/how-to-understand-automated-ml/how-to-studio-metrics.gif)

## <a name="classification-metrics"></a>Метрики классификации

Автоматический ML вычисляет метрики производительности для каждой модели классификации, создаваемой для вашего эксперимента. Эти метрики основаны на реализации scikit. 

Многие метрики классификации определены для двоичной классификации в двух классах и потребовали усреднения по классам для получения одной оценки для многоклассовой классификации. Scikit — Узнайте о нескольких усредненных методах, три из которых автоматизированный ML предоставляет: **макрос**, **Micro** и **взвешенный**.

- **Макрос** — вычисление метрики для каждого класса и получение невзвешенного среднего
- Микрорасчет метрики на глобальном **уровне путем** подсчета итоговых истинных положительных результатов, ложных негативов и ложных срабатываний (независимо от классов).
- **Взвешенный** — вычисление метрик для каждого класса и получение взвешенного среднего по числу выборок на каждый класс.

Хотя каждый метод усреднения имеет свои преимущества, одним из общих соображений при выборе соответствующего метода является дисбаланс класса. Если у классов разное количество выборок, может быть более информативным использование макроса, в среднем где доли классов имеют одинаковый вес для большинства классов. Дополнительные сведения о [двоичных и многоклассовых метриках в автоматизированном ML](#binary-vs-multiclass-classification-metrics). 

В следующей таблице перечислены метрики производительности модели, которые автоматизированное средство ML вычисляет для каждой модели классификации, создаваемой для вашего эксперимента. Дополнительные сведения см. в документации по scikit-учиться, связанной в поле **вычисления** каждой метрики. 

|Метрика|Описание|Вычисление|
|--|--|---|
|AUC | AUC — это область под [кривой рабочих характеристик получателя](#roc-curve).<br><br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1]<br> <br>Поддерживаются следующие имена метрик: <li>`AUC_macro`, среднее арифметическое AUC для каждого класса.<li> `AUC_micro`, вычисленные путем объединения истинных положительных и ложных положительных результатов от каждого класса. <li> `AUC_weighted`среднее арифметическое значение оценки для каждого класса, взвешенное по количеству истинных экземпляров в каждом классе.   |[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) | 
|accuracy| Точность — это отношение прогнозов, которые точно соответствуют истинным меткам классов. <br> <br>**Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1]|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)|
|average_precision|Для вычисления средней точности используется кривая точности и полноты в качестве взвешенного среднего значения точности, полученного для каждого порогового значения, с увеличением полноты за счет предыдущего порогового значения, используемого в качестве весового коэффициента. <br><br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1]<br> <br>Поддерживаются следующие имена метрик:<li>`average_precision_score_macro`, среднее арифметическое среднего показателя точности каждого класса.<li> `average_precision_score_micro`, вычисленные путем объединения истинных положительных и ложных срабатываний при каждой отсечки.<li>`average_precision_score_weighted`, среднее арифметическое среднее значение точности для каждого класса, взвешенное по количеству истинных экземпляров в каждом классе.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html)|
balanced_accuracy|Сбалансированная точность — это среднее арифметическое значение полноты для каждого класса.<br> <br>**Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1]|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)|
f1_score|Оценка F1 — это среднее гармоническое значение точности и полноты. Это хорошее сбалансированное измерение как ложных срабатываний, так и ложных отрицательных результатов. Однако он не учитывает истинные отрицательные результаты. <br> <br>**Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1]<br> <br>Поддерживаются следующие имена метрик:<li>  `f1_score_macro`: арифметическое среднее значение оценки F1 для каждого класса. <li> `f1_score_micro`: вычисляется путем подсчета общего количества истинных положительных, ложных отрицательных значений и ложных срабатываний. <li> `f1_score_weighted`: взвешенное среднее значение частоты класса для оценки F1 для каждого класса.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)|
log_loss|Это функция потери данных, используемая в логистической регрессии (мультиноминальное) и расширениях ИТ-сетей, таких как нейронные сети, которая определяется как отрицательная вероятность журнала для истинных меток на основе прогнозов классификатора вероятностная. <br><br> **Цель:** Ближе к 0 лучше <br> **Диапазон:** [0, INF-файл)|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html)|
norm_macro_recall| Нормализация макроса отзыв макроса — усредненный и нормализованный, поэтому значение случайной производительности имеет оценку 0, а оптимальная производительность имеет оценку 1. <br> <br>**Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1] |`(recall_score_macro - R)`&nbsp;/&nbsp;`(1 - R)` <br><br>Здесь `R` — ожидаемое значение `recall_score_macro` для случайных прогнозов.<br><br>`R = 0.5`&nbsp;для &nbsp; двоичной &nbsp; классификации. <br>`R = (1 / C)` для проблем классификации C-Class.|
matthews_correlation | Коэффициент корреляции Matthews — это сбалансированная мера точности, которую можно использовать, даже если один класс содержит гораздо больше выборок, чем другой. Коэффициент 1 обозначает идеальный прогноз, 0 случайный прогноз и-1 Обратный прогноз.<br><br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** [-1, 1]|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)|
точность|Точность — это способность модели избежать пометки отрицательных выборок как положительных. <br><br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1]<br> <br>Поддерживаются следующие имена метрик: <li> `precision_score_macro`, среднее арифметическое значений точности для каждого класса. <li> `precision_score_micro`, вычисляются глобально путем подсчета итоговых истинных положительных результатов и ложных положительных результатов. <li> `precision_score_weighted`, арифметическое среднее значение точности для каждого класса, взвешенное по числу истинных экземпляров в каждом классе.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)|
полнота| Отзыв — это способность модели обнаруживать все положительные выборки. <br><br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** [0, 1]<br> <br>Поддерживаются следующие имена метрик: <li>`recall_score_macro`: среднее арифметическое при отзыве для каждого класса. <li> `recall_score_micro`. вычисляется глобально путем подсчета итоговых истинных положительных результатов, ложных отрицательных результатов и ложных срабатываний.<li> `recall_score_weighted`: среднее арифметическое для каждого класса, взвешенное по числу истинных экземпляров в каждом классе.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)|
weighted_accuracy|Взвешенная точность — точность, в которой каждый выбор имеет взвешенное значение по общему количеству выборок, принадлежащих одному и тому же классу. <br><br>**Цель:** Ближе к 1 лучше <br>**Диапазон:** [0, 1]|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)|

### <a name="binary-vs-multiclass-classification-metrics"></a>Метрики двоичной и многоклассовой классификации

Автоматизированное МАШИНное обучение не различает метрики двоичного и многоклассного языка. Одни и те же метрики проверки сообщают, имеет ли набор данных два класса или более двух. Однако некоторые метрики предназначены для многоклассовой классификации. При применении к двоичному набору данных эти метрики не будут рассматривать класс как `true` класс, как можно ожидать. К метрикам, которые явно предназначены для многоклассового класса, добавляется суффикс `micro` , `macro` или `weighted` . Примеры:,,, `average_precision_score` `f1_score` `precision_score` `recall_score` и `AUC` .

Например, вместо того, чтобы вычислить отзыв как, среднее арифметическое вычисление `tp / (tp + fn)` в нескольких классах ( `micro` , `macro` или `weighted` ) для обоих классов набора данных двоичной классификации. Это эквивалентно вычислению отзыва для `true` класса и `false` класса отдельно, а затем получение среднего значения этих двух значений.

## <a name="confusion-matrix"></a>Матрица неточностей

Несогласованные матрицы предоставляют визуальный элемент того, как модель машинного обучения делает систематические ошибки в своих прогнозах для моделей классификации. Слово «путаница» в названии поступает из модели «путаницы» или с неправильной маркировкой. Ячейка в строке `i` и столбце `j` в матрице путаницы содержит количество выборок в наборе данных для оценки, принадлежащих классу `C_i` и классифицированных моделью как класс `C_j` .

В студии более темная ячейка указывает на большее число выборок. Выбор **нормализованного** представления в раскрывающемся списке приводит к нормализации каждой строки матрицы для отображения процента класса, `C_i` прогнозируемого в качестве класса `C_j` . Преимущество представления **RAW** по умолчанию состоит в том, что можно определить, является ли дисбаланс в распределении фактических классов причиной невозможности классификации выборок из класса миноритария, распространенной проблемой в несбалансированных наборах данных.

Матрица путаницы хорошей модели будет содержать большинство примеров по диагонали.

### <a name="confusion-matrix-for-a-good-model"></a>Матрица с путаницой для хорошей модели 
![Матрица с путаницой для хорошей модели ](./media/how-to-understand-automated-ml/chart-confusion-matrix-good.png)

### <a name="confusion-matrix-for-a-bad-model"></a>Матрица неправильной модели
![Матрица неправильной модели](./media/how-to-understand-automated-ml/chart-confusion-matrix-bad.png)

## <a name="roc-curve"></a>Кривая ROC.

Кривая "операционная характеристика приемника" (ROC) Отображает связь между истинным положительным числом (ТПР) и ложным положительным числом (зарегистрированном) при изменении порогового значения принятия решений. Кривая ROC может быть менее информативной при обучении моделей на наборах данных с высоким дисбалансом классов, так как класс большинства может Drown вклады из классов миноритария.

Область под кривой (AUC) может интерпретироваться как доля правильно классифицированных выборок. Точнее, AUC — вероятность того, что классификатор ранжирует случайным образом выбранный положительный пример выше, чем случайный выбор отрицательного числа. Форма кривой дает интуиция для связи между ТПР и зарегистрированном в качестве функции порога классификации или границы принятия решений.

Кривая, которая приближается к левому верхнему углу диаграммы, приближается к 100% ТПР и 0% зарегистрированном, лучшей возможной модели. Случайная модель создаст ROC кривую вдоль `y = x` линии из нижнего левого угла в верхнюю правую. Хуже, чем у случайной модели, ROCная кривая наследуется под `y = x` линией.
> [!TIP]
> Для экспериментов классификации каждый из графиков, созданных для автоматизированных моделей машинного обучения, можно использовать для вычисления модели по каждому классу или усреднения по всем классам. Можно переключаться между этими представлениями, щелкая метки классов в условных обозначениях справа от диаграммы.
### <a name="roc-curve-for-a-good-model"></a>ROCная кривая для хорошей модели
![ROCная кривая для хорошей модели](./media/how-to-understand-automated-ml/chart-roc-curve-good.png)

### <a name="roc-curve-for-a-bad-model"></a>Кривая ROC для неправильной модели
![Кривая ROC для неправильной модели](./media/how-to-understand-automated-ml/chart-roc-curve-bad.png)

## <a name="precision-recall-curve"></a>Кривая точности-отзыв

Кривая с точностью отзыва отображает связь между точностью и отзывом при изменении порогового значения решения. Отзыв — это способность модели обнаруживать все положительные выборки и точность — это способность модели избежать пометки отрицательных выборок как положительных. Некоторые бизнес-проблемы могут потребовать более высокого отзыва и некоторой большей точности в зависимости от относительной важности исключения ложных негативов и ложных срабатываний.
> [!TIP]
> Для экспериментов классификации каждый из графиков, созданных для автоматизированных моделей машинного обучения, можно использовать для вычисления модели по каждому классу или усреднения по всем классам. Можно переключаться между этими представлениями, щелкая метки классов в условных обозначениях справа от диаграммы.
### <a name="precision-recall-curve-for-a-good-model"></a>Кривая точности-отзыв для хорошей модели
![Кривая точности-отзыв для хорошей модели](./media/how-to-understand-automated-ml/chart-precision-recall-curve-good.png)

### <a name="precision-recall-curve-for-a-bad-model"></a>Кривая точности-отзыв для неправильной модели
![Кривая точности-отзыв для неправильной модели](./media/how-to-understand-automated-ml/chart-precision-recall-curve-bad.png)

## <a name="cumulative-gains-curve"></a>Кривая совокупных выигрышей

Кривая Накопленная прибыль отображает процент положительных выборок, которые правильно классифицируются как функция процента выборок, рассматриваемых в порядке прогнозной вероятности.

Чтобы вычислить прибыль, сначала отсортируйте все выборки от самого высокого до наименьшей вероятности, прогнозируемой моделью. Затем принимаются `x%` максимальные прогнозы достоверности. Разделить число обнаруженных положительных выборок `x%` по общему количеству положительных выборок для получения прибыли. Интегральная прибыль — это процент положительных выборок, которые обнаруживаются при рассмотрении некоторого процента данных, которые, скорее всего, будут принадлежать к положительному классу.

Идеальная модель будет ранжировать все положительные выборки выше всех отрицательных выборок, предоставляя совокупную кривую выигрышей, состоящие из двух прямых сегментов. Первая — это линия с наклоном `1 / x` от `(0, 0)` до, `(x, 1)` где `x` — доля выборок, принадлежащих положительному классу ( `1 / num_classes` Если классы сбалансированы). Второй — горизонтальная линия от `(x, 1)` до `(1, 1)` . В первом сегменте все положительные выборки классифицируются правильно, а совокупное увеличение — в `100%` рамках первого `x%` из рассматриваемых примеров.

Базовая модель "Random" будет иметь общую кривую выигрыша, `y = x` Если для `x%` образцов, которые рассматриваются только `x%` в общем количестве положительных выборок, были обнаружены только общие. Идеальная модель будет иметь линейную среднюю кривую, которая касается левого верхнего угла и средней строки макроса с наклоном `1 / num_classes` до 100%, а затем по горизонтали до тех пор, пока процент данных не будет 100.
> [!TIP]
> Для экспериментов классификации каждый из графиков, созданных для автоматизированных моделей машинного обучения, можно использовать для вычисления модели по каждому классу или усреднения по всем классам. Можно переключаться между этими представлениями, щелкая метки классов в условных обозначениях справа от диаграммы.
### <a name="cumulative-gains-curve-for-a-good-model"></a>Совокупная кривая выигрышей для хорошей модели
![Совокупная кривая выигрышей для хорошей модели](./media/how-to-understand-automated-ml/chart-cumulative-gains-curve-good.png)

### <a name="cumulative-gains-curve-for-a-bad-model"></a>Совокупная кривая выигрышей для неправильной модели
![Совокупная кривая выигрышей для неправильной модели](./media/how-to-understand-automated-ml/chart-cumulative-gains-curve-bad.png)

## <a name="lift-curve"></a>Диаграмма точности прогнозов

Кривая точности показывает, сколько раз лучшая модель выполняется по сравнению с случайной моделью. Прогноз определяется как отношение совокупного увеличения к совокупному выигрышю случайной модели.

Эта относительная производительность учитывает тот факт, что классификация усложняется по мере увеличения числа классов. (Случайная модель неправильно прогнозирует большую долю выборок из набора данных с 10 классами по сравнению с набором данных с двумя классами).

Кривая с базовым прогнозом — это `y = 1` линия, в которой производительность модели согласуется с моделью случайной модели. В целом, кривая точности для хорошей модели будет выше на этой диаграмме и дальше от оси x, что покажет, что когда модель наиболее надежна в своих прогнозах, она работает много раз лучше, чем случайное догадка.

> [!TIP]
> Для экспериментов классификации каждый из графиков, созданных для автоматизированных моделей машинного обучения, можно использовать для вычисления модели по каждому классу или усреднения по всем классам. Можно переключаться между этими представлениями, щелкая метки классов в условных обозначениях справа от диаграммы.
### <a name="lift-curve-for-a-good-model"></a>Кривая точности прогнозов для хорошей модели
![Кривая точности прогнозов для хорошей модели](./media/how-to-understand-automated-ml/chart-lift-curve-good.png)
 
### <a name="lift-curve-for-a-bad-model"></a>Кривая точности прогнозов для неправильной модели
![Кривая точности прогнозов для неправильной модели](./media/how-to-understand-automated-ml/chart-lift-curve-bad.png)

## <a name="calibration-curve"></a>Кривая калибровки

Кривая калибровки отображает уверенность модели в своих прогнозах относительно пропорции положительных выборок на каждом уровне достоверности. Хорошо откалиброванная модель правильно классифицирует 100% прогнозов, до которых она назначает 100% достоверности, 50% от прогнозов, назначая доверие на уровне 50%, 20% прогнозов и т. д. Вполне откалиброванная модель будет иметь кривую калибровку, следующую за `y = x` строкой, где модель точно прогнозирует вероятность того, что выборки относятся к каждому классу.

Чрезмерно уверенная модель будет превышена до нуля, а другая — неопределенной для класса каждого примера, а Кривая калибровки будет выглядеть так же, как в обратном направлении "S". Более надежная модель привязывает меньшую вероятность среднего к классу, который он прогнозирует, и связанная Кривая калибровки будет выглядеть примерно как "S". Кривая калибровки не описывает возможность правильно классифицировать модель, а ее способность правильно назначать прогнозы. Неправильная модель по-прежнему может иметь хорошую кривую калибровку, если модель правильно назначит низкую достоверность и высокую неопределенность.

> [!NOTE]
> Кривая калибровки чувствительна к числу выборок, поэтому небольшой набор проверки может привести к нежелательным результатам, которые трудно интерпретировать. Это не обязательно означает, что модель не будет правильно откалибрована.

### <a name="calibration-curve-for-a-good-model"></a>Кривая калибровки для хорошей модели
![Кривая калибровки для хорошей модели](./media/how-to-understand-automated-ml/chart-calibration-curve-good.png)

### <a name="calibration-curve-for-a-bad-model"></a>Кривая калибровки для неправильной модели
![Кривая калибровки для неправильной модели](./media/how-to-understand-automated-ml/chart-calibration-curve-bad.png)

## <a name="regressionforecasting-metrics"></a>Метрики регрессии и прогнозирования

Автоматический ML вычисляет одинаковые метрики производительности для каждой создаваемой модели, независимо от того, является ли это экспериментом регрессии или прогнозирования. Эти метрики также прошли нормализацию, чтобы обеспечить сравнение моделей, обученных данными, с разными диапазонами. Дополнительные сведения см. в разделе [нормализация метрик](#metric-normalization).  

В следующей таблице перечислены метрики производительности модели, созданные для экспериментов и прогнозирования. Подобно метрикам классификации, эти метрики также основываются на реализации scikit. Соответствующая документация по scikitной документации связана соответствующим образом в поле **вычисления** .

|Метрика|Описание|Вычисление|
--|--|--|
explained_variance|Описанная дисперсия измеряет степень, до которой учетные записи модели для варианта в целевой переменной. Это процент уменьшения дисперсии исходных данных по отношению к дисперсии ошибок. Если среднее значение ошибки равно 0, то оно равно коэффициенту определения (см. r2_score ниже). <br> <br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** (-INF, 1]|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html)|
mean_absolute_error|Средняя абсолютная ошибка — это ожидаемое значение абсолютного значения разности между целевым объектом и прогнозом.<br><br> **Цель:** Ближе к 0 лучше <br> **Диапазон:** [0, INF-файл) <br><br> Типов <br>`mean_absolute_error` <br>  `normalized_mean_absolute_error`mean_absolute_error, деленную на диапазон данных. | [Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)|
mean_absolute_percentage_error|Среднее значение абсолютной ошибки в процентах (MAPE) — это мера среднего различия между прогнозируемым значением и фактическим значением.<br><br> **Цель:** Ближе к 0 лучше <br> **Диапазон:** [0, INF-файл) ||
median_absolute_error|Медиана абсолютной погрешности — это медиана всех абсолютных отклонений между целевым и прогнозируемым значениями. Такая потеря устойчива к выбросам.<br><br> **Цель:** Ближе к 0 лучше <br> **Диапазон:** [0, INF-файл)<br><br>Типов <br> `median_absolute_error`<br> `normalized_median_absolute_error`: median_absolute_error, деленную на диапазон данных. |[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html)|
r2_score;|R<sup>2</sup> (коэффициент определения) измеряет пропорциональное уменьшение в среднем квадрате ошибок (MSE) относительно общей дисперсии наблюдаемых данных. <br> <br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** [-1, 1]<br><br>Примечание. R<sup>2</sup> часто имеет диапазон (-INF, 1]. Размер MSE может быть больше наблюдаемой дисперсии, поэтому R<sup>2</sup> может иметь произвольно большие отрицательные значения в зависимости от данных и прогнозов модели. Автоматический фрагмент машинного обучения сообщил о показателях R<sup>2</sup> в значении-1, поэтому значение-1 для R<sup>2</sup> , скорее всего, означает, что значение true, если показатель r<sup>2</sup> меньше-1. Рассмотрите другие значения метрик и свойства данных при интерпретации отрицательной оценки R<sup>2</sup> .|[Вычисление](https://scikit-learn.org/0.16/modules/generated/sklearn.metrics.r2_score.html)|
root_mean_squared_error |Средняя квадратная ошибка (корень СРЕДНЕКВАДРАТИЧНОЙ ПОГРЕШНОСТИ) — это квадратный корень ожидаемого квадратного различия между целевым объектом и прогнозом. Для несмещенной оценки корень СРЕДНЕКВАДРАТИЧНОЙ ПОГРЕШНОСТИ равно стандартному отклонению.<br> <br> **Цель:** Ближе к 0 лучше <br> **Диапазон:** [0, INF-файл)<br><br>Типов<br> `root_mean_squared_error` <br> `normalized_root_mean_squared_error`: root_mean_squared_error, деленную на диапазон данных. |[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)|
root_mean_squared_log_error|Корень среднего значения ошибки журнала — квадратный корень ожидаемой квадратной логарифмической ошибки.<br><br>**Цель:** Ближе к 0 лучше <br> **Диапазон:** [0, INF-файл) <br> <br>Типов <br>`root_mean_squared_log_error` <br> `normalized_root_mean_squared_log_error`: root_mean_squared_log_error, деленную на диапазон данных.  |[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html)|
spearman_correlation;| Корреляция Спирмена — это непараметрическая мера монотонности связи между двумя наборами данных. В отличие от корреляции Пирсона, для корреляции Спирмена не предполагается, что оба набора данных используют нормальное распределение. Как и другие коэффициенты корреляции, Спеарман может иметь значение от-1 до 1, и 0 не подразумевает корреляцию. Для корреляций-1 или 1 подразумевается Точная монотонная связь. <br><br> Спеарман — это метрика корреляции порядка ранжирования, которая означает, что изменения в прогнозируемых или фактических значениях не будут приводить к изменению результата Спеарман, если они не меняют порядок ранжирования или фактических значений.<br> <br> **Цель:** Ближе к 1 лучше <br> **Диапазон:** [-1, 1]|[Вычисление](https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.spearmanr.html)|

### <a name="metric-normalization"></a>Нормализация метрик

Автоматический ML нормализует метрики регрессии и прогнозирования, что позволяет сравнивать модели, обученные данными, с разными диапазонами. Модель, обученная для данных с большим диапазоном, имеет более высокую ошибку, чем та же модель, обученная данными с меньшим диапазоном, если эта ошибка не нормализована.

Несмотря на то, что стандартный метод нормализации метрик ошибок не существует, автоматизированный ML принимает общий подход к разделению ошибок на диапазон данных: `normalized_error = error / (y_max - y_min)`

При оценке модели прогнозирования на основе данных временных рядов автоматизированное средство ML выполняет дополнительные действия, чтобы убедиться, что нормализация выполняется по ИДЕНТИФИКАТОРу временного ряда (зернистости), так как у каждого временного ряда вероятность другого распределения целевых значений.
## <a name="residuals"></a>Остатки

Остаточная диаграмма представляет собой гистограмму ошибок прогнозов (остатков), созданных для экспериментов и прогнозирования. Остатки рассчитываются как `y_predicted - y_true` для всех выборок, а затем отображаются в виде гистограммы для отображения смещения модели.

В этом примере обратите внимание, что обе модели немного смещены для предсказания ниже фактического значения. Это редко используется для набора данных с асимметричным распределением фактических целевых объектов, но указывает на производительность модели хуже. Хорошая модель будет иметь распределение остатков от нуля до нескольких остатков. Более серьезная модель будет иметь распределенное распределение остатков с меньшим числом выборок, равным нулю.

### <a name="residuals-chart-for-a-good-model"></a>Диаграмма остатков для хорошей модели
![Диаграмма остатков для хорошей модели](./media/how-to-understand-automated-ml/chart-residuals-good.png)

### <a name="residuals-chart-for-a-bad-model"></a>Диаграмма остатков для неправильной модели
![Диаграмма остатков для неправильной модели](./media/how-to-understand-automated-ml/chart-residuals-bad.png)

## <a name="predicted-vs-true"></a>Предсказанные и значения true

Для эксперимента и прогнозирования на диаграмме прогнозная и истинная диаграммы отображает связь между целевой функцией (истинными и фактическими значениями) и прогнозами модели. Значения true Binned вдоль оси x и для каждой ячейки. среднее прогнозируемое значение отображается планами погрешностей. Это позволяет определить, является ли модель более смещенной в сторону прогнозирования определенных значений. В строке отображается средний прогноз, а затененная область — дисперсия прогнозов вокруг этого среднего.

Часто наиболее распространенное значение true будет иметь наиболее точные прогнозы с наименьшей дисперсией. Расстояние от линии тренда от идеальной `y = x` линии, где существует несколько истинных значений, является хорошим показателем производительности модели при выбросах. В нижней части диаграммы можно использовать гистограмму, в которой объясняется фактическое распределение данных. Включая дополнительные примеры данных, в которых распределение является разреженным, может повысить производительность модели на невидимых данных.

В этом примере обратите внимание, что лучшая модель имеет прогнозируемую и истинную строку, расположенную ближе к идеальной `y = x` линии.

### <a name="predicted-vs-true-chart-for-a-good-model"></a>Прогнозируемая и истинная диаграмма для хорошей модели
![Прогнозируемая и истинная диаграмма для хорошей модели](./media/how-to-understand-automated-ml/chart-predicted-true-good.png)

### <a name="predicted-vs-true-chart-for-a-bad-model"></a>Прогнозируемая и истинная диаграмма для неправильной модели
![Прогнозируемая и истинная диаграмма для неправильной модели](./media/how-to-understand-automated-ml/chart-predicted-true-bad.png)

## <a name="model-explanations-and-feature-importances"></a>Пояснения к модели и важность функций

Хотя метрики и диаграммы оценки модели хорошо подходят для измерения общего качества модели, проверка того, какой набор данных использует модель, которая используется для прогнозирования прогнозов, очень важно при тренировке ответственного ии. Именно поэтому автоматизированное ML предоставляет панель мониторинга для интерпретируемости модели, которая позволяет измерять и сообщать об относительных вкладах функций набора данных.

Чтобы просмотреть панель мониторинга интерпретируемости в студии, сделайте следующее:
1. [Войдите в студию студии](https://ml.azure.com/) и перейдите к рабочей области.
2. В меню слева выберите **эксперименты** .
3. Выбор эксперимента из списка экспериментов
4. В таблице в нижней части страницы выберите Запуск Аутомл.
5. На вкладке **модели** выберите **имя алгоритма** для модели, которую необходимо объяснить.
6. На вкладке **пояснения** вы можете увидеть, что уже было создано, если модель лучше
7. Чтобы создать новое пояснение, выберите **объяснить модель** и выберите удаленное вычисление, с помощью которого нужно вычислить объяснения.

[Дополнительные сведения о моделях в автоматизированном ML](how-to-machine-learning-interpretability-automl.md).

> [!NOTE]
> В настоящее время модель Форекастткн не поддерживается автоматическими объяснениями ML, а другие модели прогнозирования могут иметь ограниченный доступ к средствам интерпретации.

## <a name="next-steps"></a>Дальнейшие действия
* Попробуйте [пример автоматизированной учебной записной книжки с описанием модели машинного обучения](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/explain-model).
* Для автоматических вопросов, связанных с МАШИНным обучением, обращайтесь к askautomatedml@microsoft.com .
