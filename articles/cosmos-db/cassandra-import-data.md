---
title: Руководство. Перенос данных в учетную запись API Cassandra в Azure Cosmos DB
description: В этом руководстве описано копирование данных из Apache Cassandra в учетную запись API Cassandra в Azure Cosmos DB.
author: kanshiG
ms.author: govindk
ms.reviewer: sngun
ms.service: cosmos-db
ms.subservice: cosmosdb-cassandra
ms.topic: tutorial
ms.date: 12/03/2018
ms.custom: seodec18
ms.openlocfilehash: 7c55cbf4b8739a885c499c820a7e68825522ea4e
ms.sourcegitcommit: 56b0c7923d67f96da21653b4bb37d943c36a81d6
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/06/2021
ms.locfileid: "106449296"
---
# <a name="tutorial-migrate-your-data-to-a-cassandra-api-account"></a>Руководство. Перенос данных в учетную запись API Cassandra
[!INCLUDE[appliesto-cassandra-api](includes/appliesto-cassandra-api.md)]

Как у разработчика у вас могут существовать рабочие нагрузки Cassandra, выполняемые локально или в облаке, и может понадобиться перенести их в Azure. Такие рабочие нагрузки можно перенести в учетную запись API Cassandra в Azure Cosmos DB. В этом руководстве приведены инструкции к различным методам переноса данных Apache Cassandra в учетную запись API Cassandra в Azure Cosmos DB.

В рамках этого руководства рассматриваются следующие задачи:

> [!div class="checklist"]
> * Планирование миграции
> * Предварительные требования для миграции
> * Перенос данных с помощью команды `cqlsh` `COPY`
> * Перенос данных с помощью Spark

Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись Azure](https://azure.microsoft.com/free/?WT.mc_id=A261C142F), прежде чем начинать работу.

## <a name="prerequisites-for-migration"></a>Предварительные требования для миграции

* **Оцените требования к пропускной способности.** Прежде чем переносить данные в учетную запись API Cassandra в Azure Cosmos DB, следует оценить потребности в пропускной способности рабочей нагрузки. Как правило, рекомендуется начинать со средней пропускной способности, требуемой для операций CRUD, а затем включить дополнительную пропускную способность, необходимую для операций извлечения, преобразования и загрузки или операций, для которых характерны резкие скачки. Для планирования миграции необходимо знать следующее. 

  * **Текущий или предполагаемый размер данных.** Определяет минимальное требование к размеру базы данных и пропускной способности. Если вы оцениваете размер данных для нового приложения, можно предположить, что данные равномерно распределены по строкам, и получить примерное значение путем умножения на размер данных. 

  * **Требуемая пропускная способность.** Приблизительная пропускная способность для операций чтения (запрос, получение) и записи (изменение, удаление, вставка). Это значение необходимо для вычисления требуемого количества единиц, а также размера данных в устойчивом состоянии.  

  * **Схема.** Подключитесь к существующему кластеру Cassandra с помощью `cqlsh` и экспортируйте схему из Cassandra. 

    ```bash
    cqlsh [IP] "-e DESC SCHEMA" > orig_schema.cql
    ```

    Определив требования существующей рабочей нагрузки, создайте учетную запись Azure Cosmos DB, базу данных и контейнеры в соответствии с полученными требованиями к пропускной способности.  

  * **Определите стоимость операции в единицах запроса.** Определить ЕЗ можно с помощью любого из пакетов SDK, поддерживаемого API Cassandra. В этом примере мы используем для оценки затрат версию .NET.

    ```csharp
    var tableInsertStatement = table.Insert(sampleEntity);
    var insertResult = await tableInsertStatement.ExecuteAsync();

    foreach (string key in insertResult.Info.IncomingPayload)
      {
         byte[] valueInBytes = customPayload[key];
         double value = Encoding.UTF8.GetString(valueInBytes);
         Console.WriteLine($"CustomPayload:  {key}: {value}");
      }
    ```

* **Выделите требуемую пропускную способность.** Azure Cosmos DB поддерживает автоматическое масштабирование хранилища и пропускной способности по мере роста требований. Вы можете оценить требуемую вам пропускную способность с помощью [калькулятора единиц запроса Azure Cosmos DB](https://www.documentdb.com/capacityplanner). 

* **Создайте таблицы в учетной записи API Cassandra.** Прежде чем начать миграцию данных, предварительно создайте все таблицы с помощью портала Azure или `cqlsh`. Если вы выполняете перенос в учетную запись Azure Cosmos DB, обладающую пропускной способностью уровня базы данных, обязательно укажите ключ раздела при создании контейнеров.

* **Увеличьте пропускную способность.** Продолжительность перемещения данных зависит от пропускной способности, которую вы предоставите для таблиц в Azure Cosmos DB. Увеличьте пропускную способность на время выполнения миграции. Более высокая пропускная способность позволяет избежать ограничения скорости и выполнить перенос быстрее. После переноса уменьшите пропускную способность для экономии расходов. Также рекомендуется использовать учетную запись Azure Cosmos DB, находящуюся в том же регионе, что и база данных-источник. 

* **Включите протокол TLS.** В Azure Cosmos DB строгие требования к безопасности и стандарты. Обязательно включите TLS при взаимодействии с учетной записью. При использовании CQL с SSH у вас есть возможность предоставить сведения о TLS.

## <a name="options-to-migrate-data"></a>Варианты миграции данных

Вы можете переместить данные из существующих рабочих нагрузок Cassandra в Azure Cosmos DB с помощью команды `cqlsh` `COPY` или с помощью Spark. 

### <a name="migrate-data-by-using-the-cqlsh-copy-command"></a>Перенос данных с помощью команды cqlsh COPY

[Команда CQL COPY](https://cassandra.apache.org/doc/latest/tools/cqlsh.html#cqlsh) используется для копирования локальных данных в учетную запись API Cassandra в Azure Cosmos DB.

1. Получение сведений о строке подключения для учетной записи API Cassandra

   * Войдите на [портал Azure](https://portal.azure.com) и перейдите в учетную запись Azure Cosmos DB.

   * Откройте панель **Строка подключения**. Здесь вы можете просмотреть все сведения, необходимые для подключения к учетной записи API Cassandra из `cqlsh`.

1. Войдите в `cqlsh`, используя полученные на портале сведения о подключении.

1. Используйте команду `CQL` `COPY`, чтобы скопировать локальные данные в учетную запись API Cassandra.

   ```bash
   COPY exampleks.tablename FROM filefolderx/*.csv 
   ```

### <a name="migrate-data-by-using-spark"></a>Перенос данных с помощью Spark 

Для переноса данных в учетную запись API Cassandra с помощью Spark следуйте приведенным ниже инструкциям.

1. Подготовьте [кластер Azure Databricks](cassandra-spark-databricks.md) или [кластер Azure HDInsight](cassandra-spark-hdinsight.md). 

1. Переместите данные в целевую конечную точку API Cassandra с помощью [операции копирования таблиц](cassandra-spark-table-copy-ops.md). 

Перенос данных с помощью заданий Spark рекомендуется, если у вас есть данные, хранимые в существующем кластере в виртуальных машинах Azure или в любом другом облаке. Для этого следует настроить Spark в качестве промежуточного звена для однократного или регулярного приема данных. Можно ускорить миграцию с помощью подключений Azure ExpressRoute между локальной средой и Azure. 

## <a name="clean-up-resources"></a>Очистка ресурсов

Когда группа ресурсов, учетная запись Azure Cosmos DB и все связанные ресурсы не требуются, можно удалить их. Для этого выберите группу ресурсов для виртуальной машины, выберите **Удалить** и подтвердите имя удаляемой группы ресурсов.

## <a name="next-steps"></a>Дальнейшие действия

Из этого руководства вы узнали, как перенести данные в учетную запись API Cassandra в Azure Cosmos DB. Теперь вы можете познакомиться с другими концепциями Azure Cosmos DB:

> [!div class="nextstepaction"]
> [Настраиваемые уровни согласованности данных в Azure Cosmos DB](../cosmos-db/consistency-levels.md)




