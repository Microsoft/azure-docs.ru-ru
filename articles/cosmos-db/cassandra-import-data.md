---
title: Руководство. Перенос данных в учетную запись API Cassandra в Azure Cosmos DB
description: В этом руководстве описано использование команды CQL Copy и Spark для копирования данных из Apache Cassandra в учетную запись API Cassandra в Azure Cosmos DB
author: kanshiG
ms.author: govindk
ms.reviewer: sngun
ms.service: cosmos-db
ms.subservice: cosmosdb-cassandra
ms.topic: tutorial
ms.date: 12/03/2018
ms.custom: seodec18
ms.openlocfilehash: bd2d27addb6860e49ac12eb36d8b625b8bf92001
ms.sourcegitcommit: f28ebb95ae9aaaff3f87d8388a09b41e0b3445b5
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/29/2021
ms.locfileid: "93100411"
---
# <a name="tutorial-migrate-your-data-to-cassandra-api-account-in-azure-cosmos-db"></a>Руководство по Перенос данных в учетную запись API Cassandra в Azure Cosmos DB
[!INCLUDE[appliesto-cassandra-api](includes/appliesto-cassandra-api.md)]

Как у разработчика у вас могут существовать рабочие нагрузки Cassandra, выполняемые локально или в облаке, и может понадобиться перенести их в Azure. Такие рабочие нагрузки можно перенести в учетную запись API Cassandra в Azure Cosmos DB. В этом руководстве приведены инструкции к различным методам переноса данных Apache Cassandra в учетную запись API Cassandra в Azure Cosmos DB.

В рамках этого руководства рассматриваются следующие задачи:

> [!div class="checklist"]
> * Планирование миграции
> * Предварительные требования для миграции
> * Перенос данных с помощью команды cqlsh COPY
> * Перенос данных с помощью Spark

Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись Azure](https://azure.microsoft.com/free/?WT.mc_id=A261C142F), прежде чем начинать работу.

## <a name="prerequisites-for-migration"></a>Предварительные требования для миграции

* **Оцените требования к пропускной способности.** Прежде чем переносить данные в учетную запись API Cassandra в Azure Cosmos DB, следует оценить потребности в пропускной способности рабочей нагрузки. Как правило, рекомендуется начинать со средней пропускной способности, требуемой для операций CRUD, а затем включить дополнительную пропускную способность, необходимую для операций извлечения, преобразования и загрузки (ETL) или операций, для которых характерны резкие скачки. Для планирования миграции необходимо знать следующее. 

  * **Текущий или предполагаемый размер данных.** Определяет минимальное требование к размеру базы данных и пропускной способности. Если вы оцениваете размер данных для нового приложения, можно предположить, что данные равномерно распределены по строкам, и получить примерное значение путем умножения на размер данных. 

  * **Необходимая пропускная способность.** Приблизительная пропускная способность для операций чтения (запрос, получение) и записи (изменение, удаление, вставка). Это значение необходимо для вычисления требуемого количества единиц, а также размера данных в устойчивом состоянии.  

  * **Схема.** Подключитесь к существующему кластеру Cassandra с помощью cqlsh и экспортируйте схему из Cassandra: 

    ```bash
    cqlsh [IP] "-e DESC SCHEMA" > orig_schema.cql
    ```

    Определив требования существующей рабочей нагрузки, необходимо создать учетную запись Azure Cosmos, базу данных и контейнеры в соответствии с полученными требованиями к пропускной способности.  

  * **Определите стоимость операции в единицах запроса.** Определить ЕЗ можно с помощью любого из пакетов SDK, поддерживаемого API Cassandra. В этом примере мы используем для оценки затрат версию .NET.

    ```csharp
    var tableInsertStatement = table.Insert(sampleEntity);
    var insertResult = await tableInsertStatement.ExecuteAsync();

    foreach (string key in insertResult.Info.IncomingPayload)
      {
         byte[] valueInBytes = customPayload[key];
         double value = Encoding.UTF8.GetString(valueInBytes);
         Console.WriteLine($"CustomPayload:  {key}: {value}");
      }
    ```

* **Выделите требуемую пропускную способность.** Azure Cosmos DB поддерживает автоматическое масштабирование хранилища и пропускной способности по мере роста требований. Вы можете оценить требуемую вам пропускную способность с помощью [калькулятора единиц запроса Azure Cosmos DB](https://www.documentdb.com/capacityplanner). 

* **Создайте таблицы в учетной записи API Cassandra.** Прежде чем запустить перемещение данных, создайте все таблицы с помощью портала Azure или cqlsh. Если вы выполняете перенос в учетную запись Azure Cosmos, обладающую пропускной способностью уровня базы данных, при создании контейнеров Azure Cosmos обязательно укажите ключ раздела.

* **Увеличьте пропускную способность.** Продолжительность перемещения данных зависит от пропускной способности, которую вы предоставите для таблиц в Azure Cosmos DB. Увеличьте пропускную способность на время выполнения миграции. Более высокая пропускная способность позволяет избежать ограничения скорости и выполнить перенос быстрее. После переноса уменьшите пропускную способность для экономии расходов. Также рекомендуется разместить учетную запись Azure Cosmos в том же регионе, где находится база данных-источник. 

* **Включите протокол TLS.** В Azure Cosmos DB строгие требования к безопасности и стандарты. Обязательно включите TLS при взаимодействии с учетной записью. При использовании CQL с SSH у вас есть возможность предоставить сведения о TLS.

## <a name="options-to-migrate-data"></a>Варианты миграции данных

Вы можете переместить данные из существующих рабочих нагрузок Cassandra в Azure Cosmos DB следующим образом:

* [с помощью команды cqlsh COPY](#migrate-data-using-cqlsh-copy-command);  
* [с помощью Spark](#migrate-data-using-spark). 

## <a name="migrate-data-using-cqlsh-copy-command"></a>Перенос данных с помощью команды cqlsh COPY

[Команда CQL COPY](https://cassandra.apache.org/doc/latest/tools/cqlsh.html#cqlsh) используется для копирования локальных данных в учетную запись API Cassandra в Azure Cosmos DB. Выполните указанные ниже действия, чтобы копировать данные.

1. Получение сведений о строке подключения для учетной записи API Cassandra

   * Войдите на [портал Azure](https://portal.azure.com) и перейдите в учетную запись Azure Cosmos.

   * Откройте область **Строка подключения**, которая содержит все сведения, необходимые для подключения к учетной записи API Cassandra из cqlsh.

2. Войдите в cqhsh, используя полученные на портале сведения о подключении.

3. Используйте команду CQL COPY, чтобы скопировать локальные данные в учетную запись API Cassandra.

   ```bash
   COPY exampleks.tablename FROM filefolderx/*.csv 
   ```

## <a name="migrate-data-using-spark"></a>Перенос данных с помощью Spark 

Для переноса данных в учетную запись API Cassandra с помощью Spark следуйте приведенным ниже инструкциям.

- Подготовьте [кластер Azure Databricks](cassandra-spark-databricks.md) или [кластер HDInsight](cassandra-spark-hdinsight.md). 

- Переместите данные в целевую конечную точку API Cassandra с помощью [табличной операции копирования](cassandra-spark-table-copy-ops.md). 

Перенос данных с помощью заданий Spark рекомендуется, если у вас есть данные, хранимые в существующем кластере в виртуальных машинах Azure или в любом другом облаке. Для этого следует настроить Spark в качестве промежуточного звена для однократного или регулярного приема данных. Можно ускорить миграцию с помощью подключений Azure ExpressRoute между локальной сетью и Azure. 

## <a name="clean-up-resources"></a>Очистка ресурсов

Можно удалить группу ресурсов, учетную запись Azure Cosmos и все связанные ресурсы, когда они больше не нужны. Для этого выберите группу ресурсов для виртуальной машины, выберите **Удалить** и подтвердите имя удаляемой группы ресурсов.

## <a name="next-steps"></a>Дальнейшие действия

Из этого руководства вы узнали, как перенести данные в учетную запись API Cassandra в Azure Cosmos DB. Теперь можно перейти к следующей статье, чтобы узнать о других понятиях Azure Cosmos DB.

> [!div class="nextstepaction"]
> [Настраиваемые уровни согласованности данных в Azure Cosmos DB](../cosmos-db/consistency-levels.md)


