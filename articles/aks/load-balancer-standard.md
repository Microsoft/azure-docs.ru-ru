---
title: Использование общедоступной Load Balancer
titleSuffix: Azure Kubernetes Service
description: Узнайте, как использовать общедоступную подсистему балансировки нагрузки со стандартным SKU для предоставления служб Azure Kubernetes Service (AKS).
services: container-service
ms.topic: article
ms.date: 11/14/2020
ms.author: jpalma
author: palma21
ms.openlocfilehash: e37c5a748a8e99f49e3535946268427139bbbf44
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/20/2021
ms.locfileid: "102184429"
---
# <a name="use-a-public-standard-load-balancer-in-azure-kubernetes-service-aks"></a>Использование общедоступной Load Balancer (цен. категория "Стандартный") в службе Kubernetes Azure (AKS)

Azure Load Balancer находится на уровне 4 модели соединений Open Systems (OSI), поддерживающей как входящие, так и исходящие сценарии. Он распределяет входящие потоки, поступающие в внешний интерфейс балансировщика нагрузки, в экземпляры внутреннего пула.

**Общедоступная** Load Balancer при интеграции с AKS служит двум целям:

1. Для предоставления исходящих подключений к узлам кластера в виртуальной сети AKS. Эта цель достигается путем перевода частного IP-адреса узлов на общедоступный IP-адрес, который является частью его *исходящего пула*.
2. Для предоставления доступа к приложениям через службы Kubernetes Services типа `LoadBalancer` . С его помощью можно легко масштабировать приложения и создавать высокодоступные службы.

Используется внутренняя подсистема балансировки нагрузки **(или частная)** , где только частные IP-адреса разрешены в качестве внешнего интерфейса. Внутренние Load Balancer используются для балансировки трафика внутри виртуальной сети. Кроме того, можно получить доступ к внешнему интерфейсу балансировщика нагрузки из локальной сети в гибридном сценарии.

В этом документе рассматривается интеграция с общедоступной подсистемой балансировки нагрузки. Сведения о внутренней интеграции Load Balancer см. в [документации по внутренней подсистеме балансировки нагрузки AKS](internal-lb.md).

## <a name="before-you-begin"></a>Перед началом

Доступны два номера SKU Azure Load Balancer: ценовых категорий *Базовый* и *Стандартный*. По умолчанию при создании кластера AKS используется номер SKU " *стандартный* ". Используйте номер SKU " *стандартный* ", чтобы получить доступ к дополнительным функциям, таким как серверный пул большего размера, [**несколько пулов узлов**](use-multiple-node-pools.md)и [**зоны доступности**](availability-zones.md). Это рекомендуемый номер SKU Load Balancer AKS.

Дополнительные сведения о номерах SKU ценовых категорий *Базовый* и *Стандартный* см. в разделе [Сравнение SKU подсистемы балансировки нагрузки][azure-lb-comparison].

В этой статье предполагается, что у вас есть кластер AKS со *стандартным* номером SKU Azure Load Balancer и рассматривается использование и настройка некоторых возможностей и функций балансировщика нагрузки. Если вам нужен кластер AKS, обратитесь к краткому руководству по работе с AKS [с помощью Azure CLI][aks-quickstart-cli] или [портала Azure][aks-quickstart-portal].

> [!IMPORTANT]
> Если вы предпочитаете не использовать Azure Load Balancer для предоставления исходящего подключения и у вас есть собственный шлюз, брандмауэр или прокси-сервер для этой цели, вы можете пропустить создание исходящего пула подсистемы балансировки нагрузки и соответствующий интерфейсный IP-адрес, используя [**Тип исходящего трафика как усердефинедраутинг (UDR)**](egress-outboundtype.md). Исходящий тип определяет метод исходящего трафика для кластера и по умолчанию имеет тип: балансировщик нагрузки.

## <a name="use-the-public-standard-load-balancer"></a>Использование общедоступной подсистемы балансировки нагрузки уровня "Стандартный"

После создания кластера AKS с типом исходящего трафика: Load Balancer (по умолчанию), кластер готов использовать подсистему балансировки нагрузки для предоставления служб.

Для этого можно создать общедоступную службу типа, `LoadBalancer` как показано в следующем примере. Начните с создания манифеста службы с именем `public-svc.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: public-svc
spec:
  type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: public-app
```

Разверните общедоступный манифест службы с помощью [kubectl Apply][kubectl-apply] и укажите имя манифеста YAML:

```azurecli-interactive
kubectl apply -f public-svc.yaml
```

В Azure Load Balancer будет настроен новый общедоступный IP-адрес, который будет использоваться для этой новой службы. Поскольку Azure Load Balancer может иметь несколько интерфейсных IP-адресов, каждая развернутая служба будет получать новый выделенный интерфейсный IP для доступа к нему.

Вы можете убедиться, что служба создана и подсистема балансировки нагрузки настроена, выполнив, например:

```azurecli-interactive
kubectl get service public-svc
```

```console
NAMESPACE     NAME          TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)         AGE
default       public-svc    LoadBalancer   10.0.39.110    52.156.88.187   80:32068/TCP    52s
```

При просмотре сведений о службе общедоступный IP-адрес, созданный для этой службы в подсистеме балансировки нагрузки, отображается в столбце *External-IP* . Изменение IP-адреса с *\<pending\>* на фактический общедоступный IP-адрес может занять одну или две минуты, как показано в приведенном выше примере.

## <a name="configure-the-public-standard-load-balancer"></a>Настройка общедоступной подсистемы балансировки нагрузки уровня "Стандартный"

При использовании общедоступной подсистемы балансировки нагрузки уровня "Стандартный" существует набор параметров, которые можно настроить во время создания или путем обновления кластера. Эти параметры позволяют настраивать Load Balancer в соответствии с потребностями рабочих нагрузок и должны проверяться соответствующим образом. С помощью стандартного балансировщика нагрузки можно:

* Установка или масштабирование количества управляемых исходящих IP-адресов
* Перенесите собственные настраиваемые IP [-адреса или префикс исходящего трафика](#provide-your-own-outbound-public-ips-or-prefixes)
* Настройка количества выделенных исходящих портов для каждого узла кластера
* Настройка параметра timeout для бездействующих соединений

> [!IMPORTANT]
> В определенный момент времени можно использовать только один параметр исходящего IP-адреса (управляемые IP-адреса, их использование или префикс IP-адреса).

### <a name="scale-the-number-of-managed-outbound-public-ips"></a>Масштабирование количества управляемых исходящих общедоступных IP-адресов

Кроме входящего трафика, Azure Load Balancer обеспечивает исходящие подключения из виртуальной сети. С помощью правил для исходящего трафика можно легко настроить общедоступное исходящее преобразование сетевых адресов (NAT) Load Balancer (цен. категория "Стандартный").

Как и все правила Load Balancer, правила для исходящего трафика соответствуют тому же знакомому синтаксису, что и правила балансировки нагрузки и NAT для входящего трафика:

***IP-адреса интерфейсов + параметры + внутренний пул***

Правило для исходящего трафика настраивает NAT для исходящего трафика, предусматривающее преобразование всех виртуальных машин, определенных с помощью серверного пула, во внешний интерфейс. Параметры обеспечивают дополнительное детальное управление алгоритмом NAT для исходящего трафика.

Хотя правило для исходящего трафика можно использовать только с одним общедоступным IP-адресом, правила для исходящего трафика облегчают настройку для масштабирования NAT для исходящего трафика. Вы можете использовать несколько IP-адресов для планирования крупномасштабных сценариев, а также применять правила для исходящего трафика для обхода шаблонов, подверженных нехватке SNAT. Каждый дополнительный IP-адрес, предоставляемый интерфейсом, предоставляет временные порты размером 64 КБ для Load Balancer для использования в качестве портов SNAT. 

При использовании балансировщика нагрузки " *стандартный* " с управляемыми исходящими общедоступными IP-адресами, которые создаются по умолчанию, можно масштабировать количество управляемых исходящих общедоступных IP-адресов с помощью **`load-balancer-managed-ip-count`** параметра.

Чтобы обновить существующий кластер, выполните следующую команду. Этот параметр можно также задать во время создания кластера, чтобы использовать несколько управляемых общедоступных исходящих IP-адресов.

```azurecli-interactive
az aks update \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --load-balancer-managed-outbound-ip-count 2
```

В приведенном выше примере задано *2* управляемых общедоступных исходящих IP-адреса для кластера *myAKSCluster* в *myResourceGroup*. 

Можно также использовать параметр, **`load-balancer-managed-ip-count`** чтобы задать начальное число управляемых исходящих общедоступных IP-адресов при создании кластера, добавив **`--load-balancer-managed-outbound-ip-count`** параметр и задав для него нужное значение. По умолчанию число управляемых общедоступных исходящих IP-адресов равно 1.

### <a name="provide-your-own-outbound-public-ips-or-prefixes"></a>Укажите собственные исходящие общедоступные IP-адреса или префиксы

При использовании балансировщика нагрузки " *стандартный* " SKU кластер AKS автоматически создает общедоступный IP-адрес в группе ресурсов инфраструктуры, управляемой AKS, и назначает его исходящему пулу подсистемы балансировки нагрузки.

Общедоступный IP-адрес, созданный AKS, считается управляемым ресурсом AKS. Это означает, что жизненный цикл этого общедоступного IP-адреса должен управляться AKS и не требует вмешательства пользователя непосредственно в ресурсе общедоступного IP-адреса. Кроме того, можно назначить собственный общедоступный IP-адрес или префикс общедоступного IP-адреса во время создания кластера. Пользовательские IP-адреса можно также обновить в свойствах подсистемы балансировки нагрузки существующего кластера.

Требования к использованию собственного общедоступного IP-адреса или префикса:

- Пользовательские общедоступные IP-адреса должны быть созданы и принадлежать пользователю. Управляемые общедоступные IP-адреса, созданные AKS, не могут быть использованы повторно в качестве собственного настраиваемых IP-адресов, так как это может привести к конфликтам управления.
- Необходимо убедиться, что удостоверение кластера AKS (субъект-служба или управляемое удостоверение) имеет разрешения на доступ к исходящему IP-адресу. В соответствии со [списком необходимых разрешений общедоступных IP-адресов](kubernetes-service-principal.md#networking).
- Убедитесь, что соблюдены [Предварительные требования и ограничения](../virtual-network/public-ip-address-prefix.md#constraints) , необходимые для настройки исходящих IP-адресов или префиксов исходящего трафика.

#### <a name="update-the-cluster-with-your-own-outbound-public-ip"></a>Обновление кластера с помощью собственного исходящего общедоступного IP-адреса

Чтобы получить список идентификаторов общедоступных IP-адресов, используйте команду [az network public-ip show][az-network-public-ip-show].

```azurecli-interactive
az network public-ip show --resource-group myResourceGroup --name myPublicIP --query id -o tsv
```

Приведенная выше команда отображает идентификатор общедоступного IP-адреса *myPublicIP* в группе ресурсов *myResourceGroup*.

Используйте `az aks update` команду с **`load-balancer-outbound-ips`** параметром, чтобы обновить кластер с помощью общедоступных IP-адресов.

В следующем примере используется `load-balancer-outbound-ips` параметр с идентификаторами из предыдущей команды.

```azurecli-interactive
az aks update \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --load-balancer-outbound-ips <publicIpId1>,<publicIpId2>
```

#### <a name="update-the-cluster-with-your-own-outbound-public-ip-prefix"></a>Обновление кластера с помощью собственного исходящего префикса общедоступного IP-адреса

Для исходящего трафика подсистемы балансировки нагрузки *ценовой категории "Стандартный"* можно также использовать префиксы общедоступных IP-адресов. В следующем примере для отображения идентификаторов общедоступных IP-адресов используется команда [az network public-ip prefix show][az-network-public-ip-prefix-show].

```azurecli-interactive
az network public-ip prefix show --resource-group myResourceGroup --name myPublicIPPrefix --query id -o tsv
```

Приведенная выше команда отображает идентификатор префикса общедоступного IP-адреса *myPublicIPPrefix* в группе ресурсов *myResourceGroup*.

В следующем примере используется параметр *load-balancer-outbound-ip-prefixes* с идентификаторами из предыдущей команды.

```azurecli-interactive
az aks update \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --load-balancer-outbound-ip-prefixes <publicIpPrefixId1>,<publicIpPrefixId2>
```

#### <a name="create-the-cluster-with-your-own-public-ip-or-prefixes"></a>Создание кластера с собственными общедоступными IP-адресами или префиксами

Вы можете использовать собственные IP-адреса или префиксы IP-адресов для исходящего трафика во время создания кластера для поддержки таких сценариев, как добавление конечных точек исходящего трафика в список разрешений. Добавьте параметры, показанные выше, на шаге создания кластера, чтобы определить собственные общедоступные IP-адреса и префиксы IP-адресов в самом начале жизненного цикла кластера.

Чтобы создать кластер с указанными общедоступными IP-адресами, используйте команду *az aks create* с параметром *load-balancer-outbound-ips*.

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --load-balancer-outbound-ips <publicIpId1>,<publicIpId2>
```

Используйте команду *az aks create* с параметром *load-balancer-outbound-ip-prefixes*, чтобы создать кластер с префиксами общедоступных IP-адресов.

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --load-balancer-outbound-ip-prefixes <publicIpPrefixId1>,<publicIpPrefixId2>
```

### <a name="configure-the-allocated-outbound-ports"></a>Настройка выделенных исходящих портов

> [!IMPORTANT]
> Если в кластере есть приложения, которые должны устанавливать большое количество соединений с небольшим набором назначений, например. во многих интерфейсных экземплярах, подключающихся к базе данных SQL, существует сценарий, который очень уязвим для обнаружения нехватки портов SNAT (для подключения не нужно использовать порты). В этих сценариях настоятельно рекомендуется увеличить количество выделенных исходящих портов и исходящих IP-адресов в подсистеме балансировки нагрузки. Увеличение должно учитывать, что один (1) дополнительный IP-адрес добавляет дополнительные порты для распределения по всем узлам кластера.


Если не указано иное, AKS будет использовать значение по умолчанию для выделенных исходящих портов, которое Load Balancer (цен. категория "Стандартный") определяет при настройке. Это значение равно **null** в API AKS или **0** в API SLB, как показано в следующей команде:

```azurecli-interactive
NODE_RG=$(az aks show --resource-group myResourceGroup --name myAKSCluster --query nodeResourceGroup -o tsv)
az network lb outbound-rule list --resource-group $NODE_RG --lb-name kubernetes -o table
```

Предыдущие команды отобразили бы правило для исходящего трафика для подсистемы балансировки нагрузки, например:

```console
AllocatedOutboundPorts    EnableTcpReset    IdleTimeoutInMinutes    Name             Protocol    ProvisioningState    ResourceGroup
------------------------  ----------------  ----------------------  ---------------  ----------  -------------------  -------------
0                         True              30                      aksOutboundRule  All         Succeeded            MC_myResourceGroup_myAKSCluster_eastus  
```

Эти выходные данные не означают, что у вас 0 портов, но вместо этого вы используете [Автоматическое назначение исходящего порта на основе размера внутреннего пула][azure-lb-outbound-preallocatedports]. Например, если кластер содержит 50 или менее узлов, выделяются 1024 портов для каждого узла, при увеличении числа узлов на каждом узле постепенно увеличивается число портов.


Чтобы определить или увеличить количество выделенных исходящих портов, можно использовать следующий пример:


```azurecli-interactive
az aks update \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --load-balancer-managed-outbound-ip-count 7 \
    --load-balancer-outbound-ports 4000
```

В этом примере выделено 4000 исходящих портов для каждого узла в кластере, а с 7 IP-адресами будет *4000 портов на узел * 100 узлов = 400 тыс. всего портов < = 448k всего портов = 7 IP-адресов * 64k на каждый IP*. Это позволит безопасно масштабироваться до 100 узлов и иметь операцию обновления по умолчанию. Очень важно выделить достаточное количество портов для дополнительных узлов, необходимых для обновления и других операций. AKS по умолчанию использует один узел буфера для обновления. в этом примере для этого требуется 4000 бесплатных портов в любой момент времени. При использовании [значений макссурже](upgrade-cluster.md#customize-node-surge-upgrade)умножьте исходящие порты на узел на значение макссурже.

Чтобы безопасно пройти свыше 100 узлов, необходимо добавить дополнительные IP-адреса.


> [!IMPORTANT]
> Необходимо [рассчитать требуемую квоту и проверить требования][requirements] перед настройкой *аллокатедаутбаундпортс* , чтобы избежать проблем с подключением или масштабированием.

Можно также использовать **`load-balancer-outbound-ports`** параметры при создании кластера, но необходимо также указать **`load-balancer-managed-outbound-ip-count`** , **`load-balancer-outbound-ips`** или **`load-balancer-outbound-ip-prefixes`** .  Пример:

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --load-balancer-sku standard \
    --load-balancer-managed-outbound-ip-count 2 \
    --load-balancer-outbound-ports 1024 
```

### <a name="configure-the-load-balancer-idle-timeout"></a>Настройка времени ожидания простоя подсистемы балансировки нагрузки

Если ресурс портов SNAT исчерпан, исходящие потоки прекращаются, пока имеющиеся потоки не освободят порты SNAT. Load Balancer освобождает порты SNAT, когда поток закрывается, а подсистема балансировки нагрузки AKS использует 30-минутный таймаут простоя для освобождения портов SNAT из бездействующих потоков.
Можно также использовать транспорт (например, **`TCP keepalives`** ) или **`application-layer keepalives`** для обновления потока простоя и сброса этого времени ожидания простоя при необходимости. Это время ожидания можно настроить, следуя приведенному ниже примеру. 


```azurecli-interactive
az aks update \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --load-balancer-idle-timeout 4
```

Если предполагается наличие большого количества кратковременных подключений и долгое время бездействия не истечет и в течение длительного времени простоя, `kubectl proxy` например, `kubectl port-forward` использование или попробуйте использовать низкое значение времени ожидания, такое как 4 минуты. Кроме того, при использовании протокола TCP проверку активности достаточно включить их на одной стороне соединения. Например, достаточно включить их на стороне сервера только для сброса таймера простоя потока, и для обеих сторон не нужно запускать TCP-проверку активности. Этот же подход применим и для уровня приложений, в том числе в системах баз данных "клиент — сервер". Проверьте на стороне сервера, какие параметры существуют для конкретного приложения проверку активности.

> [!IMPORTANT]
> AKS включает сброс TCP в режиме простоя по умолчанию и рекомендует хранить эту конфигурацию в и использовать ее для более предсказуемого поведения приложения в ваших сценариях.
> TCP RST отправляется только во время подключения TCP в УСТАНОВЛЕНном состоянии. Дополнительные сведения см. [здесь](../load-balancer/load-balancer-tcp-reset.md).

### <a name="requirements-for-customizing-allocated-outbound-ports-and-idle-timeout"></a>Требования для настройки выделенных исходящих портов и времени ожидания простоя

- Значение, указанное для *allocatedOutboundPorts*, также должно быть кратно 8.
- Необходимо иметь достаточное количество исходящих IP-адресов в зависимости от числа виртуальных машин узлов и требуемых выделенных исходящих портов. Чтобы проверить, достаточно ли выделено исходящих IP-адресов, используйте приведенную ниже формулу. 
 
*outboundIPs* \* 64 000 \> *nodeVMs* \* *desiredAllocatedOutboundPorts*.
 
Например, если имеются 3 узла *nodeVMs* и 50 000 портов *desiredAllocatedOutboundPorts*, необходимо по крайней мере 3 адреса *outboundIPs*. Рекомендуется подготовить дополнительные исходящие IP-адреса. Кроме того, при вычислении емкости исходящих IP-адресов необходимо учитывать автомасштабирование кластера и возможность обновления пула узлов. Чтобы учесть автомасштабирование кластера, проверьте текущее число узлов и максимальное количество узлов и используйте большее значение. Чтобы учесть обновление, добавьте по одной дополнительной виртуальной машине узла на каждый пул узлов, который допускает обновление.

- Если для параметра *IdleTimeoutInMinutes* задано значение, отличное от значения по умолчанию (30 минут), определите, какой продолжительности исходящее подключение потребуется рабочим нагрузкам. Также учтите, что время ожидания по умолчанию для подсистемы балансировки нагрузки *ценовой категории "Стандартный"* , используемой за пределами AKS, составляет 4 минуты. Значение *IdleTimeoutInMinutes*, более точно соответствующее конкретной рабочей нагрузке AKS, может снизить нехватку адресов SNAT, вызванную поддержанием подключений, которые больше не используются.

> [!WARNING]
> Изменение значений для *аллокатедаутбаундпортс* и *идлетимеаутинминутес* может значительно изменить поведение исходящего правила для подсистемы балансировки нагрузки и не должно выполняться без проблем. не зная компромиссов и шаблонов подключения приложения, просмотрите [раздел Устранение неполадок SNAT ниже][troubleshoot-snat] и ознакомьтесь с [Load Balancer правилами исходящих][azure-lb-outbound-rules-overview] [подключений и исходящими подключениями в Azure][azure-lb-outbound-connections] перед обновлением этих значений, чтобы полностью понять влияние изменений.

## <a name="restrict-inbound-traffic-to-specific-ip-ranges"></a>Ограничить входящий трафик к определенным диапазонам IP-адресов

В приведенном ниже манифесте с помощью параметра *loadBalancerSourceRanges* указан новый диапазон IP-адресов для внешнего входящего трафика.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: azure-vote-front
spec:
  type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: azure-vote-front
  loadBalancerSourceRanges:
  - MY_EXTERNAL_IP_RANGE
```

> [!NOTE]
> Входящий внешний трафик проходит от подсистемы балансировки нагрузки к виртуальной сети для кластера AKS. Виртуальная сеть имеет группу безопасности сети (NSG), которая разрешает весь входящий трафик от балансировщика нагрузки. Этот NSG использует [тег службы][service-tags] типа балансировщика, *чтобы разрешить* трафик из балансировщика нагрузки.

## <a name="maintain-the-clients-ip-on-inbound-connections"></a>Обслуживание IP-адреса клиента при входящих подключениях

По умолчанию служба типа `LoadBalancer` [в Kubernetes](https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-type-loadbalancer) и в AKS не сохраняет IP-адрес клиента при подключении к модулю Pod. Исходным IP-адресом пакета, который доставляется в модуль Pod, будет частный IP-адрес узла. Чтобы сохранить IP-адрес клиента, необходимо задать для параметра `service.spec.externalTrafficPolicy` значение `local` в определении службы. Ниже приведен пример манифеста.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: azure-vote-front
spec:
  type: LoadBalancer
  externalTrafficPolicy: Local
  ports:
  - port: 80
  selector:
    app: azure-vote-front
```

## <a name="additional-customizations-via-kubernetes-annotations"></a>Дополнительные настройки через заметки Kubernetes

Ниже приведен список заметок, поддерживаемых для служб Kubernetes с типом `LoadBalancer` . Эти заметки применяются только к **входящим** потокам:

| Annotation | Значение | Описание
| ----------------------------------------------------------------- | ------------------------------------- | ------------------------------------------------------------ 
| `service.beta.kubernetes.io/azure-load-balancer-internal`         | `true` или `false`                     | Укажите, должна ли подсистема балансировки нагрузки быть внутренней. Значение по умолчанию — Public, если не задано.
| `service.beta.kubernetes.io/azure-load-balancer-internal-subnet`  | Имя подсети                    | Укажите подсеть, к которой должна быть привязана внутренняя подсистема балансировки нагрузки. Если значение не задано, по умолчанию используется подсеть, настроенная в облачном файле конфигурации.
| `service.beta.kubernetes.io/azure-dns-label-name`                 | Имя DNS-метки в общедоступных IP-адресах   | Укажите имя DNS-метки для **общедоступной** службы. Если задана пустая строка, запись DNS в общедоступном IP-адресе не будет использоваться.
| `service.beta.kubernetes.io/azure-shared-securityrule`            | `true` или `false`                     | Укажите, что служба должна быть предоставлена с помощью правила безопасности Azure, которое может использоваться совместно с другой службой, характерным правилом для увеличения числа служб, которые могут быть предоставлены. Эта аннотация полагается на функцию расширенных [правил безопасности](../virtual-network/network-security-groups-overview.md#augmented-security-rules) в Azure группы безопасности сети. 
| `service.beta.kubernetes.io/azure-load-balancer-resource-group`   | Имя группы ресурсов            | Укажите группу ресурсов для общедоступных IP-адресов подсистемы балансировки нагрузки, которые находятся не в той же группе ресурсов, что и инфраструктура кластера (Группа ресурсов узла).
| `service.beta.kubernetes.io/azure-allowed-service-tags`           | Список разрешенных тегов службы          | Укажите список разрешенных [тегов службы][service-tags] , разделенных запятыми.
| `service.beta.kubernetes.io/azure-load-balancer-tcp-idle-timeout` | Время ожидания простоя TCP в минутах          | Укажите время в минутах, в течение которого время ожидания простоя подключения TCP будет происходить в подсистеме балансировки нагрузки. По умолчанию и минимальное значение равно 4. Максимальное значение равно 30. Должно быть целым числом.
|`service.beta.kubernetes.io/azure-load-balancer-disable-tcp-reset` | `true`                                | Отключить `enableTcpReset` для SLB


## <a name="troubleshooting-snat"></a>Устранение неполадок SNAT

Если вы знаете, что вы запускаете множество исходящих подключений TCP или UDP к одному и тому же конечному IP-адресу и порту, то при наличии неудачных исходящих подключений или при помощи поддержки нехватки портов SNAT (с предварительно выделенными временными портами, используемыми PAT) у вас есть несколько общих вариантов устранения проблем. Ознакомьтесь с ними, чтобы выбрать доступный и подходящий вариант для своего сценария. Возможно, один или несколько вариантов помогут вам решить проблему. Подробные сведения см. в разделе [руководство по устранению неполадок исходящих подключений](../load-balancer/troubleshoot-outbound-connection.md).

Часто первопричиной нехватки SNAT является антишаблон для установки исходящего подключения и управления им или настраиваемые таймеры, значения которых отличны от значений по умолчанию. Внимательно просмотрите этот раздел.

### <a name="steps"></a>Шаги
1. Проверьте, не неактивны ли подключения в течение длительного времени, и используйте время ожидания простоя по умолчанию для освобождения этого порта. Если это так, для вашего сценария может потребоваться уменьшить время ожидания по умолчанию (30 минут).
2. Выясните, как приложение создает исходящее подключение (например, изучите код или соберите пакеты).
3. Определите, является ли действие ожидаемым или поведение приложения некорректным. Используйте [метрики](../load-balancer/load-balancer-standard-diagnostics.md) и [журналы](../load-balancer/load-balancer-monitor-log.md) в Azure Monitor, чтобы субстантиате свои результаты. Используйте категорию "сбой" для метрик подключений SNAT, например.
4. Оцените, выполнены ли соответствующие [закономерности](#design-patterns) .
5. Оцените, следует ли устранить нехватку портов SNAT с [дополнительными исходящими IP-адресами и дополнительными выделенными исходящими портами](#configure-the-allocated-outbound-ports) .

### <a name="design-patterns"></a>Шаблоны проектирования
Старайтесь повторно использовать подключения и создавать пулы подключений везде, где это возможно. Эти шаблоны позволяют устранить проблему исчерпания ресурсов и гарантировать предсказуемое поведение. Примитивы для этих шаблонов можно найти во многих библиотеках и платформах разработки.

- Атомарные запросы (один запрос на соединение) обычно не подходят для разработки. Этот антишаблон ограничивает возможности масштабирования, снижает производительность и надежность. Вместо этого повторно используйте подключения HTTP(S), чтобы уменьшить число подключений и занятых портов SNAT. Масштабирование приложений увеличит и повысит производительность, так как при использовании TLS были снижены подтверждения, затраты и стоимость операций шифрования.
- Если вы используете нестандартный кластер или пользовательский DNS-сервер или пользовательские вышестоящее серверы в Кореднс, DNS может ввести множество отдельных потоков на томе, если клиент не кэширует результат "арбитры конфликтов DNS". Не забудьте сначала настроить Кореднс, а не использовать пользовательские DNS-серверы и определить хорошее значение кэширования.
- Потоки UDP (например, поиск по DNS) занимают порты SNAT на период ожидания с бездействием. Чем дольше это время ожидания, тем выше нагрузка на порты SNAT. Используйте короткое время ожидания при бездействии (например, 4 минуты).
Используйте пулы соединений, чтобы контролировать число подключений.
- Никогда не отменяйте поток TCP без оповещения и не доверяйте очистку потоков таймерам TCP. Если не разрешить протоколу TCP явным образом закрыть подключение, состояние остается выделенным в промежуточных системах и конечных точках и делает порты SNAT недоступными для других подключений. Такой шаблон может привести к сбоям приложений и исчерпанию ресурсов SNAT.
- Не изменяйте значения таймера на уровне ОС, связанные с закрытием подключений TCP, без экспертного понимания их влияния. При восстановлении стека TCP производительность приложения может снизиться, когда конечные точки соединения будут иметь несовпадающие ожидания. Необходимость изменения таймеров обычно является признаком базовой проблемы проектирования. Изучите приведенные ниже рекомендации.


В приведенном выше примере правило изменено, чтобы разрешить внешний входящий трафик из диапазона *MY_EXTERNAL_IP_RANGE*. При замене *MY_EXTERNAL_IP_RANGE* внутренним IP-адресом подсети трафик будет ограничен только внутренними адресациями кластера. Это не позволит клиентам, находящимся за пределами кластера Kubernetes, получить доступ к подсистеме балансировки нагрузки.

## <a name="moving-from-a-basic-sku-load-balancer-to-standard-sku"></a>Переход с базовой конфигурации балансировщика нагрузки на SKU уровня "Стандартный"

Если у вас есть кластер, использующий Load Balancer ценовой категории "Базовый", следует учесть важные различия в поведении при переходе на использование кластера с Load Balancer ценовой категории "Стандартный".

Например, создание "сине-зеленых" шаблонов развертывания для миграции кластеров является распространенной практикой, так как тип `load-balancer-sku` кластера можно определить только во время создания кластера. Однако подсистемы балансировки нагрузки уровня " *базовый* " используют *базовые* IP-адреса SKU, которые несовместимы с подсистемами балансировки нагрузки уровня *"Стандартный"* , так как им требуются стандартные IP-адреса *SKU* . При миграции кластеров для обновления номеров SKU Load Balancer потребуется новый IP-адрес с совместимым номером SKU.

Дополнительные рекомендации по миграции кластеров см. в [документации по миграции](aks-migration.md). В ней вы сможете изучить список важных тем, которые следует учитывать при миграции. Приведенные ниже ограничения также являются важными различиями в поведении, которые следует учитывать при использовании экземпляров Load Balancer ценовой категории "Стандартный" в AKS.

## <a name="limitations"></a>Ограничения

При создании и администрировании кластеров AKS, поддерживающих подсистему балансировки нагрузки *ценовой категории "Стандартный"* , действуют следующие ограничения.

* Необходим по крайней мере один общедоступный IP-адрес или префикс IP-адреса для передачи исходящего трафика из кластера AKS. Общедоступный IP-адрес или префикс IP-адреса также требуется для поддержания подключения между узлами панели управления и агента и для обеспечения совместимости с предыдущими версиями AKS. Ниже приведены способы указания общедоступных IP-адресов или префиксов IP-адреса с помощью подсистемы балансировки нагрузки *ценовой категории "Стандартный"* .
    * Предоставьте собственные общедоступные IP-адреса.
    * Предоставьте собственные префиксы общедоступных IP-адресов.
    * Укажите число до 100, чтобы кластер AKS мог создать столько общедоступных IP-адресов *ценовой категории "Стандартный"* в той же группе ресурсов, в которой был создан кластер AKS. Обычно ее имя начинается с *MC_* . AKS назначит общедоступный IP-адрес подсистеме балансировки нагрузки *ценовой категории "Стандартный"* . По умолчанию один общедоступный IP-адрес будет автоматически создан в той же группе ресурсов, что и кластер AKS, если не указан общедоступный IP-адрес, префикс общедоступного IP-адреса или число IP-адресов. Кроме того, необходимо разрешить общедоступные адреса и не создавать политику Azure, запрещающую создание IP-адресов.
* Общедоступный IP-адрес, созданный AKS, нельзя использовать повторно в качестве настраиваемого для собственного общедоступного IP-адреса. Все настраиваемые IP-адреса должны создаваться и управляться пользователем.
* Определить номер SKU подсистемы балансировки нагрузки можно только при создании кластера AKS. Вы не можете изменить SKU балансировщика нагрузки после создания кластера AKS.
* В одном кластере можно использовать подсистему балансировки нагрузки только одной ценовой категории — "Базовый" или "Стандартный".
* Подсистемы балансировки нагрузки *ценовой категории "Стандартный"* поддерживают только IP-адреса *ценовой категории "Стандартный"* .


## <a name="next-steps"></a>Дальнейшие действия

Узнайте больше о службах Kubernetes в [документации по службам Kubernetes][kubernetes-services].

Дополнительные сведения об использовании внутренних Load Balancer для входящего трафика см. в [документации по внутренней Load Balancer AKS](internal-lb.md).

<!-- LINKS - External -->
[kubectl]: https://kubernetes.io/docs/user-guide/kubectl/
[kubectl-delete]: https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#delete
[kubectl-get]: https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#get
[kubectl-apply]: https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#apply
[kubernetes-services]: https://kubernetes.io/docs/concepts/services-networking/service/
[aks-engine]: https://github.com/Azure/aks-engine

<!-- LINKS - Internal -->
[advanced-networking]: configure-azure-cni.md
[aks-support-policies]: support-policies.md
[aks-faq]: faq.md
[aks-quickstart-cli]: kubernetes-walkthrough.md
[aks-quickstart-portal]: kubernetes-walkthrough-portal.md
[aks-sp]: kubernetes-service-principal.md#delegate-access-to-other-azure-resources
[az-aks-show]: /cli/azure/aks#az-aks-show
[az-aks-create]: /cli/azure/aks#az-aks-create
[az-aks-get-credentials]: /cli/azure/aks#az-aks-get-credentials
[az-aks-install-cli]: /cli/azure/aks#az-aks-install-cli
[az-extension-add]: /cli/azure/extension#az-extension-add
[az-feature-list]: /cli/azure/feature#az-feature-list
[az-feature-register]: /cli/azure/feature#az-feature-register
[az-group-create]: /cli/azure/group#az-group-create
[az-provider-register]: /cli/azure/provider#az-provider-register
[az-network-lb-outbound-rule-list]: /cli/azure/network/lb/outbound-rule#az-network-lb-outbound-rule-list
[az-network-public-ip-show]: /cli/azure/network/public-ip#az-network-public-ip-show
[az-network-public-ip-prefix-show]: /cli/azure/network/public-ip/prefix#az-network-public-ip-prefix-show
[az-role-assignment-create]: /cli/azure/role/assignment#az-role-assignment-create
[azure-lb]: ../load-balancer/load-balancer-overview.md
[azure-lb-comparison]: ../load-balancer/skus.md
[azure-lb-outbound-rules]: ../load-balancer/load-balancer-outbound-connections.md#outboundrules
[azure-lb-outbound-connections]: ../load-balancer/load-balancer-outbound-connections.md
[azure-lb-outbound-preallocatedports]: ../load-balancer/load-balancer-outbound-connections.md#preallocatedports
[azure-lb-outbound-rules-overview]: ../load-balancer/load-balancer-outbound-connections.md#outboundrules
[install-azure-cli]: /cli/azure/install-azure-cli
[internal-lb-yaml]: internal-lb.md#create-an-internal-load-balancer
[kubernetes-concepts]: concepts-clusters-workloads.md
[use-kubenet]: configure-kubenet.md
[az-extension-add]: /cli/azure/extension#az-extension-add
[az-extension-update]: /cli/azure/extension#az-extension-update
[requirements]: #requirements-for-customizing-allocated-outbound-ports-and-idle-timeout
[use-multiple-node-pools]: use-multiple-node-pools.md
[troubleshoot-snat]: #troubleshooting-snat
[service-tags]: ../virtual-network/network-security-groups-overview.md#service-tags
