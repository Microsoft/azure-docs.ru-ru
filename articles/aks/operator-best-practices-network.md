---
title: Рекомендации по использованию сетевых ресурсов
titleSuffix: Azure Kubernetes Service
description: Актуальные рекомендации для оператора кластера по использованию ресурсов и установке подключения виртуальных сетей в Службе Azure Kubernetes (AKS)
services: container-service
ms.topic: conceptual
ms.date: 12/10/2018
ms.openlocfilehash: 2bd332dbf9412f5c42e77b14ada3aab67ec8b66a
ms.sourcegitcommit: 15d27661c1c03bf84d3974a675c7bd11a0e086e6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/09/2021
ms.locfileid: "102508594"
---
# <a name="best-practices-for-network-connectivity-and-security-in-azure-kubernetes-service-aks"></a>Рекомендации по подключению сетей и обеспечению безопасности в службе Azure Kubernetes (AKS)

Создавая кластеры и управляя ими в службе Azure Kubernetes (AKS), вы обеспечиваете сетевое подключение для узлов и приложений. К этим сетевым ресурсам относятся диапазоны IP-адресов, подсистемы балансировки нагрузки и контроллеры входящего трафика. Для поддержания высокого качества обслуживания приложений эти ресурсы необходимо спланировать, а затем настроить.

В этой статье приведены рекомендации для операторов кластеров, связанные с подключениями и безопасностью сетей. Вы узнаете, как выполнять следующие задачи:

> [!div class="checklist"]
> * Сравните сетевые режимы кубенет и сетевых интерфейсов контейнеров Azure (CNI) в AKS
> * планирование IP-адресации и возможности подключения;
> * Распределение трафика с помощью подсистем балансировки нагрузки, контроллеров входящих данных или брандмауэра веб-приложения (WAF)
> * защищенное подключение к узлам кластера;

## <a name="choose-the-appropriate-network-model"></a>выбор подходящей сетевой модели.

**Советы и рекомендации.** Для интеграции с существующими виртуальными или локальными сетями используйте сеть Azure CNI в AKS. Эта сетевая модель также позволяет изолировать ресурсы и элементы управления в среде предприятия.

Виртуальные сети обеспечивают базовые возможности подключения для доступа узлов AKS и клиентов к вашим приложениям. Существует два способа развертывания кластеров AKS в виртуальных сетях:

* **Сеть kubenet** — Azure управляет ресурсами виртуальной сети по мере развертывания кластера и использует подключаемый модуль Kubernetes [kubenet][kubenet].
* **Azure CNI Networking** — развертывает в виртуальной сети и использует подключаемый модуль [интерфейса "сетевой интерфейс" контейнера Azure (CNI)][cni-networking] Kubernetes. Группы pod получают отдельные IP-адреса, которые можно направлять к другим службам сети или локальным ресурсам.

Для рабочих развертываний кубенет и Azure CNI являются допустимыми вариантами.

### <a name="cni-networking"></a>CNI сети

Container Networking Interface (CNI) — это независимый от поставщиков протокол, который позволяет среде выполнения контейнера выполнять запросы к поставщику сети. Azure CNI назначает IP-адреса группам pod и узлам, а также предоставляет функции управления IP-адресами (IPAM) при подключении к существующим виртуальным сетям Azure. Каждый узел и ресурс Pod получают IP-адрес в виртуальной сети Azure, и для взаимодействия с другими ресурсами или службами не требуется дополнительная маршрутизация.

![Схема, демонстрирующая два узла с мостами, подключающими каждый из них к одной виртуальной сети Azure](media/operator-best-practices-network/advanced-networking-diagram.png)

Важным преимуществом сети Azure CNI для рабочей среды является сетевая модель, позволяющая отделить управление ресурсами и управлять ими. С точки зрения безопасности для управления ресурсами и их защиты часто требуется задействовать разные группы сотрудников. Сеть Azure CNI позволяет подключаться к существующим ресурсам Azure, локальным ресурсам или другим службам напрямую через IP-адреса, назначенные каждой группе pod.

При использовании сети Azure CNI ресурс виртуальной сети размещается в отдельной группе ресурсов относительно кластера AKS. Делегирование разрешений для удостоверения кластера AKS для доступа к этим ресурсам и управления ими. Удостоверение кластера, используемое кластером AKS, должно иметь по крайней мере разрешения [участника сети](../role-based-access-control/built-in-roles.md#network-contributor) в подсети в виртуальной сети. Если вы хотите определить [пользовательскую роль](../role-based-access-control/custom-roles.md) вместо того, чтобы использовать встроенную роль участника сети, требуются следующие разрешения:
  * `Microsoft.Network/virtualNetworks/subnets/join/action`
  * `Microsoft.Network/virtualNetworks/subnets/read`

По умолчанию AKS использует управляемое удостоверение для своего удостоверения кластера, но вместо этого можно использовать субъект-службу. См. дополнительные сведения о [делегировании прав доступа другим ресурсам Azure в AKS][sp-delegation]. Дополнительные сведения об управляемых удостоверениях см. в разделе [Использование управляемых удостоверений](use-managed-identity.md).

Так как каждый узел и узел pod получают собственный IP-адрес, спланируйте диапазоны адресов для подсетей AKS. Подсеть должна быть достаточно большой, чтобы предоставить IP-адреса каждому узлу, группам pod и сетевым ресурсам, которые вы развертываете. Каждый кластер AKS должен быть размещен в собственной подсети. Чтобы обеспечить возможность подключения к локальным или одноранговым сетям в Azure, не используйте диапазоны IP-адресов, которые пересекаются с существующими сетевыми ресурсами. Существуют стандартные ограничения числа групп pod, запущенных на каждом узле, как при использовании сети kubenet, так и при использовании сети Azure CNI. Для управления событиями масштабирования или обновлениями кластера также требуются дополнительные IP-адреса, доступные для использования в назначенной подсети. Это дополнительное адресное пространство особенно важно при использовании контейнеров Windows Server, так как для этих пулов узлов требуется обновление для установки последних исправлений системы безопасности. Дополнительные сведения об узлах Windows Server см. [в разделе Обновление пула узлов в AKS][nodepool-upgrade].

Дополнительные сведения о планировании необходимых IP-адресов см. в статье о [настройке сети Azure CNI в AKS][advanced-networking].

При создании кластера с CNI сетями Azure вы указываете другие диапазоны адресов для использования кластером, такие как адрес моста DOCKER, IP-адреса службы DNS и диапазон адресов службы. Как правило, эти диапазоны адресов не должны перекрывать друг друга и не должны перекрываться с сетями, связанными с кластером, включая виртуальные сети, подсети, локальные и одноранговые сети. Конкретные сведения об ограничениях и размерах для этих диапазонов адресов см. [в статье Настройка сети Azure CNI в AKS][advanced-networking].

### <a name="kubenet-networking"></a>Сеть kubenet

Хотя для kubenet не требуется настраивать виртуальные сети до развертывания кластера, у этого варианта есть определенные недостатки:

* Узлы и группы pod размещаются в разных IP-подсетях. Для маршрутизации трафика между группами pod и узлами применяются определяемая пользователем маршрутизация (UDR) и IP-пересылка. Такая возможность дополнительной маршрутизации может снизить производительность сети.
* Подключения к существующим локальным сетям или пиринговые подключения к другим виртуальным сетям Azure могут быть сложными.

Kubenet подходит для небольших рабочих нагрузок при разработке или тестировании, так как не нужно создавать виртуальную сеть и подсети отдельно от кластера AKS. При работе с простыми веб-сайтами с небольшим трафиком или переносе рабочих нагрузок в контейнеры (lift-and-shift) также можно пользоваться преимуществами простых в управлении кластеров AKS, развертываемых в рамках сети kubenet. Для большинства развертываемых служб в рабочей среде следует планировать и использовать сеть Azure CNI.

Вы также можете [настроить собственные диапазоны IP-адресов и виртуальные сети для использования с kubenet][aks-configure-kubenet-networking]. Как и в случае с CNI сетями Azure, эти диапазоны адресов не должны перекрывать друг друга и не должны перекрываться с сетями, связанными с кластером, включая виртуальные сети, подсети, локальные и одноранговые сети. Подробные сведения об ограничениях и размерах для этих диапазонов адресов см. [в разделе Использование сети кубенет с собственными диапазонами IP-адресов в AKS][aks-configure-kubenet-networking].

## <a name="distribute-ingress-traffic"></a>Распределение входящего трафика

**Советы и рекомендации.** Чтобы распределить трафик HTTP или HTTPS между приложениями, используйте ресурсы и контроллеры входящего трафика. Контроллеры входящих данных предоставляют дополнительные возможности по обычной подсистеме балансировки нагрузки Azure и могут управляться как собственными ресурсами Kubernetes.

Подсистема балансировки нагрузки Azure может распределять клиентский трафик между приложениями в кластере AKS, но ее возможности по распознаванию этого трафика ограничены. Ресурс балансировки нагрузки работает на 4-м уровне, распределяя трафик на основе протоколов или портов. Большинство веб-приложений, использующих протокол HTTP или HTTPS, должны использовать ресурсы и контроллеры Kubernetes, которые работают на уровне 7. Входящий трафик можно распределять между URL-адресами приложений и обрабатывать TLS/SSL-терминацию. Эта также позволяет сократить число IP-адресов, сопоставляемых и открываемых для доступа. При использовании подсистемы балансировки нагрузки каждому приложению обычно требуется назначить общедоступный IP-адрес и сопоставить его со службой в кластере AKS. При использовании ресурса входящего трафика один IP-адрес позволяет распределять трафик между несколькими приложениями.

![Схема, показывающая поток входящего трафика в кластере AKS](media/operator-best-practices-network/aks-ingress.png)

 Для обработки входящего трафика используется два компонента:

 * *ресурс* входящего трафика;
 * Входной *контроллер*

Ресурс входящего трафика — это манифест YAML `kind: Ingress`, который определяет узел, сертификаты и правила маршрутизации трафика к службам, выполняемым в кластере AKS. Следующий пример манифеста YAML распределяет трафик для *myapp.com* к одной из двух служб: *blogservice* или *storeservice*. Клиент направляется к той или иной службе в зависимости от открываемого URL-адреса.

```yaml
kind: Ingress
metadata:
 name: myapp-ingress
   annotations: kubernetes.io/ingress.class: "PublicIngress"
spec:
 tls:
 - hosts:
   - myapp.com
   secretName: myapp-secret
 rules:
   - host: myapp.com
     http:
      paths:
      - path: /blog
        backend:
         serviceName: blogservice
         servicePort: 80
      - path: /store
        backend:
         serviceName: storeservice
         servicePort: 80
```

Контроллер входящего трафика — это управляющая программа, которая выполняется на узле AKS и отслеживает входящие запросы. Затем трафик распределяется на основе правил, определенных в ресурсе входящего трафика. Самый распространенный контроллер входящего трафика основан на [NGINX]. В AKS нет ограничений на использование определенных контроллеров, поэтому вы можете использовать другие средства, например [Contour][contour], [HAProxy][haproxy] или [Traefik][traefik].

Контроллеры входящих данных должны быть запланированы на узле Linux. Узлы Windows Server не должны запускать контроллер Ingress. Используйте селектор узлов в манифесте YAML или развертывание диаграммы Helm, чтобы указать, что ресурс должен выполняться на узле под управлением Linux. Дополнительные сведения см. [в разделе Использование селекторов узлов для управления планированием модулей Pod в AKS][concepts-node-selectors].

Существует множество сценариев обработки входящего трафика. Они описаны в следующих руководствах:

* [Создать базовый контроллер входящего трафика с внешним сетевым подключением.][aks-ingress-basic]
* [Создать контроллер входящего трафика, который использует внутреннюю, частную сети и IP-адрес.][aks-ingress-internal]
* [Создать контроллер входящего трафика, который использует ваши собственные сертификаты TLS][aks-ingress-own-tls]
* Создать контроллер входящего трафика, использующий службу Let's Encrypt для автоматического создания сертификатов TLS [с динамическим общедоступным IP-адресом][aks-ingress-tls] или [со статическим общедоступным IP-адресом][aks-ingress-static-tls].

## <a name="secure-traffic-with-a-web-application-firewall-waf"></a>Защита трафика с помощью брандмауэра веб-приложений (WAF)

**Советы и рекомендации.** Чтобы проверять входящий трафик на наличие потенциальных атак, используйте брандмауэр веб-приложений (WAF), например [Barracuda WAF для Azure][barracuda-waf], или Шлюз приложений Azure. Эти более сложные сетевые ресурсы также могут маршрутизировать трафик за пределами подключений по протоколам HTTP и HTTPS или базовому прерыванию TLS.

Контроллер входящего трафика, который распределяет трафик по службам и приложениям, обычно является ресурсом Kubernetes в кластере AKS. Контроллер работает как управляющая программа на узле AKS и потребляет некоторую часть ресурсов узла, таких как ЦП, память и пропускная способность сети. В масштабных средах часто требуется разгрузить часть маршрутизации трафика или обработки TLS-терминации в сетевой ресурс за пределами кластера AKS. Кроме того, может быть необходимо проверять входящий трафик на наличие потенциальных атак.

![Брандмауэр веб-приложений (WAF), например шлюз приложений Azure, позволяет защищать и распределять трафик для кластера AKS](media/operator-best-practices-network/web-application-firewall-app-gateway.png)

Брандмауэр веб-приложения (WAF) обеспечивает дополнительный уровень безопасности, отфильтровывая входящий трафик. OWASP — это набор правил для отслеживания атак, таких как межсайтовые сценарии или отравление файлов cookie. [Шлюз приложений Azure][app-gateway] (в настоящее время доступна в предварительной версии в AKS) — это WAF, который может интегрироваться с кластерами AKS для предоставления этих функций безопасности до того, как трафик достигнет кластера и приложений AKS. Эти функции выполняются и другими решениями сторонних поставщиков, поэтому вы можете продолжать средства, в которые вы инвестировали или с которыми вы уже работали.

Подсистема балансировки нагрузки или ресурсы входящего трафика будут и работают в кластере AKS для более точного распределения трафика. Шлюзом приложений можно централизованно управлять как контроллером входящего трафика с определением ресурса. Для начала [создайте контроллер входящего трафика Шлюза приложений][app-gateway-ingress].

## <a name="control-traffic-flow-with-network-policies"></a>Элемент управления потоком трафика с помощью политик сети

**Рекомендации**. Политики сети, дают возможность разрешать или запрещать трафик для контейнеров pod. Весь трафик разрешен между контейнерами pod в кластере по умолчанию. В целях безопасности определите правила, ограничивающие связь pod.

Политика сети — это функция Kubernetes, которая позволяет контролировать поток трафика между контейнерами pod. Вы можете разрешать или запрещать трафик в зависимости от параметров, например назначенных меток, пространства имен или порта трафика. Использование политик сети предоставляет наиболее подходящий облачный способ управления потоком трафика. Поскольку контейнеры pod динамически создаются в кластере AKS, необходимые политики сети могут применяться автоматически. Не используйте группы безопасности сети Azure для управления трафиком между pod, используйте политики сети.

Чтобы использовать политики сети, необходимо включить эту функцию при создании кластера AKS. Вы не можете включить политику сети в существующем кластере AKS. Подготовьтесь заранее, чтобы убедиться, что вы включили политику сети на кластерах и можете использовать их по мере необходимости. Политику сети следует использовать только для узлов под управлением Linux и групп pod в AKS.

Политика сети создается в качестве ресурса Kubernetes с помощью манифеста YAML. Политики применяются к определенным контейнерам pod, а затем правила входящего и исходящего трафика определяют, каким образом может происходить поток трафика. В следующем примере применяется политика сети к контейнерам pod с примененной к ним меткой *app: backend*. Затем правило входящего трафика разрешает трафик только от pod с меткой *app: frontend*.

```yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: backend-policy
spec:
  podSelector:
    matchLabels:
      app: backend
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
```

Чтобы начать работу с политиками см. статью [Secure traffic between pods using network policies in Azure Kubernetes Service (AKS)][use-network-policies] (Защита трафика между контейнерами pod с использованием политик сети в Azure Kubernetes Service (AKS)).

## <a name="securely-connect-to-nodes-through-a-bastion-host"></a>Защищенное подключение к узлам через узел-бастион

**Советы и рекомендации.** Не предоставляйте возможность удаленного подключения к узлам AKS. Создайте узел-бастион (jump box) в виртуальной сети управления. Используйте узел-бастион для защищенной маршрутизации трафика в кластер AKS для задач удаленного управления.

Большинство операций в AKS можно выполнить с помощью средств управления Azure или сервера Kubernetes API. Узлы AKS не подключаются к Интернету и доступны только в частной сети. Для подключения к узлам и выполнения обслуживания или устранения неполадок следует маршрутизировать подключения через узел-бастион. Этот узел должен находиться в отдельной виртуальной сети управления с защищенным пиринговым подключением к виртуальной сети кластера AKS.

![Подключение к узлам AKS с помощью узла-бастиона](media/operator-best-practices-network/connect-using-bastion-host-simplified.png)

Сеть управления для узла-бастиона должна быть также защищена. Используйте [Azure ExpressRoute][expressroute] или [VPN-шлюз][vpn-gateway] для подключения к локальной сети и управляйте доступом с помощью групп безопасности сети.

## <a name="next-steps"></a>Дальнейшие действия

В этой статье описаны вопросы, связанные с безопасностью и подключению сетей. См. дополнительные сведения о [сетях в Службе Azure Kubernetes (AKS)][aks-concepts-network]

<!-- LINKS - External -->
[cni-networking]: https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md
[kubenet]: https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/#kubenet
[app-gateway-ingress]: https://github.com/Azure/application-gateway-kubernetes-ingress
[nginx]: https://www.nginx.com/products/nginx/kubernetes-ingress-controller
[contour]: https://github.com/heptio/contour
[haproxy]: https://www.haproxy.org
[traefik]: https://github.com/containous/traefik
[barracuda-waf]: https://www.barracuda.com/products/webapplicationfirewall/models/5

<!-- INTERNAL LINKS -->
[aks-concepts-network]: concepts-network.md
[sp-delegation]: kubernetes-service-principal.md#delegate-access-to-other-azure-resources
[expressroute]: ../expressroute/expressroute-introduction.md
[vpn-gateway]: ../vpn-gateway/vpn-gateway-about-vpngateways.md
[aks-ingress-internal]: ingress-internal-ip.md
[aks-ingress-static-tls]: ingress-static-ip.md
[aks-ingress-basic]: ingress-basic.md
[aks-ingress-tls]: ingress-tls.md
[aks-ingress-own-tls]: ingress-own-tls.md
[app-gateway]: ../application-gateway/overview.md
[use-network-policies]: use-network-policies.md
[advanced-networking]: configure-azure-cni.md
[aks-configure-kubenet-networking]: configure-kubenet.md
[concepts-node-selectors]: concepts-clusters-workloads.md#node-selectors
[nodepool-upgrade]: use-multiple-node-pools.md#upgrade-a-node-pool