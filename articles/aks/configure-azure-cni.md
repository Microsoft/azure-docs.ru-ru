---
title: Настройка сети Azure CNI в Службе Azure Kubernetes (AKS)
description: Узнайте, как настроить сеть Azure CNI (расширенную) в Службе Azure Kubernetes (AKS), включая развертывание кластера AKS в существующую виртуальную сеть и подсеть.
services: container-service
ms.topic: article
ms.date: 06/03/2019
ms.custom: references_regions
ms.openlocfilehash: 4286b3ea8f41ac5c4c494039c5d45c2332c72226
ms.sourcegitcommit: c27a20b278f2ac758447418ea4c8c61e27927d6a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/03/2021
ms.locfileid: "101742098"
---
# <a name="configure-azure-cni-networking-in-azure-kubernetes-service-aks"></a>Настройка сети Azure CNI в Службе Azure Kubernetes (AKS)

По умолчанию кластеры AKS используют [kubenet][kubenet], а также создается виртуальная сеть и подсеть. При использовании *kubenet* узлы получают IP-адрес из подсети виртуальной сети. Затем настраивается преобразование сетевых адресов (NAT) на узлах, а модули получают IP-адрес, "скрытый" за IP-адресом узла. Такой подход уменьшает количество IP-адресов, которые необходимо зарезервировать в пространстве сети для модулей pod.

С помощью [сетевого интерфейса контейнеров Azure (CNI)][cni-networking] каждый объект pod получает IP-адрес из подсети, и к этому объекту pod можно получить прямой доступ. Эти IP-адреса должны быть уникальными во всей сети, и их следует планировать заранее. Для каждого узла предусмотрен параметр конфигурации, в котором указывается максимальное число объектов pod, которые он поддерживает. Затем на каждом узле заранее резервируется эквивалентное число IP-адресов для этого узла. Этот подход требует дополнительного планирования и часто приводит к исчерпанию IP-адресов или необходимости повторно создавать кластеры в подсети большего размера по мере увеличения потребностей вашего приложения.

В этой статье показано, как использовать сеть *Azure CNI*, чтобы создавать и использовать подсеть виртуальной сети для кластера AKS. Дополнительные сведения о сетях см. в статье [Основные понятия сети в Службе Azure Kubernetes (AKS)][aks-network-concepts].

## <a name="prerequisites"></a>Предварительные требования

* Виртуальная сеть для кластера AKS должна разрешать исходящее подключение к Интернету.
* Кластеры AKS не могут использовать `169.254.0.0/16` , `172.30.0.0/16` , или для диапазона адресов `172.31.0.0/16` `192.0.2.0/24` службы Kubernetes, диапазона адресов Pod или диапазона адресов виртуальной сети кластера.
* Субъект-служба, используемый кластером AKS, должен иметь по крайней мере разрешения [Участник сетей](../role-based-access-control/built-in-roles.md#network-contributor) в подсети в виртуальной сети. Если вы хотите определить [пользовательскую роль](../role-based-access-control/custom-roles.md) вместо того, чтобы использовать встроенную роль участника сети, требуются следующие разрешения:
  * `Microsoft.Network/virtualNetworks/subnets/join/action`
  * `Microsoft.Network/virtualNetworks/subnets/read`
* Вместо субъекта-службы можно использовать управляемое удостоверение, назначенное системой, для разрешений. Дополнительные сведения см. в статье о том, [как использовать управляемые удостоверения](use-managed-identity.md).
* Подсеть, назначенная пулу узлов AKS, не может быть [делегированной](../virtual-network/subnet-delegation-overview.md).

## <a name="plan-ip-addressing-for-your-cluster"></a>Планирование назначения IP-адресов для кластера

Для кластеров, настроенных с помощью сети Azure CNI, требуется дополнительное планирование. Размер виртуальной сети и подсети должен быть достаточным для количества контейнеров pod, которые будут одновременно запускаться, а также соответствовать количеству узлов в кластере.

IP-адреса для контейнеров pod и узлов кластера назначаются из определенной подсети в виртуальной сети. Каждый узел настраивается с помощью основного IP-адреса. По умолчанию 30 дополнительных IP-адресов предварительно настроены с помощью CNI Azure, которые назначаются для модулей, которые запланированы на узле. При масштабировании кластера каждый узел настраивается аналогичным образом с использованием IP-адресов из подсети. Вы также можете просмотреть [Максимальное число контейнеров pod на узле](#maximum-pods-per-node).

> [!IMPORTANT]
> При выборе необходимого количества IP-адресов следует учитывать операции обновления и масштабирования. Если задать диапазон IP-адресов, который поддерживает только фиксированное число узлов, обновить или масштабировать кластер будет невозможно.
>
> * При **обновлении** кластера AKS в нем развертывается новый узел. Службы и рабочие нагрузки теперь выполняются на новом узле, а старый узел удаляется из кластера. Для выполнения этого процесса последовательного обновления требуется, чтобы был доступен как минимум один дополнительный блок IP-адресов. Количество узлов будет равно `n + 1`.
>   * Это особенно важно при использовании пулов узлов Windows Server. Узлы Windows Server в AKS не применяют обновления Windows автоматически, вместо этого выполняется обновление пула узлов. Это обновление развертывает новые узлы с помощью последнего образа базового узла и исправлений безопасности для Windows Server 2019. Дополнительные сведения об обновлении пула узлов Windows Server см. в статье [Обновление пула узлов в AKS][nodepool-upgrade].
>
> * При **масштабировании** кластера AKS в него развертывается новый узел. Службы и рабочие нагрузки теперь выполняются на новом узле. При выборе диапазона IP-адресов следует учитывать, как может понадобиться увеличить количество узлов и контейнеров pod, которые кластер может поддерживать. Также следует включить один дополнительный узел для операций обновления. Количество узлов будет равно `n + number-of-additional-scaled-nodes-you-anticipate + 1`.

Если ожидается, что узлы будут запускать максимальное количество контейнеров pod и регулярно уничтожать и развертывать их, также следует учитывать несколько дополнительных IP-адресов на каждом узле. Учтите, что из-за этих дополнительных IP-адресов удаление службы, освобождение IP-адреса для новой службы, развертывание и получение адреса может занять несколько секунд.

План IP-адреса для кластера AKS содержит виртуальную сеть, по крайней мере одну подсеть для узлов и контейнеров pod, а также диапазон адресов службы Kubernetes.

| Диапазон адресов / ресурс Azure | Установления размера и ограничения |
| --------- | ------------- |
| Виртуальная сеть | Виртуальная сеть Azure может достигать размера /8, но ограничиваться 65 536 настроенными IP-адресами. Прежде чем настраивать адресное пространство, учитывайте все потребности в сети, в том числе взаимодействие со службами в других виртуальных сетях. Например, если настраивается слишком много адресного пространства, могут возникнуть проблемы с перекрытием других адресных пространств в сети.|
| Подсеть | Подсеть должна быть достаточно большой, чтобы разместить узлы, контейнеры pod и все ресурсы Kubernetes и Azure, которые могут быть выделены в кластере. Например, если развертывается внутренний Azure Load Balancer, его внешние IP-адреса выделяются из подсети кластера, а не из публичных IP-адресов. При выборе размера подсети следует также учитывать операции обновления учетной записи и будущие потребности в масштабировании.<p />Для вычисления *минимального* размера подсети, включая дополнительный узел для операции обновления, используйте следующую формулу: `(number of nodes + 1) + ((number of nodes + 1) * maximum pods per node that you configure)`.<p/>Пример для кластера из 50 узлов: `(51) + (51  * 30 (default)) = 1,581` (/21 или больше)<p/>Пример для кластера из 50 узлов, в котором предусмотрено увеличение масштаба на 10 дополнительных узлов: `(61) + (61 * 30 (default)) = 1,891` (/21 или больше).<p>Если не указать максимальное число контейнеров pod на каждом узле при создании кластера, оно будет иметь значение *30*. Минимальное число требуемых IP-адресов на основе этого значения. При расчете минимального числа требуемых IP-адресов на другое максимальное значение см. раздел [Настройка максимального числа контейнеров pod на каждом узле](#configure-maximum---new-clusters), чтобы присвоить это значение при развертывании кластера. |
| Диапазон адресов службы Kubernetes | Этот диапазон не должен использоваться элементом виртуальной сети или элементом, подключенным к ней. Адрес службы CIDR должен иметь размер меньше /12. Этот диапазон можно повторно использовать в разных кластерах AKS. |
| IP-адрес службы доменных имен (DNS) Kubernetes | IP-адрес в диапазоне адресов службы Kubernetes, который будет использоваться функцией обнаружения службы кластеров. Не используйте первый IP-адрес из своего диапазона адресов, например .1. Первый адрес в диапазоне подсети используется для адреса *kubernetes.default.svc.cluster.local*. |
| Адрес моста Docker | Сетевой адрес моста Docker представляет сетевой адрес моста по умолчанию *docker0*, который имеется во всех установках Docker. Хотя мост *docker0* не используется кластерами AKS или модулями Pod, необходимо задать этот адрес, чтобы продолжить поддержку таких сценариев, как *Сборка DOCKER* в кластере AKS. Необходимо выбрать CIDR для сетевого адреса моста DOCKER, так как в противном случае DOCKER выберет подсеть автоматически, что может конфликтовать с другими Цидрс. Необходимо выбрать адресное пространство, не конфликтующее с остальной частью Цидрс в ваших сетях, включая службу кластера CIDR и CIDR. По умолчанию — 172.17.0.1/16. Этот диапазон можно повторно использовать в разных кластерах AKS. |

## <a name="maximum-pods-per-node"></a>Максимальное число контейнеров pod на узле

Максимальное число модулей Pod на узел в кластере AKS — 250. Максимальное количество контейнеров pod *по умолчанию* для каждого узла зависит от сети *kubenet*, *Azure CNI* и метода развертывания кластера.

| Метод развертывания | По умолчанию Kubenet | По умолчанию Azure CNI | Настройка при развертывании |
| -- | :--: | :--: | -- |
| Azure CLI | 110 | 30 | Да (до 250) |
| Шаблон Resource Manager | 110 | 30 | Да (до 250) |
| Портал | 110 | 110 (настраивается на вкладке "пулы узлов") | Нет |

### <a name="configure-maximum---new-clusters"></a>Настройка максимального числа. Новые кластеры

Вы можете настроить максимальное количество модулей Pod на узел во время развертывания кластера или при добавлении новых пулов узлов. При развертывании с Azure CLI или с помощью шаблона диспетчер ресурсов можно задать максимальное значение для каждого узла в 250.

Если вы не укажете Максподс при создании пулов узлов, вы получите значение по умолчанию 30 для Azure CNI.

Минимальное значение для максимального числа модулей Pod на узел применяется для обеспечения необходимого пространства для системных модулей памяти, критически важных для работоспособности кластера. Минимальное значение, которое может быть задано для максимального числа модулей Pod на узел, равно 10, только если в конфигурации каждого пула узлов имеется место для не менее 30 модулей памяти. Например, для установки максимального числа модулей Pod на узел минимум 10 требуется, чтобы каждый пул узлов имел не менее 3 узлов. Это требование распространяется на каждый созданный пул узлов, поэтому если 10 определен как максимальное число модулей Pod на каждый узел, каждый последующий пул узлов должен иметь по крайней мере 3 узла.

| Сеть | Минимальные | Максимум |
| -- | :--: | :--: |
| Azure CNI | 10 | 250 |
| кубенет | 10 | 110 |

> [!NOTE]
> Минимальное значение в приведенной выше таблице строго применяется службой AKS. Нельзя задать значение Максподс ниже минимального значения, как это сделать, чтобы предотвратить запуск кластера.

* **Azure CLI**. Укажите аргумент `--max-pods` при развертывании кластера с помощью команды [az aks create][az-aks-create]. Максимальное значение — 250.
* **Шаблон Resource Manager**. Укажите свойство `maxPods` в объекте [ManagedClusterAgentPoolProfile] при развертывании кластера с шаблоном Resource Manager. Максимальное значение — 250.
* **Портал Azure**. Невозможно изменить максимальное количество элементов pod на узел при развертывании кластера с помощью портала Azure. Кластеры сети Azure CNI ограничены 30 моделями pod на узел при развертывании с помощью портала Azure.

### <a name="configure-maximum---existing-clusters"></a>Настройка максимального числа. Имеющиеся кластеры

Параметр Макспод на узел можно определить при создании нового пула узлов. Если необходимо увеличить параметр Макспод для каждого узла в существующем кластере, добавьте новый пул узлов с новым требуемым числом Макспод. После переноса модулей Pod в новый пул удалите старый пул. Чтобы удалить все старые пулы в кластере, убедитесь, что вы устанавливаете режимы пула узлов, как определено в [документе пулы системных узлов][system-node-pools].

## <a name="deployment-parameters"></a>Параметры развертывания

При создании кластера AKS для сети Azure CNI можно настроить следующие параметры.

**Виртуальная сеть**. Виртуальная сеть, в которую необходимо развернуть кластер Kubernetes. Если для кластера необходимо создать новую виртуальную сеть, выберите *Создать новый* и следуйте инструкциям раздела *Создание виртуальной сети*. Дополнительные сведения об ограничениях и квотах для виртуальной сети Azure см. в статье [Подписка Azure, границы, квоты и ограничения службы](../azure-resource-manager/management/azure-subscription-service-limits.md#azure-resource-manager-virtual-networking-limits).

**Подсеть**. Подсеть в виртуальной сети, в которую требуется развернуть кластер. Если для кластера необходимо создать подсеть в виртуальной сети, выберите *Создать новый* и следуйте инструкциям раздела *Создание подсети*. Для гибридных подключений диапазон адресов не должен перекрываться другими виртуальными сетями в среде.

**Подключаемый модуль сети Azure**. при использовании подключаемого модуля сети Azure внутренняя служба балансировки нагрузки с "Екстерналтраффикполици = Local" недоступна из виртуальных машин с IP-адресом в клустерЦидр, который не принадлежит к кластеру AKS.

**Диапазон адресов службы Kubernetes**. Этот параметр представляет собой набор виртуальных IP-адресов, которые Kubernetes назначает внутренним [службам][services] в кластере. Можно использовать любой диапазон частных адресов, который отвечает следующим требованиям:

* Должен быть за пределами диапазона IP-адресов виртуальной сети вашего кластера.
* Не должен пересекаться с диапазоном других виртуальных сетей, с которыми связан кластер виртуальной сети.
* не должен перекрываться с какими-либо локальными IP-адресами.
* Не должно находиться в диапазоне `169.254.0.0/16` ,, `172.30.0.0/16` `172.31.0.0/16` или `192.0.2.0/24`

Не рекомендуется указывать диапазон адресов службы в той же виртуальной сети, что и кластер, хотя технически это возможно. Перекрывающиеся диапазоны IP-адресов могут привести к непредсказуемому поведению. Дополнительные сведения см. в разделе этой статьи [с вопросами и ответами](#frequently-asked-questions). Дополнительные сведения о службах Kubernetes см. в [этой документации][services].

**IP-адрес службы DNS Kubernetes** — IP-адрес службы DNS кластера. Этот адрес должен находиться в пределах *диапазона адресов службы Kubernetes*. Не используйте первый IP-адрес из своего диапазона адресов, например .1. Первый адрес в диапазоне подсети используется для адреса *kubernetes.default.svc.cluster.local*.

**Адрес моста DOCKER**. сетевой адрес моста DOCKER представляет сетевой адрес моста *docker0* по умолчанию, который имеется во всех установках DOCKER. Хотя мост *docker0* не используется кластерами AKS или модулями Pod, необходимо задать этот адрес, чтобы продолжить поддержку таких сценариев, как *Сборка DOCKER* в кластере AKS. Необходимо выбрать CIDR для сетевого адреса моста DOCKER, так как в противном случае DOCKER выберет подсеть автоматически, которая может конфликтовать с другими Цидрс. Необходимо выбрать адресное пространство, не конфликтующее с остальной частью Цидрс в ваших сетях, включая службу кластера CIDR и CIDR.

## <a name="configure-networking---cli"></a>Настройка сети с помощью интерфейса командной строки

При создании кластера AKS с помощью Azure CLI вы можете также настроить сеть Azure CNI. Используйте указанные ниже команды для создания кластера AKS с включенной сетью Azure CNI.

Сначала получите идентификатор ресурса существующей подсети, к которой будет присоединен кластер AKS.

```azurecli-interactive
$ az network vnet subnet list \
    --resource-group myVnet \
    --vnet-name myVnet \
    --query "[0].id" --output tsv

/subscriptions/<guid>/resourceGroups/myVnet/providers/Microsoft.Network/virtualNetworks/myVnet/subnets/default
```

Используйте команду [az aks create][az-aks-create] с аргументом `--network-plugin azure` для создания кластера с функциями сетевого взаимодействия уровня "Расширенный". Измените значение `--vnet-subnet-id`, указав идентификатор подсети, полученный на предыдущем шаге.

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --network-plugin azure \
    --vnet-subnet-id <subnet-id> \
    --docker-bridge-address 172.17.0.1/16 \
    --dns-service-ip 10.2.0.10 \
    --service-cidr 10.2.0.0/24 \
    --generate-ssh-keys
```

## <a name="configure-networking---portal"></a>Настройка сети с помощью портала

На следующем снимке экрана на портале Azure показан пример настройки этих параметров во время создания кластера AKS.

! [Расширенная сетевая конфигурация в портал Azure] [портал-01-сети-дополнительно]

## <a name="dynamic-allocation-of-ips-and-enhanced-subnet-support-preview"></a>Динамическое выделение IP-адресов и расширенная поддержка подсетей (Предварительная версия)

[!INCLUDE [preview features callout](./includes/preview/preview-callout.md)]

> [!NOTE] 
> Эта предварительная версия функции в настоящее время доступна в следующих регионах:
>
> * центрально-западная часть США

Недостатком традиционных CNI является нехватка IP-адресов Pod по мере роста кластера AKS, что приводит к необходимости перестроения всего кластера в более крупной подсети. Новая возможность выделения динамического IP-адреса в Azure CNI решает эту проблему, аллоттинг IP-адреса Pod из подсети, отдельной от подсети, в которой размещен кластер AKS.  Так вы получите следующие преимущества:

* **Улучшенное использование IP-** адресов: адреса, динамически выделяемые для модулей кластера, из подсети Pod. Это приводит к более эффективному использованию IP-адресов в кластере по сравнению с традиционным решением CNI, которое выполняет статическое выделение IP-адресов для каждого узла.  

* **Масштабируемое и гибкое**: подсети с узлами и модулями Pod можно масштабировать независимо друг от друга. Одну подсеть Pod можно совместно использовать в нескольких пулах узлов кластера или в нескольких кластерах AKS, развернутых в одной виртуальной сети. Можно также настроить отдельную подсеть Pod для пула узлов.  

* **Высокая производительность**. так как для модуля Pod назначаются IP-адреса виртуальной сети, они имеют прямое подключение к другому модулю кластера и ресурсам в виртуальной сети. Решение поддерживает очень большие кластеры без снижения производительности.

* **Отдельные политики виртуальной сети для модулей** Pod: так как в модулях Pod есть отдельная подсеть, для них можно настроить отдельные политики виртуальной сети, отличные от политик узлов. Это позволяет использовать многие полезные сценарии, такие как разрешение подключения к Интернету только для модулей Pod, а не для узлов, исправление исходного IP-адреса для модуля "модуль" в пуле узлов с помощью сети виртуальной нагрузки NAT и использование группы безопасности сети для фильтрации трафика между пулами узлов.  

* **Kubernetes сети**: политики сети Azure и Калико работают с этим новым решением.  

### <a name="install-the-aks-preview-azure-cli"></a>Установка `aks-preview` Azure CLI

Вам потребуется расширение *AKS-preview* Azure CLI. Установите расширение Azure CLI *AKS-Preview* с помощью команды [AZ Extension Add][az-extension-add] . Или установите все доступные обновления с помощью команды [AZ Extension Update][az-extension-update] .

```azurecli-interactive
# Install the aks-preview extension
az extension add --name aks-preview

# Update the extension to make sure you have the latest version installed
az extension update --name aks-preview
```

### <a name="register-the-podsubnetpreview-preview-feature"></a>Регистрация `PodSubnetPreview` функции предварительной версии

Чтобы использовать эту функцию, необходимо также включить `PodSubnetPreview` флаг функции в подписке.

Зарегистрируйте `PodSubnetPreview` флаг компонента с помощью команды [AZ Feature Register][az-feature-register] , как показано в следующем примере:

```azurecli-interactive
az feature register --namespace "Microsoft.ContainerService" --name "PodSubnetPreview"
```

Через несколько минут отобразится состояние *Registered* (Зарегистрировано). Проверьте состояние регистрации с помощью команды [AZ Feature List][az-feature-list] .

```azurecli-interactive
az feature list -o table --query "[?contains(name, 'Microsoft.ContainerService/PodSubnetPreview')].{Name:name,State:properties.state}"
```

Когда все будет готово, обновите регистрацию поставщика ресурсов *Microsoft. ContainerService* с помощью команды [AZ Provider Register][az-provider-register] :

```azurecli-interactive
az provider register --namespace Microsoft.ContainerService
```

### <a name="additional-prerequisites"></a>Дополнительные требования

Предварительные требования, уже перечисленные для Azure CNI, по-прежнему применяются, но существует несколько дополнительных ограничений:

* Поддерживаются только кластеры узлов Linux и пулы узлов.
* AKS подсистемы и кластеры DIY не поддерживаются.

### <a name="planning-ip-addressing"></a>Планирование IP-адресации

При использовании этой функции Планирование гораздо проще. Так как эти узлы и модули энергонезависимо масштабируются, их адресные пространства также можно планировать отдельно. Так как подсети Pod можно настроить на детализацию пула узлов, клиенты всегда могут добавить новую подсеть при добавлении пула узлов. Системные модули в пуле кластеров или узлов также получают IP-адреса из подсети Pod, поэтому это поведение необходимо учитывать для.

Планирование IP-адресов для K8S Services и DOCKER Bridge остается неизменным.

### <a name="maximum-pods-per-node-in-a-cluster-with-dynamic-allocation-of-ips-and-enhanced-subnet-support"></a>Максимальное число модулей Pod на узел в кластере с динамическим выделением IP-адресов и расширенной поддержкой подсетей

Значения модулей Pod на узел при использовании Azure CNI с динамическим выделением IP-адресов немного изменились по сравнению с традиционным поведением CNI:

|CNI|Методы развертывания|По умолчанию|Настройка при развертывании|
|--|--| :--: |--|
|Традиционная служба Azure CNI|Azure CLI|30|Да (до 250)|
|Azure CNI с динамическим выделением IP-адресов|Azure CLI|110|Да (до 250)|

Все прочие рекомендации, связанные с настройкой максимального числа узлов на модуль, остаются неизменными.

### <a name="additional-deployment-parameters"></a>Дополнительные параметры развертывания

Описанные выше параметры развертывания все еще являются допустимыми, за одним исключением:

* Параметр **подсети** теперь ссылается на подсеть, связанную с узлами кластера.
* Дополнительная **подсеть Pod** параметра позволяет указать подсеть, IP-адреса которой будут динамически выделяться в модули Pod.

### <a name="configure-networking---cli-with-dynamic-allocation-of-ips-and-enhanced-subnet-support"></a>Настройка сети — CLI с динамическим выделением IP-адресов и расширенной поддержкой подсетей

Использование динамического выделения IP-адресов и расширенной поддержки подсетей в кластере аналогично методу по умолчанию для настройки кластера Azure CNI. В следующем примере показано, как создать новую виртуальную сеть с подсетью для узлов и подсетью для модулей Pod, а также создать кластер, использующий Azure CNI с динамическим выделением IP-адресов и расширенной поддержкой подсети. Не забудьте заменить переменные, например `$subscription` собственными значениями:

Сначала создайте виртуальную сеть с двумя подсетями:

```azurecli-interactive
$resourceGroup="myResourceGroup"
$vnet="myVirtualNetwork"

# Create our two subnet network 
az network vnet create -g $rg --name $vnet --address-prefixes 10.0.0.0/8 -o none 
az network vnet subnet create -g $rg --vnet-name $vnet --name nodesubnet --address-prefixes 10.240.0.0/16 -o none 
az network vnet subnet create -g $rg --vnet-name $vnet --name podsubnet --address-prefixes 10.241.0.0/16 -o none 
```

Затем создайте кластер, ссылаясь на подсеть узла с помощью `--vnet-subnet-id` и подсеть Pod, используя `--pod-subnet-id` :

```azurecli-interactive
$clusterName="myAKSCluster"
$location="eastus"
$subscription="aaaaaaa-aaaaa-aaaaaa-aaaa"

az aks create -n $clusterName -g $resourceGroup -l $location --max-pods 250 --node-count 2 --network-plugin azure --vnet-subnet-id /subscriptions/$subscription/resourceGroups/$resourceGroup/providers/Microsoft.Network/virtualNetworks/$vnet/subnets/nodesubnet --pod-subnet-id /subscriptions/$subscription/resourceGroups/$resourceGroup/providers/Microsoft.Network/virtualNetworks/$vnet/subnets/podsubnet  
```

#### <a name="adding-node-pool"></a>Добавление пула узлов

При добавлении пула узлов сослаться на подсеть узла с помощью `--vnet-subnet-id` и подсеть Pod с помощью `--pod-subnet-id` . В следующем примере создаются две новые подсети, на которые можно будет ссылаться при создании нового пула узлов:

```azurecli-interactive
az network vnet subnet create -g $resourceGroup --vnet-name $vnet --name node2subnet --address-prefixes 10.242.0.0/16 -o none 
az network vnet subnet create -g $resourceGroup --vnet-name $vnet --name pod2subnet --address-prefixes 10.243.0.0/16 -o none 

az aks nodepool add --cluster-name $clusterName -g $resourceGroup  -n newNodepool --max-pods 250 --node-count 2 --vnet-subnet-id /subscriptions/$subscription/resourceGroups/$resourceGroup/providers/Microsoft.Network/virtualNetworks/$vnet/subnets/node2subnet  --pod-subnet-id /subscriptions/$subscription/resourceGroups/$resourceGroup/providers/Microsoft.Network/virtualNetworks/$vnet/subnets/pod2subnet --no-wait 
```

## <a name="frequently-asked-questions"></a>Часто задаваемые вопросы

Следующие вопросы и ответы относятся к конфигурации сети **Azure CNI**.

* *Можно ли развернуть виртуальные машины в подсети моего кластера?*

  Да.

* *Какой исходный IP-адрес для внешних систем пройдет за трафиком, источником которого является модуль с поддержкой Azure CNI?*

  Системы в той же виртуальной сети, что и кластер AKS, видят IP-адрес Pod в качестве исходного адреса для любого трафика из модуля Pod. Системы за пределами виртуальной сети кластера AKS видят IP-адрес узла в качестве исходного адреса для любого трафика из модуля Pod.

* *Можно ли настроить политики сети для каждого Pod?*

  Да, сетевая политика Kubernetes доступна в AKS. Чтобы приступить к работе, см. раздел Защита трафика между модулями Pod с [помощью сетевых политик в AKS][network-policy].

* *Можно ли настроить максимальное число контейнеров pod, развертываемых на узел?*

  Да, при развертывании кластера с помощью Azure CLI или шаблона Resource Manager. См. статью [Конфигурация сети в службе Azure Kubernetes (AKS)](#maximum-pods-per-node).

  Невозможно изменить максимальное количество контейнеров pod в узле в имеющемся кластере.

* *Разделы справки настроить дополнительные свойства для подсети, созданной при создании кластера AKS? Например, конечные точки службы.*

  Полный список свойств для виртуальной сети и подсетей, создаваемых во время создания кластера AKS, можно настроить на странице стандартной конфигурации виртуальной сети на портале Azure.

* *Можно ли использовать другую подсеть в виртуальной сети кластера для* **диапазона адресов службы Kubernetes**?

  Не рекомендуется, но эта конфигурация возможна. Диапазон адресов службы — это набор виртуальных IP-адресов, которые Kubernetes присваивает внутренним службам в кластере. Сеть Azure не видит адреса в диапазоне IP-адресов службы кластера Kubernetes. Из-за этого позже возможно создать подсеть в виртуальной сети кластера, которая пересекается с диапазоном адресов службы. При возникновении такого пересекания Kubernetes может присвоить службе IP-адрес, который уже используется другим ресурсом в подсети, что приводит к непредсказуемому поведению или сбоям. Убедившись, что диапазон адресов используется за пределами виртуальной сети кластера, можно избежать такого риска пересечений.

### <a name="dynamic-allocation-of-ip-addresses-and-enhanced-subnet-support-faqs"></a>Динамическое выделение IP-адресов и часто задаваемые вопросы о поддержке подсети

Следующие вопросы и ответы относятся к **конфигурации сети Azure CNI при использовании динамического выделения IP-адресов и расширенной поддержки подсетей**.

* *Можно ли назначить несколько подсетей Pod пулу кластеров или узлов?*

  Кластеру или пулу узлов можно назначить только одну подсеть. Однако несколько кластеров или пулов узлов могут совместно использовать одну подсеть.

* *Можно ли назначить подсети Pod из другой виртуальной сети?*

  Подсеть Pod должна относиться к той же виртуальной сети, что и кластер.  

* *Могут ли некоторые пулы узлов в кластере использовать традиционные CNI, тогда как другие используют новый CNI?*

  Весь кластер должен использовать только один тип CNI.

## <a name="aks-engine"></a>Обработчик AKS

[Обработчик Службы Azure Kubernetes (обработчик AKS)][aks-engine] — это проект с открытым исходным кодом, создающий шаблоны Azure Resource Manager, которые можно использовать для развертывания кластеров Kubernetes в Azure.

Кластеры Kubernetes, созданные с помощью обработчика AKS, поддерживают подключаемые модули [kubenet][kubenet] и [Azure CNI][cni-networking]. Таким образом, обработчик AKS поддерживает оба сценария сети.

## <a name="next-steps"></a>Дальнейшие действия

Узнайте больше о сетевом взаимодействии в AKS из следующих статей:

* [Использование статического IP-адреса с подсистемой балансировки нагрузки Azure Kubernetes Service (AKS)](static-ip.md)
* [Использование внутренней подсистемы балансировки нагрузки со Службой контейнеров Azure (AKS)](internal-lb.md)

* [Создать базовый контроллер входящего трафика с внешним сетевым подключением.][aks-ingress-basic]
* [Включить надстройку маршрутизации приложений HTTP.][aks-http-app-routing]
* [Создать контроллер входящего трафика, который использует внутреннюю, частную сети и IP-адрес.][aks-ingress-internal]
* [Создать контроллер входящего трафика с динамическим общедоступным IP-адресом и настроить шифрование для автоматического создания TLS-сертификатов.][aks-ingress-tls]
* [Создание контроллера входящего трафика со статическим общедоступным IP-адресом и настройка шифрования для автоматического создания TLS-сертификатов][aks-ingress-static-tls]
<!-- IMAGES -->
[Advanced-Networking-Diagram-01]:./медиа/нетворкинг-овервиев/advanced-networking-diagram-01.png [портал-01-Networks-Advanced]:./медиа/нетворкинг-овервиев/portal-01-networking-advanced.png

<!-- LINKS - External -->
[aks-engine]: https://github.com/Azure/aks-engine
[services]: https://kubernetes.io/docs/concepts/services-networking/service/
[portal]: https://portal.azure.com
[cni-networking]: https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md
[kubenet]: https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/#kubenet

<!-- LINKS - Internal -->
[az-aks-create]: /cli/azure/aks?view=azure-cli-latest#az-aks-create
[aks-ssh]: ssh.md
[ManagedClusterAgentPoolProfile]: /azure/templates/microsoft.containerservice/managedclusters#managedclusteragentpoolprofile-object
[aks-network-concepts]: concepts-network.md
[aks-ingress-basic]: ingress-basic.md
[aks-ingress-tls]: ingress-tls.md
[aks-ingress-static-tls]: ingress-static-ip.md
[aks-http-app-routing]: http-application-routing.md
[aks-ingress-internal]: ingress-internal-ip.md
[az-extension-add]: https://docs.microsoft.com/cli/azure/extension?view=azure-cli-latest&preserve-view=true#az_extension_add
[az-extension-update]: https://docs.microsoft.com/cli/azure/extension?view=azure-cli-latest&preserve-view=true#az_extension_update
[az-feature-register]: https://docs.microsoft.com/cli/azure/feature?view=azure-cli-latest&preserve-view=true#az_feature_register
[az-feature-list]: https://docs.microsoft.com/cli/azure/feature?view=azure-cli-latest&preserve-view=true#az_feature_list
[az-provider-register]: https://docs.microsoft.com/cli/azure/provider?view=azure-cli-latest&preserve-view=true#az_provider_register
[network-policy]: use-network-policies.md
[nodepool-upgrade]: use-multiple-node-pools.md#upgrade-a-node-pool
[network-comparisons]: concepts-network.md#compare-network-models
[system-node-pools]: use-system-pools.md
