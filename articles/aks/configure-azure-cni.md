---
title: Настройка сети Azure CNI в Службе Azure Kubernetes (AKS)
description: Узнайте, как настроить сеть Azure CNI (расширенную) в Службе Azure Kubernetes (AKS), включая развертывание кластера AKS в существующую виртуальную сеть и подсеть.
services: container-service
ms.topic: article
ms.date: 06/03/2019
ms.openlocfilehash: 0a6ea45156477c0d0e95b9d345cffe1a75c773b6
ms.sourcegitcommit: 436518116963bd7e81e0217e246c80a9808dc88c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/27/2021
ms.locfileid: "98917813"
---
# <a name="configure-azure-cni-networking-in-azure-kubernetes-service-aks"></a>Настройка сети Azure CNI в Службе Azure Kubernetes (AKS)

По умолчанию кластеры AKS используют [kubenet][kubenet], а также создается виртуальная сеть и подсеть. При использовании *kubenet* узлы получают IP-адрес из подсети виртуальной сети. Затем настраивается преобразование сетевых адресов (NAT) на узлах, а модули получают IP-адрес, "скрытый" за IP-адресом узла. Такой подход уменьшает количество IP-адресов, которые необходимо зарезервировать в пространстве сети для модулей pod.

С помощью [сетевого интерфейса контейнеров Azure (CNI)][cni-networking] каждый объект pod получает IP-адрес из подсети, и к этому объекту pod можно получить прямой доступ. Эти IP-адреса должны быть уникальными во всей сети, и их следует планировать заранее. Для каждого узла предусмотрен параметр конфигурации, в котором указывается максимальное число объектов pod, которые он поддерживает. Затем на каждом узле заранее резервируется эквивалентное число IP-адресов для этого узла. Этот подход требует дополнительного планирования и часто приводит к исчерпанию IP-адресов или необходимости повторно создавать кластеры в подсети большего размера по мере увеличения потребностей вашего приложения.

В этой статье показано, как использовать сеть *Azure CNI*, чтобы создавать и использовать подсеть виртуальной сети для кластера AKS. Дополнительные сведения о сетях см. в статье [Основные понятия сети в Службе Azure Kubernetes (AKS)][aks-network-concepts].

## <a name="prerequisites"></a>Предварительные требования

* Виртуальная сеть для кластера AKS должна разрешать исходящее подключение к Интернету.
* Кластеры AKS не могут использовать `169.254.0.0/16` , `172.30.0.0/16` , `172.31.0.0/16` или `192.0.2.0/24` для диапазона адресов службы Kubernetes, диапазона адресов Pod или диапазона адресов виртуальной сети кластера. 
* Субъект-служба, используемый кластером AKS, должен иметь по крайней мере разрешения [Участник сетей](../role-based-access-control/built-in-roles.md#network-contributor) в подсети в виртуальной сети. Если вы хотите определить [пользовательскую роль](../role-based-access-control/custom-roles.md) вместо того, чтобы использовать встроенную роль участника сети, требуются следующие разрешения:
  * `Microsoft.Network/virtualNetworks/subnets/join/action`
  * `Microsoft.Network/virtualNetworks/subnets/read`
* Вместо субъекта-службы можно использовать управляемое удостоверение, назначенное системой, для разрешений. Дополнительные сведения см. в статье о том, [как использовать управляемые удостоверения](use-managed-identity.md).
* Подсеть, назначенная пулу узлов AKS, не может быть [делегированной](../virtual-network/subnet-delegation-overview.md).

## <a name="plan-ip-addressing-for-your-cluster"></a>Планирование назначения IP-адресов для кластера

Для кластеров, настроенных с помощью сети Azure CNI, требуется дополнительное планирование. Размер виртуальной сети и подсети должен быть достаточным для количества контейнеров pod, которые будут одновременно запускаться, а также соответствовать количеству узлов в кластере.

IP-адреса для контейнеров pod и узлов кластера назначаются из определенной подсети в виртуальной сети. Каждый узел настраивается с помощью основного IP-адреса. По умолчанию 30 дополнительных IP-адресов предварительно настроены с помощью CNI Azure, которые назначаются для модулей, которые запланированы на узле. При масштабировании кластера каждый узел настраивается аналогичным образом с использованием IP-адресов из подсети. Вы также можете просмотреть [Максимальное число контейнеров pod на узле](#maximum-pods-per-node).

> [!IMPORTANT]
> При выборе необходимого количества IP-адресов следует учитывать операции обновления и масштабирования. Если задать диапазон IP-адресов, который поддерживает только фиксированное число узлов, обновить или масштабировать кластер будет невозможно.
>
> - При **обновлении** кластера AKS в нем развертывается новый узел. Службы и рабочие нагрузки теперь выполняются на новом узле, а старый узел удаляется из кластера. Для выполнения этого процесса последовательного обновления требуется, чтобы был доступен как минимум один дополнительный блок IP-адресов. Количество узлов будет равно `n + 1`.
>   - Это особенно важно при использовании пулов узлов Windows Server. Узлы Windows Server в AKS не применяют обновления Windows автоматически, вместо этого выполняется обновление пула узлов. Это обновление развертывает новые узлы с помощью последнего образа базового узла и исправлений безопасности для Windows Server 2019. Дополнительные сведения об обновлении пула узлов Windows Server см. в статье [Обновление пула узлов в AKS][nodepool-upgrade].
>
> - При **масштабировании** кластера AKS в него развертывается новый узел. Службы и рабочие нагрузки теперь выполняются на новом узле. При выборе диапазона IP-адресов следует учитывать, как может понадобиться увеличить количество узлов и контейнеров pod, которые кластер может поддерживать. Также следует включить один дополнительный узел для операций обновления. Количество узлов будет равно `n + number-of-additional-scaled-nodes-you-anticipate + 1`.

Если ожидается, что узлы будут запускать максимальное количество контейнеров pod и регулярно уничтожать и развертывать их, также следует учитывать несколько дополнительных IP-адресов на каждом узле. Учтите, что из-за этих дополнительных IP-адресов удаление службы, освобождение IP-адреса для новой службы, развертывание и получение адреса может занять несколько секунд.

План IP-адреса для кластера AKS содержит виртуальную сеть, по крайней мере одну подсеть для узлов и контейнеров pod, а также диапазон адресов службы Kubernetes.

| Диапазон адресов / ресурс Azure | Установления размера и ограничения |
| --------- | ------------- |
| Виртуальная сеть | Виртуальная сеть Azure может достигать размера /8, но ограничиваться 65 536 настроенными IP-адресами. Прежде чем настраивать адресное пространство, учитывайте все потребности в сети, в том числе взаимодействие со службами в других виртуальных сетях. Например, если настраивается слишком много адресного пространства, могут возникнуть проблемы с перекрытием других адресных пространств в сети.|
| Подсеть | Подсеть должна быть достаточно большой, чтобы разместить узлы, контейнеры pod и все ресурсы Kubernetes и Azure, которые могут быть выделены в кластере. Например, если развертывается внутренний Azure Load Balancer, его внешние IP-адреса выделяются из подсети кластера, а не из публичных IP-адресов. При выборе размера подсети следует также учитывать операции обновления учетной записи и будущие потребности в масштабировании.<p />Для вычисления *минимального* размера подсети, включая дополнительный узел для операции обновления, используйте следующую формулу: `(number of nodes + 1) + ((number of nodes + 1) * maximum pods per node that you configure)`.<p/>Пример для кластера из 50 узлов: `(51) + (51  * 30 (default)) = 1,581` (/21 или больше)<p/>Пример для кластера из 50 узлов, в котором предусмотрено увеличение масштаба на 10 дополнительных узлов: `(61) + (61 * 30 (default)) = 1,891` (/21 или больше).<p>Если не указать максимальное число контейнеров pod на каждом узле при создании кластера, оно будет иметь значение *30*. Минимальное число требуемых IP-адресов на основе этого значения. При расчете минимального числа требуемых IP-адресов на другое максимальное значение см. раздел [Настройка максимального числа контейнеров pod на каждом узле](#configure-maximum---new-clusters), чтобы присвоить это значение при развертывании кластера. |
| Диапазон адресов службы Kubernetes | Этот диапазон не должен использоваться элементом виртуальной сети или элементом, подключенным к ней. Адрес службы CIDR должен иметь размер меньше /12. Этот диапазон можно повторно использовать в разных кластерах AKS. |
| IP-адрес службы доменных имен (DNS) Kubernetes | IP-адрес в диапазоне адресов службы Kubernetes, который будет использоваться функцией обнаружения службы кластеров. Не используйте первый IP-адрес из своего диапазона адресов, например .1. Первый адрес в диапазоне подсети используется для адреса *kubernetes.default.svc.cluster.local*. |
| Адрес моста Docker | Сетевой адрес моста Docker представляет сетевой адрес моста по умолчанию *docker0*, который имеется во всех установках Docker. Хотя мост *docker0* не используется кластерами AKS или модулями Pod, необходимо задать этот адрес, чтобы продолжить поддержку таких сценариев, как *Сборка DOCKER* в кластере AKS. Необходимо выбрать CIDR для сетевого адреса моста DOCKER, так как в противном случае DOCKER выберет подсеть автоматически, которая может конфликтовать с другими Цидрс. Необходимо выбрать адресное пространство, не конфликтующее с остальной частью Цидрс в ваших сетях, включая службу кластера CIDR и CIDR. По умолчанию — 172.17.0.1/16. Этот диапазон можно повторно использовать в разных кластерах AKS. |

## <a name="maximum-pods-per-node"></a>Максимальное число контейнеров pod на узле

Максимальное число модулей Pod на узел в кластере AKS — 250. Максимальное количество контейнеров pod *по умолчанию* для каждого узла зависит от сети *kubenet*, *Azure CNI* и метода развертывания кластера.

| Метод развертывания | По умолчанию Kubenet | По умолчанию Azure CNI | Настройка при развертывании |
| -- | :--: | :--: | -- |
| Azure CLI | 110 | 30 | Да (до 250) |
| Шаблон Resource Manager | 110 | 30 | Да (до 250) |
| Портал | 110 | 30 | нет |

### <a name="configure-maximum---new-clusters"></a>Настройка максимального числа. Новые кластеры

Вы можете настроить максимальное количество модулей Pod на узел во время развертывания кластера или при добавлении новых пулов узлов. При развертывании с Azure CLI или с помощью шаблона диспетчер ресурсов можно задать максимальное значение для каждого узла в 250.

Если вы не укажете Максподс при создании пулов узлов, вы получите значение по умолчанию 30 для Azure CNI.

Минимальное значение для максимального числа модулей Pod на узел применяется для обеспечения необходимого пространства для системных модулей памяти, критически важных для работоспособности кластера. Минимальное значение, которое может быть задано для максимального числа модулей Pod на узел, равно 10, только если в конфигурации каждого пула узлов имеется место для не менее 30 модулей памяти. Например, для установки максимального числа модулей Pod на узел минимум 10 требуется, чтобы каждый пул узлов имел не менее 3 узлов. Это требование распространяется на каждый созданный пул узлов, поэтому если 10 определен как максимальное число модулей Pod на каждый узел, каждый последующий пул узлов должен иметь по крайней мере 3 узла.

| Сеть | Минимальные | Максимальная |
| -- | :--: | :--: |
| Azure CNI | 10 | 250 |
| кубенет | 10 | 110 |

> [!NOTE]
> Минимальное значение в приведенной выше таблице строго применяется службой AKS. Нельзя задать значение Максподс ниже минимального значения, как это сделать, чтобы предотвратить запуск кластера.

* **Azure CLI**. Укажите аргумент `--max-pods` при развертывании кластера с помощью команды [az aks create][az-aks-create]. Максимальное значение — 250.
* **Шаблон Resource Manager**. Укажите свойство `maxPods` в объекте [ManagedClusterAgentPoolProfile] при развертывании кластера с шаблоном Resource Manager. Максимальное значение — 250.
* **Портал Azure**. Невозможно изменить максимальное количество элементов pod на узел при развертывании кластера с помощью портала Azure. Кластеры сети Azure CNI ограничены 30 моделями pod на узел при развертывании с помощью портала Azure.

### <a name="configure-maximum---existing-clusters"></a>Настройка максимального числа. Имеющиеся кластеры

Параметр Макспод на узел можно определить при создании нового пула узлов. Если необходимо увеличить параметр Макспод для каждого узла в существующем кластере, добавьте новый пул узлов с новым требуемым числом Макспод. После переноса модулей Pod в новый пул удалите старый пул. Чтобы удалить все старые пулы в кластере, убедитесь, что вы устанавливаете режимы пула узлов, как определено в [документе пулы системных узлов][system-node-pools].

## <a name="deployment-parameters"></a>Параметры развертывания

При создании кластера AKS для сети Azure CNI можно настроить следующие параметры.

**Виртуальная сеть**. Виртуальная сеть, в которую необходимо развернуть кластер Kubernetes. Если для кластера необходимо создать новую виртуальную сеть, выберите *Создать новый* и следуйте инструкциям раздела *Создание виртуальной сети*. Дополнительные сведения об ограничениях и квотах для виртуальной сети Azure см. в статье [Подписка Azure, границы, квоты и ограничения службы](../azure-resource-manager/management/azure-subscription-service-limits.md#azure-resource-manager-virtual-networking-limits).

**Подсеть**. Подсеть в виртуальной сети, в которую требуется развернуть кластер. Если для кластера необходимо создать подсеть в виртуальной сети, выберите *Создать новый* и следуйте инструкциям раздела *Создание подсети*. Для гибридных подключений диапазон адресов не должен перекрываться другими виртуальными сетями в среде.

**Подключаемый модуль сети Azure**. при использовании подключаемого модуля сети Azure внутренняя служба балансировки нагрузки с "Екстерналтраффикполици = Local" недоступна из виртуальных машин с IP-адресом в клустерЦидр, который не принадлежит к кластеру AKS.

**Диапазон адресов службы Kubernetes**: это набор виртуальных IP-адресов, которые Kubernetes назначает внутренним [службам][services] в кластере. Можно использовать любой диапазон частных адресов, который отвечает следующим требованиям:

* Должен быть за пределами диапазона IP-адресов виртуальной сети вашего кластера.
* Не должен пересекаться с диапазоном других виртуальных сетей, с которыми связан кластер виртуальной сети.
* не должен перекрываться с какими-либо локальными IP-адресами.
* Не должно находиться в диапазоне `169.254.0.0/16` ,, `172.30.0.0/16` `172.31.0.0/16` или `192.0.2.0/24`

Не рекомендуется указывать диапазон адресов службы в той же виртуальной сети, что и кластер, хотя технически это возможно. Перекрывающиеся диапазоны IP-адресов могут привести к непредсказуемому поведению. Дополнительные сведения см. в разделе этой статьи [с вопросами и ответами](#frequently-asked-questions). Дополнительные сведения о службах Kubernetes см. в [этой документации][services].

**IP-адрес службы DNS Kubernetes** — IP-адрес службы DNS кластера. Этот адрес должен находиться в пределах *диапазона адресов службы Kubernetes*. Не используйте первый IP-адрес из своего диапазона адресов, например .1. Первый адрес в диапазоне подсети используется для адреса *kubernetes.default.svc.cluster.local*.

**Адрес моста DOCKER**. сетевой адрес моста DOCKER представляет сетевой адрес моста *docker0* по умолчанию, который имеется во всех установках DOCKER. Хотя мост *docker0* не используется кластерами AKS или модулями Pod, необходимо задать этот адрес, чтобы продолжить поддержку таких сценариев, как *Сборка DOCKER* в кластере AKS. Необходимо выбрать CIDR для сетевого адреса моста DOCKER, так как в противном случае DOCKER выберет подсеть автоматически, которая может конфликтовать с другими Цидрс. Необходимо выбрать адресное пространство, не конфликтующее с остальной частью Цидрс в ваших сетях, включая службу кластера CIDR и CIDR.

## <a name="configure-networking---cli"></a>Настройка сети с помощью интерфейса командной строки

При создании кластера AKS с помощью Azure CLI вы можете также настроить сеть Azure CNI. Используйте указанные ниже команды для создания кластера AKS с включенной сетью Azure CNI.

Сначала получите идентификатор ресурса существующей подсети, к которой будет присоединен кластер AKS.

```azurecli-interactive
$ az network vnet subnet list \
    --resource-group myVnet \
    --vnet-name myVnet \
    --query "[0].id" --output tsv

/subscriptions/<guid>/resourceGroups/myVnet/providers/Microsoft.Network/virtualNetworks/myVnet/subnets/default
```

Используйте команду [az aks create][az-aks-create] с аргументом `--network-plugin azure` для создания кластера с функциями сетевого взаимодействия уровня "Расширенный". Измените значение `--vnet-subnet-id`, указав идентификатор подсети, полученный на предыдущем шаге.

```azurecli-interactive
az aks create \
    --resource-group myResourceGroup \
    --name myAKSCluster \
    --network-plugin azure \
    --vnet-subnet-id <subnet-id> \
    --docker-bridge-address 172.17.0.1/16 \
    --dns-service-ip 10.2.0.10 \
    --service-cidr 10.2.0.0/24 \
    --generate-ssh-keys
```

## <a name="configure-networking---portal"></a>Настройка сети с помощью портала

На следующем снимке экрана на портале Azure показан пример настройки этих параметров во время создания кластера AKS.

![Конфигурация расширенного сетевого взаимодействия на портале Azure][portal-01-networking-advanced]

## <a name="frequently-asked-questions"></a>Часто задаваемые вопросы

Следующие вопросы и ответы относятся к конфигурации сети **Azure CNI**.

* *Можно ли развернуть виртуальные машины в подсети моего кластера?*

  Да.

* *Какой исходный IP-адрес для внешних систем пройдет за трафиком, источником которого является модуль с поддержкой Azure CNI?*

  Системы в той же виртуальной сети, что и кластер AKS, видят IP-адрес Pod в качестве исходного адреса для любого трафика из модуля Pod. Системы за пределами виртуальной сети кластера AKS видят IP-адрес узла в качестве исходного адреса для любого трафика из модуля Pod. 

* *Можно ли настроить политики сети для каждого Pod?*

  Да, сетевая политика Kubernetes доступна в AKS. Чтобы приступить к работе, см. раздел Защита трафика между модулями Pod с [помощью сетевых политик в AKS][network-policy].

* *Можно ли настроить максимальное число контейнеров pod, развертываемых на узел?*

  Да, при развертывании кластера с помощью Azure CLI или шаблона Resource Manager. См. статью [Конфигурация сети в службе Azure Kubernetes (AKS)](#maximum-pods-per-node).

  Невозможно изменить максимальное количество контейнеров pod в узле в имеющемся кластере.

* *Разделы справки настроить дополнительные свойства для подсети, созданной при создании кластера AKS? Например, конечные точки службы.*

  Полный список свойств для виртуальной сети и подсетей, создаваемых во время создания кластера AKS, можно настроить на странице стандартной конфигурации виртуальной сети на портале Azure.

* *Можно ли использовать другую подсеть в виртуальной сети кластера для* **диапазона адресов службы Kubernetes**?

  Не рекомендуется, но эта конфигурация возможна. Диапазон адресов службы — это набор виртуальных IP-адресов, которые Kubernetes присваивает внутренним службам в кластере. Сеть Azure не видит адреса в диапазоне IP-адресов службы кластера Kubernetes. Из-за этого позже возможно создать подсеть в виртуальной сети кластера, которая пересекается с диапазоном адресов службы. При возникновении такого пересекания Kubernetes может присвоить службе IP-адрес, который уже используется другим ресурсом в подсети, что приводит к непредсказуемому поведению или сбоям. Убедившись, что диапазон адресов используется за пределами виртуальной сети кластера, можно избежать такого риска пересечений.

## <a name="next-steps"></a>Дальнейшие действия

Узнайте больше о сетевом взаимодействии в AKS из следующих статей:

- [Использование статического IP-адреса с подсистемой балансировки нагрузки Azure Kubernetes Service (AKS)](static-ip.md)
- [Использование внутренней подсистемы балансировки нагрузки со Службой контейнеров Azure (AKS)](internal-lb.md)

- [Создать базовый контроллер входящего трафика с внешним сетевым подключением.][aks-ingress-basic]
- [Включить надстройку маршрутизации приложений HTTP.][aks-http-app-routing]
- [Создать контроллер входящего трафика, который использует внутреннюю, частную сети и IP-адрес.][aks-ingress-internal]
- [Создать контроллер входящего трафика с динамическим общедоступным IP-адресом и настроить шифрование для автоматического создания TLS-сертификатов.][aks-ingress-tls]
- [Создание контроллера входящего трафика со статическим общедоступным IP-адресом и настройка шифрования для автоматического создания TLS-сертификатов][aks-ingress-static-tls]

### <a name="aks-engine"></a>Обработчик AKS

[Обработчик Службы Azure Kubernetes (обработчик AKS)][aks-engine] — это проект с открытым исходным кодом, создающий шаблоны Azure Resource Manager, которые можно использовать для развертывания кластеров Kubernetes в Azure.

Кластеры Kubernetes, созданные с помощью обработчика AKS, поддерживают подключаемые модули [kubenet][kubenet] и [Azure CNI][cni-networking]. Таким образом, обработчик AKS поддерживает оба сценария сети.

<!-- IMAGES -->
[advanced-networking-diagram-01]: ./media/networking-overview/advanced-networking-diagram-01.png
[portal-01-networking-advanced]: ./media/networking-overview/portal-01-networking-advanced.png

<!-- LINKS - External -->
[aks-engine]: https://github.com/Azure/aks-engine
[services]: https://kubernetes.io/docs/concepts/services-networking/service/
[portal]: https://portal.azure.com
[cni-networking]: https://github.com/Azure/azure-container-networking/blob/master/docs/cni.md
[kubenet]: https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/#kubenet

<!-- LINKS - Internal -->
[az-aks-create]: /cli/azure/aks?view=azure-cli-latest#az-aks-create
[aks-ssh]: ssh.md
[ManagedClusterAgentPoolProfile]: /azure/templates/microsoft.containerservice/managedclusters#managedclusteragentpoolprofile-object
[aks-network-concepts]: concepts-network.md
[aks-ingress-basic]: ingress-basic.md
[aks-ingress-tls]: ingress-tls.md
[aks-ingress-static-tls]: ingress-static-ip.md
[aks-http-app-routing]: http-application-routing.md
[aks-ingress-internal]: ingress-internal-ip.md
[network-policy]: use-network-policies.md
[nodepool-upgrade]: use-multiple-node-pools.md#upgrade-a-node-pool
[network-comparisons]: concepts-network.md#compare-network-models
[system-node-pools]: use-system-pools.md
