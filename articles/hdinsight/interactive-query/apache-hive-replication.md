---
title: Как использовать репликацию Apache Hive в кластерах Azure HDInsight
description: Узнайте, как использовать репликацию Hive в кластерах HDInsight для репликации хранилище метаданных Hive и Azure Data Lake Storage Gen 2 Data Lake.
ms.service: hdinsight
ms.topic: conceptual
ms.date: 10/08/2020
ms.openlocfilehash: 3dd894a46b666703f64e44336c0bf022da8a063a
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98941331"
---
# <a name="how-to-use-apache-hive-replication-in-azure-hdinsight-clusters"></a>Как использовать репликацию Apache Hive в кластерах Azure HDInsight

В контексте баз данных и хранилищ репликация — это процесс копирования сущностей из одного хранилища в другое. Дублирование может применяться ко всей базе данных или к меньшему уровню, например к таблице или секции. Целью является наличие реплики, которая изменяется при изменении базовой сущности. Репликация в Apache Hive фокусируется на аварийном восстановлении и предлагает однонаправленную репликацию первичного копирования. В кластерах HDInsight репликация Hive может использоваться для однонаправленной репликации хранилище метаданных Hive и связанных с ними базовых данных Data Lake на Azure Data Lake Storage 2-го поколения.  

Репликация Hive была развиваться в течение нескольких лет с новыми версиями, обеспечивающими лучшую функциональность и требующую более быстрых и менее ресурсоемких ресурсов. В этой статье обсуждается репликация Hive (Replv2), которая поддерживается в типах кластеров HDInsight 3,6 и HDInsight 4,0.

## <a name="advantages-of-replv2"></a>Преимущества Replv2

[ReplicationV2 Hive](https://cwiki.apache.org/confluence/display/Hive/HiveReplicationv2Development) или (Replv2) имеет следующие преимущества по сравнению с первой версией репликации Hive, которая использовала [Импорт и экспорт](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ImportExport)Hive:

- Добавочная репликация на основе событий
- Репликация на момент времени  
- Сниженные требования к пропускной способности  
- Сокращение количества промежуточных копий  
- Состояние репликации сохраняется
- Ограниченная репликация  
- Поддержка модели с центральным и периферийным моделями  
- Поддержка таблиц ACID (в HDInsight 4,0)

## <a name="replication-phases"></a>Этапы репликации

Репликация на основе событий Hive настраивается между основным и дополнительным кластерами. Эта репликация состоит из двух отдельных этапов: начальной загрузки и добавочных запусков.

### <a name="bootstrapping"></a>Начальной загрузки

Начальная загрузка предназначена для однократного выполнения репликации базового состояния баз данных с первичной на вторичную. При необходимости можно настроить начальную загрузку, чтобы включить подмножество таблиц в целевой базе данных, в которых необходимо включить репликацию.

### <a name="incremental-runs"></a>Добавочные запуски

После начальной загрузки добавочные запуски автоматически выполняются на основном кластере, а события, созданные во время этих добавочных запусков, воспроизводятся в дополнительном кластере. Когда дополнительный кластер начинает подключаться к основному кластеру, он будет согласовываться с событиями первичной реплики.

## <a name="replication-commands"></a>Команды репликации

Hive предоставляет набор команд REPL — `DUMP` , `LOAD` и `STATUS` — для координации потока событий. `DUMP`Команда создает локальный журнал всех событий DDL/DML в основном кластере. `LOAD`Команда является подходом к отложенному копированию метаданных и данных, регистрируемых в извлеченных выходных данных репликации, и выполняется в целевом кластере. `STATUS`Команда выполняется из целевого кластера, чтобы предоставить актуальный идентификатор события, который был успешно реплицирован последней нагрузкой репликации.

### <a name="set-replication-source"></a>Задать источник репликации

Перед началом работы с репликацией убедитесь, что база данных, которая должна быть реплицирована, задана в качестве источника репликации. Можно использовать команду, `DESC DATABASE EXTENDED <db_name>` чтобы определить, задан ли параметр `repl.source.for` с именем политики.

Если политика запланирована и `repl.source.for` параметр не задан, необходимо сначала задать этот параметр с помощью `ALTER DATABASE <db_name> SET DBPROPERTIES ('repl.source.for'='<policy_name>')` .

```sql
ALTER DATABASE tpcds_orc SET DBPROPERTIES ('repl.source.for'='replpolicy1') 
```

### <a name="dump-metadata-to-the-data-lake"></a>Дамп метаданных в Data Lake

`REPL DUMP [database name]. => location / event_id`Команда используется на этапе начальной загрузки для дампа соответствующих метаданных в Azure Data Lake Storage 2-го поколения. `event_id`Указывает минимальное событие, в которое помещаются соответствующие метаданные в Azure Data Lake Storage 2-го поколения. 
 
```sql
repl dump tpcds_orc; 
```
Выходные данные примера:

| dump_dir|last_repl_id
|-|-|
|/tmp/hive/repl/38896729-67d5-41b2-90dc-46eeed4c5dd0|2925|

### <a name="load-data-to-the-target-cluster"></a>Загрузка данных в целевой кластер

`REPL LOAD [database name] FROM [ location ] { WITH ( ‘key1’=‘value1’{, ‘key2’=‘value2’} ) }`Команда используется для загрузки данных в целевой кластер как для начальной загрузки, так и для добавочных фаз репликации. `[database name]`Может совпадать с источником или другим именем в целевом кластере. Объект `[location]` представляет расположение из выходных данных предыдущей `REPL DUMP` команды. Это означает, что целевой кластер должен иметь возможность взаимодействовать с исходным кластером. `WITH`Предложение было в основном добавлено для предотвращения перезапуска целевого кластера, что позволяет выполнять репликацию.

```sql
repl load tpcds_orc from '/tmp/hive/repl/38896729-67d5-41b2-90dc-46eeed4c5dd0'; 
```

### <a name="output-the-last-replicated-event-id"></a>Вывод последнего реплицированного события с ИД

`REPL STATUS [database name]`Команда выполняется в целевых кластерах и выводит последнюю реплицированную реплику `event_id` . Команда также позволяет пользователям узнать состояние репликации целевого кластера. Выходные данные этой команды можно использовать для создания следующей `REPL DUMP` команды для добавочной репликации.

```sql
repl status tpcds_orc;
```

Выходные данные примера:

|last_repl_id|
|-|
|2925|

### <a name="dump-relevant-data-and-metadata-to-the-data-lake"></a>Дамп релевантных данных и метаданных в Data Lake

`REPL DUMP [database name] FROM [event-id] { TO [event-id] } { LIMIT [number of events] }`Команда используется для дампа соответствующих метаданных и данных в Azure Data Lake Storage. Эта команда используется на этапе добавочного выполнения и выполняется в исходном хранилище. Параметр `FROM [event-id]` необходим для инкрементной фазы, а значение `event-id` может быть получено путем выполнения `REPL STATUS [database name]` команды в целевом хранилище.

```sql
repl dump tpcds_orc from 2925;
```

Выходные данные примера:

|dump_dir|last_repl_id|
|-|-|
| /tmp/hive/repl/38896729-67d5-41b2-90dc-466466agadd0 | 2960|

## <a name="hive-replication-process"></a>Процесс репликации Hive

Следующие шаги являются последовательными событиями, происходящими во время репликации Hive.

1. Убедитесь, что таблицы для репликации заданы в качестве источника репликации для определенной политики.

1. `REPL_DUMP`Команда выдается основному кластеру с соответствующими ограничениями, такими как имя базы данных, диапазон идентификаторов событий и URL-адрес хранилища Azure Data Lake Storage 2-го поколения.

1. Система сериализует дамп всех отслеживаний событий от хранилище метаданных до последней. Этот дамп хранится в учетной записи хранения Azure Data Lake Storage 2-го поколения в основном кластере по URL-адресу, указанному параметром `REPL_DUMP` .  

1. Основной кластер сохраняет метаданные репликации в хранилище Azure Data Lake Storage 2-го поколения основного кластера. Путь можно настроить в пользовательском интерфейсе настройки Hive в Ambari. Процесс предоставляет путь, по которому хранятся метаданные, и идентификатор последнего отслеживающего события DML/DDL.

1. `REPL_LOAD`Команда выдается из дополнительного кластера. Команда указывает путь, настроенный на шаге 3.

1. Дополнительный кластер считывает файл метаданных с отслеживающими событиями, созданными на шаге 3. Убедитесь, что дополнительный кластер имеет сетевое подключение к Azure Data Lake Storage 2-го поколенияному хранилищу основного кластера, в котором хранятся отслеживание событий `REPL_DUMP` .  

1. Вторичный кластер порождает распределенное копирование ( `DistCP` ) вычислений.

1. Вторичный кластер копирует данные из хранилища основного кластера.  

1. Хранилище метаданных в дополнительном кластере обновляется.  

1. Последний записанный ИД события хранится в первичной хранилище метаданных.

Добавочная репликация выполняется таким же образом и требует наличия последнего реплицированного события в качестве входных данных. Это приводит к добавочному копированию с момента последнего события репликации. Добавочные репликации обычно автоматизируются с предварительно определенной частотой для достижения требуемых целей точки восстановления (RPO).

:::image type="content" source="media/apache-hive-replication/hive-replication-diagram.png" alt-text="Схема репликации Hive":::

## <a name="replication-patterns"></a>Шаблоны репликации  

Репликация обычно настраивается однонаправленным способом между первичной и вторичной репликой, где основная подсчитывает запросы на чтение и запись. Дополнительный кластер предназначен только для запросов на чтение. Операции записи разрешены на сервере-получателе в случае аварии, но обратная репликация должна быть настроена обратно в базу данных-источник.

:::image type="content" source="media/apache-hive-replication/replication-pattern.png" alt-text="Шаблон репликации Hive":::

Для репликации Hive доступно множество шаблонов, в том числе первичная — вторичная, Центральная и резервная.

В HDInsight Активный первичный — резервный вторичный сервер — это распространенный шаблон непрерывности бизнес-процессов и аварийного восстановления (BCDR), и HiveReplicationV2 может использовать этот шаблон с разделенными по регионам кластерами HDInsight Hadoop с пирингом виртуальной сети. Для размещения скриптов автоматизации репликации можно использовать общую виртуальную машину для обоих кластеров. Дополнительные сведения о возможных шаблонах BCDR HDInsight см. в [документации по обеспечению непрерывности бизнес-процессов hdinsight](../hdinsight-business-continuity.md).  

### <a name="hive-replication-with-enterprise-security-package"></a>Репликация Hive с Корпоративный пакет безопасности  

В случаях, когда репликация Hive планируется в кластерах HDInsight Hadoop с Корпоративный пакет безопасности, необходимо учитывать механизмы репликации для Ranger хранилище метаданных и доменных служб Azure Active Directory (AD DS).  

Используйте функцию "Наборы реплик AD DS Azure", чтобы создать несколько наборов реплик Azure AD DS для каждого клиента Azure AD в нескольких регионах. Каждый отдельный набор реплик должен быть соединен с HDInsight виртуальных сетей в соответствующих регионах. В этой конфигурации изменения AD DS Azure, включая конфигурацию, удостоверение пользователя и учетные данные, группы, объекты групповой политики, объекты компьютеров и другие изменения, применяются ко всем наборам реплик в управляемом домене с помощью репликации Azure AD DS.
  
Политики Ranger можно периодически архивировать и реплицировать из базы данных-источника в базу данных-получателя с помощью функций Ranger Import-Export. Вы можете выбрать репликацию всех или подмножества политик Ranger в зависимости от уровня авторизации, которую вы хотите реализовать в дополнительном кластере.  

## <a name="sample-code"></a>Образец кода  

В следующей последовательности кода приведен пример того, как можно реализовать начальную и добавочную репликацию для образца таблицы с именем `tpcds_orc` .  

1. Задайте таблицу в качестве источника для политики репликации.

   ```sql
   ALTER DATABASE tpcds_orc SET DBPROPERTIES ('repl.source.   for'='replpolicy1');
   ```

1. Дамп начальной загрузки в основном кластере.

   ```sql
   repl dump tpcds_orc with ('hive.repl.rootdir'='/tmpag/hiveag/replag'); 
   ```
   
   Выходные данные примера:
   
   |dump_dir|last_repl_id|
   |-|-|
   |/tmpag/hiveag/replag/675d1bea-2361-4cad-bcbf-8680d305a27a|2925|
 
1. Загрузка начальной загрузки в дополнительном кластере. 

   ```sql
   repl load tpcds_orc from '/tmpag/hiveag/replag 675d1bea-2361-4cad-bcbf-8680d305a27a'; 
   ```

1. Проверьте `REPL` состояние во вторичном кластере.

   ```sql
   repl status tpcds_orc; 
   ```
 
   |last_repl_id|
   |-|
   |2925|

1. Добавочный дамп в основном кластере.

   ```sql
   repl dump tpcds_orc from 2925 with ('hive.repl.rootdir'='/tmpag/hiveag/ replag');
   ```

   Выходные данные примера:
   
   |dump_dir | last_repl_id|
   |-|-|
   |/tmpag/hiveag/replag/31177ff7-a40f-4f67-a613-3b64ebe3bb31|2960|

1. Добавочная загрузка в дополнительном кластере.  

   ```sql
   repl load tpcds_orc from '/tmpag/hiveag/replag/31177ff7-a40f-4f67-a613-3b64ebe3bb31';
   ```

1. Проверьте `REPL` состояние во вторичном кластере.

   ```sql
   repl status tpcds_orc;
   ```

   |last_repl_id|
   |-|
   |2960|

## <a name="next-steps"></a>Дальнейшие действия

Дополнительные сведения об элементах, обсуждаемых в этой статье, см. в следующих статьях:

- [Непрерывность бизнес-процессов Azure HDInsight](../hdinsight-business-continuity.md)
- [Архитектура обеспечения непрерывности бизнес-процессов Azure HDInsight](../hdinsight-business-continuity-architecture.md)
- [Пример использования архитектуры высокодоступного решения Azure HDInsight](../hdinsight-high-availability-case-study.md)
- [Обзор Apache Hive и HiveQL в Azure HDInsight](../hadoop/hdinsight-use-hive.md)