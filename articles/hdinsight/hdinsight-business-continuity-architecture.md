---
title: Архитектура обеспечения непрерывности бизнес-процессов Azure HDInsight
description: В этой статье обсуждаются различные возможные архитектуры обеспечения непрерывности бизнес-процессов для HDInsight.
keywords: Высокая доступность Hadoop
ms.service: hdinsight
ms.topic: conceptual
ms.date: 10/07/2020
ms.openlocfilehash: f74309370f1489714013344116e7feb9551fbfd5
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98933443"
---
# <a name="azure-hdinsight-business-continuity-architectures"></a>Архитектура обеспечения непрерывности бизнес-процессов Azure HDInsight

В этой статье приводится несколько примеров архитектуры обеспечения непрерывности бизнес-процессов, которые можно использовать для Azure HDInsight. Допуск к ограниченной функциональности во время аварии — это бизнес-решение, которое меняется от одного приложения к другому. Некоторые приложения могут быть недоступными или частично доступными с ограниченной функциональностью или отложенной обработкой за период. Для других приложений любая ограниченная функциональность может быть неприемлемой.

> [!NOTE]
> Архитектуры, представленные в этой статье, не являются исчерпывающими. Вы должны спроектировать собственные уникальные архитектуры после того, как вы предоставили целевые определения для обеспечения непрерывности бизнеса, сложности и стоимости владения.

## <a name="apache-hive-and-interactive-query"></a>Apache Hive и интерактивный запрос

Для обеспечения непрерывности бизнес-процессов в кластерах HDInsight и интерактивных запросов рекомендуется использовать [репликацию Hive версии 2](https://cwiki.apache.org/confluence/display/Hive/HiveReplicationv2Development#HiveReplicationv2Development-REPLSTATUS) . Постоянные разделы кластера автономных кустов, которые необходимо реплицировать, — это уровень хранилища и хранилище метаданных Hive. Кластеры Hive в сценарии с несколькими пользователями с Корпоративный пакет безопасности необходимы Azure Active Directory доменных служб и Ranger хранилище метаданных.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/hive-interactive-query.png" alt-text="Архитектура Hive и интерактивных запросов":::

Репликация на основе событий Hive настраивается между основным и дополнительным кластерами. Это состоит из двух отдельных фаз: начальная загрузка и добавочные запуски.

* Начальная загрузка реплицирует весь хранилище Hive, включая сведения о хранилище метаданных Hive от первичной до вторичной.

* Добавочные запуски выполняются автоматически в основном кластере, а события, созданные во время добавочных запусков, воспроизводятся в дополнительном кластере. Дополнительный кластер перехватывает события, созданные на основе основного кластера, гарантируя, что вторичный кластер будет соответствовать событиям основного кластера после выполнения репликации.

Вторичный кластер необходим только во время репликации для выполнения распределенной копии, `DistCp` но хранилище и метахранилища должны быть постоянными. Можно выбрать запуск сценария вторичного кластера по запросу перед репликацией, запустить на нем сценарий репликации, а затем удалить его после успешной репликации.

Вторичный кластер обычно доступен только для чтения. Вторичный кластер может быть доступен для чтения и записи, но это добавляет дополнительную сложность, включающую репликацию изменений из вторичного кластера в основной.

### <a name="hive-event-based-replication-rpo--rto"></a>RPO & RTO репликации на основе событий Hive

* RPO: потери данных ограничиваются Последнее успешное событие добавочной репликации с первичной на вторичную.

* RTO — время между сбоем и возобновлением вышестоящей и подчиненной транзакций с базой данных-получателем.

### <a name="apache-hive-and-interactive-query-architectures"></a>Apache Hive и интерактивные архитектуры запросов

#### <a name="hive-active-primary-with-on-demand-secondary"></a>Активный первичный раздел Hive с вторичным сервером по запросу

В *активном первичном экземпляре с вторичной* архитектурой по запросу приложения записываются в активный основной регион, а кластер не подготавливается в дополнительном регионе во время нормальной работы. SQL хранилище метаданных и хранилище в дополнительном регионе сохраняются, а кластер HDInsight создается и развертывается по требованию только до запуска запланированной репликации Hive.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/active-primary-on-demand-secondary.png" alt-text="Активный первичный сервер с вторичным сервером по запросу":::

#### <a name="hive-active-primary-with-standby-secondary"></a>Активный первичный куст Hive с резервной базой данных-получателем

В *активном первичном экземпляре с резервной базой данных-получателем* приложения записываются в активный основной регион, в то время как в режиме только для чтения во время нормальной работы будет запущен резервный кластер, масштабируемый до. Во время нормальной работы можно выбрать отправку отдельных операций чтения для дополнительного региона.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/active-primary-standby-secondary.png" alt-text="Активный первичный сервер с резервной базой данных-получателем":::

Дополнительные сведения о репликации Hive и примерах кода см. [в статье Apache Hive репликация в кластерах Azure HDInsight](./interactive-query/apache-hive-replication.md) .

## <a name="apache-spark"></a>Apache Spark

Рабочие нагрузки Spark могут не затрагивать компонент Hive. Чтобы рабочие нагрузки Spark SQL прочитали и записывали данные из Hive, кластеры HDInsight Spark совместно используют пользовательские метахранилища из Hive/Интерактивные кластеры запросов в том же регионе. В таких случаях Межрегиональная репликация рабочих нагрузок Spark должна также сопровождаться репликацией метахранилища и хранилища Hive. Сценарии отработки отказа в этом разделе относятся к следующим:

* [Spark SQL для ТАБЛИЦ ACID, использующих установку соединителя хранилища Hive (HWC)](./interactive-query/apache-hive-warehouse-connector.md) с помощью кластера интерактивных запросов HDInsight.
* Рабочая нагрузка Spark SQL в таблицах без ACID с помощью кластера HDInsight Hadoop.

В сценариях, где Spark работает в автономном режиме, проверенные данные и хранимые Jarи Spark (для заданий Livy) должны быть регулярно реплицированы из основного региона в дополнительный, используя фабрику данных Azure `DistCP` .

Мы рекомендуем использовать системы управления версиями для хранения записных книжек и библиотек Spark, где их можно легко развернуть на первичных или вторичных кластерах. Убедитесь, что решения на основе ноутбуков и других ноутбуков готовы к загрузке правильных подключений к данным в основной или дополнительной рабочей области.

Если существуют библиотеки, относящиеся к клиентам, которые выходят за рамки того, что HDInsight предоставляет изначально, они должны быть записаны и периодически загружены в резервный вторичный кластер.  

### <a name="apache-spark-replication-rpo--rto"></a>Apache Spark RPO репликации & RTO

* RPO: потери данных ограничены последней успешной добавочной репликацией (Spark и Hive) с первичной на вторичную.

* RTO — время между сбоем и возобновлением вышестоящей и подчиненной транзакций с базой данных-получателем.

### <a name="apache-spark-architectures"></a>Архитектуры Apache Spark

#### <a name="spark-active-primary-with-on-demand-secondary"></a>Активная первичная база данных Spark с вторичным сервером по запросу

Приложения считывают и записывают в кластеры Spark и Hive в основном регионе, в то время как при нормальных операциях кластеры не подготавливаются в дополнительном регионе. SQL хранилище метаданных, хранилище Hive и хранилище Spark являются постоянными в дополнительном регионе. Кластеры Spark и Hive записываются в скрипт и развертываются по требованию. Репликация Hive используется для репликации хранилища Hive и метахранилища Hive, в то время как фабрика данных Azure `DistCP` может использоваться для копирования автономного хранилища Spark. Кластеры Hive необходимо развернуть перед каждым запуском репликации Hive из-за `DistCp` вычислений зависимостей.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/active-primary-on-demand-secondary-spark.png" alt-text="Активный первичный сервер с архитектурой вторичного Apache Spark по запросу":::

#### <a name="spark-active-primary-with-standby-secondary"></a>Основной первичный сервер Spark с резервной базой данных-получателем

Приложения считывают и выполняют запись в кластерах Spark и Hive в основном регионе, в то время как кластеры Hive и Spark в режиме только для чтения выполняются в дополнительном регионе во время нормальной работы. Во время нормальной работы можно выбрать отправку отдельных кустов Hive и операций чтения Spark на сервер-получатель.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/active-primary-standby-secondary-spark.png" alt-text="Активная первичная вторичная резервная Apache Spark ":::

## <a name="apache-hbase"></a>Apache HBase

Репликация по экспорту HBase и HBase — это распространенные способы обеспечения непрерывности бизнес-процессов между кластерами HDInsight HBase.

Экспорт HBase — это процесс пакетной репликации, использующий программу экспорта HBase для экспорта таблиц из основного кластера HBase в базовое хранилище Azure Data Lake Storage поколения 2. Затем экспортированные данные можно получить из дополнительного кластера HBase и импортировать в таблицы, которые должны существовать в базе данных-получателе. Хотя при экспорте HBase обеспечивается гранулярность уровня таблицы, в ситуациях добавочного обновления модуль автоматизации экспорта управляет диапазоном добавочных строк, включаемых в каждый запуск. Дополнительные сведения см. в статье [резервное копирование и репликация HDInsight HBase](./hbase/apache-hbase-backup-replication.md#export-then-import).

Репликация HBase использует репликацию почти в реальном времени между кластерами HBase полностью автоматизированным способом. Репликация выполняется на уровне таблицы. Для репликации можно ориентироваться либо на все таблицы, либо на отдельные таблицы. Репликация HBase в конечном итоге согласуется, а это означает, что последние изменения в таблице в основном регионе могут быть недоступны для всех баз данных-получателей немедленно. Базы данных-получатели, в конечном итоге, будут согласованы с базой данных-источником. Репликацию HBase можно настроить между двумя или несколькими кластерами HDInsight HBase, если:

* Первичная и вторичная реплики находятся в одной виртуальной сети.
* Основной и дополнительный серверы находятся в разных одноранговых виртуальных сетей в одном регионе.
* Основной и дополнительный узлы находятся в разных виртуальных сетей в разных регионах.

Дополнительные сведения см. [в статье Настройка репликации кластера Apache HBase в виртуальных сетях Azure](./hbase/apache-hbase-replication.md).

Существует несколько других способов выполнения резервного копирования кластеров HBase, таких как [копирование папки HBase](./hbase/apache-hbase-backup-replication.md#copy-the-hbase-folder), [копирование таблиц](./hbase/apache-hbase-backup-replication.md#copy-tables) и [моментальных снимков](./hbase/apache-hbase-backup-replication.md#snapshots).

### <a name="hbase-rpo--rto"></a>ЦЕЛЕВая точка HBase & RTO

#### <a name="hbase-export"></a>Экспорт HBase

* RPO: потери данных ограничены последним успешным добавочным импортом пакета из первичной реплики.
* RTO: время между сбоями основного и возобновления операций ввода-вывода на вторичном сервере.

#### <a name="hbase-replication"></a>Репликация HBase

* RPO: потери данных ограничены последней отгрузкой Валедит, полученной на сервере-получателе.
* RTO: время между сбоями основного и возобновления операций ввода-вывода на вторичном сервере.

### <a name="hbase-architectures"></a>Архитектуры HBase

Репликацию HBase можно настроить в трех режимах: "ведущий", "Leader-Leader" и "циклический".

#### <a name="hbase-replication--leader--follower-model"></a>Репликация HBase: лидер — модель-след

В этой перекрестной области репликация выполняется с однонаправленной обратной стороной от основного региона к дополнительному региону. Для однонаправленной репликации можно определить либо все таблицы, либо отдельные таблицы в первичной реплике. Во время нормальной работы можно использовать вторичный кластер для обслуживания запросов чтения в своем собственном регионе.

Дополнительный кластер работает как стандартный кластер HBase, который может размещать собственные таблицы и может обслуживать операции чтения и записи из региональных приложений. Однако операции записи в реплицированные таблицы или таблицы, которые являются собственными для базы данных-получателя, не реплицируются обратно в базу данных-источник.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/hbase-leader-follower.png" alt-text="Модель следов по лидерам HBase":::

#### <a name="hbase-replication--leader--leader-model"></a>Репликация HBase: лидер — модель лидера

Эта настройка между регионами очень похожа на установленную однонаправленную установку, за исключением того, что репликация между основным регионом и дополнительным регионом выполняется в двунаправленном состоянии. Приложения могут использовать оба кластера в режиме Read-Write, а обновления — асинхронный обмен между ними.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/hbase-leader-leader.png" alt-text="Модель лидера лидера HBase":::

#### <a name="hbase-replication-multi-region-or-cyclic"></a>Репликация HBase: несколько регионов или циклическая

Модель многоязыковой или циклической репликации является расширением репликации HBase и может использоваться для создания глобально избыточной архитектуры HBase с несколькими приложениями, которые считывают и записывают в отдельные кластеры HBase. Кластеры можно настроить в различных сочетаниях лидера/лидера или лидера/следов в зависимости от бизнес-требований.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/hbase-cyclic.png" alt-text="Циклическая модель HBase":::

## <a name="apache-kafka"></a>Apache Kafka

Чтобы включить доступность между регионами, HDInsight 4,0 поддерживает Kafka MirrorMaker, которые можно использовать для поддержки вторичной реплики основного кластера Kafka в другом регионе. MirrorMaker выступает в качестве пары "потребитель-производитель" высокого уровня, принимает от определенного раздела в основном кластере и создает раздел с тем же именем в базе-получателе. Межкластерная репликация для аварийного восстановления высокого уровня доступности с помощью MirrorMaker поставляется с предположением о том, что производители и потребители должны выполнить отработку отказа в кластере реплик. Дополнительные сведения см. [в статье Использование MirrorMaker для репликации Apache Kafka разделов с помощью Kafka в HDInsight](./kafka/apache-kafka-mirroring.md) .

В зависимости от раздела время существования репликации MirrorMaker раздел Репликация может привести к различным смещениям между разделами источника и реплики. Кластеры HDInsight Kafka также поддерживают репликацию секций разделов, которая является функцией высокого уровня доступности на уровне отдельного кластера.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/kafka-replication.png" alt-text="Репликация Apache Kafka":::

### <a name="apache-kafka-architectures"></a>Архитектуры Apache Kafka

#### <a name="kafka-replication-active--passive"></a>Репликация Kafka: активная — пассивный

Программа установки Active-Passive позволяет асинхронно однонаправленное зеркальное отображение от активного к пассивному. Производителям и потребителям необходимо знать о существовании активного и пассивного кластера, и они должны быть готовы к отработку отказа в пассивный режим в случае сбоя активного. Ниже приведены некоторые преимущества и недостатки установки Active-Passive.

Преимущества:

* Задержка в сети между кластерами не влияет на производительность активного кластера.
* Простота однонаправленной репликации.

Недостатки:

* Пассивный кластер может оставаться недостаточным.
* Сложность проектирования при внедрении поддержки отработки отказа в производителях и потребителях приложений.
* Возможная потери данных во время сбоя активного кластера.
* Окончательная согласованность между разделами между активными и пассивными кластерами.
* Тестовое to PRIMARY может привести к несогласованности сообщений в разделах.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/kafka-active-passive.png" alt-text="Активная пассивная модель Apache Kafka":::

#### <a name="kafka-replication-active--active"></a>Репликация Kafka: активная — активна

Active-Active Настройка включает два разделенных по регионам кластера HDInsight Kafka с поддержкой двунаправленной асинхронной репликации с помощью MirrorMaker. В этой структуре сообщения, используемые потребителями в базе данных-источнике, также становятся доступными для потребителей во вторичном и наоборот. Ниже приведены некоторые преимущества и недостатки установки Active-Active.

Преимущества:

* Из-за дублирования состояния отработки отказа и тестовое проще выполнять.

Недостатки:

* Настройка, управление и мониторинг более сложны, чем активные-пассивные.
* Проблема, связанная с циклической репликацией, должна быть решена.  
* Двунаправленная репликация ведет к более высокому региону для исходящего трафика данных.

:::image type="content" source="./media/hdinsight-business-continuity-architecture/kafka-active-active.png" alt-text="Активная активная модель Apache Kafka":::

## <a name="hdinsight-enterprise-security-package"></a>Корпоративный пакет безопасности HDInsight

Эта настройка используется для включения многопользовательского функционирования как на основном, так и на вторичном уровне, а также в [Azure AD DS наборы реплик](../active-directory-domain-services/tutorial-create-replica-set.md) , чтобы пользователи могли проходить проверку подлинности в обоих кластерах. Во время нормальной работы политики Ranger необходимо настроить в базе данных-получателе, чтобы пользователи могли только выполнять операции чтения. В приведенной ниже архитектуре объясняется, как может выглядеть протокол ESP, Активный первичный — резервная вторичная база данных.

Репликация Ranger хранилище метаданных:

Ranger хранилище метаданных используется для постоянного хранения и обслуживания политик Ranger для управления авторизацией данных. Рекомендуется поддерживать независимые политики Ranger в первичной и вторичной репликах, а также поддерживать базу данных-получатель в качестве репликации для чтения.
  
Если требуется, чтобы политики Ranger были синхронизированы между первичной и вторичной репликой, используйте [Ranger Import/Export](https://cwiki.apache.org/confluence/display/RANGER/User+Guide+For+Import-Export) для периодической архивации и импорта политик Ranger из базы данных-источника в базу данных-получателя.

Репликация политик Ranger между первичной и вторичной репликой может привести к тому, что база данных-получатель станет доступной для записи, что может привести к непреднамеренному выполнению операций записи во вторичной базе данных.  

:::image type="content" source="./media/hdinsight-business-continuity-architecture/hdinsight-enterprise-security-package.png" alt-text="Архитектура HDInsight Корпоративный пакет безопасности":::

## <a name="next-steps"></a>Дальнейшие действия

Дополнительные сведения об элементах, обсуждаемых в этой статье, см. в следующих статьях:

* [Непрерывность бизнес-процессов Azure HDInsight](./hdinsight-business-continuity.md)
* [Пример использования архитектуры высокодоступного решения Azure HDInsight](./hdinsight-high-availability-case-study.md)
* [Обзор Apache Hive и HiveQL в Azure HDInsight](./hadoop/hdinsight-use-hive.md)