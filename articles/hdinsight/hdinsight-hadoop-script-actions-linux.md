---
title: Разработка действий сценария для настройки кластеров Azure HDInsight
description: Узнайте, как использовать Bash scripts для настройки кластеров HDInsight. Действия сценария позволяют запускать скрипты во время или после создания кластера для изменения параметров конфигурации кластера или установки дополнительного программного обеспечения.
ms.service: hdinsight
ms.topic: how-to
ms.date: 11/28/2019
ms.openlocfilehash: b6705728fddc9a5a3c9cb8eb2f1811412fb3a290
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98945476"
---
# <a name="script-action-development-with-hdinsight"></a>Разработка действий сценариев с помощью HDInsight

Узнайте, как настроить кластер HDInsight с помощью сценариев Bash. Действия сценариев предназначены для настройки HDInsight во время или после создания кластера.

## <a name="what-are-script-actions"></a>Что такое действия сценариев?

Действия сценариев — это сценарии Bash, которые Azure выполняет на узлах кластера, чтобы вносить изменения в конфигурацию или устанавливать программное обеспечение. Действие сценария выполняется от имени привилегированного пользователя и предоставляет права полного доступа к узлам кластера.

Действия сценариев могут применяться следующими способами:

| Этот метод используется для применения сценария… | При создании кластера… | В работающем кластере… |
| --- |:---:|:---:|
| Портал Azure |✓ |✓ |
| Azure PowerShell |✓ |✓ |
| Классический Azure CLI |&nbsp; |✓ |
| Пакет SDK для HDInsight .NET |✓ |✓ |
| Шаблон Azure Resource Manager |✓ |&nbsp; |

Дополнительные сведения об использовании этих методов см. в статье [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md).

## <a name="best-practices-for-script-development"></a><a name="bestPracticeScripting"></a>Рекомендации по разработке скриптов

При разработке пользовательского сценария для кластера HDInsight следует иметь в виду некоторые рекомендации.

* [Выбор целевой версии Apache Hadoop](#bPS1)
* [Выбор версии ОС](#bps10)
* [Стабильные ссылки на ресурсы скрипта](#bPS2)
* [Использование предварительно скомпилированных ресурсов](#bPS4)
* [Обеспечение идемпотентности сценария настройки кластера](#bPS3)
* [Обеспечение высокого уровня доступности кластера](#bPS5)
* [Настройка пользовательских компонентов для использования хранилища BLOB-объектов Azure](#bPS6)
* [Запись информации в STDOUT и STDERR](#bPS7)
* [Сохранение файлов в формате ASCII с использованием LF в качестве символа завершения строки](#bps8)
* [Использование логики повтора для восстановления после временных ошибок](#bps9)

> [!IMPORTANT]  
> Действия сценария должны завершиться в течение 60 минут. В противном случае процесс завершиться ошибкой. Во время подготовки узла данный сценарий выполняется одновременно с другими процессами установки и настройки. Конкуренция за ресурсы, такие как ЦП или пропускная способность сети, может привести к затягиванию выполнения сценария по сравнению со временем его выполнения в среде разработки.

### <a name="target-the-apache-hadoop-version"></a><a name="bPS1"></a>Выбор целевой версии Apache Hadoop

В различных версиях HDInsight используются различные версии служб Hadoop и компонентов. Если сценарий предполагает наличие определенной версии службы или компонента, то такой сценарий следует использовать только с версией HDInsight, включающей необходимые компоненты. Сведения о версиях компонентов, включенных в HDInsight, можно найти в документе [Версии компонентов HDInsight](hdinsight-component-versioning.md) .

### <a name="checking-the-operating-system-version"></a>Проверка версии операционной системы

Для разных версий HDInsight используются конкретные версии Ubuntu. В сценарии следует проверить различия между версиями ОС. Например, может потребоваться установить двоичный файл, привязанный к версии Ubuntu.

Чтобы проверить версию операционной системы, используйте `lsb_release`. Например, ниже показано, как создать ссылку на конкретный TAR-файл в зависимости от версии операционной системы:

```bash
OS_VERSION=$(lsb_release -sr)
if [[ $OS_VERSION == 14* ]]; then
    echo "OS version is $OS_VERSION. Using hue-binaries-14-04."
    HUE_TARFILE=hue-binaries-14-04.tgz
elif [[ $OS_VERSION == 16* ]]; then
    echo "OS version is $OS_VERSION. Using hue-binaries-16-04."
    HUE_TARFILE=hue-binaries-16-04.tgz
fi
```

### <a name="target-the-operating-system-version"></a><a name="bps10"></a> Целевая версия операционной системы

HDInsight основывается на распределении Ubuntu Linux. Для разных версий HDInsight используются разные версии Ubuntu. Это может изменить поведение сценария. Например, HDInsight версии 3.4 и более ранних версий основан на версии Ubuntu, в которой используется Upstart. Версия 3.5 и более поздние версии основана на Ubuntu версии 16.04, в которой используется Systemd. Systemd и Upstart используют разные команды, поэтому сценарий нужно написать таким образом, чтобы он был совместим и с тем, и с другим.

Еще одно важное различие между HDInsight версии 3.4 и 3.5 заключается в том, что теперь `JAVA_HOME` указывает на Java 8. В следующем коде показано, как определить версию Ubuntu (14 или 16), в которой выполняется сценарий:

```bash
OS_VERSION=$(lsb_release -sr)
if [[ $OS_VERSION == 14* ]]; then
    echo "OS version is $OS_VERSION. Using hue-binaries-14-04."
    HUE_TARFILE=hue-binaries-14-04.tgz
elif [[ $OS_VERSION == 16* ]]; then
    echo "OS version is $OS_VERSION. Using hue-binaries-16-04."
    HUE_TARFILE=hue-binaries-16-04.tgz
fi
...
if [[ $OS_VERSION == 16* ]]; then
    echo "Using systemd configuration"
    systemctl daemon-reload
    systemctl stop webwasb.service    
    systemctl start webwasb.service
else
    echo "Using upstart configuration"
    initctl reload-configuration
    stop webwasb
    start webwasb
fi
...
if [[ $OS_VERSION == 14* ]]; then
    export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
elif [[ $OS_VERSION == 16* ]]; then
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
fi
```

Полный скрипт, который содержит эти фрагменты кода, находится здесь: https://hdiconfigactions.blob.core.windows.net/linuxhueconfigactionv02/install-hue-uber-v02.sh.

Сведения о версии Ubuntu, используемой в HDInsight, см. в документе [HDInsight component version](hdinsight-component-versioning.md) (Версия компонента HDInsight).

Сведения о различиях между Systemd и Upstart см. в статье [Systemd for Upstart users](https://wiki.ubuntu.com/SystemdForUpstartUsers) (Systemd для пользователей Upstart).

### <a name="provide-stable-links-to-script-resources"></a><a name="bPS2"></a>Стабильные ссылки на ресурсы скрипта

Сценарии и связанные ресурсы должны оставаться доступными на протяжении жизненного цикла кластера. Эти ресурсы необходимы, если во время операций масштабирования в кластер добавляются новые узлы.

Мы советуем скачивать и архивировать все данные в свою учетную запись хранения Azure.

> [!IMPORTANT]  
> Используемая учетная запись хранения должна быть учетной записью хранения по умолчанию для кластера или общедоступным и открытым только для чтения контейнером в другой учетной записи хранения.

Например, примеры, предоставляемые корпорацией Майкрософт, хранятся в [https://hdiconfigactions.blob.core.windows.net/](https://hdiconfigactions.blob.core.windows.net/) учетной записи хранения. Это открытый и доступный только для чтения контейнер, который поддерживает команда HDInsight.

### <a name="use-pre-compiled-resources"></a><a name="bPS4"></a>Использование предварительно скомпилированных ресурсов

Чтобы сократить время выполнения сценария, избегайте операций, компилирующих ресурсы из исходного кода. Например, заранее скомпилируйте и сохраните ресурсы в BLOB-объекте учетной записи хранения Azure в том же центре обработки данных, что и кластер HDInsight.

### <a name="ensure-that-the-cluster-customization-script-is-idempotent"></a><a name="bPS3"></a>Обеспечение идемпотентности сценария настройки кластера

Сценарии должны быть идемпотентными. Имеется в виду, что при многократном выполнении в каждом случае сценарий должен обеспечивать возврат кластера к одному и тому же состоянию.

Например, скрипт, изменяющий файлы конфигурации, не должен добавлять дублирующиеся записи, если они выполнялись несколько раз.

### <a name="ensure-high-availability-of-the-cluster-architecture"></a><a name="bPS5"></a>Обеспечение высокого уровня доступности кластера

В кластерах HDInsight под управлением Linux есть два головных узла, активных в пределах кластера. Действия сценария выполняются на обоих узлах. Если устанавливаемые компоненты предполагают только один головной узел, не устанавливайте компоненты на обоих головных узлах.

> [!IMPORTANT]  
> Службы, устанавливаемые вместе с HDInsight, выполняют отработку отказа между двумя узлами. Эта функциональность не распространяется на пользовательские компоненты, устанавливаемые при выполнении действий сценария. Если требуется высокий уровень доступности пользовательских компонентов, необходимо реализовать собственный механизм отработки отказа.

### <a name="configure-the-custom-components-to-use-azure-blob-storage"></a><a name="bPS6"></a>Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure

Компоненты, устанавливаемые на кластере, могут по умолчанию использовать хранилище распределенной файловой системы (HDFS) Apache Hadoop. В качестве хранилища по умолчанию HDInsight использует хранилище Azure или Data Lake Storage. Это обеспечивает совместимую с HDFS файловую систему, которая сохраняет данные даже после удаления кластера. Может потребоваться настроить устанавливаемые компоненты для использования WASB или ADL вместо HDFS.

Для большинства операций указывать файловую систему не требуется. Например, следующая копия файла хадуп-Коммон. jar копируется из локальной файловой системы в хранилище кластера:

```bash
hdfs dfs -put /usr/hdp/current/hadoop-client/hadoop-common.jar /example/jars/
```

В этом примере команда `hdfs` прозрачно использует хранилище кластера по умолчанию. Для некоторых операций может потребоваться указать URI. Например `adl:///example/jars` для Azure Data Lake Storage 1-го поколения, `abfs:///example/jars` Azure Data Lake Storage 2-го поколения или `wasb:///example/jars` для службы хранилища Azure.

### <a name="write-information-to-stdout-and-stderr"></a><a name="bPS7"></a>Запись информации в STDOUT и STDERR

HDInsight заносит в журнал выходные данные сценария, которые записываются в поток STDOUT и STDERR. Эти данные можно просмотреть с помощью веб-интерфейса Ambari.

> [!NOTE]  
> Веб-интерфейс Apache Ambari доступен, только если кластер успешно создан. Если во время создания кластера используется действие сценария и происходит сбой создания, см. раздел [Устранение неполадок в действиях сценария](./troubleshoot-script-action.md) для других способов доступа к информации в журнале.

Большинство программ и пакетов установки добавляют данные в STDOUT и STDERR по умолчанию, однако вам может потребоваться добавить дополнительные записи в журнал. Для отправки текста в STDOUT используйте `echo`. Пример:

```bash
echo "Getting ready to install Foo"
```

По умолчанию ключевое слово `echo` отправляет строку в STDOUT. Чтобы направить строку в STDERR, добавьте `>&2` перед `echo`. Пример:

```bash
>&2 echo "An error occurred installing Foo"
```

Информация, записываемая в STDOUT, перенаправляется STDERR (2). Дополнительные сведения о перенаправлении операций ввода-вывода см [https://www.tldp.org/LDP/abs/html/io-redirection.html](https://www.tldp.org/LDP/abs/html/io-redirection.html) . в разделе.

Дополнительные сведения о просмотре сведений, регистрируемых действиями скрипта, см. в разделе [Устранение неполадок в сценариях](./troubleshoot-script-action.md).

### <a name="save-files-as-ascii-with-lf-line-endings"></a><a name="bps8"></a> Сохранять файлы в формате ASCII с символами перевода строки (LF)

Сценарии Bash должны храниться в формате ASCII. Для завершения строк в этом файле используется символ LF. Если в файлах используется кодировка UTF-8 или используется CRLF в качестве конца строки, сценарий может завершиться следующей ошибкой:

```
$'\r': command not found
line 1: #!/usr/bin/env: No such file or directory
```

### <a name="use-retry-logic-to-recover-from-transient-errors"></a><a name="bps9"></a> Использование логики повторных попыток для восстановления после временных ошибок

При загрузке файлов, установке пакетов с помощью apt-get или других действий, передающих данные через Интернет, действие может завершиться ошибкой из-за временных ошибок сети. Например, удаленный ресурс, с которым вы обмениваетесь данными, может находиться в процессе отработки отказа на узел резервного копирования.

Чтобы сделать свой сценарий устойчивым к временным ошибкам, можно реализовать логику повтора. Приведенная ниже функция демонстрирует реализацию логику повтора. Она повторяет операцию три раза до сбоя.

```bash
#retry
MAXATTEMPTS=3

retry() {
    local -r CMD="$@"
    local -i ATTMEPTNUM=1
    local -i RETRYINTERVAL=2

    until $CMD
    do
        if (( ATTMEPTNUM == MAXATTEMPTS ))
        then
                echo "Attempt $ATTMEPTNUM failed. no more attempts left."
                return 1
        else
                echo "Attempt $ATTMEPTNUM failed! Retrying in $RETRYINTERVAL seconds..."
                sleep $(( RETRYINTERVAL ))
                ATTMEPTNUM=$ATTMEPTNUM+1
        fi
    done
}
```

В следующих примерах показано, как использовать эту функцию.

```bash
retry ls -ltr foo

retry wget -O ./tmpfile.sh https://hdiconfigactions.blob.core.windows.net/linuxhueconfigactionv02/install-hue-uber-v02.sh
```

## <a name="helper-methods-for-custom-scripts"></a><a name="helpermethods"></a>Вспомогательные методы для пользовательских скриптов

Вспомогательные методы действий сценариев — это служебные программы, которые можно использовать при создании пользовательских сценариев. Эти методы содержатся в [https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh](https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh) скрипте. Чтобы скачать и использовать их как часть сценария, используйте следующую команду:

```bash
# Import the helper method module.
wget -O /tmp/HDInsightUtilities-v01.sh -q https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh && source /tmp/HDInsightUtilities-v01.sh && rm -f /tmp/HDInsightUtilities-v01.sh
```

Эта команда открывает доступ к следующим вспомогательным приложениям, доступным для использования в сценарии:

| Назначение вспомогательного приложения | Описание |
| --- | --- |
| `download_file SOURCEURL DESTFILEPATH [OVERWRITE]` |Скачивает файл из исходного универсального кода ресурса (URI) и сохраняет его в указанное расположение. По умолчанию существующий файл не перезаписывается. |
| `untar_file TARFILE DESTDIR` |Извлекает TAR-файл (с помощью `-xf`) в папку назначения. |
| `test_is_headnode` |Если сценарий выполнялся на головном узле кластера, возвращается значение 1; в противном случае — значение 0. |
| `test_is_datanode` |Если текущий узел является узлом данных (рабочим узлом), то возвращается значение 1, в противном случае — 0. |
| `test_is_first_datanode` |Если текущий узел является первым узлом данных (рабочим узлом с именем workernode0), возвращается значение 1, в противном случае — 0. |
| `get_headnodes` |Возвращает полное доменное имя головных узлов в кластере. Имена содержат разделители-запятые. При возникновении ошибки возвращается пустая строка. |
| `get_primary_headnode` |Возвращает полное доменное имя основного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_secondary_headnode` |Возвращает полное доменное имя дополнительного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_primary_headnode_number` |Возвращает числовой суффикс основного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_secondary_headnode_number` |Возвращает числовой суффикс дополнительного головного узла. При возникновении ошибки возвращается пустая строка. |

## <a name="common-usage-patterns"></a><a name="commonusage"></a>Общие шаблоны использования

В этом разделе содержится руководство по реализации некоторых общих вариантов использования, которые могут понадобиться при написании пользовательского сценария.

### <a name="passing-parameters-to-a-script"></a>Передача параметров в сценарий

В некоторых случаях для сценария требуется указывать параметры. Например, при использовании интерфейса Ambari REST API может потребоваться пароль администратора кластера.

Параметры, передаваемые в сценарий, называются *позиционными параметрами*, т. е. `$1` соответствует первому параметру, `$2` — второму и т.д. Значение `$0` содержит имя самого сценария.

Значения, передаваемые в сценарий в качестве параметров, должны быть заключены в одинарные кавычки ('). В этом случае переданное значение рассматривается как литерал.

### <a name="setting-environment-variables"></a>Настройка переменных среды

Настройка переменной среды выполняется следующим образом:

```bash
VARIABLENAME=value
```

В предыдущем примере `VARIABLENAME` — это имя переменной. Для доступа к переменной используйте `$VARIABLENAME`. Например, чтобы присвоить значение позиционного параметра переменной среды с именем PASSWORD, воспользуйтесь следующей инструкцией:

```bash
PASSWORD=$1
```

Для последующего доступа к данным используйте `$PASSWORD`.

Переменные среды, заданные в сценарии, существуют только в пределах области сценария. В некоторых случаях может потребоваться добавить переменные среды, которые значимы на уровне системы и значение которых сохранится после выполнения сценария. Чтобы добавить переменные среды уровня системы, добавьте переменную в `/etc/environment`. Например, следующий оператор добавляет `HADOOP_CONF_DIR`:

```bash
echo "HADOOP_CONF_DIR=/etc/hadoop/conf" | sudo tee -a /etc/environment
```

### <a name="access-to-locations-where-the-custom-scripts-are-stored"></a>Доступ к расположениям, в которых хранятся пользовательские сценарии

Сценарии, используемые для настройки кластера, должны храниться в одном из следующих расположений:

* __учетной записи хранения Azure__, связанной с кластером;

* __дополнительной учетной записи хранения__, связанной с кластером;

* __ресурсе с общедоступным URI__. Например, URL-адрес к данным, хранящимся в OneDrive, Dropbox или других службах размещения файлов.

* __Учетная запись Azure Data Lake Storage__, связанная с кластером HDInsight. Дополнительные сведения об использовании Azure Data Lake Storage с HDInsight см. в разделе [Краткое руководство. Настройка кластеров в hdinsight](./hdinsight-hadoop-provision-linux-clusters.md).

    > [!NOTE]  
    > Кластер HDInsight субъекта-службы с доступом к Data Lake Storage должен иметь доступ к сценарию с правами на чтение.

Ресурсы, используемые сценарием, также должны быть общедоступными.

Сохранение файлов в учетной записи хранения Azure или Azure Data Lake Storage поможет обеспечить быстрый доступ к файлам, так как оба хранилища находятся в сети Azure.

> [!NOTE]  
> Формат универсального кода ресурса (URI), используемый для ссылки на скрипт, отличается в зависимости от используемой службы. Для учетной записи хранения, связанной с кластером HDInsight, используйте `wasb://` или `wasbs://`, для общедоступного универсального кода ресурса (URI) — `http://` или `https://`, а для Data Lake Storage — `adl://`.

## <a name="checklist-for-deploying-a-script-action"></a><a name="deployScript"></a>Контрольный список для развертывания действия сценария

Ниже приведены шаги для подготовки к развертыванию сценария:

* Поместите файлы, содержащие пользовательские сценарии, в месте, доступном из узлов кластера во время развертывания. Например, в хранилище по умолчанию для кластера. Файлы также могут храниться в общедоступных службах размещения.
* Скрипт должен быть идемпотентным. Это обеспечит многократное выполнение сценария на одном узле.
* Используйте папку для временных файлов, например /tmp, чтобы хранить скачанные файлы, используемый сценариями. После выполнения сценариев очистите эту папку.
* В случае изменений параметров на уровне операционной системы или файлов конфигурации службы Hadoop может потребоваться перезапуск служб HDInsight.

## <a name="how-to-run-a-script-action"></a><a name="runScriptAction"></a>Как запустить действие сценария

Действия сценариев можно использовать для настройки кластеров HDInsight с помощью следующих методов:

* Портал Azure
* Azure PowerShell
* Шаблоны Azure Resource Manager
* Пакет SDK для HDInsight .NET.

Дополнительные сведения об использовании каждого метода см. в разделе по [использованию действия сценария](hdinsight-hadoop-customize-cluster-linux.md).

## <a name="custom-script-samples"></a><a name="sampleScripts"></a>Примеры пользовательских сценариев

Корпорация Майкрософт предоставляет примеры сценариев для установки компонентов в кластере HDInsight. Пример действия сценария см. [в разделе Установка и использование оттенок в кластерах HDInsight](hdinsight-hadoop-hue-linux.md) .

## <a name="troubleshooting"></a>Устранение неполадок

Ниже приведены ошибки, которые могут возникнуть при использовании разработанных скриптов.

**Ошибка**: `$'\r': command not found` . Иногда дополняется фразой `syntax error: unexpected end of file`.

*Причина.* Эта ошибка возникает, когда для завершения строк в сценарии используется символ CRLF. В системах UNIX для завершения строк допускается только символ LF.

Зачастую эта проблема возникает при написании сценария в среде Windows, так как в текстовых редакторах для этой системы CRLF является стандартным символом завершения строки.

*Решение*. Если это параметр в текстовом редакторе, выберите формат UNIX или LF для конца строки. Кроме того, в системе Unix вы можете использовать следующие команды изменения CRLF на LF.

> [!NOTE]  
> Для замены символов CRLF на LF могут использоваться следующие аналогичные команды. Выберите подходящий вариант в зависимости от наличия в системе соответствующих служебных программ.

| Get-Help | Примечания |
| --- | --- |
| `unix2dos -b INFILE` |Для исходного файла будет создана резервная копия с расширением BAK. |
| `tr -d '\r' < INFILE > OUTFILE` |В файле OUTFILE для окончания строк будут использоваться только символы LF. |
| `perl -pi -e 's/\r\n/\n/g' INFILE` | Изменяет файл напрямую. |
| ```sed 's/$'"/`echo \\\r`/" INFILE > OUTFILE``` |В файле OUTFILE для окончания строк будут использоваться только символы LF. |

**Ошибка**: `line 1: #!/usr/bin/env: No such file or directory` .

*Причина.* Эта ошибка возникает, если сценарий сохранен в кодировке UTF-8 с меткой порядка байтов (BOM).

*Решение.* Сохраните файл в формате ASCII или UTF-8 без метки порядка байтов. Кроме того, для создания файла без метки порядка байтов в системе Linux или Unix вы можете использовать следующую команду:

```bash
awk 'NR==1{sub(/^\xef\xbb\xbf/,"")}{print}' INFILE > OUTFILE
```

Замените `INFILE` на файл с меткой порядка байтов. `OUTFILE` должно быть новым именем файла, который будет содержать сценарий без метки порядка байтов.

## <a name="next-steps"></a><a name="seeAlso"></a>Следующие шаги

* Узнайте, как [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md)
* Используйте [справочник по пакету SDK .NET для HDInsight](/dotnet/api/overview/azure/hdinsight) , чтобы узнать больше о создании приложений .NET, которые управляют HDInsight.
* Используйте [REST API HDInsight](/rest/api/hdinsight/) , чтобы узнать, как использовать REST для выполнения операций управления кластерами HDInsight.