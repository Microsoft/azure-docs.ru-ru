---
title: Запуск настраиваемых программ MapReduce в Azure HDInsight
description: Когда и как выполнять пользовательские программы Apache MapReduce в кластерах Azure HDInsight.
ms.service: hdinsight
ms.topic: how-to
ms.custom: hdinsightactive
ms.date: 01/01/2020
ms.openlocfilehash: 0f7a3676db14dbf61d3976690c8f9c71a660f889
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98943230"
---
# <a name="run-custom-mapreduce-programs"></a>Запуск настраиваемых программ MapReduce

Системы для работы с большими данными Apache Hadoop, такие как HDInsight, позволяют обрабатывать данные с использованием разных инструментов и технологий. Преимущества и рекомендации каждого из них описаны в следующей таблице.

| Механизм запроса | Преимущества | Рекомендации |
| --- | --- | --- |
| **Использование Apache Hive с HiveQL** | <ul><li>Это идеальное решение для пакетной обработки и анализа больших объемов неизменяемых данных, для обобщения данных и отправки запросов данных по требованию. Использует знакомый синтаксис типа SQL.</li><li>С его помощью можно создавать постоянные таблицы данных, которые легко секционируются и индексируются.</li><li>Для одних и тех же данных можно создать несколько внешних таблиц и представлений.</li><li>Поддерживает простую реализацию хранилища данных, которая обеспечивает широкие возможности горизонтального масштабирования и отказоустойчивости для хранения и обработки данных.</li></ul> | <ul><li>Требует, чтобы исходные данные имели хотя бы какую-то идентифицируемую структуру.</li><li>Он не подходит для запросов в реальном времени и обновлений на уровне строк. Он лучше использовать для пакетных заданий по отношению к большим наборам данных.</li><li>Возможно, не сможет выполнять некоторые типы сложных задач обработки.</li></ul> |
| **Использование Apache Pig с Pig Latin** | <ul><li>Это идеальное решение для обработки данных в виде наборов, объединения и фильтрации наборов данных, применения функций к записям или группам записей, а также для реструктуризации данных путем определения столбцов, группировки значений или преобразования столбцов в строки.</li><li>Для последовательности операций с данными может использовать подход на основе рабочих процессов.</li></ul> | <ul><li>Для пользователей SQL Pig Latin может быть менее знакомым и более сложным в использовании, чем HiveQL.</li><li>По умолчанию выходные данные обычно представляют собой текстовый файл, поэтому их сложнее использовать с инструментами визуализации, такими как Excel. Как правило, таблица Hive будет разслойно поверх выходных данных.</li></ul> |
| **Настраиваемое сопоставление и сжатие** | <ul><li>Он предоставляет полный контроль над этапами Map и reduce и выполнением.</li><li>Позволяет оптимизировать запросы, чтобы достичь максимальной производительности кластера или чтобы свести к минимуму нагрузку на серверах и в сети.</li><li>Компоненты могут быть написаны на одном из общеизвестных языков из широкого диапазона.</li></ul> | <ul><li>Это сложнее, чем использование Pig или Hive, так как необходимо создать собственные компоненты Map и reduce.</li><li>Процессы, для которых нужно объединение наборов данных, сложнее реализовать.</li><li>Несмотря на наличие доступных тестовых платформ, код отладки сложнее, чем в обычном приложении, так как он выполняется как пакетное задание под управлением планировщика заданий Hadoop.</li></ul> |
| **Apache HCatalog** | <ul><li>Абстрагирует сведения о пути хранилища, что упрощает администрирование. К тому же при его использовании пользователям не нужно знать, где хранятся данные.</li><li>Предоставляет уведомления о событиях, таких как доступность данных, позволяя другим средствам, например Oozie, определять, когда выполнялись операции.</li><li>Обеспечивает реляционное представление данных, включая секционирование по ключу, а также упрощает доступ к данным.</li></ul> | <ul><li>Поддерживает RCFile, текст в формате CSV, текст в формате JSON, SequenceFile и форматы файла ORC по умолчанию, однако для него может потребоваться написание пользовательских SerDe для других форматов.</li><li>HCatalog не является потокобезопасным.</li><li>Существуют некоторые ограничения для типов данных столбцов при использовании загрузчика HCatalog в скриптах Pig. Дополнительные сведения см. в документации по Apache HCatalog в разделе о [типах данных HCatLoader](https://cwiki.apache.org/confluence/display/Hive/HCatalog%20LoadStore#HCatalogLoadStore-HCatLoaderDataTypes).</li></ul> |

Как правило, из подходов, которые могут предоставить нужные результаты, используется самый простой. Например, таких результатов можно достичь с помощью Hive, однако для более сложных сценариев нужно использовать Pig или даже написать собственные компоненты сопоставления и сжатия. Поэкспериментировав с Hive или Pig, вы можете решить, что настраиваемые компоненты сопоставления и сжатия обеспечивают лучшую производительность, позволяя настроить и оптимизировать обработку.

## <a name="custom-mapreduce-components"></a>Настраиваемые компоненты сопоставления и сжатия

Код сопоставления и сжатия состоит из двух отдельных функций, которые реализованы в виде компонентов **map** и **reduce**. Компонент **map** выполняется параллельно на нескольких узлах кластера, причем каждый узел применяет сопоставление к собственному подмножеству данных узла. Компонент **reduce** объединяет и суммирует результаты всех функций сопоставления. Дополнительные сведения об этих компонентах см. в статье [Использование MapReduce в Hadoop в HDInsight](hdinsight-use-mapreduce.md).

В большинстве сценариев обработки HDInsight проще и эффективнее использовать абстракцию более высокого уровня, например Pig или Hive. Вы также можете создать компоненты настраиваемого сопоставления и сжатия для использования в скриптах Hive, чтобы выполнить более сложную обработку.

Обычно компоненты настраиваемого сопоставления и сжатия пишутся на языке Java. Hadoop предоставляет интерфейс потоковой передачи, который также позволяет использовать компоненты, разработанные на других языках, таких как C#, F#, Visual Basic, Python и JavaScript.

* Пошаговые инструкции по разработке настраиваемых программ MapReduce на Java см. в статье [Разработка программ MapReduce на Java для Hadoop в HDInsight](apache-hadoop-develop-deploy-java-mapreduce-linux.md).

Рекомендуем создать собственные компоненты сопоставления и сжатия при следующих условиях:

* Для получения структурированных сведений из неструктурированных данных вам необходимо обработать эти данные путем анализа и использовать настраиваемую логику.
* Вам требуется выполнять сложные задачи, которые трудно (или невозможно) выразить в Pig или Hive, не создавая определяемые пользователем функции (UDF). Например, вам потребуется внешняя служба геокодирования, чтобы преобразовать широту и долготу координат или IP-адресов в исходных данных в названия географических расположений.
* Вам нужно повторно использовать имеющиеся коды .NET, Python или JavaScript в компонентах сопоставления и сжатия с помощью интерфейса потоковой передачи Hadoop.

## <a name="upload-and-run-your-custom-mapreduce-program"></a>Загрузка и запуск настраиваемой программы MapReduce

Самые распространенные программы MapReduce написаны на языке Java и скомпилированы в виде JAR-файла.

1. После разработки, компиляции и тестирования программы MapReduce используйте `scp` команду, чтобы передать JAR-файл в головного узла.

    ```cmd
    scp mycustomprogram.jar sshuser@CLUSTERNAME-ssh.azurehdinsight.net
    ```

    Замените CLUSTERNAME именем кластера. Если для защиты учетной записи SSH использовался пароль, вам будет предложено ввести пароль. Если используется сертификат, может потребоваться использовать параметр `-i` , чтобы указать соответствующий файл закрытого ключа.

1. С помощью команды [ssh command](../hdinsight-hadoop-linux-use-ssh-unix.md) подключитесь к кластеру. Измените приведенную ниже команду, заменив CLUSTERNAME именем своего кластера, а затем введите команду:

    ```cmd
    ssh sshuser@CLUSTERNAME-ssh.azurehdinsight.net
    ```

1. Из сеанса SSH выполните свою программу MapReduce через YARN.

    ```bash
    yarn jar mycustomprogram.jar mynamespace.myclass /example/data/sample.log /example/data/logoutput
    ```

    Эта команда отправляет задание MapReduce в YARN. Входной файл — `/example/data/sample.log`, а выходной каталог — `/example/data/logoutput`. Файлы ввода и любые файлы вывода хранятся в хранилище кластера по умолчанию.

## <a name="next-steps"></a>Дальнейшие действия

* [Использование C# для потоковой передачи MapReduce в Apache Hadoop в HDInsight](apache-hadoop-dotnet-csharp-mapreduce-streaming.md)
* [Разработка программ MapReduce на Java для Apache Hadoop в HDInsight](apache-hadoop-develop-deploy-java-mapreduce-linux.md)
* [Создание приложений Apache Spark для кластера HDInsight с помощью Azure Toolkit for Eclipse](../spark/apache-spark-eclipse-tool-plugin.md)
* [Использование определяемых пользователем функций Python с Apache Hive и Apache Pig в HDInsight](python-udf-hdinsight.md)
