---
title: 'Архитектура: локальное Apache Hadoop в Azure HDInsight'
description: Ознакомьтесь с рекомендациями по архитектуре в контексте миграции локальных кластеров Hadoop в Azure HDInsight.
ms.reviewer: ashishth
ms.service: hdinsight
ms.topic: how-to
ms.custom: hdinsightactive
ms.date: 12/06/2019
ms.openlocfilehash: 519dc53f6373ae1a9c8853d3fa90d137e9fa934b
ms.sourcegitcommit: 867cb1b7a1f3a1f0b427282c648d411d0ca4f81f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/20/2021
ms.locfileid: "102435415"
---
# <a name="migrate-on-premises-apache-hadoop-clusters-to-azure-hdinsight---architecture-best-practices"></a>Миграция локальных кластеров Apache Hadoop в Azure HDInsight — рекомендации по архитектуре

В этой статье представлены рекомендации для архитектуры систем Azure HDInsight. Это часть цикла, где приведены лучшие методики, применимые при перемещении локальных систем Apache Hadoop в Azure HDInsight.

## <a name="use-multiple-workload-optimized-clusters"></a>Использование кластеров, оптимизированных для нескольких рабочих нагрузок

Большое количество локальных развертываний Apache Hadoop состоит из одного большого кластера, который поддерживает многие рабочие нагрузки. Этот отдельный кластер может быть комплексным и требовать компромиссов для отдельных служб, чтобы обеспечить их совместную работу. При миграции локальных кластеров Hadoop в Azure HDInsight нужен измененный подход.

Кластеры Azure HDInsight предназначены для конкретного типа использований вычислений. Так как хранилище может совместно использоваться несколькими кластерами, можно создать несколько кластеров, оптимизированных для рабочей нагрузки, в соответствии с потребностями различных заданий. У каждого типа кластера есть оптимальная конфигурация для конкретной рабочей нагрузки. В следующей таблице перечислены поддерживаемые типы кластеров в HDInsight и соответствующие рабочие нагрузки.

|Рабочая нагрузка|Тип кластера HDInsight|
|---|---|
|Пакетная обработка (ETL/ELT)|Hadoop, Spark|
|Хранение данных|Hadoop, Spark, Interactive Query|
|Центр Интернета вещей или потоковая передача|Kafka, Storm, Spark|
|Обработка транзакций NoSQL|HBase|
|Кэширование в памяти для обеспечения интерактивных и ускоренных запросов|Интерактивный запрос|
|Обработка и анализ данных|Службы машинного обучения, Spark|

В приведенной ниже таблице представлены различные способы создания кластера HDInsight.

|Инструмент|На основе браузера|Командная строка|REST API|SDK|
|---|---|---|---|---|
|[Портал Azure](../hdinsight-hadoop-create-linux-clusters-portal.md)|X||||
|[Фабрика данных Azure](../hdinsight-hadoop-create-linux-clusters-adf.md).|X|X|X|X|
|[Azure CLI (версия 1.0)](../hdinsight-hadoop-create-linux-clusters-azure-cli.md)||X|||
|[Azure PowerShell](../hdinsight-hadoop-create-linux-clusters-azure-powershell.md)||X|||
|[cURL](../hdinsight-hadoop-create-linux-clusters-curl-rest.md)||X|X||
|[Пакет SDK для .NET](/dotnet/api/overview/azure/hdinsight)||||X|
|[Пакет SDK для Python](/python/api/overview/azure/hdinsight)||||X|
|[пакет SDK для Java](/java/api/overview/azure/hdinsight)||||X|
|[Шаблоны диспетчера ресурсов Azure](../hdinsight-hadoop-create-linux-clusters-arm-templates.md)||X|||

Дополнительные сведения см. в статье [Что такое Azure HDInsight и стек технологий Apache Hadoop](../hadoop/apache-hadoop-introduction.md).

## <a name="use-transient-on-demand-clusters"></a>Использование промежуточных кластеров по запросу

Кластеры HDInsight могут не использоваться в течение длительного периода времени. Для экономии расходов на ресурсы HDInsight поддерживает промежуточные кластеры по запросу, которые можно удалить после успешного выполнения рабочей нагрузки.

При удалении кластера связанная учетная запись хранения и внешние метаданные не удаляются. Кластер можно создавать повторно с использованием тех же учетных записей хранения и хранилищ метаданных.

Фабрику данных Azure можно использовать для планирования создания кластеров HDInsight по запросу. Дополнительные сведения см. в статье [Руководство. Создание кластеров Apache Hadoop в HDInsight по запросу с помощью Фабрики данных Azure](../hdinsight-hadoop-create-linux-clusters-adf.md).

## <a name="decouple-storage-from-compute"></a>Отделение ресурсов хранилища от вычислительных ресурсов

Стандартное локальное развертывание Hadoop использует один набор компьютеров для хранения и обработки данных. Так как они совместно размещены, расчеты и хранилище должны масштабироваться вместе.

В кластерах HDInsight хранилище не нужно совместно использовать с COMPUTE и может быть в службе хранилища Azure, Azure Data Lake Storage или в обоих случаях. Отделение хранилища от вычислительных ресурсов предоставляет следующие преимущества:

- совместное использование данных кластерами;
- использование промежуточных кластеров, так как данные не зависят от кластера;
- снижение затрат на хранилище;
- масштабирование хранилища и вычислительных ресурсов отдельно;
- репликация данных между регионами.

Вычислительные кластеры создаются близко к ресурсам учетной записи хранения в регионе Azure, чтобы устранить ухудшения производительности при разделении вычислительных ресурсов и хранилища. Высокоскоростные сети позволяют вычислительным узлам получать эффективный доступ к данным в службе хранилища Azure.

## <a name="use-external-metadata-stores"></a>Использование внешних хранилищ метаданных

Существует два основных метахранилища, которые работают с кластерами HDInsight: [Apache Hive](https://hive.apache.org/) и [Apache Oozie](https://oozie.apache.org/). Хранилище метаданных Hive — это центральный репозиторий схемы, который могут использовать модули обработки данных, такие как Hadoop, Spark, LLAP, Presto и Apache Pig. Хранилище метаданных Oozie хранит сведения о планировании, состояние хода выполнения и выполненные задания Hadoop.

HDInsight использует Базу данных SQL Azure для хранилищ метаданных Hive и Oozie. Есть два способа настроить хранилище метаданных для кластеров HDInsight.

1. Хранилище метаданных по умолчанию

    - Дополнительные затраты не требуются.
    - Хранилище метаданных удаляется при удалении кластера.
    - Хранилище метаданных не может совместно использоваться разными кластерами.
    - Использует простую Базу данных SQL Azure с ограничением в пять единиц передачи данных.

1. Пользовательское внешнее хранилище метаданных

    - В качестве хранилища метаданных указывается внешняя База данных SQL Azure.
    - Кластеры могут создаваться и удаляться без потери метаданных, включая сведения о задании Oozie схемы Hive.
    - Одна база данных хранилища метаданных может совместно использоваться различными типами кластеров.
    - При необходимости можно увеличить масштаб хранилища метаданных.
    - Дополнительную информацию см. в статье [Использование внешних хранилищ метаданных в Azure HDInsight](../hdinsight-use-external-metadata-stores.md).

## <a name="best-practices-for-hive-metastore"></a>Рекомендации по хранилищу метаданных Hive

Ниже приведены некоторые рекомендации по хранилищу метаданных Hive HDInsight:

- Используйте пользовательское внешнее хранилище метаданных, чтобы разделить вычислительные ресурсы и метаданные.
- Начните с уровня S2 экземпляра SQL Azure, предоставляющего 50 DTU и хранилище размером 250 ГБ. Если вы видите узкое место, можно увеличить масштаб базы данных.
- Не используйте хранилище метаданных, созданное для одной версии кластера HDInsight, с кластерами других версий. Различные версии Hive используют отличающиеся схемы. Например, хранилище метаданных нельзя совместно использовать с кластерами Hive 1.2 и Hive 2.1.
- Периодически архивируйте пользовательское хранилище метаданных.
- Разместите хранилище метаданных и кластер HDInsight в одном регионе.
- Отслеживайте производительность и доступность хранилище метаданных с помощью средств мониторинга базы данных SQL Azure, таких как портал Azure или журналов Azure Monitor.
- Выполните `ANALYZE TABLE` команду в соответствии с требованиями для создания статистики по таблицам и столбцам. Например, `ANALYZE TABLE [table_name] COMPUTE STATISTICS`.

## <a name="best-practices-for-different-workloads"></a>Рекомендации для различных рабочих нагрузок

- Рассмотрите возможность использования кластера LLAP для интерактивных запросов Hive с улучшенным временем отклика [LLAP](https://cwiki.apache.org/confluence/display/Hive/LLAP) — новая функция в Hive 2,0, позволяющая кэшировать запросы в памяти. LLAP создает запросы Hive гораздо быстрее — в [некоторых случаях в 26 раз быстрее, чем Hive версии 1.x](https://hortonworks.com/blog/announcing-apache-hive-2-1-25x-faster-queries-much/).
- Рассмотрите возможность использования заданий Spark вместо заданий Hive.
- Рассмотрите возможность замены запросов на основе Impala на запросы LLAP.
- Рассмотрите возможность замены заданий MapReduce на задания Spark.
- Обдумайте возможность замены пакетных заданий Spark с низкой задержкой на задания структурированной потоковой передачи Spark.
- Рассмотрите возможность использования Фабрики данных Azure (ADF) версии 2.0 для оркестрации данных.
- Рассмотрите использование Ambari для управления кластером.
- Измените хранилище данных для обработки сценариев с локальной системы HDFS на WASB, ADLS или ADFS.
- Рассмотрите использование Ranger RBAC для таблиц Hive и аудита.
- Рассмотрите вопрос об использовании CosmosDB вместо MongoDB или Cassandra.

## <a name="next-steps"></a>Дальнейшие действия

Прочитайте следующую статью в этом цикле:

- [Migrate on-premises Apache Hadoop clusters to Azure HDInsight - infrastructure best practices](apache-hadoop-on-premises-migration-best-practices-infrastructure.md) (Миграция локальных кластеров Apache Hadoop в Azure HDInsight. Рекомендации по инфраструктуре)