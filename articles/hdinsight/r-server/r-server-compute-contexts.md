---
title: Параметры контекста вычислений для Служб машинного обучения в HDInsight в Azure
description: Сведения о различных параметрах контекста вычислений, доступных для пользователей Служб машинного обучения служб машинного обучения в HDInsight.
ms.service: hdinsight
ms.topic: how-to
ms.custom: hdinsightactive
ms.date: 01/02/2020
ms.openlocfilehash: 71ce0d87faa33bd7d533242edfcf3b131c8f7e47
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98943957"
---
# <a name="compute-context-options-for-ml-services-on-hdinsight"></a>Параметры контекста вычислений для Служб машинного обучения в HDInsight

Службы машинного обучения в Azure HDInsight управляют выполнением вызовов, задавая контекст вычисления. В этой статье приведены параметры, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight.

Для подключения к кластеру и выполнения скриптов на языке R удобно использовать граничный узел кластеров. На граничном узле вы можете выполнять распараллеленные распределенные функции RevoScaleR на ядрах сервера граничного узла. Кроме того, вы можете выполнять эти функции на узлах кластера с помощью контекста вычислений Hadoop Map Reduce или Apache Spark RevoScaleR.

## <a name="ml-services-on-azure-hdinsight"></a>Службы машинного обучения в Azure HDInsight

[Службы машинного обучения в Azure HDInsight](r-server-overview.md) предоставляют новейшие возможности для анализа на основе R. Он может использовать данные, хранящиеся в контейнере Apache Hadoop HDFS в учетной записи хранения [BLOB-объектов Azure](../../storage/common/storage-introduction.md "Хранилище BLOB-объектов Azure") , Data Lake Store или локальной файловой системе Linux. Поскольку службы машинного обучения основаны на R с открытым исходным кодом, создаваемые приложения на основе R могут применять любой из пакетов R с открытым кодом из 8000. Также вы можете использовать подпрограммы [RevoScaleR](/machine-learning-server/r-reference/revoscaler/revoscaler) — пакета аналитики больших данных от корпорации Майкрософт, который предоставляется вместе со Службами машинного обучения.  

## <a name="compute-contexts-for-an-edge-node"></a>Контексты вычислений для граничного узла

Как правило, скрипт R, выполняемый в Службах машинного обучения на граничном узле, выполняется в интерпретаторе R на этом узле. Исключением являются те действия, которые вызывают функцию RevoScaleR. Вызовы RevoScaleR будут осуществляться в среде вычислений с учетом настройки контекста вычислений RevoScaleR.  При выполнении скрипта R из граничного узла возможны следующие значения контекста вычислений:

- локальный последовательный (*local*);
- локальный параллельный (*localpar*);
- Map Reduce
- Spark

Значения *local* и *localpar* отличаются только способом выполнения вызовов **rxExec**. Они оба выполняют другие вызовы функций RX параллельно по всем доступным ядрам, если только не указаны другие действия посредством параметра RevoScaleR **numCoresToUse**, например `rxOptions(numCoresToUse=6)`. Параметры параллельного выполнения обеспечивают оптимальную производительность.

В таблице ниже приведена сводка различных параметров контекста вычислений, определяющих способ выполнения вызовов.

| Контекст вычислений  | Метод настройки                      | Контекст выполнения                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| Локальный последовательный | rxSetComputeContext('local')    | Распараллеленное выполнение во всех ядрах сервера граничного узла, за исключением вызовов rxExec, которые выполняются последовательно. |
| Локальный параллельный   | rxSetComputeContext('localpar') | Распараллеленное выполнение во всех ядрах сервера граничного узла. |
| Spark            | RxSpark()                       | Распараллеленное распределенное выполнение с использованием Spark во всех узлах кластера HDI |
| Map Reduce       | RxHadoopMR()                    | Распараллеленное распределенное выполнение с использованием Map Reduce во всех узлах кластера HDI |

## <a name="guidelines-for-deciding-on-a-compute-context"></a>Рекомендации по выбору контекста вычислений

Выбор варианта распараллеленного выполнения зависит от характера задач анализа, а также размера и местонахождения данных. Нет простой формулы, указывающей, какой контекст вычислений использовать. Однако есть некоторые базовые принципы, которые помогут вам определиться или хотя бы сузить выбор еще до запуска теста производительности. К ним относятся следующие:

- Локальная файловая система Linux работает быстрее, чем HDFS.
- Повторный анализ выполняется быстрее для данных в локальной среде, особенно в формате XDF.
- Из текстовых источников данных желательно передавать небольшие объемы данных. Если данные имеют большой объем, преобразуйте их в формат XDF перед анализом.
- При копировании или потоковой передаче на граничный узел больших объемов данных для анализа нагрузка быстро становится запредельной.
- Apache Spark работает быстрее, чем MapReduce для анализа в Hadoop.

С учетом этих принципов в следующем разделе приведены некоторые общие правила выбора контекста вычислений.

### <a name="local"></a>Локальная

- Если объем анализируемых данных мал и не требует повторяющегося анализа, то следует передать его непосредственно в подпрограммы анализа с помощью *локальных* или *localpar*.
- Если нужно проанализировать данные небольшого или среднего объема, для которых потребуется повторный анализ, скопируйте их в локальную файловую систему, импортируйте в XDF-формат и проанализируйте в контексте *local* или *localpar*.

### <a name="apache-spark"></a>Apache Spark

- Если нужно проанализировать большой объем данных, импортируйте их в Spark DataFrame с помощью **RxHiveData** или **RxParquetData** либо в XDF-файл в файловой системе HDFS (при наличии достаточного пространства для хранения) и проанализируйте эти данные в контексте вычислений Spark.

### <a name="apache-hadoop-map-reduce"></a>Apache Hadoop MapReduce

- Используйте контекст Map reduce COMPUTE только в том случае, если вы используете непреодолимые проблему с контекстом вычислений Spark, так как он обычно работает медленнее.  

## <a name="inline-help-on-rxsetcomputecontext"></a>Встроенная справка по rxSetComputeContext
Чтобы получить дополнительные сведения по контекстам вычислений RevoScaleR с соответствующими примерами, воспользуйтесь встроенной справкой в консоли R с помощью метода rxSetComputeContext, например:

```console
> ?rxSetComputeContext
```

Также см. [обзор распределенных вычислений](/machine-learning-server/r/how-to-revoscaler-distributed-computing) в [документации Machine Learning Server](/machine-learning-server/).

## <a name="next-steps"></a>Дальнейшие действия

В этой статье вы ознакомились с параметрами, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight. Дополнительные сведения об использовании Служб машинного обучения в кластерах HDInsight см. в следующих статьях:

- [Основные сведения о службах машинного обучения и возможностях открытого кода R в HDInsight](r-server-overview.md)
- [Решения службы хранилища Azure для R Server в Azure HDInsight](r-server-storage.md)