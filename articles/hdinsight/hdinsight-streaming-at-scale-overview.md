---
title: Потоковая передача в нужном масштабе в Azure HDInsight
description: Как использовать потоковую передачу данных с масштабируемыми кластерами Apache в Azure HDInsight.
ms.service: hdinsight
ms.topic: conceptual
ms.custom: hdinsightactive
ms.date: 12/17/2019
ms.openlocfilehash: 2b2dfe9da55548f2648f847a9d7c2cb3478e6bad
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98931714"
---
# <a name="streaming-at-scale-in-hdinsight"></a>Потоковая передача в нужном масштабе в HDInsight

Решения для обработки больших данных в реальном времени работают с данными, которые находятся в движении. Как правило эти данные наиболее полезны во время поступления. Если входной поток данных становится большим, чем можно обработать в данный момент, может потребоваться регулирование ресурсов. Кроме того, кластер HDInsight может масштабироваться путем добавления узлов по запросу в соответствии с требованиями решения потоковой передачи.

В приложении потоковой передачи один или несколько источников данных создают события (иногда миллионы в секунду), которые нужно быстро принять без потери полезной информации. Входящие события обрабатываются с помощью *потоковой буферизации*, называемой также *очередью событий*, такими службами как [Apache Kafka](kafka/apache-kafka-introduction.md) или [Центры событий](https://azure.microsoft.com/services/event-hubs/). После сбора событий можно проанализировать данные в пределах уровня *обработки потока* с помощью системы аналитики в реальном времени, такой как [Apache Storm](storm/apache-storm-overview.md) или [потоковая передача Apache Spark](spark/apache-spark-streaming-overview.md). Обработанные данные могут храниться в долгосрочном хранилище данных, таком как [Azure Data Lake Storage](https://azure.microsoft.com/services/storage/data-lake-storage/), и отображаться в режиме реального времени на панели мониторинга бизнес-аналитики, такой как [Power BI](https://powerbi.microsoft.com), Tableau, или на настраиваемой веб-странице.

![Шаблоны потоковой передачи Azure HDInsight](./media/hdinsight-streaming-at-scale-overview/HDInsight-streaming-patterns.png)

## <a name="apache-kafka"></a>Apache Kafka

Apache Kafka предоставляет службу очередей сообщений с высокой пропускной способностью и низкими показателями задержки и теперь является частью набора программного обеспечения с открытым кодом Apache. Kafka использует модель обмена сообщениями с помощью публикаций и подписки и безопасно сохраняет потоки секционированных данных в распределенном реплицируемом кластере. С увеличением пропускной способности Kafka линейно масштабируется.

Дополнительные сведения см. в статье по [началу работы с Apache Kafka в HDInsight](kafka/apache-kafka-introduction.md).

## <a name="apache-storm"></a>Apache Storm

Apache Storm — это распределенная отказоустойчивая вычислительная система с открытым кодом, оптимизированная для обработки данных в реальном времени с использованием Hadoop. Основная единица данных входящего события — кортеж, который является неизменяемым набором пар "ключ — значение". Неограниченная последовательность кортежей формирует поток, который поступает из spout. Spout помещает источник потоковой передачи данных (например, Kafka) в оболочку и выдает кортежи. Топология Storm — это последовательность преобразований в этих потоках.

Дополнительные сведения см. в статье [Основные сведения об Apache Storm в Azure HDInsight](storm/apache-storm-overview.md).

## <a name="spark-streaming"></a>Потоковая передача Spark

Потоковая передача Spark — это расширение Spark, которое позволяет повторно использовать тот же код, который использовался для пакетной обработки. Вы можете объединить пакетные и интерактивные запросы в одном приложении. В отличие от этого, потоковая передача Spark обеспечивает отслеживание состояния только после семантики обработки. При использовании в сочетании с [прямым интерфейсом API Kafka](https://spark.apache.org/docs/latest/streaming-kafka-integration.html), что гарантирует, что все данные Kafka получаются потоковой передачей Spark ровно один раз, можно добиться сквозного выполнения только после гарантии. Одним из преимуществ потоковой передачи Spark является ее отказоустойчивость, быстрое восстановление узлов с ошибками, когда несколько узлов используются в кластере.

Дополнительные сведения см. в статье [Общие сведения о потоковой передаче Apache Spark](./spark/apache-spark-streaming-overview.md).

## <a name="scaling-a-cluster"></a>Масштабирование кластера

Количество узлов указывается во время создания кластера. Тем не менее рабочая нагрузка может меняться, и тогда возникает необходимость увеличить или уменьшить размер кластера. Все кластеры HDInsight позволяют [изменять количество узлов в кластере](hdinsight-administer-use-portal-linux.md#scale-clusters). Кластеры Spark можно удалить без потери данных, так как все данные хранятся в службе хранилища Azure или Data Lake Storage.

В разделении технологий есть преимущества. Например, Kafka — это технология буферизации событий, поэтому она занимает очень много операций ввода-вывода и не требует больших вычислительных ресурсов. Для сравнения обработчики потоков, например потоковая передача Spark, потребляют много ресурсов и им требуются более мощные виртуальные машины. Если эти технологии разделены по разным кластерам, их можно масштабировать независимо друг от друга и оптимизировать использование виртуальных машин.

### <a name="scale-the-stream-buffering-layer"></a>Масштабирование на уровне буферизации потоковой передачи

И технологии буферизации потоковой передачи Центров событий, и Kafka используют секционирование, а объекты-получатели читают эти разделы. Масштабирование пропускной способности ввода требует увеличения числа секций, что в свою очередь повышает уровень параллелизма. В концентраторах событий число секций не может быть изменено после развертывания, поэтому важно начать с целевого масштабирования. С помощью Kafka можно [добавлять секции](https://kafka.apache.org/documentation.html#basic_ops_cluster_expansion), даже если Kafka обрабатывает данные. Kafka предоставляет средство для переназначения секций, `kafka-reassign-partitions.sh`. HDInsight предоставляет средство повторной [балансировки реплик секций](https://github.com/hdinsight/hdinsight-kafka-tools),  `rebalance_rackaware.py` . Средство перераспределения вызывает средство `kafka-reassign-partitions.sh` таким образом, что каждая реплика помещается в отдельный домен сбоя и домен обновления, оповещая стойку Kafka и увеличивая отказоустойчивость.

### <a name="scale-the-stream-processing-layer"></a>Масштабирование на уровне обработки потоковой передачи

И Apache Storm, и потоковая передача Spark поддерживают добавление рабочих узлов в кластеры даже при обработке данных.

Чтобы воспользоваться преимуществами новых узлов, добавленных с помощью масштабирования Storm, необходимо повторно сбалансировать топологии Storm, запущенные до увеличения размера кластера. Это перераспределение можно выполнить с помощью пользовательского веб-интерфейса Storm или CLI. Дополнительные сведения см. в [документации по Apache Storm.](https://storm.apache.org/documentation/Understanding-the-parallelism-of-a-Storm-topology.html)

В Apache Spark используется три ключевых параметра при настройке среды в зависимости от требований к приложению: `spark.executor.instances`, `spark.executor.cores` и `spark.executor.memory`. *Исполнитель* — это процесс, запущенный для приложения Spark. Он выполняется на рабочем узле и отвечает за выполнение задач этого приложения. Число исполнителей по умолчанию и размеры исполнителя для каждого кластера определяются с учетом числа рабочих узлов и размера каждого рабочего узла. Эти числа хранятся в файле `spark-defaults.conf` на каждом головном узле кластера.

Эти три параметра можно настроить на уровне кластера (для всех приложений, работающих в кластере) или для каждого отдельного приложения. Дополнительные сведения см. в статье [Управление ресурсами для кластера Apache Spark в Azure HDInsight](spark/apache-spark-resource-manager.md).

## <a name="next-steps"></a>Дальнейшие действия

* [Учебник: создание и мониторинг топологии Apache Storm в Azure HDInsight](storm/apache-storm-quickstart.md)
* [Примеры топологий и компонентов Storm для Apache Storm в HDInsight](storm/apache-storm-example-topology.md)
* [Apache Spark в Azure HDInsight](spark/apache-spark-overview.md)
* [Приступая к работе с Apache Kafka в HDInsig](kafka/apache-kafka-get-started.md)