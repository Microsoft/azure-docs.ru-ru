---
title: Устранение проблем с производительностью Apache HBase в Azure HDInsight
description: Различные рекомендации по настройке производительности Apache HBase и советы по обеспечению оптимальной производительности в Azure HDInsight.
ms.service: hdinsight
ms.topic: troubleshooting
ms.date: 09/24/2019
ms.openlocfilehash: 466fac524601e2d569bfa0ccf90179fe9419210d
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98942896"
---
# <a name="troubleshoot-apache-hbase-performance-issues-on-azure-hdinsight"></a>Устранение проблем с производительностью Apache HBase в Azure HDInsight

В этой статье описываются различные рекомендации по настройке производительности Apache HBase и советы по обеспечению оптимальной производительности в Azure HDInsight. Многие из этих советов зависят от конкретной рабочей нагрузки и шаблона чтения, записи и проверки. Перед применением изменений конфигурации в рабочей среде тщательно протестируйте их.

## <a name="hbase-performance-insights"></a>Аналитика производительности HBase

Основной узким местом в большинстве рабочих нагрузок HBase является журнал упреждающего записи (WAL). Это серьезно влияет на производительность записи. HDInsight HBase имеет разделенную модель вычислений с хранилищем. Данные хранятся в службе хранилища Azure удаленно, даже если на виртуальных машинах размещены серверы регионов. В течение последнего времени WAL был также записан в службу хранилища Azure. В HDInsight такое поведение было усилено. Функция [ускоренного записи](./apache-hbase-accelerated-writes.md) предназначена для решения этой проблемы. Он записывает WAL в диски, управляемые SSD (цен. категория "Премиум") Azure. Это невероятно преимущества для повышения производительности и помогает решать многие проблемы, с которыми сталкиваются некоторые рабочие нагрузки с интенсивными операциями записи.

Чтобы получить значительное улучшение операций чтения, используйте [учетную запись хранения блочного BLOB-объекта](https://azure.microsoft.com/blog/azure-premium-block-blob-storage-is-now-generally-available/) уровня "Премиум" в качестве удаленного хранилища. Этот параметр возможен только в том случае, если включен компонент WAL.

## <a name="compaction"></a>Сжатия

Сжатие — это еще одна потенциальная узкие места, которые в сообществе имеют принципиальное согласие. По умолчанию крупное сжатие отключено в кластерах HDInsight HBase. Сжатие отключено, поскольку, несмотря на то, что это ресурсоемкий процесс, клиенты имеют полную гибкость в планировании в соответствии с их рабочими нагрузками. Например, они могут запланировать его в часы наименьшей нагрузки. Кроме того, локализация данных не является проблемой, так как хранилище является удаленным (поддерживается службой хранилища Azure), а не локальным распределенная файловая система Hadoop (HDFS).

Клиенты должны запланировать значительное сжатие по своему усмотрению. Если это не сделано, сжатие отрицательно повлияет на производительность чтения в долгосрочном запуске.

Для операций сканирования среднее значение задержки, которое значительно выше 100 миллисекунд, должно быть причиной проблемы. Проверьте, правильно ли было запланировано значительное сжатие.

## <a name="apache-phoenix-workload"></a>Рабочая нагрузка Apache Phoenix

Ответы на следующие вопросы помогут лучше понять вашу рабочую нагрузку Apache Phoenix.

* Будут ли все операции чтения преобразованы для просмотра?
    * Если да, каковы характеристики этих проверок?
    * Оптимизирована ли схема таблицы Phoenix для таких проверок, включая соответствующую индексацию?
* Вы использовали `EXPLAIN` инструкцию, чтобы понять планы запросов, создаваемые при чтении?
* Вы пишете "Upsert-Selects"?
    * Если да, то они также будут выполнять проверки. Ожидаемая задержка для проверок среднего значения приблизительно 100 миллисекунд, по сравнению с 10 миллисекундами для Point в HBase.  

## <a name="test-methodology-and-metrics-monitoring"></a>Проверка методологии и мониторинга метрик

Если вы используете тесты производительности, такие как Yahoo! Cloud обслуживает тесты производительности, JMeter или Ферф, чтобы протестировать и настроить производительность, убедитесь, что:

- Клиентские компьютеры не являются узким местом. Для этого проверьте загрузку ЦП на клиентских компьютерах.

- Конфигурации на стороне клиента, например количество потоков, настраиваются соответствующим образом, чтобы повысить пропускную способность клиента.

- Результаты тестов записываются точно и систематически.

Если запросы внезапно начали намного хуже, проверьте наличие потенциальных ошибок в коде приложения. Неожиданно ли создаются большие объемы недопустимых данных? Если это так, это может увеличить задержку чтения.

## <a name="migration-issues"></a>Проблемы с миграцией

Если вы выполняете миграцию в Azure HDInsight, убедитесь, что миграция выполняется систематически и точно, желательно с помощью службы автоматизации. Избегайте ручной миграции. Убедитесь, что выполнены следующие условия:

- Атрибуты таблицы переносятся точно. Атрибуты могут включать как сжатие, фильтры раскрытия и т. д.

- Параметры Salt в таблицах Phoenix соответствуют новому размеру кластера. Например, число сегментов соли должно быть кратно количеству рабочих узлов в кластере. И следует использовать множитель, который является коэффициентом интенсивности оперативного выявления.

## <a name="server-side-configuration-tunings"></a>Настройки конфигурации на стороне сервера

В HDInsight HBase файлах hFile хранятся в удаленном хранилище. При промахе кэша стоимость операций чтения выше, чем в локальных системах, так как данные на локальных системах поддерживаются локальными HDFS. В большинстве сценариев Интеллектуальное использование кэшей HBase (кэш блоков и кэш контейнеров) предназначено для обхода этой проблемы. В тех случаях, когда проблема не обходится, может помочь эта проблема при использовании учетной записи блочного BLOB-объекта уровня "Премиум". Драйвер Windows Azure Storage Blob использует определенные свойства, например `fs.azure.read.request.size` для извлечения данных в блоках на основе того, что он определяет как режим чтения (последовательное и случайное), поэтому при чтении могут возникать и другие экземпляры с большим количеством задержек. С помощью экспериментов мы обнаружили, что установка размера блока запроса чтения ( `fs.azure.read.request.size` ) в 512 КБ и совпадение размера блока таблиц HBase с тем же размером дает наилучший результат на практике.

Для большинства кластеров узлов с большим размером в HDInsight HBase предоставляется в `bucketcache` виде файла на локальном SSD (цен. Категория "Премиум"), подключенном к виртуальной машине, которая работает `regionservers` . Использование кэша без кучи может обеспечить некоторое улучшение. Это решение имеет ограничение на использование доступной памяти и может быть меньше, чем файловый кэш, поэтому он может не всегда быть лучшим выбором.

Ниже приведены некоторые из других параметров, которые мы настраиваете, и которые были полезны в различной степени:

- Увеличьте `memstore` Размер по умолчанию 128 МБ до 256 МБ. Как правило, этот параметр рекомендуется использовать для больших сценариев записи.

- Увеличьте число потоков, выделенных для сжатия, от значения по умолчанию от **1** до **4**. Этот параметр важен, если мы наблюдаем частые небольшие сжатия.

- Старайтесь не блокировать `memstore` очистку из-за ограничения хранилища. Чтобы предоставить этот буфер, увеличьте `Hbase.hstore.blockingStoreFiles` значение параметра равным **100**.

- Для управления сбросами используйте следующие параметры.

    - `Hbase.regionserver.maxlogs`: **140** (предотвращение очистки из-за ограничений WAL)

    - `Hbase.regionserver.global.memstore.lowerLimit`: **0,55**

    - `Hbase.regionserver.global.memstore.upperLimit`: **0,60**

- Конфигурации для настройки пула потоков, зависящие от Phoenix:

    - `Phoenix.query.queuesize`: **10000**

    - `Phoenix.query.threadpoolsize`: **512**

- Другие конфигурации, относящиеся к Phoenix:

    - `Phoenix.rpc.index.handler.count`: **50** (при наличии большого числа поисков в индексе)

    - `Phoenix.stats.updateFrequency`: **1 час**

    - `Phoenix.coprocessor.maxmetadatacachetimetolivems`: **1 час**

    - `Phoenix.coprocessor.maxmetadatacachesize`: **50 МБ**

- Время ожидания RPC: **3 минуты**

   - Таймауты RPC включают время ожидания RPC для HBase, время ожидания клиентского сканера HBase и время ожидания запроса в Phoenix. 
   - Убедитесь, что `hbase.client.scanner.caching` для параметра задано одинаковое значение как на стороне сервера, так и на стороне клиента. Если они не совпадают, этот параметр приводит к ошибкам клиента, связанным с `OutOfOrderScannerException` . Для этого параметра следует задать низкое значение для больших просмотров. Это значение устанавливается равным **100**.

## <a name="other-considerations"></a>Другие замечания

Ниже приведены дополнительные параметры, которые следует учесть при настройке.

- `Hbase.rs.cacheblocksonwrite` — по умолчанию для HDI этот параметр имеет значение **true**.

- Параметры, позволяющие отложить незначительное сжатие для последующего использования.

- Экспериментальные параметры, такие как настройка процентных долей очередей, зарезервированных для запросов на чтение и запись.

## <a name="next-steps"></a>Дальнейшие действия

Если проблема не решена, посетите один из следующих каналов для получения дополнительной поддержки.

- Получите ответы специалистов Azure на [сайте поддержки сообщества пользователей Azure](https://azure.microsoft.com/support/community/).

- Обратитесь за помощью в Твиттер — [@AzureSupport](https://twitter.com/azuresupport). Это официальная учетная запись Microsoft Azure для улучшения качества взаимодействия с клиентами. Он подключает сообщество Azure к нужным ресурсам: ответы, поддержка и эксперты.

- Если вам нужна дополнительная помощь, отправьте запрос в службу поддержки на [портале Azure](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade/). Выберите **Поддержка** в строке меню или откройте центр **Справка и поддержка**. Дополнительные сведения см. в статье [Создание запроса на поддержку Azure](../../azure-portal/supportability/how-to-create-azure-support-request.md). Ваша Подписка Microsoft Azure включает доступ к управлению подписками и поддержке выставления счетов, а техническая поддержка предоставляется через один из [планов поддержки Azure](https://azure.microsoft.com/support/plans/).