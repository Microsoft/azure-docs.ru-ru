---
title: Мониторинг производительности кластера в Azure HDInsight
description: Как отслеживать работоспособность и производительность кластеров Apache Hadoop в Azure HDInsight.
ms.service: hdinsight
ms.topic: how-to
ms.custom: hdinsightactive
ms.date: 03/09/2020
ms.openlocfilehash: f910054c803093eb62db494a596219c50791d136
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98945350"
---
# <a name="monitor-cluster-performance-in-azure-hdinsight"></a>Мониторинг производительности кластера в Azure HDInsight

Мониторинг работоспособности и производительности кластера HDInsight важен для обеспечения оптимальной производительности и эффективного использования ресурсов. Мониторинг может также помочь вам обнаружить и устранить ошибки конфигурации кластера и проблемы с пользовательским кодом.

В следующих разделах описывается, как отслеживать и оптимизировать нагрузку на кластеры, очереди Apache Hadoop YARN и обнаруживать проблемы регулирования хранилища.

## <a name="monitor-cluster-load"></a>Мониторинг загрузки кластера

Кластеры Hadoop могут обеспечить наиболее оптимальную производительность, когда нагрузка на кластер равномерно распределена по всем узлам. Это позволяет избежать ограничения задач обработки из-за нехватки ресурсов ОЗУ, ЦП и дисков на отдельных узлах.

Чтобы получить общий взгляд на узлы кластера и их загрузку, войдите в [веб-интерфейс Ambari](hdinsight-hadoop-manage-ambari.md), а затем выберите вкладку **узлы** . Узлы указываются по полным доменным именам. Состояние каждого узла обозначается цветным индикатором работоспособности.

| Color | Description |
| --- | --- |
| Красный | Как минимум один ведущий компонент на узле не работает. Наведите указатель мыши, чтобы просмотреть подсказку с перечнем затронутых компонентов. |
| Оранжевый | По крайней мере один дополнительный компонент на узле не работает. Наведите указатель мыши, чтобы просмотреть подсказку с перечнем затронутых компонентов. |
| Желтый | Сервер Ambari не получил пульс от узла более 3 минут. |
| Зеленый | Нормальное рабочее состояние. |

Вы также увидите столбцы с указанием количества ядер и объема ОЗУ для каждого узла, сведений об использовании дисков и средней загрузки.

![Обзор вкладки "узлы Apache Ambari"](./media/hdinsight-key-scenarios-to-monitor/apache-ambari-hosts-tab.png)

Выберите любое имя узла, чтобы подробное изучить компоненты, работающие на этом узле, и их метрики. Метрики отображаются в виде доступной для выбора временной шкалы использования ЦП, загрузки, использование диска, использование памяти, использование сети и числа процессов.

![Общие сведения об узле Apache Ambari](./media/hdinsight-key-scenarios-to-monitor/apache-ambari-host-details.png)

Подробные сведения о настройке оповещений и просмотре метрик см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md).

## <a name="yarn-queue-configuration"></a>Конфигурация очереди YARN

На распределенной платформе Hadoop выполняются различные службы. YARN (Yet Another Resource Negotiator, что переводится как "Еще одна система управления ресурсами") координирует эти службы, выделяет ресурсы кластера для обеспечения равномерного распределения нагрузки по кластеру.

YARN разделяет две обязанности JobTracker: управление ресурсами и планирование и мониторинг заданий — между двумя управляющими программами: глобальным приложением Resource Manager и приложением ApplicationMaster для каждого приложения (AM).

Resource Manager является *только планировщиком* и единолично управляет доступными ресурсами для всех конкурирующих приложений. Resource Manager обеспечивает постоянное использование всех ресурсов, оптимизируя различные константы, такие как соглашения об уровне обслуживания, гарантии емкости и т. д. ApplicationMaster согласовывает ресурсы, полученные от Resource Manager, и работает с экземплярами NodeManager для выполнения и отслеживания контейнеров и их потребления ресурсов.

Если несколько клиентов совместно используют большой кластер, существует конкуренция за ресурсы кластера. CapacityScheduler является подключаемым планировщиком, который упрощает предоставление общего доступа к ресурсам, ставя запросы в очередь. CapacityScheduler также поддерживает *иерархические очереди* , чтобы обеспечить совместное использование ресурсов в подочередях Организации, прежде чем очереди других приложений смогут использовать свободные ресурсы.

YARN позволяет выделять ресурсы для этих очередей, а также показывает, назначены ли все доступные ресурсы. Чтобы просмотреть сведения об очередях, войдите в пользовательский веб-интерфейс Ambari и в верхнем меню щелкните **YARN Queue Manager** (Диспетчер очередей YARN).

![Диспетчер очереди YARN Apache Ambari](./media/hdinsight-key-scenarios-to-monitor/apache-yarn-queue-manager.png)

В левой части страницы "YARN Queue Manager" (Диспетчер очередей YARN) отображается список очередей, а также назначенный каждой из них процент емкости.

![Страница сведений диспетчера очередей YARN](./media/hdinsight-key-scenarios-to-monitor/yarn-queue-manager-details.png)

Чтобы более подробно изучить очереди, на панели мониторинга Ambari из списка слева выберите службу **YARN**. Затем из раскрывающегося меню **Quick Links** (Быстрые ссылки) выберите **Resource Manager UI** (Пользовательский интерфейс Resource Manager) под активным узлом.

![Ссылки на меню пользовательского интерфейса диспетчер ресурсов](./media/hdinsight-key-scenarios-to-monitor/resource-manager-ui-menu-link.png)

В пользовательском интерфейсе Resource Manager в меню слева выберите **Scheduler** (Планировщик). Список очередей отобразится в разделе *Application Queues* (Очереди приложений). Здесь можно просмотреть емкость, используемую для каждой из очередей, узнать, насколько хорошо задания распределены между ними, и имеются ли задания, которым не хватает ресурсов.

![Меню пользовательского интерфейса диспетчер ресурсов Apache HAdoop](./media/hdinsight-key-scenarios-to-monitor/resource-manager-ui-menu.png)

## <a name="storage-throttling"></a>Регулирование хранилища

Узкое место производительности кластера может возникнуть на уровне хранилища. Этот тип узкого места чаще всего происходит из-за *блокировки* операций ввода-вывода, которые происходят, когда выполняемые задачи отправляют больше операций ввода/вывода, чем служба хранилища может справиться. Эта блокировка приводит к образованию очереди запросов на ввод-вывод, ожидающих обработки после завершения обработки текущих операций ввода-вывода. Блоки обусловлены *регулированием хранилища*, которое не является физическим ограничением, а ограничением, наложенным службой хранилища соглашением об уровне обслуживания (SLA). Это ограничение гарантирует невозможность монополизации службы каким-ибо одним клиентом. Соглашение об уровне обслуживания ограничивает количество операций ввода-вывода в секунду для службы хранилища Azure. Дополнительные сведения см. в разделе [целевые показатели масштабируемости и производительности для стандартных учетных записей хранения](../storage/common/scalability-targets-standard-account.md).

Если вы используете службу хранилища Azure, дополнительные сведения о мониторинге проблем, связанных с хранилищем, включая регулирование, см. в разделе [мониторинг, диагностика и устранение неполадок служба хранилища Microsoft Azure](../storage/common/storage-monitoring-diagnosing-troubleshooting.md).

Если резервное хранилище кластера находится Azure Data Lake Storage (ADLS), регулирование скорее всего обусловлено ограничениями пропускной способности. В данном случае регулирование можно заметить, отслеживая ошибки регулирования в журналах задач. Сведения об использовании ADLS приведены в разделе о регулировании для соответствующей службы в следующих статьях:

* [Рекомендации по настройке производительности для Hive в HDInsight и Azure Data Lake Storage](../data-lake-store/data-lake-store-performance-tuning-hive.md)
* [Рекомендации по настройке производительности для MapReduce в HDInsight и Azure Data Lake Storage](../data-lake-store/data-lake-store-performance-tuning-mapreduce.md)
* [Рекомендации по настройке производительности для Storm в HDInsight и Azure Data Lake Storage](../data-lake-store/data-lake-store-performance-tuning-storm.md)

## <a name="troubleshoot-sluggish-node-performance"></a>Устранение низкой производительности узла

В некоторых случаях снижение скорости может возникать из-за нехватки дискового пространства в кластере. Изучите следующие шаги:

1. Используйте [команду SSH](./hdinsight-hadoop-linux-use-ssh-unix.md) для подключения к каждому из узлов.

1. Проверьте использование диска, выполнив одну из следующих команд:

    ```bash
    df -h
    du -h --max-depth=1 / | sort -h
    ```

1. Просмотрите выходные данные и проверьте наличие больших файлов в `mnt` папке или других папках. Как правило, `usercache` папки, и `appcache` (МНТ/Resource/Hadoop/Yarn/Local/усеркаче/Hive/аппкаче/) содержат файлы большого размера.

1. При наличии больших файлов текущее задание приведет к увеличению размера файла или сбою предыдущего задания, которое могло быть связано с этой проблемой. Чтобы проверить, связано ли это поведение с текущим заданием, выполните следующую команду: 

    ```bash
    sudo du -h --max-depth=1 /mnt/resource/hadoop/yarn/local/usercache/hive/appcache/
    ```

1. Если эта команда указывает конкретное задание, можно завершить задание с помощью команды, которая выглядит следующим образом:

    ```bash
    yarn application -kill -applicationId <application_id>
    ```

    Замените на `application_id` идентификатор приложения. Если конкретные задания не определены, перейдите к следующему шагу.

1. После выполнения приведенной выше команды или при отсутствии определенных заданий удалите большие файлы, которые вы определили, выполнив команду, подобную следующей:

    ```bash
    rm -rf filecache usercache
    ```

Дополнительные сведения о проблемах с дисковым пространством см. в разделе [недостаточно места на диске](./hadoop/hdinsight-troubleshoot-out-disk-space.md).

> [!NOTE]  
> Если у вас есть большие файлы, которые вы хотите защитить, но в которых возникли проблемы с нехваткой места на диске, необходимо увеличить масштаб кластера HDInsight и перезапустить службы. После выполнения этой процедуры и ожидания в течение нескольких минут вы заметите, что хранилище будет освобождено и что восстанавливается обычная производительность узла.

## <a name="next-steps"></a>Дальнейшие действия

Перейдите по следующим ссылкам, чтобы получить дополнительные сведения об устранении неполадок и мониторинге кластеров:

* [Сведения об анализе журналов Azure HDInsight в этой статье](./hdinsight-troubleshoot-guide.md)
* [Доступ к журналам приложений Apache Hadoop YARN в HDInsight под управлением Linux](hdinsight-hadoop-access-yarn-app-logs-linux.md)
* [Включение дампов кучи для служб Apache Hadoop в HDInsight под управлением Linux](hdinsight-hadoop-collect-debug-heap-dump-linux.md)