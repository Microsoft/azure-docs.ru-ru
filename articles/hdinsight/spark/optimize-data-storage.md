---
title: Оптимизация хранилища данных для Apache Spark (Azure HDInsight)
description: Сведения о том, как оптимизировать хранилище данных для Apache Spark в Azure HDInsight.
ms.service: hdinsight
ms.topic: conceptual
ms.date: 05/20/2020
ms.custom: contperf-fy21q1
ms.openlocfilehash: 10f99bdc4a5d418ae1b432a6799c5979e473c5ed
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/19/2021
ms.locfileid: "98926988"
---
# <a name="data-storage-optimization-for-apache-spark"></a>Оптимизация хранилища данных для Apache Spark

В этой статье обсуждаются стратегии оптимизации хранилища данных для эффективного выполнения заданий Apache Spark в Azure HDInsight.

## <a name="overview"></a>Обзор

Spark поддерживает многие форматы, такие как CSV, JSON, XML, PARQUET, ORC и AVRO. С помощью внешних источников данных его можно расширить для поддержки большего количества форматов. Дополнительные сведения см. на странице [пакетов Apache Spark](https://spark-packages.org).

Лучший формат для повышения производительности — PARQUET со *сжатием Snappy*, который является стандартным форматом в кластере Spark 2.x. В формате PARQUET данные хранятся в столбцах. Этот формат высоко оптимизирован в Spark.

## <a name="choose-data-abstraction"></a>Выбор абстракции данных

В более ранних версиях Spark используются наборы RDD для абстракции данных. В Spark версии 1.3 и 1.6 были представлены DataFrames и DataSets соответственно. Рассмотрим следующие относительные характеристики:

* **Кадры данных**
    * Оптимальный вариант в большинстве случаев.
    * Предоставляет оптимизацию запросов через Catalyst.
    * Комплексное создание кода.
    * Прямой доступ к памяти.
    * Низкие накладные расходы при сборке мусора.
    * Не настолько удобны для разработчиков, как наборы данных, так как отсутствуют проверки со временем компиляции или программирование на основе объекта домена.
* **Наборы данных**
    * Подходят для использования в сложных конвейерах ETL, где допустимо влияние производительности.
    * Не подходят для использования в статистических функциях, где весомо влияние производительности.
    * Предоставляет оптимизацию запросов через Catalyst.
    * Удобны для разработчиков, так как обеспечивают программирование на основе объекта домена и проверки со временем компиляции.
    * Увеличивают нагрузку при десериализации и сериализации.
    * Высокие накладные расходы при сборке мусора.
    * Разбивают комплексное создание кода на этапы.
* **Устойчивые распределенные наборы данных (RDD)**
    * Вам необязательно использовать наборы RDD, если только вам не нужно создать пользовательский RDD.
    * Отсутствует оптимизация запросов через Catalyst.
    * Отсутствует комплексное создание кода.
    * Высокие накладные расходы при сборке мусора.
    * Необходимо использовать устаревшие API-интерфейсы Spark 1.x.

## <a name="select-default-storage"></a>Выбор хранилища по умолчанию

При создании кластера Spark вы можете выбрать хранилище BLOB-объектов Azure или Azure Data Lake Storage в качестве хранилища кластера по умолчанию. Оба варианта предоставляют возможность долговременного хранения промежуточных кластеров. Это означает, что данные не будут автоматически удаляться при удалении кластера. Вы можете повторно создать промежуточный кластер и по-прежнему иметь доступ к данным.

| Тип хранилища данных | Файловая система | Speed | Промежуточный | Варианты использования |
| --- | --- | --- | --- | --- |
| хранилище BLOB-объектов Azure | **wasb:** //url/ | **Standard Edition** | Да | Промежуточный кластер |
| Хранилище BLOB-объектов (защищенное) | **wasbs:** //url/ | **Standard Edition** | Да | Промежуточный кластер |
| Azure Data Lake Storage 2-го поколения| **abfs:** //url/ | **Более быстрая** | Да | Промежуточный кластер |
| Azure Data Lake Storage 1-го поколения| **adl:** //url/ | **Более быстрая** | Да | Промежуточный кластер |
| Локальная система HDFS | **hdfs:** //url/ | **Самая быстрая** | нет | Интерактивный постоянно доступный кластер |

Полный список вариантов хранилища см. в статье [Сравнение вариантов хранения для использования с кластерами Azure HDInsight](../hdinsight-hadoop-compare-storage-options.md).

## <a name="use-the-cache"></a>Использование кэша

Spark обеспечивает собственные механизмы кэширования, которые можно использовать с помощью различных методов, например `.persist()`, `.cache()` и `CACHE TABLE`. Такое встроенное кэширование эффективно при работе с небольшими наборами данных, а также в конвейерах ETL, где требуется кэшировать промежуточные результаты. Однако встроенное кэширование Spark в настоящее время не подходит для работы с секционированием, так как в кэшированнной таблице не хранятся секционированные данные. Более универсальным и надежным способом кэширования является *кэширование на уровне хранилища*.

* Встроенное кэширование Spark (не рекомендуется)
    * Подходит для небольших наборов данных.
    * Не подходит для работы с секционированием, но в следующих выпусках Spark это может измениться.

* Кэширование на уровне хранилища (рекомендуется)
    * Можно реализовать в HDInsight с использованием функции [Кэш операций ввода-вывода](apache-spark-improve-performance-iocache.md).
    * Использует кэширование SSD и в памяти.

* Локальная система HDFS (рекомендуется)
    * Путь `hdfs://mycluster`.
    * Использует кэширование SSD.
    * Кэшированные данные будут потеряны при удалении кластера, что требует перестроения кэша.

## <a name="optimize-data-serialization"></a>Оптимизация сериализации данных

Так как задания кластера Spark можно распределить, соответствующая сериализация данных представляет собой важный шаг для повышения производительности.  Есть два варианта сериализации данных Spark:

* Сериализация Java, используемая по умолчанию.
* Сериализация `Kryo` (новый формат), которая может ускорить сериализацию и сделать ее компактнее по сравнению с сериализацией Java.  При использовании сериализации `Kryo` необходимо зарегистрировать классы в программе. Пока что поддерживаются не все сериализуемые типы.

## <a name="use-bucketing"></a>Использование группирования

Группирование аналогично секционированию данных, но каждая группа может содержать не одно значение столбца, а набор. Этот метод подходит для секционирования большого количества значений (миллионов и более), например идентификаторов продукта. Контейнер определяется хэшированием ключа контейнера строки. Таблицы в контейнерах предлагают уникальную оптимизацию, так как в них хранятся метаданные о способах группирования и сортировки.

Ниже приведены некоторые расширенные функции группирования.

* Оптимизация запросов на основе группирования метасведений.
* Оптимизированные статистические функции.
* Оптимизированные соединения.

Вы можете одновременно использовать секционирование и группирование.

## <a name="next-steps"></a>Дальнейшие действия

* [Оптимизация обработки данных для Apache Spark](optimize-cluster-configuration.md)
* [Оптимизация потребления памяти для Apache Spark](optimize-memory-usage.md)
* [Оптимизация конфигурации кластера для Apache Spark](optimize-cluster-configuration.md)
