---
title: Оптимизация использования памяти в Apache Spark — Azure HDInsight
description: Сведения о том, как оптимизировать использование памяти в Apache Spark на базе Azure HDInsight.
ms.service: hdinsight
ms.topic: conceptual
ms.date: 05/20/2020
ms.custom: contperf-fy21q1
ms.openlocfilehash: d54cf4e9025dfd75d9029dec534fc5dc5dd990a5
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98944171"
---
# <a name="memory-usage-optimization-for-apache-spark"></a>Оптимизация использования памяти для Apache Spark

В этой статье описано, как оптимизировать управление памятью для кластера Apache Spark, чтобы обеспечить наилучшую производительность в Azure HDInsight.

## <a name="overview"></a>Обзор

Spark работает путем размещения данных в памяти. Поэтому управление ресурсами памяти является ключевым аспектом оптимизации выполнения заданий Spark.  Есть несколько методов, которые можно применить для эффективного использования памяти кластера.

* В рамках стратегии секционирования рекомендуется выбирать небольшие секции данных и учитывать размер данных, типы и распределение.
* Лучше ознакомиться с более новой и эффективной [`Kryo data serialization`](https://github.com/EsotericSoftware/kryo), а не использовать стандартную сериализацию Java.
* Рекомендуется использовать YARN, так как можно разделить `spark-submit` по пакету.
* Отслеживайте и настраивайте параметры конфигурации Spark.

Для справки структура памяти Spark и некоторые основные параметры памяти исполнителя показаны на рисунке ниже.

## <a name="spark-memory-considerations"></a>Рекомендации по использованию памяти Spark

Если вы используете Apache Hadoop YARN, эта платформа управляет объемом памяти, используемой всеми контейнерами на каждом узле Spark.  На схеме ниже показаны ключевые объекты и их связи.

![Управление памятью Spark в YARN](./media/apache-spark-perf/apache-yarn-spark-memory.png)

При получении сообщений о нехватке памяти сделайте следующее:

* Просмотрите операции перемешивания при управлении группами обеспечения доступности баз данных. Ограничьте их путем снижения на стороне сопоставления, выполните предварительное секционирование (или разбиение на группы) исходных данных, увеличьте объем операций перемешивания для отдельных процессов и сократите объем отправляемых данных.
* Выберите `ReduceByKey` с фиксированным объемом памяти, а не `GroupByKey`, который обеспечивает статистические функции, управление окнами и другие возможности, но включает неограниченный объем памяти.
* Выберите `TreeReduce`, который в основном обрабатывает исполнителей или секции, а не `Reduce`, который в основном обрабатывает драйвер.
* Используйте кадры данных, а не объекты устойчивого распределенного набора данных более низкого уровня.
* Создайте типы ComplexTypes, инкапсулирующие действия, такие как "Первые N", различные статистические функции или операции управления окнами.

Дополнительные инструкции по устранению неполадок см. в статье [Исключений OutOfMemoryError для Apache Spark в Azure HDInsight](apache-spark-troubleshoot-outofmemory.md).

## <a name="next-steps"></a>Дальнейшие действия

* [Оптимизация обработки данных для Apache Spark](optimize-cluster-configuration.md)
* [Оптимизация хранения данных для Apache Spark](optimize-data-storage.md)
* [Оптимизация конфигурации кластера для Apache Spark](optimize-cluster-configuration.md)
