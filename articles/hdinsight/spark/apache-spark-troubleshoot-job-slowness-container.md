---
title: Apache Spark замедляться, когда хранилище Azure HDInsight содержит много файлов
description: Apache Spark задание выполняется медленно, когда контейнер хранилища Azure содержит много файлов в Azure HDInsight.
ms.service: hdinsight
ms.topic: troubleshooting
ms.date: 08/21/2019
ms.openlocfilehash: c26baec66248ca00ef212acf3d773c2566b3aea9
ms.sourcegitcommit: 2f9f306fa5224595fa5f8ec6af498a0df4de08a8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2021
ms.locfileid: "98946367"
---
# <a name="apache-spark-job-run-slowly-when-the-azure-storage-container-contains-many-files-in-azure-hdinsight"></a>Задание Apache Spark выполняется медленно, если контейнер службы хранилища Azure содержит много файлов в Azure HDInsight

В этой статье описываются действия по устранению неполадок и возможные способы исправления проблем, возникающих при использовании компонентов Apache Spark в кластерах Azure HDInsight.

## <a name="issue"></a>Проблема

При запуске кластера HDInsight задание Apache Spark, которое выполняет запись в контейнер службы хранилища Azure, замедлит работу при наличии большого количества файлов и вложенных папок. Например, при записи в новый контейнер может потребоваться 20 секунд, а при записи в контейнер с 200 000 деятелей-файлами — 2 минуты.

## <a name="cause"></a>Причина

Это известная проблема Spark. Медленная работа поступает из `ListBlob` операций и `GetBlobProperties` во время выполнения задания Spark.

Для отслеживания секций Spark должен поддерживать, `FileStatusCache` который содержит сведения о структуре каталогов. С помощью этого кэша Spark может анализировать пути и получать информацию о доступных секциях. Преимущество отслеживания секций заключается в том, что Spark касается только необходимых файлов при чтении данных. Чтобы сохранить эти сведения в актуальном состоянии, при записи новых данных Spark должен вывести список всех файлов в каталоге и обновить этот кэш.

В Spark 2,1 не требуется обновлять кэш после каждой операции записи, Spark проверяет, совпадает ли существующий столбец секционирования с предложенным в текущем запросе записи, поэтому он также приводит к переписи операций в начале каждой операции записи.

В Spark 2,2 при записи данных в режиме добавления эта проблема производительности должна быть исправлена.

## <a name="resolution"></a>Решение

При создании секционированного набора данных важно использовать схему секционирования, которая будет ограничивать количество файлов, которые будут перечислены в Spark для обновления `FileStatusCache` .

Для каждого n-го микропакета, где N %100 = = 0 100 (всего лишь пример), переместите существующие данные в другой каталог, который может быть загружен Spark.

## <a name="next-steps"></a>Дальнейшие действия

[!INCLUDE [troubleshooting next steps](../../../includes/hdinsight-troubleshooting-next-steps.md)]